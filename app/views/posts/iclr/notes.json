{"notes": [{"id": "H1xSNiRcF7", "original": "HkltNFR5Ym", "number": 1, "cdate": 1538087725357, "ddate": null, "tcdate": 1538087725357, "tmdate": 1538156263189, "tddate": null, "forum": "H1xSNiRcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Smoothing the Geometry of Probabilistic Box Embeddings", "abstract": "There is growing interest in geometrically-inspired embeddings for learning\nhierarchies, partial orders, and lattice structures, with natural applications to\ntransitive relational data such as entailment graphs. Recent work has extended these ideas beyond deterministic hierarchies to probabilistically calibrated models, which enable learning from uncertain supervision and inferring soft-inclusions among concepts, while maintaining the geometric inductive bias of hierarchical embedding models. We build on the Box Lattice model of Vilnis et al. (2018), which showed promising results in modeling soft-inclusions through an overlapping hierarchy of sets, parameterized as high-dimensional hyperrectangles (boxes). However, the hard edges of the boxes present difficulties for standard gradient based optimization; that work employed a special surrogate function for the disjoint case, but we find this method to be fragile.  In this work, we present a novel hierarchical embedding model, inspired by a relaxation of box embeddings into parameterized density functions using Gaussian convolutions over the boxes. Our approach provides an alternative surrogate to the original lattice measure that improves the robustness of optimization in the disjoint case, while also preserving the desirable properties with respect to the original lattice. We demonstrate increased or matching performance on WordNet hypernymy prediction, Flickr caption entailment, and a MovieLens-based market basket dataset. We show especially marked improvements in the case of sparse data, where many conditional probabilities should be low, and thus boxes should be nearly disjoint.", "keywords": ["embeddings", "order embeddings", "knowledge graph embedding", "relational learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1/Authors"], "authors": ["Anonymous"], "TL;DR": "Improve hierarchical embedding models using kernel smoothing", "pdf": "/pdf/611e90d4097cd1d4f64925915d3fb0c61b1b8b36.pdf", "paperhash": "anonymous|smoothing_the_geometry_of_probabilistic_box_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019smoothing,    \ntitle={Smoothing the Geometry of Probabilistic Box Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xSNiRcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gUVjCqKm", "original": "HyenhvCqKX", "number": 2, "cdate": 1538087725593, "ddate": null, "tcdate": 1538087725593, "tmdate": 1538156262792, "tddate": null, "forum": "S1gUVjCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised classification into unknown k classes", "abstract": "We propose a novel spectral decomposition framework for the unsupervised classification\ntask. Unlike the widely used classification method, this architecture\ndoes not require the labels of data and the number of classes. Our key idea is\nto introduce a piecewise linear map and a spectral decomposition method on the\ndimension reduced space into generative adversarial networks. Inspired by the\nhuman visual recognition system, the proposed framework can classify and also\ngenerate images as the human brains do. We build a piecewise linear connection\nanalogous to the cerebral cortex, between the discriminator D and the generator\nG. This connection allows us to estimate the number of classes k and extract the\nvectors that represent each class. We show that our framework has the reasonable\nperformance in the experiment.\n", "keywords": ["unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper2/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9268ad9895978e2074d03df7ca086da91ff5a9ce.pdf", "paperhash": "anonymous|unsupervised_classification_into_unknown_k_classes", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised classification into unknown k classes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gUVjCqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkl84iCcFm", "original": "HygqaYAcFm", "number": 3, "cdate": 1538087725796, "ddate": null, "tcdate": 1538087725796, "tmdate": 1538156262590, "tddate": null, "forum": "Hkl84iCcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "R ESIDUAL NETWORKS CLASSIFY INPUTS BASED ON THEIR NEURAL TRANSIENT DYNAMICS", "abstract": "In this study, we analyze the input-output behavior of residual networks from a\ndynamical system point of view by disentangling the residual dynamics from the\noutput activities before the classification stage. For a network with simple skip\nconnections between every successive layer, and for logistic activation function, and\nshared weights between layers, we show analytically that there is a cooperation and\ncompetition dynamics between residuals corresponding to each input dimension.\nInterpreting these kind of networks as nonlinear filters, the steady state value of the\nresiduals in the case of attractor networks are indicative of the common features\nbetween different input dimensions that the network has observed during training,\nand has encoded in those components. In cases where residuals do not converge to\nan attractor state, their internal dynamics are separable for each input class, and the\nnetwork can reliably approximate the output. We bring analytical and empirical\nevidence that residual networks classify inputs based on the integration of the\ntransient dynamics of the residuals. Different inputs are considered as different\ninitial conditions that undergo different transitions through the network, and finally\nend up in different representations in the output layer. These transitions are critical\nin assigning the right class to the data. Based on these findings, we also develop a\nnew method to adjust the depth for residual networks during training. As it turns\nout, after pruning the depth of a Resnet using this algorithm,the network is still\ncapable of classifying inputs with a high accuracy.", "keywords": ["Residual Networks", "Dynamical Systems", "Classification"], "authorids": ["ICLR.cc/2019/Conference/Paper3/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9e90c382494c012bd6a85f8d45925c22946d6ed7.pdf", "paperhash": "anonymous|r_esidual_networks_classify_inputs_based_on_their_neural_transient_dynamics", "_bibtex": "@inproceedings{    \nanonymous2019r,    \ntitle={R ESIDUAL NETWORKS CLASSIFY INPUTS BASED ON THEIR NEURAL TRANSIENT DYNAMICS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkl84iCcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJfIVjAcKm", "original": "SJl8QZNFKm", "number": 4, "cdate": 1538087725988, "ddate": null, "tcdate": 1538087725988, "tmdate": 1538156262375, "tddate": null, "forum": "BJfIVjAcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability", "abstract": "We explore the concept of co-design in the context of neural network verification. Specifically, we aim to train deep neural networks that not only are robust to adversarial perturbations but also whose robustness can be verified more easily. To this end, we identify two properties of network models - weight sparsity and so-called ReLU stability - that turn out to significantly impact the complexity of the corresponding verification task. We demonstrate that improving weight sparsity alone already enables us to turn computationally intractable verification problems into tractable ones. Then, improving ReLU stability leads to an additional 4-13x speedup in verification times. An important feature of our methodology is its \"universality,\" in the sense that it can be used with a broad range of training procedures and verification approaches.\n", "paperhash": "anonymous|training_for_faster_adversarial_robustness_verification_via_inducing_relu_stability", "keywords": ["verification", "adversarial robustness", "adversarial examples", "stability", "deep learning", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper4/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop methods to train deep neural models that are both robust to adversarial perturbations and whose robustness is significantly easier to verify.", "pdf": "/pdf/f97205dffbb0eeef5da14ab30aee4c965355d388.pdf", "_bibtex": "@inproceedings{    \nanonymous2019training,    \ntitle={Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfIVjAcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMINj05tQ", "original": "Syl_KXmKt7", "number": 5, "cdate": 1538087726187, "ddate": null, "tcdate": 1538087726187, "tmdate": 1538156262171, "tddate": null, "forum": "HJMINj05tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Nesterov's method is the discretization of a differential equation with Hessian damping", "abstract": "Su-Boyd-Candes (2014) made a connection between Nesterov's method and an ordinary differential equation (ODE).  We show if a Hessian damping term is added to the ODE from Su-Boyd-Candes (2014), then Nesterov's method arises as a straightforward discretization of the modified ODE. Analogously,  in the strongly convex case, a Hessian damping term is added to Polyak's ODE, which is then discretized to yield Nesterov's method for strongly convex functions.   Despite the Hessian term, both second order ODEs can be represented as first order systems.\n\nEstablished Liapunov analysis is used to recover the accelerated rates of convergence in both continuous and discrete time.  Moreover, the Liapunov analysis can be extended to the case of stochastic gradients which allows the full gradient case to be considered as a special case of the stochastic case.  The result is a unified approach to convex acceleration in both continuous and discrete time and in  both the stochastic and full gradient cases. \n", "paperhash": "anonymous|nesterovs_method_is_the_discretization_of_a_differential_equation_with_hessian_damping", "keywords": ["Nesterov's method", "convex optimization", "first-order methods", "stochastic gradient descent", "differential equations", "Liapunov's method"], "authorids": ["ICLR.cc/2019/Conference/Paper5/Authors"], "authors": ["Anonymous"], "TL;DR": "We derive Nesterov's method arises as a straightforward discretization of an ODE different from the one in Su-Boyd-Candes and prove acceleration the stochastic case", "pdf": "/pdf/84926e0df0bffb14be9ee086418341d7705d45e7.pdf", "_bibtex": "@inproceedings{    \nanonymous2019nesterov's,    \ntitle={Nesterov's method is the discretization of a differential equation with Hessian damping},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMINj05tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkE8NjCqYm", "original": "Hyxdt-7YYm", "number": 6, "cdate": 1538087726374, "ddate": null, "tcdate": 1538087726374, "tmdate": 1538156261963, "tddate": null, "forum": "BkE8NjCqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "(Unconstrained) Beam Search is Sensitive to Large Search Discrepancies", "abstract": "Beam search is the most popular inference algorithm for decoding neural sequence models. Unlike greedy search, beam search allows for a non-greedy local decisions that can potentially lead to a sequence with a higher overall probability. However, previous work found that the performance of beam search tends to degrade with large beam widths. In this work, we perform an empirical study of the behavior of the beam search algorithm across three sequence synthesis tasks. We find that increasing the beam width leads to sequences that are disproportionately based on early and highly non-greedy decisions. These sequences typically include a very low probability token that is followed by a sequence of tokens with higher (conditional) probability leading to an overall higher probability sequence. However, as beam width increases, such sequences are more likely to have a lower evaluation score. Based on our empirical analysis we propose to constrain the beam search from taking highly non-greedy decisions early in the search. We evaluate two methods to constrain the search and show that constrained beam search effectively eliminates the problem of beam search degradation and in some cases even leads to higher evaluation scores. Our results generalize and improve upon previous observations on copies and training set predictions.", "paperhash": "anonymous|unconstrained_beam_search_is_sensitive_to_large_search_discrepancies", "keywords": ["beam search", "sequence models", "search", "sequence to sequence"], "authorids": ["ICLR.cc/2019/Conference/Paper6/Authors"], "authors": ["Anonymous"], "TL;DR": "Analysis of the performance degradation in beam search and how constraining the the search can help avoiding it", "pdf": "/pdf/6459eea181e08bb8b5936ada5c0ac4156c2e4ff0.pdf", "_bibtex": "@inproceedings{    \nanonymous2019(unconstrained),    \ntitle={(Unconstrained) Beam Search is Sensitive to Large Search Discrepancies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkE8NjCqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgD4jAcYX", "original": "HJgQhhI_t7", "number": 7, "cdate": 1538087726570, "ddate": null, "tcdate": 1538087726570, "tmdate": 1538156261758, "tddate": null, "forum": "SkgD4jAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Convolutional ReLUs", "abstract": "Rectified linear units (ReLUs) are currently the most popular activation function used in neural networks. Although ReLUs can solve the gradient vanishing problem and accelerate training convergence, it suffers from the dying ReLU problem in which some neurons are never activated if the weights are not updated properly. In this work, we propose a novel activation function, known as the adaptive convolutional ReLU (ConvReLU), that can better mimic brain neuron activation behaviors and overcome the dying ReLU problem. With our novel parameter sharing scheme, ConvReLUs can be applied to convolution layers that allow each input neuron to be activated by different trainable thresholds without involving a large number of extra parameters. We employ the zero initialization scheme in ConvReLU to encourage trainable thresholds to be close to zero. Finally, we develop a partial replacement strategy that only replaces the ReLUs in the early layers of the network. This resolves the dying ReLU problem and retains sparse representations for linear classifiers. Experimental results demonstrate that our proposed ConvReLU has consistently better performance compared to ReLU, LeakyReLU, and PReLU. In addition, the partial replacement strategy is shown to be effective not only for our ConvReLU but also for LeakyReLU and PReLU.", "paperhash": "anonymous|adaptive_convolutional_relus", "keywords": ["adaptive", "convolutional", "ReLUs"], "authorids": ["ICLR.cc/2019/Conference/Paper7/Authors"], "authors": ["Anonymous"], "TL;DR": "we propose a novel activation function, ConvReLU, that can better mimic brain neuron activation behaviors and overcome the dying ReLU problem.", "pdf": "/pdf/408430101df54204ceb47494e987a3424e7fe4fd.pdf", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Convolutional ReLUs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgD4jAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkeDEoCctQ", "original": "SJgJ4blOFX", "number": 8, "cdate": 1538087726767, "ddate": null, "tcdate": 1538087726767, "tmdate": 1538156261539, "tddate": null, "forum": "BkeDEoCctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Curiosity Search: Intra-Life Exploration Can Improve Performance on Challenging Deep Reinforcement Learning Problems", "abstract": "Traditional exploration methods in reinforcement learning (RL) require agents to perform random actions to find rewards. But these approaches struggle on sparse-reward domains like Montezuma\u2019s Revenge where the probability that any random action sequence leads to reward is extremely low. Recent algorithms have performed well on such tasks by encouraging agents to visit new states or perform new actions in relation to all prior training episodes (which we call across-training novelty). But such algorithms do not consider whether an agent exhibits intra-life novelty: doing something new within the current episode, regardless of whether those behaviors have been performed in previous episodes. We hypothesize that across-training novelty might discourage agents from revisiting initially non-rewarding states that could become important stepping stones later in training\u2014a problem remedied by encouraging intra-life novelty. We introduce Curiosity Search for deep reinforcement learning, or Deep Curiosity Search (DeepCS), which encourages intra-life exploration by rewarding agents for visiting as many different states as possible within each episode, and show that DeepCS matches the performance of current state-of-the-art methods on Montezuma\u2019s Revenge. We further show that DeepCS improves exploration on Amidar, Freeway, Gravitar, and Tutankham (many of which are hard exploration games). Surprisingly, DeepCS also doubles A2C performance on Seaquest, a game we would not have expected to benefit from intra-life exploration because the arena is small and already easily navigated by naive exploration techniques. In one run, DeepCS achieves a maximum training score of 80,000 points on Seaquest\u2014higher than any methods other than Ape-X. The strong performance of DeepCS on these sparse- and dense-reward tasks suggests that encouraging intra-life novelty is an interesting, new approach for improving performance in Deep RL and motivates further research into hybridizing across-training and intra-life exploration methods.", "paperhash": "anonymous|deep_curiosity_search_intralife_exploration_can_improve_performance_on_challenging_deep_reinforcement_learning_problems", "authorids": ["ICLR.cc/2019/Conference/Paper8/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/ea7ffa446d2756ab38c592d7481e25cd97ba1f9d.pdf", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Curiosity Search: Intra-Life Exploration Can Improve Performance on Challenging Deep Reinforcement Learning Problems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeDEoCctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGDEjCcK7", "original": "r1g55QzFYQ", "number": 9, "cdate": 1538087726963, "ddate": null, "tcdate": 1538087726963, "tmdate": 1538156261326, "tddate": null, "forum": "ryGDEjCcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CONTROLLING COVARIATE SHIFT USING EQUILIBRIUM NORMALIZATION OF WEIGHTS", "abstract": "We introduce a new normalization technique that exhibits the fast convergence properties of batch normalization using a transformation of layer weights instead of layer outputs. The proposed technique keeps the contribution of positive and negative weights to the layer output in equilibrium. We validate our method on a set of standard benchmarks including CIFAR-10/100, SVHN and ILSVRC 2012 ImageNet.", "paperhash": "anonymous|controlling_covariate_shift_using_equilibrium_normalization_of_weights", "keywords": ["normalization", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper9/Authors"], "authors": ["Anonymous"], "TL;DR": "An alternative normalization technique to batch normalization", "pdf": "/pdf/1965ccb8901bc3e36e5865246d3f6a1cc8b85fe5.pdf", "_bibtex": "@inproceedings{    \nanonymous2019controlling,    \ntitle={CONTROLLING COVARIATE SHIFT USING EQUILIBRIUM NORMALIZATION OF WEIGHTS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGDEjCcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkMPNoCcKQ", "original": "rke797MtFX", "number": 10, "cdate": 1538087727162, "ddate": null, "tcdate": 1538087727162, "tmdate": 1538156261118, "tddate": null, "forum": "SkMPNoCcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Linearizing Visual Processes with Deep Generative Models", "abstract": "This work studies the problem of modeling non-linear visual processes by leveraging deep generative architectures for learning linear, Gaussian models of observed sequences. We propose a joint learning framework, combining a multivariate autoregressive model and deep convolutional generative networks. After justification of theoretical assumptions of inearization, we propose an architecture that allows Variational Autoencoders and Generative Adversarial Networks to simultaneously learn the non-linear observation as well as the linear state-transition model from a sequence of observed frames. Finally, we demonstrate our approach on conceptual toy examples and dynamic textures.", "paperhash": "anonymous|linearizing_visual_processes_with_deep_generative_models", "keywords": ["Genearative Adversarial Network", "Variational Autoencoder", "Wasserstein GAN", "Autoregressive Model", "Dynamic Texture", "Video"], "authorids": ["ICLR.cc/2019/Conference/Paper10/Authors"], "authors": ["Anonymous"], "TL;DR": "We model non-linear visual processes as autoregressive noise via generative deep learning.", "pdf": "/pdf/fc23fe20cdc02ca00a4bcbf5782fc1ccba1c9e73.pdf", "_bibtex": "@inproceedings{    \nanonymous2019linearizing,    \ntitle={Linearizing Visual Processes with Deep Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkMPNoCcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1VPNiA5Fm", "original": "SylXyMGttm", "number": 11, "cdate": 1538087727353, "ddate": null, "tcdate": 1538087727353, "tmdate": 1538156260915, "tddate": null, "forum": "r1VPNiA5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Universal Approximation Power of Finite-Width Deep ReLU Networks", "abstract": "We show that finite-width deep ReLU neural networks yield rate-distortion optimal approximation (B\u00f6lcskei et al., 2018) of a wide class of functions, including polynomials, windowed sinusoidal functions, one-dimensional oscillatory textures, and the Weierstrass function, a fractal function which is continuous but nowhere differentiable. Together with the recently established universal approximation result for affine function systems (B\u00f6lcskei et al., 2018), this demonstrates that deep neural networks approximate vastly different signal structures generated by the affine group, the Weyl-Heisenberg group, or through warping, and even certain fractals, all with approximation error decaying exponentially in the number of neurons. We also prove that in the approximation of sufficiently smooth functions finite-width deep networks require strictly fewer neurons than finite-depth wide networks.", "paperhash": "anonymous|the_universal_approximation_power_of_finitewidth_deep_relu_networks", "authorids": ["ICLR.cc/2019/Conference/Paper11/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/f2e8797884f6a488a16fbd5382ce894d3b736bd8.pdf", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Universal Approximation Power of Finite-Width Deep ReLU Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1VPNiA5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1g_EsActm", "original": "SkgvAc6OKX", "number": 12, "cdate": 1538087727546, "ddate": null, "tcdate": 1538087727546, "tmdate": 1538156260715, "tddate": null, "forum": "S1g_EsActm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE", "abstract": "In traditional neural networks for image processing, the inputs of the neural networks should be the same size such as 224\u00d7224\u00d73. But how can we train the neural net model with different input size? A common way to do is image deformation which accompany a problem of information loss (e.g. image crop or wrap). In this paper we propose a new network structure called Attention Incorporate Network(AIN). It solve the problem of different size of input images and extract the key features of the inputs by attention mechanism, pay different attention depends on the importance of the features not rely on the data size. Experimentally, AIN achieve a higher accuracy, better convergence comparing to the same size of other network structure.", "paperhash": "anonymous|attention_incorporate_network_a_network_can_adapt_various_data_size", "authorids": ["ICLR.cc/2019/Conference/Paper12/Authors"], "authors": ["Anonymous"], "keywords": ["attention mechanism", "various image size"], "pdf": "/pdf/3760fb7e13f529371f30a46e9c3fa552297df62b.pdf", "_bibtex": "@inproceedings{    \nanonymous2019attention,    \ntitle={ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1g_EsActm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyed4i05KX", "original": "HyxHHinuFQ", "number": 13, "cdate": 1538087727751, "ddate": null, "tcdate": 1538087727751, "tmdate": 1538156260511, "tddate": null, "forum": "Hyed4i05KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Interpreting Layered Neural Networks via Hierarchical Modular Representation", "abstract": "Interpreting the prediction mechanism of complex models is currently one of the most important tasks in the machine learning field, especially with layered neural networks, which have achieved high predictive performance with various practical data sets. To reveal the global structure of a trained neural network in an interpretable way, a series of clustering methods have been proposed, which decompose the units into clusters according to the similarity of their inference roles. The main problems in these studies were that (1) we have no prior knowledge about the optimal resolution for the decomposition, or the appropriate number of clusters, and (2) there was no method with which to acquire knowledge about whether the outputs of each cluster have a positive or negative correlation with the input and output dimension values. \nIn this paper, to solve these problems, we propose a method for obtaining a hierarchical modular representation of a layered neural network. The application of a hierarchical clustering method to a trained network reveals a tree-structured relationship among hidden layer units, based on their feature vectors defined by their correlation with the input and output dimension values. ", "paperhash": "anonymous|interpreting_layered_neural_networks_via_hierarchical_modular_representation", "keywords": ["interpretabile machine learning", "neural network", "hierarchical clustering"], "authorids": ["ICLR.cc/2019/Conference/Paper13/Authors"], "authors": ["Anonymous"], "TL;DR": "A method for obtaining a hierarchical cluster structure of a trained layered neural network", "pdf": "/pdf/482b96f95283bdda7d6ec0427b77369b0ba558a0.pdf", "_bibtex": "@inproceedings{    \nanonymous2019interpreting,    \ntitle={Interpreting Layered Neural Networks via Hierarchical Modular Representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyed4i05KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ldNoC9tX", "original": "SkljryRvKX", "number": 14, "cdate": 1538087727942, "ddate": null, "tcdate": 1538087727942, "tmdate": 1538156260306, "tddate": null, "forum": "H1ldNoC9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Classification from Positive, Unlabeled and Biased Negative Data", "abstract": "Positive-unlabeled (PU) learning addresses the problem of learning a binary classifier from positive (P) and unlabeled (U) data. It is often applied to situations where negative (N) data are difficult to be fully labeled. However, collecting a non-representative N set that contains only a small portion of all possible N data can be much easier in many practical situations. This paper studies a novel classification framework which incorporates such biased N (bN) data in PU learning. The fact that the training N data are biased also makes our work very different from those of standard semi-supervised learning. We provide an empirical risk minimization-based method to address this PUbN classification problem. Our approach can be regarded as a variant of traditional example-reweighting algorithms, with the weight of each example computed through a preliminary step that draws inspiration from PU learning. We also derive an estimation error bound for the proposed method. Experimental results demonstrate the effectiveness of our algorithm in not only PUbN learning scenarios but also ordinary PU leaning scenarios on several benchmark datasets.", "paperhash": "anonymous|classification_from_positive_unlabeled_and_biased_negative_data", "keywords": ["positive-unlabeled learning", "dataset shift", "empirical risk minimization"], "authorids": ["ICLR.cc/2019/Conference/Paper14/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper studied the PUbN classification problem, where we incorporate biased negative (bN) data, i.e., negative data that is not fully representative of the true underlying negative distribution, into positive-unlabeled (PU) learning.", "pdf": "/pdf/4b711e6591b58b7eee43c1b56dd7f3ab0d5888fd.pdf", "_bibtex": "@inproceedings{    \nanonymous2019classification,    \ntitle={Classification from Positive, Unlabeled and Biased Negative Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ldNoC9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJg_NjCqtX", "original": "BJxfKXkKtX", "number": 15, "cdate": 1538087728141, "ddate": null, "tcdate": 1538087728141, "tmdate": 1538156260093, "tddate": null, "forum": "rJg_NjCqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CHEMICAL NAMES STANDARDIZATION USING NEURAL SEQUENCE TO SEQUENCE MODEL", "abstract": "Chemical information extraction is to convert chemical knowledge in text into true chemical database, which is a text processing task heavily relying on chemical compound name identification and standardization. Once a systematic name for a chemical compound is given, it will naturally and much simply convert the name into the eventually required molecular formula. However, for many chemical substances, they have been shown in many other names besides their systematic names which poses a great challenge for this task. In this paper, we propose a framework to do the auto standardization from the non-systematic names to the corresponding systematic names by using the spelling error correction, byte pair encoding tokenization and neural sequence to sequence model. Our framework is trained end to end and is fully data-driven. Our standardization accuracy on the test dataset achieves 54.04% which has a great improvement compared to previous state-of-the-art result.", "paperhash": "anonymous|chemical_names_standardization_using_neural_sequence_to_sequence_model", "keywords": ["Chemical Names Standardization", "Byte Pair Encoding", "Sequence to Sequence Model"], "authorids": ["ICLR.cc/2019/Conference/Paper15/Authors"], "authors": ["Anonymous"], "TL;DR": "We designed an end-to-end framework using sequence to sequence model to do the  chemical names standardization.", "pdf": "/pdf/d65fa15c186f149785944d1b4a00aca3145f500c.pdf", "_bibtex": "@inproceedings{    \nanonymous2019chemical,    \ntitle={CHEMICAL NAMES STANDARDIZATION USING NEURAL SEQUENCE TO SEQUENCE MODEL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJg_NjCqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygONjRqKm", "original": "HygAwRc7FX", "number": 16, "cdate": 1538087728331, "ddate": null, "tcdate": 1538087728331, "tmdate": 1538156259882, "tddate": null, "forum": "SygONjRqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Amortized Context Vector Inference for Sequence-to-Sequence Networks", "abstract": "Neural attention (NA) is an effective mechanism for inferring complex structural data dependencies that span long temporal horizons. As a consequence, it has become a key component of sequence-to-sequence models that yield state-of-the-art performance in as hard tasks as abstractive document summarization (ADS), machine translation (MT), and video captioning (VC). NA mechanisms perform inference of context vectors; these constitute weighted sums of deterministic input sequence encodings, adaptively sourced over long temporal horizons. However, recent work in the field of amortized variational inference (AVI) has shown that it is often useful to treat the representations generated by deep networks as latent random variables. This allows for the models to learn to infer representations that offer much stronger generalization capacity.  Based on this motivation, in this work we introduce a novel regard towards a popular NA mechanism, namely soft-attention (SA). Our approach treats the context vectors generated by SA models as latent variables, the finite mixture model posteriors of which are inferred by employing AVI. Both the component means and the covariance matrices of the inferred posteriors are parameterized via deep network mechanisms similar to those employed in the context of standard SA. To illustrate our method, we implement it in the context of popular sequence-to-sequence model variants with SA. We conduct an extensive experimental evaluation using challenging ADS, VC, and MT benchmarks, and show how our approach compares to the baselines. \n", "paperhash": "anonymous|amortized_context_vector_inference_for_sequencetosequence_networks", "keywords": ["neural attention", "sequence-to-sequence", "variational inference"], "authorids": ["ICLR.cc/2019/Conference/Paper16/Authors"], "authors": ["Anonymous"], "TL;DR": "A generalisation of context representation in neural attention under the variational inference rationale.", "pdf": "/pdf/3150fa253394221ab9cc144bb5fab19f8277d893.pdf", "_bibtex": "@inproceedings{    \nanonymous2019amortized,    \ntitle={Amortized Context Vector Inference for Sequence-to-Sequence Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygONjRqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxYEoA5FX", "original": "Hklyjj-K_7", "number": 17, "cdate": 1538087728518, "ddate": null, "tcdate": 1538087728518, "tmdate": 1538156259677, "tddate": null, "forum": "SyxYEoA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Invariance and Inverse Stability under ReLU", "abstract": "We flip the usual approach to study invariance and robustness of neural networks by considering the non-uniqueness and instability of the inverse mapping. We provide theoretical and numerical results on the inverse of ReLU-layers. First, we derive a necessary and sufficient condition on the existence of invariance that provides a geometric interpretation. Next, we move to robustness via analyzing local effects on the inverse. To conclude, we show how this reverse point of view not only provides insights into key effects, but also enables to view adversarial examples from different perspectives.", "paperhash": "anonymous|invariance_and_inverse_stability_under_relu", "keywords": ["deep neural networks", "invertibility", "invariance", "robustness", "ReLU networks"], "authorids": ["ICLR.cc/2019/Conference/Paper17/Authors"], "authors": ["Anonymous"], "TL;DR": "We analyze the invertibility of deep neural networks by studying preimages of ReLU-layers and the stability of the inverse.", "pdf": "/pdf/02e99b90b51c379942569aa61e8b3fc86bdb71a5.pdf", "_bibtex": "@inproceedings{    \nanonymous2019invariance,    \ntitle={Invariance and Inverse Stability under ReLU},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxYEoA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxYEsAqY7", "original": "SkgN6zT_Y7", "number": 18, "cdate": 1538087728708, "ddate": null, "tcdate": 1538087728708, "tmdate": 1538156259470, "tddate": null, "forum": "BJxYEsAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "FEED: Feature-level Ensemble Effect for knowledge Distillation", "abstract": "This paper proposes a versatile and powerful training algorithm named Feature-level Ensemble Effect for knowledge Distillation(FEED), which is inspired by the work of factor transfer. The factor transfer is one of the knowledge transfer methods that improves the performance of a student network with a strong teacher network. It transfers the knowledge of a teacher in the feature map level using high-capacity teacher network, and our training algorithm FEED is an extension of it. FEED aims to transfer ensemble knowledge, using either multiple teachers in parallel or multiple training sequences. Adapting the peer-teaching framework, we introduce a couple of training algorithms that transfer ensemble knowledge to the student at the feature map level, both of which help the student network find more generalized solutions in the parameter space. Experimental results on CIFAR-100 and ImageNet show that our method, FEED, has clear performance enhancements,without introducing any additional parameters or computations at test time.", "paperhash": "anonymous|feed_featurelevel_ensemble_effect_for_knowledge_distillation", "authorids": ["ICLR.cc/2019/Conference/Paper18/Authors"], "authors": ["Anonymous"], "keywords": ["Knowledge Distillation", "Ensemble Effect", "Knowledge Transfer"], "pdf": "/pdf/06272e082c548589ac291f2da2be2d6d70186f53.pdf", "_bibtex": "@inproceedings{    \nanonymous2019feed:,    \ntitle={FEED: Feature-level Ensemble Effect for knowledge Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxYEsAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkzK4iC5Ym", "original": "rJerJMTdFm", "number": 19, "cdate": 1538087728892, "ddate": null, "tcdate": 1538087728892, "tmdate": 1538156259266, "tddate": null, "forum": "SkzK4iC5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diminishing Batch Normalization", "abstract": "In this paper, we propose a generalization of the BN algorithm, diminishing batch normalization (DBN), where we update the BN parameters in a diminishing moving average way. Batch normalization (BN) is very effective in accelerating the convergence of a neural network training phase that it has become a common practice. \nOur proposed DBN algorithm remains the overall structure of the original BN algorithm while introduces a weighted averaging update to some trainable parameters. \nWe provide an analysis of the convergence of the DBN algorithm that converges to a stationary point with respect to trainable parameters. Our analysis can be easily generalized for original BN algorithm by setting some parameters to constant. To the best knowledge of authors, this analysis is the first of its kind for convergence with Batch Normalization introduced. We analyze a two-layer model with arbitrary activation function. \nThe primary challenge of the analysis is the fact that some parameters are updated by gradient while others are not. \nThe convergence analysis applies to any activation function that satisfies our common assumptions.\nFor the analysis, we also show the sufficient and necessary conditions for the stepsizes and diminishing weights to ensure the convergence. \nIn the numerical experiments, we use more complex models with more layers and ReLU activation. We observe that DBN outperforms the original BN algorithm on Imagenet, MNIST, NI and CIFAR-10 datasets with reasonable complex FNN and CNN models.", "paperhash": "anonymous|diminishing_batch_normalization", "keywords": ["deep learning", "learning theory", "convergence analysis", "batch normalization"], "authorids": ["ICLR.cc/2019/Conference/Paper19/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a extension of the batch normalization, show a first-of-its-kind convergence analysis for this extension and show in numerical experiments that it has better performance than the original batch normalizatin.", "pdf": "/pdf/be274762f32c2d1260fcd5bc9cf93a52ed3dce74.pdf", "_bibtex": "@inproceedings{    \nanonymous2019diminishing,    \ntitle={Diminishing Batch Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkzK4iC5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rket4i0qtX", "original": "H1l7YpILKX", "number": 20, "cdate": 1538087729081, "ddate": null, "tcdate": 1538087729081, "tmdate": 1538156259060, "tddate": null, "forum": "rket4i0qtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The meaning of \"most\" for visual question answering models", "abstract": "The correct interpretation of quantifier statements in the context of a visual scene requires non-trivial inference mechanisms. For the example of \"most\", we discuss two strategies which rely on fundamentally different cognitive concepts. Our aim is to identify what strategy deep learning models for visual question answering learn when trained on such questions. To this end, we carefully design data to replicate experiments from psycholinguistics where the same question was investigated for humans. Our experiments indicate that a form of approximate number system emerges whose performance declines with more difficult scenes as predicted by Weber's law. Moreover, we identify confounding factors, like spatial arrangement of the scene, which impede the effectiveness of this system.", "paperhash": "anonymous|the_meaning_of_most_for_visual_question_answering_models", "keywords": ["quantifier", "evaluation methodology", "psycholinguistics", "visual question answering"], "authorids": ["ICLR.cc/2019/Conference/Paper20/Authors"], "authors": ["Anonymous"], "TL;DR": "Psychology-inspired evaluation of quantifier understanding for visual question answering models", "pdf": "/pdf/cba285da9672270198bcc24fb2a062fe8a1908db.pdf", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The meaning of \"most\" for visual question answering models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rket4i0qtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gKNs0qYX", "original": "SJlPe9o_F7", "number": 21, "cdate": 1538087729269, "ddate": null, "tcdate": 1538087729269, "tmdate": 1538156258856, "tddate": null, "forum": "r1gKNs0qYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Filter Training and Maximum Response: Classification via Discerning", "abstract": "This report introduces a training and recognition scheme, in which classification is realized via class-wise discerning. Trained with datasets whose labels are randomly shuffled except for one class of interest, a neural network learns class-wise parameter values, and remolds itself from a feature sorter into feature filters, each of which discerns objects belonging to one of the classes only. Classification of an input can be inferred from the maximum response of the filters. A multiple check with multiple versions of filters can diminish fluctuation and yields better performance. This scheme of discerning, maximum response and multiple check is a method of general viability to improve performance of feedforward networks, and the filter training itself is a promising feature abstraction procedure. In contrast to the direct sorting, the scheme mimics the classification process mediated by a series of one component picking.", "paperhash": "anonymous|filter_training_and_maximum_response_classification_via_discerning", "keywords": ["filter training", "maximum response", "multiple check", "ensemble learning"], "authorids": ["ICLR.cc/2019/Conference/Paper21/Authors"], "authors": ["Anonymous"], "TL;DR": "The proposed scheme mimics the classification process mediated by a series of one component picking.", "pdf": "/pdf/9a0066cc0eefc78484561fbc69c77a123fd49a18.pdf", "_bibtex": "@inproceedings{    \nanonymous2019filter,    \ntitle={Filter Training and Maximum Response: Classification via Discerning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gKNs0qYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJeFNoRcFQ", "original": "rkeksuoOKm", "number": 22, "cdate": 1538087729454, "ddate": null, "tcdate": 1538087729454, "tmdate": 1538156258648, "tddate": null, "forum": "SJeFNoRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Traditional and Heavy Tailed Self Regularization in Neural Network Models", "abstract": "Random Matrix Theory (RMT) is applied to analyze the weight matrices of Deep Neural Networks (DNNs), including both production quality, pre-trained models such as AlexNet and Inception, and smaller models trained from scratch, such as LeNet5 and a miniature-AlexNet.  Empirical and theoretical results clearly indicate that the empirical spectral density (ESD) of DNN layer matrices displays signatures of traditionally-regularized statistical models, even in the absence of exogenously specifying traditional forms of regularization, such as Dropout or Weight Norm constraints.  Building on recent results in RMT, most notably its extension to Universality classes of Heavy-Tailed matrices, we develop a theory to identify 5+1 Phases of Training, corresponding to increasing amounts of Implicit Self-Regularization.  For smaller and/or older DNNs, this Implicit Self-Regularization is like traditional Tikhonov regularization, in that there is a \"size scale\" separating signal from noise.  For state-of-the-art DNNs, however, we identify a novel form of Heavy-Tailed Self-Regularization, similar to the self-organization seen in the statistical physics of disordered systems.  This implicit Self-Regularization can depend strongly on the many knobs of the training process.  By exploiting the generalization gap phenomena, we demonstrate that we can cause a small model to exhibit all 5+1 phases of training simply by changing the batch size.", "paperhash": "anonymous|traditional_and_heavy_tailed_self_regularization_in_neural_network_models", "keywords": ["statistical mechanics", "self-regularization", "random matrix", "glassy behavior", "heavy-tailed"], "authorids": ["ICLR.cc/2019/Conference/Paper22/Authors"], "authors": ["Anonymous"], "TL;DR": "See the abstract.", "pdf": "/pdf/7d055f132d15c5770aceedacaee1a1500db46c19.pdf", "_bibtex": "@inproceedings{    \nanonymous2019traditional,    \ntitle={Traditional and Heavy Tailed Self Regularization in Neural Network Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJeFNoRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJx94o0qYX", "original": "Byl-ArsdF7", "number": 23, "cdate": 1538087729643, "ddate": null, "tcdate": 1538087729643, "tmdate": 1538156258450, "tddate": null, "forum": "SJx94o0qYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Precision Highway for Ultra Low-precision Quantization", "abstract": "Quantization of a neural network has an inherent problem called accumulated quantization error, which is the key obstacle towards ultra-low precision, e.g., 2- or 3-bit precision. To resolve this problem, we propose precision highway, which forms an end-to-end high-precision information flow while performing the ultra-low-precision computation. First, we describe how the precision highway reduce the accumulated quantization error in both convolutional and recurrent neural networks. We also provide the quantitative analysis of the benefit of precision highway and evaluate the overhead on the state-of-the-art hardware accelerator. In the experiments, our proposed method outperforms the best existing quantization methods while offering 3-bit weight/activation quantization with no accuracy loss and 2-bit quantization with a 2.45 % top-1 accuracy loss in ResNet-50. We also report that the proposed method significantly outperforms the existing method in the 2-bit quantization of an LSTM for language modeling.", "paperhash": "anonymous|precision_highway_for_ultra_lowprecision_quantization", "keywords": ["neural network", "quantization", "optimization", "low-precision", "convolutional network", "recurrent network"], "authorids": ["ICLR.cc/2019/Conference/Paper23/Authors"], "authors": ["Anonymous"], "TL;DR": "precision highway; a generalized concept of high-precision information flow for sub 4-bit quantization ", "pdf": "/pdf/10c916b6c8cf83082ad91510637f6fa27f1c0cd1.pdf", "_bibtex": "@inproceedings{    \nanonymous2019precision,    \ntitle={Precision Highway for Ultra Low-precision Quantization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJx94o0qYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1l9Nj09YQ", "original": "B1grA7jdKX", "number": 24, "cdate": 1538087729827, "ddate": null, "tcdate": 1538087729827, "tmdate": 1538156258246, "tddate": null, "forum": "r1l9Nj09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards Language Agnostic Universal Representations", "abstract": "When a bilingual student learns to solve word problems in math, we expect the student to be able to solve these problem in both languages the student is fluent in, even if the math lessons were only taught in one language. However, current representations in machine learning are language dependent. In this work, we present a method to decouple the language from the problem by learning language agnostic representations and therefore allowing training a model in one language and applying to a different one in a zero shot fashion. We learn these representations by taking inspiration from linguistics and formalizing Universal Grammar as an optimization process (Chomsky, 2014; Montague, 1970). We demonstrate the capabilities of these representations by showing that the models trained on a single language using language agnostic representations achieve very similar accuracies in other languages.", "paperhash": "anonymous|towards_language_agnostic_universal_representations", "keywords": ["universal representations", "language agnostic representations", "NLP", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper24/Authors"], "authors": ["Anonymous"], "TL;DR": "By formalizing universal grammar as an optimization problem we learn language agnostic universal representations which we can utilize to do zero-shot learning across languages.", "pdf": "/pdf/c56aa9baae313c2008bb0d559e737f494158902d.pdf", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Language Agnostic Universal Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1l9Nj09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byg54oC5tQ", "original": "rJluamsuFQ", "number": 25, "cdate": 1538087730012, "ddate": null, "tcdate": 1538087730012, "tmdate": 1538156258041, "tddate": null, "forum": "Byg54oC5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Model For Material Irradiation Experiments Based On Prior Knowledge And Attention Mechanism", "abstract": "Material irradiation experiment is dangerous and complex, which requires large number of high-level expertise in the manual processing of experimental images and data.  In this paper, we propose a generative adversarial model based on prior knowledge and attention mechanism to achieve the generation of irradiated material images (data-to-image model), and a prediction model for corresponding industrial performance (image-to-data model).  With the proposed models, researchers can skip the dangerous and complex irradiation experiments and obtain the irradiation images and industrial performance parameters directly by inputing some experimental parameters only.  We also introduce a new dataset ISMD which contains 22000 irradiated images with 22,143 sets of corresponding parameters.  Our model achieved high quality results by compared with several baseline models. The evaluation and detailed analysis are also performed.", "paperhash": "anonymous|generative_model_for_material_irradiation_experiments_based_on_prior_knowledge_and_attention_mechanism", "authorids": ["ICLR.cc/2019/Conference/Paper25/Authors"], "authors": ["Anonymous"], "keywords": ["Generative Model", "Images of Irradiation Experiments", "Prior Knowledge", "Attention Mechanism"], "pdf": "/pdf/3bf7b090abe2a748606fb70ec9e690c732f5148e.pdf", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Model For Material Irradiation Experiments Based On Prior Knowledge And Attention Mechanism},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byg54oC5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJx54i05tX", "original": "ryePGS4OY7", "number": 26, "cdate": 1538087730206, "ddate": null, "tcdate": 1538087730206, "tmdate": 1538156257830, "tddate": null, "forum": "HJx54i05tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING", "abstract": "We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena when the depth becomes large. This, in particular, provides quantitative answers and insights to three questions that were yet fully understood in the literature. Firstly, we provide a precise answer on how the random deep weight-tied autoencoder model performs \u201capproximate inference\u201d as posed by Scellier et al. (2018), and its connection to reversibility considered by several theoretical studies. Secondly, we show that deep autoencoders display a higher degree of sensitivity to perturbations in the parameters, distinct from the shallow counterparts. Thirdly, we obtain insights on pitfalls in training initialization practice, and demonstrate experimentally that it is possible to train a deep autoencoder, even with the tanh activation and a depth as large as 200 layers, without resorting to techniques such as layer-wise pre-training or batch normalization. Our analysis is not specific to\nany depths or any Lipschitz activations, and our analytical techniques may have broader applicability.", "paperhash": "anonymous|on_random_deep_autoencoders_exact_asymptotic_analysis_phase_transitions_and_implications_to_training", "keywords": ["Random Deep Autoencoders", "Exact Asymptotic Analysis", "Phase Transitions"], "authorids": ["ICLR.cc/2019/Conference/Paper26/Authors"], "authors": ["Anonymous"], "TL;DR": "We study the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, our analysis reveals interesting phase transition phenomena.", "pdf": "/pdf/084d1ec7b41acae7220605b1dbb7f5e480819e2b.pdf", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={ON RANDOM DEEP AUTOENCODERS: EXACT ASYMPTOTIC ANALYSIS, PHASE TRANSITIONS, AND IMPLICATIONS TO TRAINING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJx54i05tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1G5ViAqFm", "original": "S1eqoiK_tQ", "number": 27, "cdate": 1538087730393, "ddate": null, "tcdate": 1538087730393, "tmdate": 1538156257623, "tddate": null, "forum": "B1G5ViAqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Convolutional Neural Networks on Non-uniform Geometrical Signals Using Euclidean Spectral Transformation", "abstract": "Convolutional Neural Networks (CNN) have been successful in processing data signals that are uniformly sampled in the spatial domain (e.g., images). However, most data signals do not natively exist on a grid, and in the process of being sampled onto a uniform physical grid suffer significant aliasing error and information loss. Moreover, signals can exist in different topological structures as, for example, points, lines, surfaces and volumes. It has been challenging to analyze signals with mixed topologies (for example, point cloud with surface mesh). To this end, we develop mathematical formulations for Non-Uniform Fourier Transforms (NUFT) to directly, and optimally, sample nonuniform data signals of different topologies defined on a simplex mesh into the spectral domain with no spatial sampling error. The spectral transform is performed in the Euclidean space, which removes the translation ambiguity from works on the graph spectrum. Our representation has four distinct advantages: (1) the process causes no spatial sampling error during initial sampling, (2) the generality of this approach provides a unified framework for using CNNs to analyze signals of mixed topologies, (3) it allows us to leverage state-of-the-art backbone CNN architectures for effective learning without having to design a particular architecture for a particular data structure in an ad-hoc fashion, and (4) the representation allows weighted meshes where each element has a different weight (i.e., texture) indicating local properties. We achieve good results on-par with state-of-the-art for 3D shape retrieval task, and new state-of-the-art for point cloud to surface reconstruction task.", "paperhash": "anonymous|convolutional_neural_networks_on_nonuniform_geometrical_signals_using_euclidean_spectral_transformation", "keywords": ["Non-uniform Fourier Transform", "3D Learning", "CNN", "surface reconstruction"], "authorids": ["ICLR.cc/2019/Conference/Paper27/Authors"], "authors": ["Anonymous"], "TL;DR": "We use non-Euclidean Fourier Transformation of shapes defined by a simplicial complex for deep learning, achieving significantly better results than point-based sampling techiques used in current 3D learning literature.", "pdf": "/pdf/9e4659a9003721d3f0d4b668e7c998c6e6524aa5.pdf", "_bibtex": "@inproceedings{    \nanonymous2019convolutional,    \ntitle={Convolutional Neural Networks on Non-uniform Geometrical Signals Using Euclidean Spectral Transformation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1G5ViAqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgiNo0cKX", "original": "Syl78WduYQ", "number": 28, "cdate": 1538087730569, "ddate": null, "tcdate": 1538087730569, "tmdate": 1538156257419, "tddate": null, "forum": "SJgiNo0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multiple Encoder-Decoders Net for Lane Detection", "abstract": "For semantic image segmentation and lane detection, nets with a single spatial pyramid structure or encoder-decoder structure are usually exploited. Convolutional neural networks (CNNs) show great results on both high-level and low-level features representations, however, the capability has not been fully embodied for lane detection task. In especial, it's still a challenge for model-based lane detection to combine the multi-scale context with a pixel-level accuracy because of the weak visual appearance and strong prior information. In this paper, we we propose an novel network for lane detection, the three main contributions are as follows. First, we employ multiple encoder-decoders module in end-to-end ways and show the promising results for lane detection. Second, we analysis different configurations of multiple encoder-decoders nets. Third, we make our attempts to rethink the evaluation methods of lane detection for the limitation of the popular methods based on IoU.", "paperhash": "anonymous|multiple_encoderdecoders_net_for_lane_detection", "authorids": ["ICLR.cc/2019/Conference/Paper28/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/a4671e76e1ae467960cd8e7a6626d548510d0141.pdf", "_bibtex": "@inproceedings{    \nanonymous2019multiple,    \ntitle={Multiple Encoder-Decoders Net for Lane Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgiNo0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1giVsRcYm", "original": "r1xPmGw_Fm", "number": 29, "cdate": 1538087730765, "ddate": null, "tcdate": 1538087730765, "tmdate": 1538156257204, "tddate": null, "forum": "S1giVsRcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Count-Based Exploration with the Successor Representation", "abstract": "The problem of exploration in reinforcement learning is well-understood in the tabular case and many sample-efficient algorithms are known. Nevertheless, it is often unclear how the algorithms in the tabular setting can be extended to tasks with large state-spaces where generalization is required. Recent promising developments generally depend on problem-specific density models or handcrafted features. In this paper we introduce a simple approach for exploration that allows us to develop theoretically justified algorithms in the tabular case but that also give us intuitions for new algorithms applicable to settings where function approximation is required. Our approach and its underlying theory is based on the substochastic successor representation, a concept we develop here. While the traditional successor representation is a representation that defines state generalization by the similarity of successor states, the substochastic successor representation is also able to implicitly count the number of times each state (or feature) has been observed. This extension connects two until now disjoint areas of research. We show in traditional tabular domains (RiverSwim and SixArms) that our algorithm empirically performs as well as other sample-efficient algorithms. We then describe a deep reinforcement learning algorithm inspired by these ideas and show that it matches the performance of recent pseudo-count-based methods in hard exploration Atari 2600 games.", "paperhash": "anonymous|countbased_exploration_with_the_successor_representation", "keywords": ["reinforcement learning", "successor representation", "exploration", "atari"], "authorids": ["ICLR.cc/2019/Conference/Paper29/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose the idea of using the norm of the successor representation an exploration bonus in reinforcement learning. In hard exploration Atari games, our the deep RL algorithm matches the performance of recent pseudo-count-based methods.", "pdf": "/pdf/2edce4f08cfd819a26e8783f2f668cea20679fe3.pdf", "_bibtex": "@inproceedings{    \nanonymous2019count-based,    \ntitle={Count-Based Exploration with the Successor Representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1giVsRcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByzoVi0cFQ", "original": "B1elf1vdt7", "number": 30, "cdate": 1538087730950, "ddate": null, "tcdate": 1538087730950, "tmdate": 1538156256992, "tddate": null, "forum": "ByzoVi0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transfer Learning for Estimating Causal Effects Using Neural Networks", "abstract": "We develop new algorithms for estimating heterogeneous treatment effects, combining recent developments in transfer learning for neural networks with insights from the causal inference literature. By taking advantage of transfer learning, we are able to efficiently use different data sources that are related to the same underlying causal mechanisms. We compare our algorithms with those in the extant literature using extensive simulation studies based on large-scale voter persuasion experiments and the MNIST database. Our methods can perform an order of magnitude better than existing benchmarks while using a fraction of the data.", "paperhash": "anonymous|transfer_learning_for_estimating_causal_effects_using_neural_networks", "keywords": ["machine learning", "causal inference", "causal neural networks", "deep learning", "CATE estimation", "transfer learning", "meta-learning", "causal transfer"], "authorids": ["ICLR.cc/2019/Conference/Paper30/Authors"], "authors": ["Anonymous"], "TL;DR": "Transfer learning for estimating causal effects using neural networks.", "pdf": "/pdf/caf2d8c58f700eb73d556a6f3698e2e0cbcc02e2.pdf", "_bibtex": "@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer Learning for Estimating Causal Effects Using Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByzoVi0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1fs4oRqKm", "original": "B1xvr5UuYm", "number": 31, "cdate": 1538087731132, "ddate": null, "tcdate": 1538087731132, "tmdate": 1538156256783, "tddate": null, "forum": "H1fs4oRqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "UNSUPERVISED MONOCULAR DEPTH ESTIMATION WITH CLEAR BOUNDARIES", "abstract": "Unsupervised monocular depth estimation has made great progress after deep\nlearning is involved. Training with binocular stereo images is considered as a\ngood option as the data can be easily obtained. However, the depth or disparity\nprediction results show poor performance for the object boundaries. The main\nreason is related to the handling of occlusion areas during the training. In this paper,\nwe propose a novel method to overcome this issue. Exploiting disparity maps\nproperty, we generate an occlusion mask to block the back-propagation of the occlusion\nareas during image warping. We also design new networks with flipped\nstereo images to induce the networks to learn occluded boundaries. It shows that\nour method achieves clearer boundaries and better evaluation results on KITTI\ndriving dataset and Virtual KITTI dataset.", "paperhash": "anonymous|unsupervised_monocular_depth_estimation_with_clear_boundaries", "keywords": ["monocular depth estimation", "unsupervised learning", "image warping"], "authorids": ["ICLR.cc/2019/Conference/Paper31/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper propose a mask method which solves the previous blurred results of unsupervised monocular depth estimation caused by occlusion", "pdf": "/pdf/fd8a95731363be1f28040da1e23cdeea49808d03.pdf", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={UNSUPERVISED MONOCULAR DEPTH ESTIMATION WITH CLEAR BOUNDARIES},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1fs4oRqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJVoEiCqKQ", "original": "rken9UgutQ", "number": 32, "cdate": 1538087731328, "ddate": null, "tcdate": 1538087731328, "tmdate": 1538156256570, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "anonymous|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["ICLR.cc/2019/Conference/Paper32/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJVoEiCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skh4jRcKQ", "original": "HkxB3XguKm", "number": 33, "cdate": 1538087731517, "ddate": null, "tcdate": 1538087731517, "tmdate": 1538156256358, "tddate": null, "forum": "Skh4jRcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets", "abstract": "Training activation quantized neural networks involves piecewise constant loss functions with the sampled gradient vanishing almost everywhere, which is undesirable for back-propagation. An empirical way around this issue is to use a straight-through estimator (STE) (Bengio et al., 2013) in the backward pass, so that the resulting unusual \u201cgradient\u201d becomes non-trivial. In this paper, we make the first theoretical justification for the concept of STE, by considering the problem of learning a one-hidden-layer convolutional network with binarized ReLU activation and Gaussian input data. We refer to the unusual \u201cgradient\u201d based on STE as coarse gradient, which essentially is not the gradient of any function. Apparently, the choice of STE is not unique. We prove that if the STE is properly chosen, the negative expected coarse gradient is a descent direction for minimizing the population loss, and the associated coarse gradient descent algorithm converges to a local minimum (more rigorously, a critical point) of the population loss minimization problem. Moreover, we show that a relatively poor choice of STE may lead to instability of the training algorithm near certain local minima, which is also validated by our CIFAR-10 experiments.\n", "paperhash": "anonymous|understanding_straightthrough_estimator_in_training_activation_quantized_neural_nets", "keywords": ["straight-through estimator", "quantized activation", "binary neuron"], "authorids": ["ICLR.cc/2019/Conference/Paper33/Authors"], "authors": ["Anonymous"], "TL;DR": "We make the first theoretical justification for the concept of straight-through estimator.", "pdf": "/pdf/e3aa4208c3bf03ac5980860e3489456c8b299dc8.pdf", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skh4jRcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlhEs09YQ", "original": "Syl_e6N_tQ", "number": 34, "cdate": 1538087731714, "ddate": null, "tcdate": 1538087731714, "tmdate": 1538156256145, "tddate": null, "forum": "BJlhEs09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "End-to-end Learning of a Convolutional Neural Network via Deep Tensor Decomposition", "abstract": "In this paper we study the problem of learning the weights of a deep convolutional neural network. We consider a network where convolutions are carried out over non-overlapping patches with a single kernel in each layer. We develop an algorithm for simultaneously learning all the kernels from the training data. Our approach dubbed Deep Tensor Decomposition (DeepTD) is based on a rank-1 tensor decomposition. We theoretically investigate DeepTD under a realizable model for the training data where the inputs are chosen i.i.d. from a Gaussian distribution and the labels are generated according to planted convolutional kernels. We show that DeepTD is data-efficient and provably works as soon as the sample size exceeds the total number of convolutional weights in the network. Our numerical experiments demonstrate the effectiveness of DeepTD and verify our theoretical findings.", "paperhash": "anonymous|endtoend_learning_of_a_convolutional_neural_network_via_deep_tensor_decomposition", "keywords": ["convolutional neural network", "tensor decomposition", "sample complexity", "approximation"], "authorids": ["ICLR.cc/2019/Conference/Paper34/Authors"], "authors": ["Anonymous"], "TL;DR": "We consider a simplified deep convolutional neural network model. We show that all layers of this network can be approximately learned with a proper application of tensor decomposition.", "pdf": "/pdf/af6bda4b01a1ddda57321e68b2271d38a60373a3.pdf", "_bibtex": "@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-end Learning of a Convolutional Neural Network via Deep Tensor Decomposition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlhEs09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJl2Ns0qKX", "original": "rJe36mb_F7", "number": 35, "cdate": 1538087731897, "ddate": null, "tcdate": 1538087731897, "tmdate": 1538156255937, "tddate": null, "forum": "HJl2Ns0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions", "abstract": "We present a neural network architecture based upon the Autoencoder (AE) and Generative Adversarial Network (GAN) that promotes a convex latent distribution by training adversarially on latent space interpolations. By using an AE as both the generator and discriminator of a GAN, we pass a pixel-wise error function across the discriminator, yielding an AE which produces non-blurry samples that match both high- and low-level features of the original images. Interpolations between images in this space remain within the latent-space distribution of real images as trained by the discriminator, and therfore preserve realistic resemblances to the network inputs. ", "paperhash": "anonymous|generative_adversarial_interpolative_autoencoding_adversarial_training_on_latent_space_interpolations_encourage_convex_latent_distributions", "keywords": ["convex", "GAN", "autoencoder", "interpolation", "stimuli generation", "adversarial", "latent distribution"], "authorids": ["ICLR.cc/2019/Conference/Paper35/Authors"], "authors": ["Anonymous"], "TL;DR": "We designed an autoencoder which is trained to learn a convex latent distribution by using an adversarial loss function to discriminate latent space interpolations from real data. ", "pdf": "/pdf/1a62a3def496fa2f8aba843dac07892611901bed.pdf", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJl2Ns0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1l3NiCqY7", "original": "B1xeDJmOFm", "number": 36, "cdate": 1538087732080, "ddate": null, "tcdate": 1538087732080, "tmdate": 1538156255725, "tddate": null, "forum": "r1l3NiCqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Lipschitz regularized Deep Neural Networks converge and generalize", "abstract": "Generalization of deep neural networks (DNNs) is an open problem which, if solved, could impact the reliability and verification of deep neural network architectures.   In this paper, we show that if the usual fidelity term used in training DNNs is augmented by a Lipschitz regularization term, then the networks converge and generalize.  The convergence is in the limit as the number of data points, $n\\to \\infty$,  while also allowing the network to grow as needed to fit the data.   Two regimes are identified: in the case of clean labels, we prove convergence to the label function which corresponds to zero loss,  in the case of corrupted labels  which we prove convergence to a regularized label function which is the solution of a limiting variational problem.  In both cases, a convergence rate is also provided.  ", "paperhash": "anonymous|lipschitz_regularized_deep_neural_networks_converge_and_generalize", "keywords": ["Deep Neural Networks", "Regularization", "Generalization", "Convergence", "Lipschitz", "Stability"], "authorids": ["ICLR.cc/2019/Conference/Paper36/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove generalization of DNNs by adding a Lipschitz regularization term to the training loss", "pdf": "/pdf/04fc05d10265237538bcb39976dfb2b74fd0ddcd.pdf", "_bibtex": "@inproceedings{    \nanonymous2019lipschitz,    \ntitle={Lipschitz regularized Deep Neural Networks converge and generalize},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1l3NiCqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeh4jA9F7", "original": "HkeDx8REKQ", "number": 37, "cdate": 1538087732268, "ddate": null, "tcdate": 1538087732268, "tmdate": 1538156255517, "tddate": null, "forum": "ryeh4jA9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Playing the Game of Universal Adversarial Perturbations", "abstract": "We study the problem of learning classifiers robust to universal adversarial perturbations. While prior work approaches this problem via robust optimization, adversarial training, or input transformation, we instead phrase it as a two-player zero-sum game. In this new formulation, both players simultaneously play the same game, where one player chooses a classifier that minimizes a classification loss whilst the other player creates an adversarial perturbation that increases the same loss when applied to every sample in the training set.\nBy observing that performing a classification (respectively creating adversarial samples) is the best response to the other player, we propose a novel extension of a game-theoretic algorithm, namely fictitious play,  to the domain of training robust classifiers. Finally, we empirically show the robustness and versatility of our approach in two defence scenarios where universal attacks are performed on several image classification datasets -- CIFAR10, CIFAR100 and ImageNet.", "paperhash": "anonymous|playing_the_game_of_universal_adversarial_perturbations", "keywords": ["adversarial perturbations", "universal adversarial perturbations", "game theory", "robust machine learning"], "authorids": ["ICLR.cc/2019/Conference/Paper37/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a robustification method under the presence of universal adversarial perturbations, by connecting a game theoretic method (fictitious play) with the problem of robustification, and making it more scalable.", "pdf": "/pdf/6cd41234a734d984abec18c6ef243a2e4073f4b2.pdf", "_bibtex": "@inproceedings{    \nanonymous2019playing,    \ntitle={Playing the Game of Universal Adversarial Perturbations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeh4jA9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGh4sR9YQ", "original": "r1l-0SMdKX", "number": 38, "cdate": 1538087732458, "ddate": null, "tcdate": 1538087732458, "tmdate": 1538156255233, "tddate": null, "forum": "HyGh4sR9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning", "abstract": "Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. \nEvolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient.\nThat raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. \nHere we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of neuroevolution techniques that improve performance. We demonstrate the latter by showing that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g.\\  DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN (it can train Atari in {\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}4 hours on one workstation or {\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}1 hour distributed on 720 cores), and enables a state-of-the-art, up to 10,000-fold compact encoding technique. ", "paperhash": "anonymous|deep_neuroevolution_genetic_algorithms_are_a_competitive_alternative_for_training_deep_neural_networks_for_reinforcement_learning", "authorids": ["ICLR.cc/2019/Conference/Paper38/Authors"], "authors": ["Anonymous"], "keywords": ["Neuroevolution", "Reinforcement Learning"], "pdf": "/pdf/aa3b6c178ca713705223c888d688173daeef546f.pdf", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGh4sR9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxaNjA9Ym", "original": "HyeA9cWOFQ", "number": 39, "cdate": 1538087732694, "ddate": null, "tcdate": 1538087732694, "tmdate": 1538156255028, "tddate": null, "forum": "rkxaNjA9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Per-Tensor Fixed-Point Quantization of the Back-Propagation Algorithm", "abstract": "The high computational and parameter complexity of neural networks makes their training very slow and difficult to deploy on energy and storage-constrained comput- ing systems. Many network complexity reduction techniques have been proposed including fixed-point implementation. However, a systematic approach for design- ing full fixed-point training and inference of deep neural networks remains elusive. We describe a precision assignment methodology for neural network training in which all network parameters, i.e., activations and weights in the feedforward path, gradients and weight accumulators in the feedback path, are assigned close to minimal precision. The precision assignment is derived analytically and enables tracking the convergence behavior of the full precision training, known to converge a priori. Thus, our work leads to a systematic methodology of determining suit- able precision for fixed-point training. The near optimality (minimality) of the resulting precision assignment is validated empirically for four networks on the CIFAR-10, CIFAR-100, and SVHN datasets. The complexity reduction arising from our approach is compared with other fixed-point neural network designs.", "paperhash": "anonymous|pertensor_fixedpoint_quantization_of_the_backpropagation_algorithm", "keywords": ["deep learning", "reduced precision", "fixed-point", "quantization", "back-propagation algorithm"], "authorids": ["ICLR.cc/2019/Conference/Paper39/Authors"], "authors": ["Anonymous"], "TL;DR": "We analyze and determine the precision requirements for training neural networks when all tensors, including back-propagated signals and weight accumulators, are quantized to fixed-point format.", "pdf": "/pdf/b5870f76b5d8c448398e3de6885d467a3dd3c0c0.pdf", "_bibtex": "@inproceedings{    \nanonymous2019per-tensor,    \ntitle={Per-Tensor Fixed-Point Quantization of the Back-Propagation Algorithm},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxaNjA9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gTEj09FX", "original": "HkgPILZuK7", "number": 40, "cdate": 1538087732876, "ddate": null, "tcdate": 1538087732876, "tmdate": 1538156254826, "tddate": null, "forum": "H1gTEj09FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RotDCF: Decomposition of Convolutional Filters for Rotation-Equivariant Deep Networks", "abstract": "Explicit encoding of group actions in deep features makes it possible for convolutional neural networks (CNNs) to handle global deformations of images, which is critical to success in many vision tasks. This paper proposes to decompose the convolutional filters over joint steerable bases across the space and the group geometry simultaneously, namely a rotation-equivariant CNN with decomposed convolutional filters (RotDCF). This decomposition facilitates computing the joint convolution, which is proved to be necessary for the group equivariance. It significantly reduces the model size and computational complexity while preserving performance, and truncation of the bases expansion serves implicitly to regularize the filters. On datasets involving in-plane and out-of-plane object rotations, RotDCF deep features demonstrate greater robustness and interpretability than regular CNNs. The stability of the equivariant representation to input variations is also proved theoretically. The RotDCF framework can be extended to groups other than rotations, providing a general approach which achieves both group equivariance and representation stability at a reduced model size.", "paperhash": "anonymous|rotdcf_decomposition_of_convolutional_filters_for_rotationequivariant_deep_networks", "authorids": ["ICLR.cc/2019/Conference/Paper40/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/73a2f92b5f4abd54cc96041f004febc691b5af15.pdf", "_bibtex": "@inproceedings{    \nanonymous2019rotdcf:,    \ntitle={RotDCF: Decomposition of Convolutional Filters for Rotation-Equivariant Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gTEj09FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGpEiAcFQ", "original": "HyeSDTwFdQ", "number": 41, "cdate": 1538087733069, "ddate": null, "tcdate": 1538087733069, "tmdate": 1538156254622, "tddate": null, "forum": "ryGpEiAcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Synaptic Neural Network and Synapse Learning", "abstract": "A Synaptic Neural Network (SynaNN) consists of synapses and neurons. Inspired by the research of biological synapses, we abstracted a synapse as a nonlinear function of two excitatory and inhibitory probabilities. After introducing the surprisal space, we discovered that the surprisal synapse is the sum of the surprisal of the excitatory probability and the topologically conjugate surprisal of the inhibitory probability. From the formula $\\frac{\\partial}{\\partial{\\gamma}}{log(1-e^{-\\gamma})} = \\frac{1}{e^\\gamma-1}$, we concluded that the derivative of the surprisal synapse over the parameter is equal to the negative Bose-Einstein distribution. In addition, we could construct a synapse graph such as a fully connected synapse graph (synapse tensor), and embedded it into other neural networks to form a hybrid neural network. Furthermore, we proved the gradient expression of the cross-entropy loss function over parameters, so the synapse learning was compatible with the gradient descent and backpropagation of deep learning. To prove the concept, we performed the MNIST experiment with synaptic neural network and achieved a high accuracy in the model training and inference.\n", "paperhash": "anonymous|a_synaptic_neural_network_and_synapse_learning", "keywords": ["synaptic neural network", "surprisal", "synapse", "probability", "excitation", "inhibition", "synapse learning", "bose-einstein distribution", "tensor", "gradient", "loss function", "mnist", "topologically conjugate"], "authorids": ["ICLR.cc/2019/Conference/Paper41/Authors"], "authors": ["Anonymous"], "TL;DR": "A synaptic neural network with synapse graph and learning that has the feature of Bose-Einstein distribution in surprisal space.  ", "pdf": "/pdf/bbfda8ced228c22df03a8bfb5cd82d814090ddc0.pdf", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Synaptic Neural Network and Synapse Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGpEiAcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryfaViR9YX", "original": "rJl21FRPKm", "number": 42, "cdate": 1538087733245, "ddate": null, "tcdate": 1538087733245, "tmdate": 1538156254420, "tddate": null, "forum": "ryfaViR9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "anonymous|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["ICLR.cc/2019/Conference/Paper42/Authors"], "authors": ["Anonymous"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@inproceedings{    \nanonymous2019variation,    \ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryfaViR9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1E64jC5tm", "original": "BJeTbdnDYX", "number": 43, "cdate": 1538087733433, "ddate": null, "tcdate": 1538087733433, "tmdate": 1538156254206, "tddate": null, "forum": "S1E64jC5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Forward-Backward Embedding of Directed Graphs", "abstract": "We introduce a novel embedding of directed graphs derived from the singular value decomposition (SVD) of the  normalized adjacency matrix. Specifically, we show that, after proper normalization of the singular vectors,  \n the  distances between vectors in  the embedding space are proportional to the mean commute times between the corresponding  nodes by a  forward-backward random walk in the graph, which follows the edges  alternately in forward and backward directions.  In particular, two nodes having many common successors in the graph tend to be represented by close vectors in the embedding space. More formally, we prove that our representation of the graph is  equivalent to the spectral embedding of some co-citation graph, where  nodes are linked with respect to their common set of successors in the original graph. The interest of our approach is that it does not require to build this co-citation graph, which is typically much denser than the original graph. Experiments  on  real datasets show the efficiency of the approach. \n", "paperhash": "anonymous|the_forwardbackward_embedding_of_directed_graphs", "authorids": ["ICLR.cc/2019/Conference/Paper43/Authors"], "authors": ["Anonymous"], "keywords": ["Graph embedding", "SVD", "random walk", "co-clustering"], "pdf": "/pdf/d25e767a13aafe634f5e0cd07ab5fb80cdbb3488.pdf", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Forward-Backward Embedding of Directed Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1E64jC5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygREjC9YQ", "original": "rklMIgFLF7", "number": 44, "cdate": 1538087733616, "ddate": null, "tcdate": 1538087733616, "tmdate": 1538156253999, "tddate": null, "forum": "BygREjC9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A unified theory of adaptive stochastic gradient descent as Bayesian filtering", "abstract": "We formulate stochastic gradient descent (SGD) as a Bayesian filtering problem.  Inference in the Bayesian setting naturally gives rise to BRMSprop and BAdam: Bayesian variants of RMSprop and Adam.  Remarkably, the Bayesian approach recovers many features of state-of-the-art adaptive SGD methods, including amoungst others root-mean-square normalization, Nesterov acceleration and AdamW.  As such, the Bayesian approach provides one explanation for the empirical effectiveness of state-of-the-art adaptive SGD algorithms.  Empirically comparing BRMSprop and BAdam with naive RMSprop and Adam on MNIST, we find that Bayesian methods have the potential to considerably reduce test loss and classification error.", "paperhash": "anonymous|a_unified_theory_of_adaptive_stochastic_gradient_descent_as_bayesian_filtering", "keywords": ["SGD", "Bayesian", "RMSprop", "Adam"], "authorids": ["ICLR.cc/2019/Conference/Paper44/Authors"], "authors": ["Anonymous"], "TL;DR": "We formulated SGD as a Bayesian filtering problem, and show that this gives rise to RMSprop, Adam, AdamW, NAG and other features of state-of-the-art adaptive methods", "pdf": "/pdf/4e56e81773649bf45484c00adb60200a92a9a60a.pdf", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A unified theory of adaptive stochastic gradient descent as Bayesian filtering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygREjC9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklAEsR5t7", "original": "ryeENiBPY7", "number": 45, "cdate": 1538087733796, "ddate": null, "tcdate": 1538087733796, "tmdate": 1538156253795, "tddate": null, "forum": "BklAEsR5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Large-scale classification of structured objects using a CRF with deep class embedding", "abstract": "This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. We model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local-visual features and neighboring class information. The visual features are learned by convolutional layers, whereas class-structure information is reparametrized by factorizing the CRF pairwise potential matrix. This forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, we develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse. The performance of the proposed method is illustrated on a huge dataset that contains images of retail-store product displays, and shows significantly improved results compared to linear CRF parametrization, unnormalized likelihood optimization, and RNN modeling.", "paperhash": "anonymous|largescale_classification_of_structured_objects_using_a_crf_with_deep_class_embedding", "keywords": ["large-scale structure prediction", "likelihood approximation", "deep class embedding"], "authorids": ["ICLR.cc/2019/Conference/Paper45/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a  technique for ultrafine-grained, large-scale structured classification, based on CRF modeling with factorized pairwise potentials, learned as neighboring class embedding in a whitened space.", "pdf": "/pdf/f82d45d67087a64b5616851caa33611ff3f944cf.pdf", "_bibtex": "@inproceedings{    \nanonymous2019large-scale,    \ntitle={Large-scale classification of structured objects using a CRF with deep class embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklAEsR5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxANsC9tQ", "original": "rkxBJVyFum", "number": 46, "cdate": 1538087733989, "ddate": null, "tcdate": 1538087733989, "tmdate": 1538156253594, "tddate": null, "forum": "SkxANsC9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Graph Representations by Dendrograms", "abstract": "Hierarchical  clustering is a common approach to analysing  the \nmulti-scale structure of  graphs observed in practice.  \nWe propose a novel  metric for assessing the quality of a hierarchical clustering. This metric reflects the ability to reconstruct the graph from the dendrogram encoding the hierarchy. The best  representation of the graph for this metric in turn yields a  novel hierarchical clustering algorithm. Experiments on both real and synthetic data illustrate the efficiency of the approach. \n", "paperhash": "anonymous|learning_graph_representations_by_dendrograms", "keywords": ["Graph", "hierarchical clustering", "dendrogram", "quality metric", "reconstruction", "entropy"], "authorids": ["ICLR.cc/2019/Conference/Paper46/Authors"], "authors": ["Anonymous"], "TL;DR": "Novel quality metric for hierarchical graph clustering", "pdf": "/pdf/b711a6cde6788973da7b0db7968262113576adaf.pdf", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Graph Representations by Dendrograms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxANsC9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylRVjC9K7", "original": "H1lVb5fvt7", "number": 47, "cdate": 1538087734173, "ddate": null, "tcdate": 1538087734173, "tmdate": 1538156253391, "tddate": null, "forum": "BylRVjC9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Explaining Adversarial Examples with Knowledge Representation", "abstract": "Adversarial examples are modified samples that preserve original image structures but deviate classifiers. Researchers have put efforts into developing methods for generating adversarial examples and finding out origins. Past research put much attention on decision boundary changes caused by these methods. This paper, in contrast, discusses the origin of adversarial examples from a more underlying knowledge representation point of view. Human beings can learn and classify prototypes as well as transformations of objects. While neural networks store learned knowledge in a more hybrid way of combining all prototypes and transformations as a whole distribution. Hybrid storage may lead to lower distances between different classes so that small modifications can mislead the classifier. A one-step distribution imitation method is designed to imitate distribution of the nearest different class neighbor. Experiments show that simply by imitating distributions from a training set without any knowledge of the classifier can still lead to obvious impacts on classification results from deep networks. It also implies that adversarial examples can be in more forms than small perturbations. Potential ways of alleviating adversarial examples are discussed from the representation point of view. The first path is to change the encoding of data sent to the training step. Training data that are more prototypical can help seize more robust and accurate structural knowledge. The second path requires constructing learning frameworks with improved representations.", "paperhash": "anonymous|explaining_adversarial_examples_with_knowledge_representation", "keywords": ["adversarial example", "knowledge representation", "distribution imitation"], "authorids": ["ICLR.cc/2019/Conference/Paper47/Authors"], "authors": ["Anonymous"], "TL;DR": "Hybird storage and representation of learned knowledge may be a reason for adversarial examples.", "pdf": "/pdf/e46a3e53ea904c657b33f5beb48c79474cb1cdac.pdf", "_bibtex": "@inproceedings{    \nanonymous2019explaining,    \ntitle={Explaining Adversarial Examples with Knowledge Representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylRVjC9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygANjA5FX", "original": "H1lhSrfvFQ", "number": 48, "cdate": 1538087734360, "ddate": null, "tcdate": 1538087734360, "tmdate": 1538156253182, "tddate": null, "forum": "BygANjA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "IEA: Inner Ensemble Average within a convolutional neural network", "abstract": "Ensemble learning is a method of combining multiple trained models to improve the model accuracy. We introduce the usage of such methods, specifically ensemble average inside Convolutional Neural Networks (CNNs) architectures. By Inner Average Ensemble (IEA) of multiple convolutional neural layers (CNLs) replacing the single CNL inside the CNN architecture, the accuracy of the CNN increased. A visual and a similarity score analysis of the features generated from IEA explains why it boosts the model performance. Empirical results using different benchmarking datasets and well-known deep model architectures shows that IEA outperforms the ordinary CNL used in CNNs.", "paperhash": "anonymous|iea_inner_ensemble_average_within_a_convolutional_neural_network", "keywords": ["Ensemble Convolutional Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper48/Authors"], "authors": ["Anonymous"], "TL;DR": "We inner ensemble the features of a convolutional neural layer, it increases the network accuracy and generates distinct features.", "pdf": "/pdf/34008da103199cc508d78a04c0c73e4065a250f4.pdf", "_bibtex": "@inproceedings{    \nanonymous2019iea:,    \ntitle={IEA: Inner Ensemble Average within a convolutional neural network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygANjA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygJSiA5YQ", "original": "B1lzkyfDYQ", "number": 49, "cdate": 1538087734539, "ddate": null, "tcdate": 1538087734539, "tmdate": 1538156252975, "tddate": null, "forum": "SygJSiA5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Weak contraction mapping and optimization", "abstract": "The weak contraction mapping is a self mapping that the range is always a subset of the domain, which admits a unique fixed-point. The iteration of weak contraction mapping is a Cauchy sequence that yields the unique fixed-point. A gradient-free optimization method as an application of weak contraction mapping is proposed to achieve global minimum convergence. The optimization method is robust to local minima and initial point position.", "paperhash": "anonymous|weak_contraction_mapping_and_optimization", "keywords": ["Weak contraction mapping", "fixed-point theorem", "non-convex optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper49/Authors"], "authors": ["Anonymous"], "TL;DR": "A gradient-free method is proposed for non-convex optimization problem ", "pdf": "/pdf/ebedc0fff9ff314dc8a781f4c8d7716ea77038b6.pdf", "_bibtex": "@inproceedings{    \nanonymous2019weak,    \ntitle={Weak contraction mapping and optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygJSiA5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJx1SsAcYQ", "original": "H1l2do1DFQ", "number": 50, "cdate": 1538087734717, "ddate": null, "tcdate": 1538087734717, "tmdate": 1538156252766, "tddate": null, "forum": "BJx1SsAcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discovering Low-Precision Networks Close to Full-Precision Networks for Efficient Embedded Inference", "abstract": "To realize the promise of ubiquitous embedded deep network inference, it is essential to seek limits of energy and area efficiency.  To this end, low-precision networks offer tremendous promise because both energy and area scale down quadratically with the reduction in precision.  Here, for the first time, we demonstrate ResNet-18, ResNet-34, ResNet-50, ResNet-152, Inception-v3, densenet-161, and VGG-16bn networks on the ImageNet classification benchmark that, at 8-bit precision exceed the accuracy of the full-precision baseline networks after one epoch of finetuning, thereby leveraging the availability of pretrained models.\nWe also demonstrate for the first time ResNet-18, ResNet-34, and ResNet-50 4-bit models that match the accuracy of the full-precision baseline networks. Surprisingly, the weights of the low-precision networks are very close (in cosine similarity) to the weights of the corresponding baseline networks, making training from scratch unnecessary.\n\nWe find that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise. The number of iterations required by stochastic gradient descent to achieve a given training error is related to the square of (a) the distance of the initial solution from the final plus (b) the maximum variance of the gradient estimates.  By drawing inspiration from this observation, we (a) reduce solution distance by starting with pretrained fp32 precision baseline networks and fine-tuning, and (b) combat noise introduced by quantizing weights and activations during training, by using larger batches along with matched learning rate annealing.  Sensitivity analysis indicates that these techniques, coupled with proper activation function range calibration, offer a promising heuristic to discover low-precision networks, if they exist, close to fp32 precision baseline networks.\n", "paperhash": "anonymous|discovering_lowprecision_networks_close_to_fullprecision_networks_for_efficient_embedded_inference", "keywords": ["Deep Learning", "Convolutional Neural Networks", "Low-precision inference", "Network quantization"], "authorids": ["ICLR.cc/2019/Conference/Paper50/Authors"], "authors": ["Anonymous"], "TL;DR": "Finetuning after quantization matches or exceeds full-precision state-of-the-art networks at both 8- and 4-bit quantization.", "pdf": "/pdf/4b2a2d0aa3afc563e1b0e987db5d1a66d32f04c2.pdf", "_bibtex": "@inproceedings{    \nanonymous2019discovering,    \ntitle={Discovering Low-Precision Networks Close to Full-Precision Networks for Efficient Embedded Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJx1SsAcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGkSo0qYm", "original": "rJl6V6TUKQ", "number": 51, "cdate": 1538087734907, "ddate": null, "tcdate": 1538087734907, "tmdate": 1538156252557, "tddate": null, "forum": "ryGkSo0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Large Scale Graph Learning From Smooth Signals", "abstract": "Graphs are a prevalent tool in data science, as they model the inherent structure of the data. Typically they are constructed either by connecting nearest samples, or by learning them from data, solving an optimization problem. While graph learning does achieve a better quality, it also comes with a higher computational cost. In particular, the current state-of-the-art model cost is O(n^2) for n samples.\nIn this paper, we show how to scale it, obtaining an approximation with leading cost of O(n log(n)), with quality that approaches the exact graph learning model. Our algorithm uses known approximate nearest neighbor techniques to reduce the number of variables, and automatically selects the correct parameters of the model, requiring a single intuitive input: the desired edge density.", "paperhash": "anonymous|large_scale_graph_learning_from_smooth_signals", "authorids": ["ICLR.cc/2019/Conference/Paper51/Authors"], "authors": ["Anonymous"], "keywords": ["Graph learning", "Graph signal processing", "Network inference"], "pdf": "/pdf/1e5d7f4167a76ce8bbea5f007b2821da472c4f4b.pdf", "_bibtex": "@inproceedings{    \nanonymous2019large,    \ntitle={Large Scale Graph Learning From Smooth Signals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGkSo0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGySsAct7", "original": "S1xgEdnLKX", "number": 52, "cdate": 1538087735091, "ddate": null, "tcdate": 1538087735091, "tmdate": 1538156252351, "tddate": null, "forum": "HyGySsAct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "anonymous|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["ICLR.cc/2019/Conference/Paper52/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@inproceedings{    \nanonymous2019targeted,    \ntitle={Targeted Adversarial Examples for Black Box Audio Systems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGySsAct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJEyrjRqYX", "original": "HJxQXBo8tm", "number": 53, "cdate": 1538087735272, "ddate": null, "tcdate": 1538087735272, "tmdate": 1538156252139, "tddate": null, "forum": "rJEyrjRqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reduced-Gate Convolutional LSTM Design Using Predictive Coding for Next-Frame Video Prediction", "abstract": "Spatiotemporal sequence prediction is an important problem in deep learning. We\nstudy next-frame video prediction using a deep-learning-based predictive coding\nframework that uses convolutional, long short-term memory (convLSTM) modules.\nWe introduce a novel reduced-gate convolutional LSTM architecture. Our\nreduced-gate model achieves better next-frame prediction accuracy than the original\nconvolutional LSTM while using a smaller parameter budget, thereby reducing\ntraining time. We tested our reduced gate modules within a predictive coding architecture\non the moving MNIST and KITTI datasets. We found that our reduced-gate\nmodel has a significant reduction of approximately 40 percent of the total\nnumber of training parameters and training time in comparison with the standard\nLSTM model which makes it attractive for hardware implementation especially\non small devices.", "paperhash": "anonymous|reducedgate_convolutional_lstm_design_using_predictive_coding_for_nextframe_video_prediction", "keywords": ["rgcLSTM", "convolutional LSTM", "unsupervised learning", "predictive coding", "video prediction", "moving MNIST", "KITTI datasets", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper53/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel reduced-gate convolutional LSTM design using predictive coding for next-frame video prediction", "pdf": "/pdf/0944772eda7f226579dbc500d7ef1fbe0257d981.pdf", "_bibtex": "@inproceedings{    \nanonymous2019reduced-gate,    \ntitle={Reduced-Gate Convolutional LSTM Design Using Predictive Coding for Next-Frame Video Prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJEyrjRqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "By41BjA9YQ", "original": "HkxkP_LEFQ", "number": 54, "cdate": 1538087735463, "ddate": null, "tcdate": 1538087735463, "tmdate": 1538156251931, "tddate": null, "forum": "By41BjA9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Laplacian Smoothing Gradient Descent", "abstract": "We propose a class of very simple modifications of gradient descent and stochastic gradient descent. We show that when applied to a large variety of machine learning problems, ranging from softmax regression to deep neural nets, the proposed surrogates can dramatically reduce the variance and improve the generalization accuracy. The methods only involve multiplying the usual (stochastic) gradient by the inverse of a positive definitive matrix coming from the discrete Laplacian or high order generalizations.  The theory of Hamilton-Jacobi partial differential equations demonstrates that the new algorithm is almost the same as doing gradient descent on a new function which (i) has the same global minima as the original function and (ii) is \u201cmore convex\u201d.  We show that optimization algorithms with these surrogates converge uniformly in the discrete Sobolev H^p_\\sigma sense and reduce the optimality gap for convex optimization problems.  We implement our algorithm into both PyTorch and Tensorflow platforms which only involves changing of a few lines of code. The code will be available on Github.", "paperhash": "anonymous|laplacian_smoothing_gradient_descent", "keywords": ["Laplacian Smoothing", "Nonconvex Optimization", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper54/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposal a simple surrogate for gradient descent to improve training of deep neural nets and other optimization problems.", "pdf": "/pdf/ebb3a55322574101ab494e4d7bd950c6bb6e848d.pdf", "_bibtex": "@inproceedings{    \nanonymous2019laplacian,    \ntitle={Laplacian Smoothing Gradient Descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=By41BjA9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklgHoRqt7", "original": "S1xQBIFUYm", "number": 55, "cdate": 1538087735645, "ddate": null, "tcdate": 1538087735645, "tmdate": 1538156251722, "tddate": null, "forum": "SklgHoRqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Metric-Optimized Example Weights", "abstract": "Real-world machine learning applications often have complex test metrics, and may have training and test data that follow different distributions.  We propose addressing these issues by using a weighted loss function with a standard convex loss, but with weights on the training examples that are learned to optimize the test metric of interest on the validation set. These metric-optimized example weights can be learned for any test metric, including black box losses and customized metrics for specific applications.  We illustrate the performance of our proposal with public benchmark datasets and real-world applications with domain shift and custom loss functions that balance multiple objectives, impose fairness policies, and are non-convex and non-decomposable.", "paperhash": "anonymous|metricoptimized_example_weights", "authorids": ["ICLR.cc/2019/Conference/Paper55/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/3f8a6e7afd72b4708ebbc8015ff04031d7a7f982.pdf", "_bibtex": "@inproceedings{    \nanonymous2019metric-optimized,    \ntitle={Metric-Optimized Example Weights},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklgHoRqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylxrsR9Fm", "original": "BklVSY3GFm", "number": 56, "cdate": 1538087735827, "ddate": null, "tcdate": 1538087735827, "tmdate": 1538156251508, "tddate": null, "forum": "rylxrsR9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neuron Hierarchical Networks", "abstract": "In this paper, we propose a neural network framework called neuron hierarchical network (NHN), that evolves beyond the hierarchy in layers, and concentrates on the hierarchy of neurons. We observe mass redundancy in the weights of both handcrafted and randomly searched architectures. Inspired by the development of human brains, we prune low-sensitivity neurons in the model and add new neurons to the graph, and the relation between individual neurons are emphasized and the existence of layers weakened. We propose a process to discover the best base model by random architecture search, and discover the best locations and connections of the added neurons by evolutionary search. Experiment results show that the NHN achieves higher test accuracy on Cifar-10 than state-of-the-art handcrafted and randomly searched architectures, while requiring much fewer parameters and less searching time.", "paperhash": "anonymous|neuron_hierarchical_networks", "TL;DR": "By breaking the layer hierarchy, we propose a 3-step approach to the construction of neuron-hierarchy networks that outperform NAS, SMASH and hierarchical representation with fewer parameters and shorter searching time.", "authorids": ["ICLR.cc/2019/Conference/Paper56/Authors"], "authors": ["Anonymous"], "keywords": ["neural network", "architecture search", "evolution strategy"], "pdf": "/pdf/5d6d874ccbd892c528ca10fc9f258b9908b5620f.pdf", "_bibtex": "@inproceedings{    \nanonymous2019neuron,    \ntitle={Neuron Hierarchical Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylxrsR9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGgSsAcFQ", "original": "B1loMZhHt7", "number": 57, "cdate": 1538087736010, "ddate": null, "tcdate": 1538087736010, "tmdate": 1538156251299, "tddate": null, "forum": "ryGgSsAcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep, Skinny Neural Networks are not Universal Approximators", "abstract": "In order to choose a neural network architecture that will be effective for a particular modeling problem, one must understand the limitations imposed by each of the potential options. These limitations are typically described in terms of information theoretic bounds, or by comparing the relative complexity needed to approximate example functions between different architectures. In this paper, we examine the topological constraints that the architecture of a neural network imposes on the level sets of all the functions that it is able to approximate. This approach is novel for both the nature of the limitations and the fact that they are independent of network depth for a broad family of activation functions.", "paperhash": "anonymous|deep_skinny_neural_networks_are_not_universal_approximators", "TL;DR": "This paper proves that skinny neural networks cannot approximate certain functions, no matter how deep they are.", "authorids": ["ICLR.cc/2019/Conference/Paper57/Authors"], "authors": ["Anonymous"], "keywords": ["neural network", "universality", "expressability"], "pdf": "/pdf/afa296ef9ab2e35b9d60d42628c5fc668dbad59a.pdf", "_bibtex": "@inproceedings{    \nanonymous2019deep,,    \ntitle={Deep, Skinny Neural Networks are not Universal Approximators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGgSsAcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1llBiR5YX", "original": "r1xhCc7rFX", "number": 58, "cdate": 1538087736200, "ddate": null, "tcdate": 1538087736200, "tmdate": 1538156251095, "tddate": null, "forum": "S1llBiR5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Accidental explorationa through value predictors", "abstract": "Infinite length of trajectories is an almost universal assumption in the theoretical foundations of reinforcement learning. Of course, in practice this is never the case. In this paper we examine a specific result of this disparity. We focus on the case where the finiteness of trajectories also makes the underlying process to lose the Markov property. This causes the standard state value estimators to become biased, which in turn manifests as a vastly different learning dynamic\nwhen algorithms use value predictors.\n\nWe investigate these claims theoretically for a one dimensional random walk and Wiener process, and empirically on a number of simple environments. We use GAE as an algorithm which uses a value predictor and compare it to a plain policy gradient.", "paperhash": "anonymous|accidental_explorationa_through_value_predictors", "TL;DR": "We study the biases introduced in common value predictors by the fact that trajectories are, in practice, finite.", "authorids": ["ICLR.cc/2019/Conference/Paper58/Authors"], "authors": ["Anonymous"], "keywords": ["reinforcement learning", "value predictors", "exploration"], "pdf": "/pdf/13459323c79a628c70f09cc4c89e6061efd2d498.pdf", "_bibtex": "@inproceedings{    \nanonymous2019accidental,    \ntitle={Accidental explorationa through value predictors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1llBiR5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxlHsActm", "original": "Bkg5Pm9VFQ", "number": 59, "cdate": 1538087736376, "ddate": null, "tcdate": 1538087736376, "tmdate": 1538156250893, "tddate": null, "forum": "HyxlHsActm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Dictionary Learning with Gradient Descent", "abstract": "Randomly initialized first-order optimization algorithms are the method of choice for solving many high-dimensional nonconvex problems in machine learning, yet general theoretical guarantees cannot rule out convergence to critical points of poor objective value. For some highly structured nonconvex problems however, the success of gradient descent can be understood by studying the geometry of the objective. We study one such problem -- complete orthogonal dictionary learning, and provide converge guarantees for randomly initialized gradient descent to the neighborhood of a global optimum. The resulting rates scale as low order polynomials in the dimension even though the objective possesses an exponential number of saddle points. This efficient convergence can be viewed as a consequence of negative curvature normal to the stable manifolds associated with saddle points, and we provide evidence that this feature is shared by other nonconvex problems of importance as well. ", "paperhash": "anonymous|efficient_dictionary_learning_with_gradient_descent", "TL;DR": "We provide an efficient convergence rate for gradient descent on the complete orthogonal dictionary learning objective based on a geometric analysis.", "authorids": ["ICLR.cc/2019/Conference/Paper59/Authors"], "authors": ["Anonymous"], "keywords": ["dictionary learning", "nonconvex optimization"], "pdf": "/pdf/3e45a265d01fd7351c1a3cd99261b0894afae18e.pdf", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Dictionary Learning with Gradient Descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxlHsActm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxWrsC5FQ", "original": "rJt3xy4tX", "number": 60, "cdate": 1538087736560, "ddate": null, "tcdate": 1538087736560, "tmdate": 1538156250686, "tddate": null, "forum": "HkxWrsC5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Provable Guarantees on Learning Hierarchical Generative Models with Deep CNNs", "abstract": "Learning deep networks is computationally hard in the general case. To show any positive theoretical results, one must make assumptions on the data distribution. Current theoretical works often make assumptions that are very far from describing real data, like sampling from Gaussian distribution or linear separability of the data. We describe an algorithm that learns convolutional neural network,\nassuming the data is sampled from a deep generative model that generates images level by level,\nwhere lower resolution images correspond to latent semantic classes. We analyze the convergence rate of our algorithm assuming the data is indeed generated according to this model (as well as\nadditional assumptions). While we do not pretend to claim that the assumptions are realistic for natural images, we do believe that they capture some true properties of real data. Furthermore, we show that on CIFAR-10, the algorithm we analyze achieves results in the same ballpark with vanilla convolutional neural networks that are trained with SGD.", "paperhash": "anonymous|provable_guarantees_on_learning_hierarchical_generative_models_with_deep_cnns", "TL;DR": "A generative model for deep CNNs with provable theoretical guarantees that actually works", "authorids": ["ICLR.cc/2019/Conference/Paper60/Authors"], "authors": ["Anonymous"], "keywords": ["deep learning", "theory"], "pdf": "/pdf/e34ccc95fd575a165005997fc965927b3db54536.pdf", "_bibtex": "@inproceedings{    \nanonymous2019provable,    \ntitle={Provable Guarantees on Learning Hierarchical Generative Models with Deep CNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxWrsC5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1l-SjA5t7", "original": "BJelFrcmtX", "number": 61, "cdate": 1538087736739, "ddate": null, "tcdate": 1538087736739, "tmdate": 1538156250472, "tddate": null, "forum": "H1l-SjA5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task", "abstract": "Deep latent variable models, such as variational autoencoders, have been successfully used to disentangle factors of variation in image datasets. The structure of the representations learned by such models is usually observed after training and iteratively refined by tuning the network architecture and loss function. Here we propose a method that can explicitly place information into a specific subset of the latent variables. We demonstrate the use of the method in a task of disentangling global structure from local features in images. One subset of the latent variables is encouraged to represent local features through an auxiliary modelling task. In this auxiliary task, the global structure of an image is destroyed by dividing it into pixel patches which are then randomly shuffled. The full set of latent variables is trained to model the original data, obliging the remainder of the latent representation to model the global structure. We demonstrate that this approach successfully disentangles the latent variables for global structure from local structure by observing the generative samples of SVHN and CIFAR10. We also clustering the disentangled global structure of SVHN and found that the emerging clusters represent meaningful groups of global structures \u2013 including digit identities and the number of digits presence. Finally, we discuss the problem of evaluating the clustering accuracy when ground truth categories are not expressive enough.", "paperhash": "anonymous|explicit_information_placement_on_latent_variables_using_auxiliary_generative_modelling_task", "TL;DR": "We propose a method that can explicitly place information into a specific subset of the latent variables in deep generative models.  We demonstrate the use of the method in a task of disentangling global structure from local features in images.  ", "authorids": ["ICLR.cc/2019/Conference/Paper61/Authors"], "authors": ["Anonymous"], "keywords": ["disentanglement", "vae", "clustering", "prior imposition", "deep generative models"], "pdf": "/pdf/0963e7ecec6d55ab43319686739a4e9a843e48bf.pdf", "_bibtex": "@inproceedings{    \nanonymous2019explicit,    \ntitle={Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1l-SjA5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkzZBi0cFQ", "original": "HJxCng_fYm", "number": 62, "cdate": 1538087736919, "ddate": null, "tcdate": 1538087736919, "tmdate": 1538156250266, "tddate": null, "forum": "HkzZBi0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Quantization for Rapid Deployment of Deep Neural Networks", "abstract": "This paper aims at rapid deployment of the state-of-the-art deep neural networks (DNNs) to energy efficient accelerators without time-consuming fine tuning or the availability of the full datasets.  Converting DNNs in full precision to limited precision is essential in taking advantage of the accelerators with reduced memory footprint and computation power. However, such a task is not trivial since it often requires the full training and validation datasets for profiling the network statistics and fine tuning the networks to recover the accuracy lost after quantization. To address these issues, we propose a simple method recognizing channel-level distribution to reduce the quantization-induced accuracy loss and minimize the required image samples for profiling. We evaluated our method on eleven networks trained on the ImageNet classification benchmark and a network trained on the Pascal VOC object detection benchmark. The results prove that the networks can be quantized into 8-bit integer precision without fine tuning.", "paperhash": "anonymous|quantization_for_rapid_deployment_of_deep_neural_networks", "authorids": ["ICLR.cc/2019/Conference/Paper62/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/ba9149a03c9b67809a491e5f7cb02c38ae864f39.pdf", "_bibtex": "@inproceedings{    \nanonymous2019quantization,    \ntitle={Quantization for Rapid Deployment of Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzZBi0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgZrsC5t7", "original": "Hyl7aX8zFX", "number": 63, "cdate": 1538087737109, "ddate": null, "tcdate": 1538087737109, "tmdate": 1538156250060, "tddate": null, "forum": "HJgZrsC5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving On-policy Learning with Statistical Reward Accumulation", "abstract": "Deep reinforcement learning has obtained significant breakthroughs in recent years. Most methods in deep-RL achieve good results via the maximization of the reward signal provided by the environment, typically in the form of discounted cumulative returns. Such reward signals represent the immediate feedback of a particular action performed by an agent. However, tasks with sparse reward signals are still challenging to on-policy methods. In this paper, we introduce an effective characterization of past reward statistics (which can be seen as long-term feedback signals) to supplement this immediate reward feedback. In particular, value functions are learned with multi-critics supervision, enabling complex value functions to be more easily approximated in on-policy learning, even when the reward signals are sparse. We also introduce a novel exploration mechanism called ``hot-wiring'' that can give a boost to seemingly trapped agents. We demonstrate the effectiveness of our advantage actor multi-critic (A2MC) method across the discrete domains in Atari games as well as continuous domains in the MuJoCo environments. A video demo is provided at https://youtu.be/zBmpf3Yz8tc and source codes will be made available upon paper acceptance.", "paperhash": "anonymous|improving_onpolicy_learning_with_statistical_reward_accumulation", "TL;DR": "Improving On-policy Learning with Statistical Reward Accumulation", "authorids": ["ICLR.cc/2019/Conference/Paper63/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/fe25aa3d73b78f8f539d155035fc8a2be6884966.pdf", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving On-policy Learning with Statistical Reward Accumulation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgZrsC5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgWBi09Ym", "original": "S1lYp4VftX", "number": 64, "cdate": 1538087737292, "ddate": null, "tcdate": 1538087737292, "tmdate": 1538156249859, "tddate": null, "forum": "rkgWBi09Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-Modal Generative Adversarial Networks for Diverse Datasets", "abstract": "Generative Adversarial Networks (GANs) have been shown to produce realistically looking synthetic images with remarkable success, yet their performance seems less impressive when the training set is highly diverse. In order to provide a better fit to the target data distribution when the dataset includes many different classes, we propose a variant of the basic GAN model, a Multi-Modal Gaussian-Mixture GAN (GM-GAN), where the probability distribution over the latent space is a mixture of Gaussians. We also propose a supervised variant which is capable of conditional sample synthesis. In order to evaluate the model's performance, we propose a new scoring method which separately takes into account two (typically conflicting) measures - diversity vs. quality of the generated data.  Through a series of experiments, using both synthetic and real-world datasets, we quantitatively show that GM-GANs outperform baselines, both when evaluated using the commonly used Inception Score, and when evaluated using our own alternative scoring method. In addition, we qualitatively demonstrate how the unsupervised variant of GM-GAN tends to map latent vectors sampled from different Gaussians in the latent space to samples of different classes in the data space. We show how this phenomenon can be exploited for the task of unsupervised clustering, and provide quantitative evaluation showing the superiority of our method for the unsupervised clustering of image datasets. Finally, we demonstrate a feature which further sets our model apart from other GAN models: the option to control the quality-diversity trade-off by altering, post-training, the probability distribution of the latent space. This allows one to sample higher quality and lower diversity samples, or vice versa, according to one's needs.", "paperhash": "anonymous|multimodal_generative_adversarial_networks_for_diverse_datasets", "TL;DR": "Multi modal Guassian distribution of latent space in GAN models improves performance and allows to trade-off quality vs. diversity", "authorids": ["ICLR.cc/2019/Conference/Paper64/Authors"], "authors": ["Anonymous"], "keywords": ["generative adversarial networks", "generative models", "clustering", "visual object recognition"], "pdf": "/pdf/9581241e7ba8411f54fe22635236fd8108ea2a10.pdf", "_bibtex": "@inproceedings{    \nanonymous2019multi-modal,    \ntitle={Multi-Modal Generative Adversarial Networks for Diverse Datasets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgWBi09Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl-HsR9KX", "original": "B1lgU5MMYX", "number": 65, "cdate": 1538087737484, "ddate": null, "tcdate": 1538087737484, "tmdate": 1538156249648, "tddate": null, "forum": "rJl-HsR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discriminative Active Learning", "abstract": "We propose a new batch mode active learning algorithm designed for neural networks and large query batch sizes. The method, Discriminative Active Learning (DAL), poses active learning as a binary classification task, attempting to choose examples to label in such a way as to make the labeled set and the unlabeled pool indistinguishable. Experimenting on image classification tasks, we empirically show our method to be on par with state of the art methods in medium and large query batch sizes, while being simple to implement and also extend to other domains besides classification tasks. Our experiments also show that none of the state of the art methods of today are clearly better than uncertainty sampling, negating some of the reported results in the recent literature.", "paperhash": "anonymous|discriminative_active_learning", "TL;DR": "A new active learning algorithm for the batch mode setting using neural networks", "authorids": ["ICLR.cc/2019/Conference/Paper65/Authors"], "authors": ["Anonymous"], "keywords": ["Active Learning", "Neural Networks"], "pdf": "/pdf/ae2f233b7d9bc6456d2c09624017bebac2830416.pdf", "_bibtex": "@inproceedings{    \nanonymous2019discriminative,    \ntitle={Discriminative Active Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl-HsR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlMBjAcYX", "original": "B1lnJ_ActX", "number": 66, "cdate": 1538087737664, "ddate": null, "tcdate": 1538087737664, "tmdate": 1538156249442, "tddate": null, "forum": "rJlMBjAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance. In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines. Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization. Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper66/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1e5875aa94670102890369a0ee6874ac48b77ee2.pdf", "paperhash": "anonymous|optimizing_for_generalization_in_machine_learning_with_crossvalidation_gradients", "_bibtex": "@inproceedings{    \nanonymous2019optimizing,    \ntitle={Optimizing for Generalization in Machine Learning with Cross-Validation Gradients},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlMBjAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxGSsR9FQ", "original": "rkgApEZMYQ", "number": 67, "cdate": 1538087737844, "ddate": null, "tcdate": 1538087737844, "tmdate": 1538156249239, "tddate": null, "forum": "ByxGSsR9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "L2-Nonexpansive Neural Networks", "abstract": "This paper proposes a class of well-conditioned neural networks in which a unit amount of change in the inputs causes at most a unit amount of change in the outputs or any of the internal layers. We develop the known methodology of controlling Lipschitz constants to realize its full potential in maximizing robustness, with a new regularization scheme for linear layers, new ways to adapt nonlinearities and a new loss function. With MNIST and CIFAR-10 classifiers, we demonstrate a number of advantages. Without needing any adversarial training, the proposed classifiers exceed the state of the art in robustness against white-box L2-bounded adversarial attacks. They generalize better than ordinary networks from noisy data with partially random labels. Their outputs are quantitatively meaningful and indicate levels of confidence and generalization, among other desirable properties.", "paperhash": "anonymous|l2nonexpansive_neural_networks", "authorids": ["ICLR.cc/2019/Conference/Paper67/Authors"], "authors": ["Anonymous"], "keywords": ["adversarial defense", "regularization", "robustness", "generalization"], "pdf": "/pdf/e34a451c9819a2b0a51f6085ff65145c5ac02b2c.pdf", "_bibtex": "@inproceedings{    \nanonymous2019l2-nonexpansive,    \ntitle={L2-Nonexpansive Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxGSsR9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lGHsA9KX", "original": "S1eNFL0-YX", "number": 68, "cdate": 1538087738029, "ddate": null, "tcdate": 1538087738029, "tmdate": 1538156249034, "tddate": null, "forum": "H1lGHsA9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Resizable Mini-batch Gradient Descent based on a Multi-Armed Bandit", "abstract": "Determining the appropriate batch size for mini-batch gradient descent is always time consuming as it often relies on grid search. This paper considers a resizable mini-batch gradient descent (RMGD) algorithm based on a multi-armed bandit for achieving best performance in grid search by selecting an appropriate batch size at each epoch with a probability defined as a function of its previous success/failure. This probability encourages exploration of different batch size and then later exploitation of batch size with history of success. At each epoch, the RMGD samples a batch size from its probability distribution, then uses the selected batch size for mini-batch gradient descent. After obtaining the validation loss at each epoch, the probability distribution is updated to incorporate the effectiveness of the sampled batch size. The RMGD essentially assists the learning process to explore the possible domain of the batch size and exploit successful batch size. Experimental results show that the RMGD achieves performance better than the best performing single batch size. Furthermore, it, obviously, attains this performance in a shorter amount of time than grid search. It is surprising that the RMGD achieves better performance than grid search.", "paperhash": "anonymous|a_resizable_minibatch_gradient_descent_based_on_a_multiarmed_bandit", "TL;DR": "An optimization algorithm that explores various batch sizes based on probability and automatically exploits successful batch size which minimizes validation loss.", "authorids": ["ICLR.cc/2019/Conference/Paper68/Authors"], "authors": ["Anonymous"], "keywords": ["Batch size", "Optimization", "Mini-batch gradient descent", "Multi-armed bandit"], "pdf": "/pdf/2dec0de7fef4cc60a48110b3e2b5d0ca07224c04.pdf", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Resizable Mini-batch Gradient Descent based on a Multi-Armed Bandit},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lGHsA9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkeMHjR9Ym", "original": "rJxfoV9WKQ", "number": 69, "cdate": 1538087738211, "ddate": null, "tcdate": 1538087738211, "tmdate": 1538156248827, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "anonymous|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["ICLR.cc/2019/Conference/Paper69/Authors"], "authors": ["Anonymous"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/fd7f478e51e33d3691ca999d7b7c836445fab95c.pdf", "_bibtex": "@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeMHjR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyeGBj09Fm", "original": "BkxQbsw0uX", "number": 70, "cdate": 1538087738389, "ddate": null, "tcdate": 1538087738389, "tmdate": 1538156248618, "tddate": null, "forum": "HyeGBj09Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generating Liquid Simulations with Deformation-aware Neural Networks", "abstract": "We propose a novel approach for deformation-aware neural networks that learn the weighting and synthesis of dense volumetric deformation fields. Our method specifically targets the space-time representation of physical surfaces from liquid simulations. Liquids exhibit highly complex, non-linear behavior under changing simulation conditions such as different initial conditions. Our algorithm captures these complex phenomena in two stages: a first neural network computes a weighting function for a set of pre-computed deformations, while a second network directly generates a deformation field for refining the surface. Key for successful training runs in this setting is a suitable loss function that encodes the effect of the deformations, and a robust calculation of the corresponding gradients. To demonstrate the effectiveness of our approach, we showcase our method with several complex examples of flowing liquids with topology changes. Our representation makes it possible to rapidly generate the desired implicit surfaces. We have implemented a mobile application to demonstrate that real-time interactions with complex liquid effects are possible with our approach.", "paperhash": "anonymous|generating_liquid_simulations_with_deformationaware_neural_networks", "TL;DR": "Learning weighting and deformations of space-time data sets for highly efficient approximations of liquid behavior.", "authorids": ["ICLR.cc/2019/Conference/Paper70/Authors"], "authors": ["Anonymous"], "keywords": ["deformation learning", "spatial transformer networks", "fluid simulation"], "pdf": "/pdf/01c1d7fa3f5553d5953a1bd18e689543efe53dea.pdf", "_bibtex": "@inproceedings{    \nanonymous2019generating,    \ntitle={Generating Liquid Simulations with Deformation-aware Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeGBj09Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xQSjCqFQ", "original": "Hklbk67btm", "number": 71, "cdate": 1538087738572, "ddate": null, "tcdate": 1538087738572, "tmdate": 1538156248406, "tddate": null, "forum": "H1xQSjCqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Excitation Dropout: Encouraging Plasticity in Deep Neural Networks", "abstract": "We propose a guided dropout regularizer for deep networks based on the evidence of a network prediction: the firing of neurons in specific paths. In this work, we utilize the evidence at each neuron to determine the probability of dropout, rather than dropping out neurons uniformly at random as in standard dropout. In essence, we dropout with higher probability those neurons which contribute more to decision making at training time. This approach penalizes high saliency neurons that are most relevant for model prediction, i.e. those having stronger evidence. By dropping such high-saliency neurons, the network is forced to learn alternative paths in order to maintain loss minimization, resulting in a plasticity-like behavior, a characteristic of human brains too. We demonstrate better generalization ability, an increased utilization of network neurons, and a higher resilience to network compression using several metrics over four image/video recognition benchmarks.", "paperhash": "anonymous|excitation_dropout_encouraging_plasticity_in_deep_neural_networks", "TL;DR": "We propose a guided dropout regularizer for deep networks based on the evidence of a network prediction.", "authorids": ["ICLR.cc/2019/Conference/Paper71/Authors"], "authors": ["Anonymous"], "keywords": ["Dropout", "Saliency", "Deep Neural Networks"], "pdf": "/pdf/623c838a3bff4791d451bc23e6b2783d2f6888c0.pdf", "_bibtex": "@inproceedings{    \nanonymous2019excitation,    \ntitle={Excitation Dropout: Encouraging Plasticity in Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xQSjCqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlmHoR5tQ", "original": "H1eIaq_xKX", "number": 72, "cdate": 1538087738757, "ddate": null, "tcdate": 1538087738757, "tmdate": 1538156248205, "tddate": null, "forum": "HJlmHoR5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Imitation via Variational Inverse Reinforcement Learning", "abstract": "We consider a problem of learning a reward and policy from expert examples under unknown dynamics in high-dimensional scenarios. Our proposed method builds on the framework of generative adversarial networks and exploits reward shaping to learn near-optimal rewards and policies. Potential-based reward shaping functions are known to guide the learning agent whereas in this paper we bring forward their benefits in learning near-optimal rewards. Our method simultaneously learns a potential-based reward shaping function through variational information maximization along with the reward and policy under the adversarial learning formulation. We evaluate our method on various high-dimensional complex control tasks. We also evaluate our learned rewards in transfer learning problems where training and testing environments are made to be different from each other in terms of dynamics or structure. Our experimentation shows that our proposed method not only learns near-optimal rewards and policies matching expert behavior, but also performs significantly better than state-of-the-art inverse reinforcement learning algorithms.", "paperhash": "anonymous|adversarial_imitation_via_variational_inverse_reinforcement_learning", "TL;DR": "Our proposed method builds on GANs and exploits potential-based reward shaping to learn near-optimal rewards and policies from expert demonstrations.", "authorids": ["ICLR.cc/2019/Conference/Paper72/Authors"], "authors": ["Anonymous"], "keywords": ["Inverse Reinforcement Learning", "Imitation learning", "Variational lnference", "Learning from demonstrations"], "pdf": "/pdf/df27bd2cecfddfa6ac63df264d58fc0a180b2632.pdf", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Imitation via Variational Inverse Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlmHoR5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1fQSiCcYm", "original": "HkgqhPiF_m", "number": 73, "cdate": 1538087738937, "ddate": null, "tcdate": 1538087738937, "tmdate": 1538156248001, "tddate": null, "forum": "S1fQSiCcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer", "abstract": "Autoencoders provide a powerful framework for learning compressed representations by encoding all of the information needed to reconstruct a data point in a latent code. In some cases, autoencoders can \"interpolate\": By decoding the convex combination of the latent codes for two datapoints, the autoencoder can produce an output which semantically mixes characteristics from the datapoints. In this paper, we propose a regularization procedure which encourages interpolated outputs to appear more realistic by fooling a critic network which has been trained to recover the mixing coefficient from interpolated data. We then develop a simple benchmark task where we can quantitatively measure the extent to which various autoencoders can interpolate and show that our regularizer dramatically improves interpolation in this setting. We also demonstrate empirically that our regularizer produces latent codes which are more effective on downstream tasks, suggesting a possible link between interpolation abilities and learning useful representations.", "paperhash": "anonymous|understanding_and_improving_interpolation_in_autoencoders_via_an_adversarial_regularizer", "TL;DR": "We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.", "authorids": ["ICLR.cc/2019/Conference/Paper73/Authors"], "authors": ["Anonymous"], "keywords": ["autoencoders", "interpolation", "unsupervised learning", "representation learning", "adversarial learning"], "pdf": "/pdf/357b5d3f7f41676a64265e11c2a5a37e9250067a.pdf", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1fQSiCcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJfQrs0qt7", "original": "H1eyVgbgYQ", "number": 74, "cdate": 1538087739116, "ddate": null, "tcdate": 1538087739116, "tmdate": 1538156247801, "tddate": null, "forum": "HJfQrs0qt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Learning Dynamics of Deep Neural Networks", "abstract": "While a lot of progress has been made in recent years, the dynamics of learning in deep nonlinear neural networks remain to this day largely misunderstood. In this work, we study the case of binary classification and prove various properties of learning in such networks under strong assumptions such as linear separability of the data. Extending existing results from the linear case, we confirm empirical observations by proving that the classification error also follows a sigmoidal shape in nonlinear architectures. We show that given proper initialization, learning expounds parallel independent modes and that certain regions of parameter space might lead to failed training. We also demonstrate that input norm and features' frequency in the dataset lead to distinct convergence speeds which might shed some light on the generalization capabilities of deep neural networks. We provide a comparison between the dynamics of learning with cross-entropy and hinge losses, which could prove useful to understand recent progress in the training of generative adversarial networks. Finally, we identify a phenomenon that we baptize gradient starvation where the most frequent features in a dataset prevent the learning of other less frequent but equally informative features.", "paperhash": "anonymous|on_the_learning_dynamics_of_deep_neural_networks", "TL;DR": "This paper analyzes the learning dynamics of neural networks on classification tasks solved by gradient descent using the cross-entropy and hinge losses.", "authorids": ["ICLR.cc/2019/Conference/Paper74/Authors"], "authors": ["Anonymous"], "keywords": ["learning dynamics", "gradient descent", "classification", "optimization", "cross-entropy", "hinge loss", "implicit regularization", "gradient starvation"], "pdf": "/pdf/54c69d0b2eadffd6051e13cefe6dcd0cfeed3dee.pdf", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Learning Dynamics of Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJfQrs0qt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygQro05KX", "original": "BygGNz9yY7", "number": 75, "cdate": 1538087739288, "ddate": null, "tcdate": 1538087739288, "tmdate": 1538156247596, "tddate": null, "forum": "HygQro05KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "$A^*$ sampling with probability matching", "abstract": "Probabilistic methods often need to draw samples from a nontrivial distribution. $A^*$ sampling is a nice algorithm by building upon a top-down construction of a Gumbel process, where a large state space is divided into subsets and at each round $A^*$ sampling selects a subset to process. However, the selection rule depends on a bound function, which can be intractable. Moreover, we show that such a selection criterion can be inefficient. This paper aims to improve $A^*$ sampling by addressing these issues. To design a suitable selection rule, we apply \\emph{Probability Matching}, a widely used method for decision making, to $A^*$ sampling. We provide insights into the relationship between $A^*$ sampling and probability matching by analyzing a nontrivial special case in which the state space is partitioned into two subsets. We show that in this case probability matching is optimal within a constant gap. Furthermore, as directly applying probability matching to $A^*$ sampling is time consuming, we design an approximate version based on Monte-Carlo estimators. We also present an efficient implementation by leveraging special properties of Gumbel distributions and well-designed balanced trees. Empirical results show that our method saves a significantly amount of computational resources on suboptimal regions compared with $A^*$ sampling.", "paperhash": "anonymous|a^_sampling_with_probability_matching", "authorids": ["ICLR.cc/2019/Conference/Paper75/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/b6b0788d4814feecb2129cc6fd45dc67877a7886.pdf", "_bibtex": "@inproceedings{    \nanonymous2019$a^*$,    \ntitle={$A^*$ sampling with probability matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygQro05KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJeXSo09FQ", "original": "BJe_VKd1KX", "number": 76, "cdate": 1538087739462, "ddate": null, "tcdate": 1538087739462, "tmdate": 1538156247392, "tddate": null, "forum": "SJeXSo09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Localized Generative Models for 3D Point Clouds via Graph Convolution", "abstract": "Point clouds are an important type of geometric data and have widespread use in computer graphics and vision. However, learning representations for point clouds is particularly challenging due to their nature as being an unordered collection of points irregularly distributed in 3D space. Graph convolution, a generalization of the convolution operation for data defined over graphs, has been recently shown to be very successful at extracting localized features from point clouds in supervised or semi-supervised tasks such as classification or segmentation. This paper studies the unsupervised problem of a generative model exploiting graph convolution. We focus on the generator of a GAN and define methods for graph convolution when the graph is not known in advance as it is the very output of the generator. The proposed architecture learns to generate localized features that approximate graph embeddings of the output geometry. We also study the problem of defining an upsampling layer in the graph-convolutional generator, whereby it learns to exploit a self-similarity prior to sample the data distribution.", "paperhash": "anonymous|learning_localized_generative_models_for_3d_point_clouds_via_graph_convolution", "TL;DR": "A GAN using graph convolution operations with dynamically computed graphs from hidden features", "authorids": ["ICLR.cc/2019/Conference/Paper76/Authors"], "authors": ["Anonymous"], "keywords": ["GAN", "graph convolution", "point clouds"], "pdf": "/pdf/d179dd225157a9dc80a442eb1733cb48b17a0365.pdf", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Localized Generative Models for 3D Point Clouds via Graph Convolution},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJeXSo09FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rke4HiAcY7", "original": "rJxVUUUJtQ", "number": 77, "cdate": 1538087739641, "ddate": null, "tcdate": 1538087739641, "tmdate": 1538156247186, "tddate": null, "forum": "rke4HiAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pathologies in information bottleneck for deterministic supervised learning", "abstract": "Information bottleneck (IB) is a method for extracting information from one random variable X that is relevant for predicting another random variable Y. To do so, IB identifies an intermediate \"bottleneck variable\" T that has low mutual information I(X;T) and high mutual information  I(Y;T). The \"IB curve\" characterizes the set of bottleneck variables that achieve maximal I(Y;T) for a given I(X;T), and is typically explored by optimizing the \"IB Lagrangian\", I(Y;T) - \u03b2I(X;T). Recently, there has been interest in applying IB to supervised learning, particularly for classification problems that use neural networks. In most classification problems, the output class Y is a deterministic function of the input X, which we refer to as \"deterministic supervised learning\". We demonstrate three pathologies that arise when IB is used in any scenario where Y is a deterministic function of X: (1) the IB curve cannot be recovered by optimizing the IB Lagrangian for different values of \u03b2; (2) there are \"uninteresting\" solutions at all points of the IB curve; and (3) for classifiers that achieve low error rates, the activity of different hidden layers will not exhibit a strict trade-off between compression and prediction, contrary to a recent proposal. To address problem (1), we propose a functional that, unlike the IB Lagrangian, can recover the IB curve in all cases. We finish by demonstrating these issues on the MNIST dataset.", "paperhash": "anonymous|pathologies_in_information_bottleneck_for_deterministic_supervised_learning", "TL;DR": "Information bottleneck has pathologies in supervised learning scenarios where the output is a deterministic function of the input.", "authorids": ["ICLR.cc/2019/Conference/Paper77/Authors"], "authors": ["Anonymous"], "keywords": ["information bottleneck", "supervised learning", "deep learning", "information theory"], "pdf": "/pdf/b60a5fa4e638a84ffb2b0feac14f620d09b6960d.pdf", "_bibtex": "@inproceedings{    \nanonymous2019pathologies,    \ntitle={Pathologies in information bottleneck for deterministic supervised learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rke4HiAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gNHs05FX", "original": "ryljFK6COX", "number": 78, "cdate": 1538087739831, "ddate": null, "tcdate": 1538087739831, "tmdate": 1538156246979, "tddate": null, "forum": "H1gNHs05FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Clinical Risk: wavelet reconstruction networks for marked point processes", "abstract": "Timestamped sequences of events, pervasive in domains with data logs, e.g., health records, are often modeled as point processes with rate functions over time. Leading classical methods for risk scores such as Cox and Hawkes processes use such data but make strong assumptions about the shape and form of multivariate influences, resulting in time-to-event distributions irreflective of many real world processes. Recent methods in point processes and recurrent neural networks capably model rate functions but may be complex and difficult to interrogate. Our work develops a high-performing, interrogable model.  We introduce wavelet reconstruction networks, a multivariate point process with a sparse wavelet reconstruction kernel to model rate functions from marked, timestamped data. We show they achieve improved performance and interrogability over baselines in forecasting complications and scheduled care visits in patients with diabetes.", "paperhash": "anonymous|clinical_risk_wavelet_reconstruction_networks_for_marked_point_processes", "TL;DR": "Wavelet reconstructions on relative time, used in absolute-time point process models, improve risk prediction of complications and adherence in diabetes.", "authorids": ["ICLR.cc/2019/Conference/Paper78/Authors"], "authors": ["Anonymous"], "keywords": ["point processes", "wavelets", "temporal neural networks", "Hawkes processes"], "pdf": "/pdf/2afccc06e9ff27a485ac285b754275b54785c138.pdf", "_bibtex": "@inproceedings{    \nanonymous2019clinical,    \ntitle={Clinical Risk: wavelet reconstruction networks for marked point processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gNHs05FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl4BsR5KX", "original": "H1lerc30um", "number": 79, "cdate": 1538087739999, "ddate": null, "tcdate": 1538087739999, "tmdate": 1538156246772, "tddate": null, "forum": "rJl4BsR5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural Networks and Memory Networks", "abstract": "k-Nearest Neighbors is one of the most fundamental but effective classification models. In this paper, we propose two families of models built on a sequence to sequence model and a memory network model to mimic the k-Nearest Neighbors model, which generate a sequence of labels, a sequence of out-of-sample feature vectors and a final label for classification, and thus they could also function as oversamplers. We also propose `out-of-core' versions of our models which assume that only a small portion of data can be loaded into memory. Computational experiments show that our models outperform k-Nearest Neighbors, a feed-forward neural network and a memory network, due to the fact that our models must produce additional output and not just the label. As an oversampler on imbalanced datasets, the sequence to sequence kNN model often outperforms Synthetic Minority Over-sampling Technique and Adaptive Synthetic Sampling.\n", "paperhash": "anonymous|knearest_neighbors_by_means_of_sequence_to_sequence_deep_neural_networks_and_memory_networks", "authorids": ["ICLR.cc/2019/Conference/Paper79/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/51acf3f6c9e86f207f689eceabd764aa5d591a52.pdf", "_bibtex": "@inproceedings{    \nanonymous2019k-nearest,    \ntitle={k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural Networks and Memory Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl4BsR5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJM4rsRqFX", "original": "B1g46xj6O7", "number": 80, "cdate": 1538087740222, "ddate": null, "tcdate": 1538087740222, "tmdate": 1538156246546, "tddate": null, "forum": "HJM4rsRqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Variational Inference For Embedding Knowledge Graphs", "abstract": "Recent advances in Neural Variational Inference allowed for a renaissance in latent variable models in a variety of domains involving high-dimensional data. In this paper, we introduce two generic Variational Inference frameworks for generative models of Knowledge Graphs; Latent Fact Model and Latent Information Model.  While traditional variational methods derive an analytical approximation for the intractable distribution over the latent variables, here we construct an inference network conditioned on the symbolic representation of entities and relation types in the Knowledge Graph, to provide the variational distributions. The new framework can create models able to discover underlying probabilistic semantics for the symbolic representation by utilising parameterisable distributions which permit training by back-propagation in the context of neural variational inference, resulting in a highly-scalable method. Under a Bernoulli sampling framework, we provide an alternative justification for commonly used techniques in large-scale stochastic variational inference, which drastically reduces training time at a cost of an additional approximation to the variational lower bound.  The generative frameworks are flexible enough to allow training under any prior distribution that permits a re-parametrisation trick, as well as under any scoring function that permits maximum likelihood estimation of the parameters. Experiment results display the potential and efficiency of this framework by improving upon multiple benchmarks with Gaussian prior representations. Code publicly available on Github additionally allows learning Hyperspherical representations under a von-Mises Fisher prior distribution. ", "paperhash": "anonymous|neural_variational_inference_for_embedding_knowledge_graphs", "TL;DR": "Working toward generative knowledge graph models to better estimate predictive uncertainty in knowledge inference. ", "authorids": ["ICLR.cc/2019/Conference/Paper80/Authors"], "authors": ["Anonymous"], "keywords": ["Statistical Relational Learning", "Knowledge Graphs", "Knowledge Extraction", "Latent Feature Models", "Variational Inference."], "pdf": "/pdf/65ce33c74966378df34ed13e5b0ef78778a462dd.pdf", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Variational Inference For Embedding Knowledge Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJM4rsRqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJM4SjR5KQ", "original": "HkxEPgO0um", "number": 81, "cdate": 1538087740404, "ddate": null, "tcdate": 1538087740404, "tmdate": 1538156246262, "tddate": null, "forum": "HJM4SjR5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected Entities", "abstract": "We propose a framework to model the distribution of sequential data coming from\na set of entities connected in a graph with a known topology. The method is\nbased on a mixture of shared hidden Markov models (HMMs), which are trained\nin order to exploit the knowledge of the graph structure and in such a way that the\nobtained mixtures tend to be sparse. Experiments in different application domains\ndemonstrate the effectiveness and versatility of the method.", "paperhash": "anonymous|spamhmm_sparse_mixture_of_hidden_markov_models_for_graph_connected_entities", "TL;DR": "A method to model the generative distribution of sequences coming from graph connected entities.", "authorids": ["ICLR.cc/2019/Conference/Paper81/Authors"], "authors": ["Anonymous"], "keywords": ["multi-entity sequential data", "hidden markov models"], "pdf": "/pdf/07cc47ade35cb7a7e403954909325ba469a6e2e9.pdf", "_bibtex": "@inproceedings{    \nanonymous2019spamhmm:,    \ntitle={SpaMHMM: Sparse Mixture of Hidden Markov Models for Graph Connected Entities},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJM4SjR5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgBHoCqYX", "original": "SklWTYwRu7", "number": 82, "cdate": 1538087740585, "ddate": null, "tcdate": 1538087740585, "tmdate": 1538156246053, "tddate": null, "forum": "rkgBHoCqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Kernel Random Matrix-Based Approach for Sparse PCA", "abstract": "In this paper, we present a random matrix approach to recover sparse principal components from n p-dimensional vectors. Specifically, considering the large dimensional setting where n, p \u2192 \u221e with p/n \u2192 c \u2208 (0, \u221e) and under Gaussian vector observations, we study kernel random matrices of the type f (\u0108), where f is a three-times continuously differentiable function applied entry-wise to the sample covariance matrix \u0108 of the data. Then, assuming that the principal components are sparse, we show that taking f in such a way that f'(0) = f''(0) = 0 allows for powerful recovery of the principal components, thereby generalizing previous ideas involving more specific f functions such as the soft-thresholding function.", "paperhash": "anonymous|a_kernel_random_matrixbased_approach_for_sparse_pca", "authorids": ["ICLR.cc/2019/Conference/Paper82/Authors"], "authors": ["Anonymous"], "keywords": ["Random Matrix Theory", "Concentration of Measure", "Sparse PCA", "Covariance Thresholding"], "pdf": "/pdf/5a5ae035c96399d605d91b140a31382759eaea67.pdf", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Kernel Random Matrix-Based Approach for Sparse PCA},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgBHoCqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkxSHsC5FQ", "original": "S1g-aEu9um", "number": 83, "cdate": 1538087740772, "ddate": null, "tcdate": 1538087740772, "tmdate": 1538156245843, "tddate": null, "forum": "BkxSHsC5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SupportNet: solving catastrophic forgetting in class incremental learning with support data", "abstract": "A plain well-trained deep learning model often does not have the ability to learn new knowledge without forgetting the previously learned knowledge, which is known as catastrophic forgetting. Here we propose a novel method, SupportNet, to efficiently and effectively solve the catastrophic forgetting problem in the class incremental learning scenario. SupportNet combines the strength of deep learning and support vector machine (SVM), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training so that the model can review the essential information of the old data when learning the new information. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. We validate our method with comprehensive experiments on various tasks, which show that SupportNet drastically outperforms the state-of-the-art incremental learning methods and even reaches similar performance as the deep learning model trained from scratch on both old and new data.", "paperhash": "anonymous|supportnet_solving_catastrophic_forgetting_in_class_incremental_learning_with_support_data", "authorids": ["ICLR.cc/2019/Conference/Paper83/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/897a2a53969ae5155ef00e9cb345d9212278350f.pdf", "_bibtex": "@inproceedings{    \nanonymous2019supportnet:,    \ntitle={SupportNet: solving catastrophic forgetting in class incremental learning with support data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkxSHsC5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GSBsRcFX", "original": "SJlZP5E6OX", "number": 84, "cdate": 1538087740954, "ddate": null, "tcdate": 1538087740954, "tmdate": 1538156245636, "tddate": null, "forum": "B1GSBsRcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stop memorizing: A data-dependent regularization framework for intrinsic pattern learning", "abstract": "Deep neural networks (DNNs) typically have enough capacity to fit random data by brute force even when conventional data-dependent regularizations focusing on the geometry of the features are imposed. We find out that the reason for this is the inconsistency between the enforced geometry and the standard softmax cross entropy loss. To resolve this, we propose a new framework for data-dependent DNN regularization, the Geometrically-Regularized-Self-Validating neural Networks (GRSVNet). During training, the geometry enforced on one batch of features is simultaneously validated on a separate batch using a validation loss consistent with the geometry. We study  a particular case of GRSVNet, the Orthogonal-Low-rank Embedding (OLE)-GRSVNet, which is capable of producing highly discriminative features residing in orthogonal low-rank subspaces. Numerical experiments show that OLE-GRSVNet outperforms DNNs with conventional regularization when trained on real data. More importantly, unlike conventional DNNs, OLE-GRSVNet refuses to memorize random data or random labels, suggesting it only learns intrinsic patterns by reducing the memorizing capacity of the baseline DNN.", "paperhash": "anonymous|stop_memorizing_a_datadependent_regularization_framework_for_intrinsic_pattern_learning", "TL;DR": "we propose a new framework for data-dependent DNN regularization that can prevent DNNs from overfitting random data or random labels.", "authorids": ["ICLR.cc/2019/Conference/Paper84/Authors"], "authors": ["Anonymous"], "keywords": ["deep neural networks", "memorizing", "data-dependent regularization"], "pdf": "/pdf/fbf3bad55a29c48cd74c3d470ebe5ccaeb147e61.pdf", "_bibtex": "@inproceedings{    \nanonymous2019stop,    \ntitle={Stop memorizing: A data-dependent regularization framework for intrinsic pattern learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GSBsRcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1MSBjA9Ym", "original": "rkgLXrB3Om", "number": 85, "cdate": 1538087741140, "ddate": null, "tcdate": 1538087741140, "tmdate": 1538156245429, "tddate": null, "forum": "r1MSBjA9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Collapse of deep and narrow neural nets", "abstract": "Recent theoretical work has demonstrated that deep neural networks have superior performance over shallow networks, but their training is more difficult, e.g., they suffer from the vanishing gradient problem. This problem can be typically resolved by the rectified linear unit (ReLU) activation. However, here we show that even for such activation, deep and narrow neural networks will converge to erroneous mean or median states of the target function depending on the loss with high probability. We demonstrate this collapse of deep and narrow neural networks both numerically and theoretically, and provide estimates of the probability of collapse. We also construct a diagram of a safe region of designing neural networks that avoid the collapse to erroneous states. Finally, we examine different ways of initialization and normalization that may avoid the collapse problem.", "paperhash": "anonymous|collapse_of_deep_and_narrow_neural_nets", "TL;DR": "Deep and narrow neural networks will converge to erroneous mean or median states of the target function depending on the loss with high probability.", "authorids": ["ICLR.cc/2019/Conference/Paper85/Authors"], "authors": ["Anonymous"], "keywords": ["neural networks", "deep and narrow", "ReLU", "collapse"], "pdf": "/pdf/b3d4bc9d6e92acb17e27985ea0d9b434b160cf0d.pdf", "_bibtex": "@inproceedings{    \nanonymous2019collapse,    \ntitle={Collapse of deep and narrow neural nets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1MSBjA9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlSHsAcK7", "original": "HJgQms2tdm", "number": 86, "cdate": 1538087741316, "ddate": null, "tcdate": 1538087741316, "tmdate": 1538156245220, "tddate": null, "forum": "BJlSHsAcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Overcoming catastrophic forgetting through weight consolidation and long-term memory", "abstract": "Sequential learning of multiple tasks in artificial neural networks using gradient descent leads to catastrophic forgetting, whereby previously learned knowledge is erased during learning of new, disjoint knowledge. Here, we propose a new approach to sequential learning which leverages the recent discovery of adversarial examples. We use adversarial subspaces from previous tasks to enable learning of new tasks with less interference. We apply our method to sequentially learning to classify digits 0, 1, 2 (task 1), 4, 5, 6, (task 2), and 7, 8, 9 (task 3) in MNIST (disjoint MNIST task). We compare and combine our Adversarial Direction (AD) method with the recently proposed Elastic Weight Consolidation (EWC) method for sequential learning. We train each task for 20 epochs, which yields good initial performance (99.24% correct task 1 performance). After training task 2, and then task 3, both plain gradient descent (PGD) and EWC largely forget task 1 (task 1 accuracy 32.95% for PGD and 41.02% for EWC), while our combined approach (AD+EWC) still achieves 94.53% correct on task 1. We obtain similar results with a much more difficult disjoint CIFAR10 task (70.10% initial task 1 performance, 67.73% after learning tasks 2 and 3 for AD+EWC, while PGD and EWC both fall to chance level). We confirm qualitatively similar results for EMNIST with 5 tasks and under 3 variants of our approach. Our results suggest that AD+EWC can provide better sequential learning performance than either PGD or EWC.", "paperhash": "anonymous|overcoming_catastrophic_forgetting_through_weight_consolidation_and_longterm_memory", "TL;DR": "We enable sequential learning of multiple tasks by adding task-dependent memory units to avoid interference between tasks", "authorids": ["ICLR.cc/2019/Conference/Paper86/Authors"], "authors": ["Anonymous"], "keywords": ["Catastrophic Forgetting", "Life-Long Learning", "adversarial examples"], "pdf": "/pdf/d416b27ccc89fe33c2a5d954a1277f2bb407f0bb.pdf", "_bibtex": "@inproceedings{    \nanonymous2019overcoming,    \ntitle={Overcoming catastrophic forgetting through weight consolidation and long-term memory},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlSHsAcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1erHoR5t7", "original": "HklMWLIYu7", "number": 87, "cdate": 1538087741492, "ddate": null, "tcdate": 1538087741492, "tmdate": 1538156245014, "tddate": null, "forum": "S1erHoR5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": " The relativistic discriminator: a key element missing from standard GAN", "abstract": "In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. \n\nWe show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. \n\nEmpirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.", "paperhash": "anonymous|the_relativistic_discriminator_a_key_element_missing_from_standard_gan", "TL;DR": "Improving the quality and stability of GANs using a relativistic discriminator; IPM GANs (such as WGAN-GP) are a special case.", "authorids": ["ICLR.cc/2019/Conference/Paper87/Authors"], "authors": ["Anonymous"], "keywords": ["AI", "deep learning", "generative models", "GAN"], "pdf": "/pdf/6f08e177c7628c9b522eb7632606fe32fb65b534.pdf", "_bibtex": "@inproceedings{    \nanonymous2019,    \ntitle={ The relativistic discriminator: a key element missing from standard GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1erHoR5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1l8SsR9Fm", "original": "H1gBRL4KFQ", "number": 88, "cdate": 1538087741725, "ddate": null, "tcdate": 1538087741725, "tmdate": 1538156244805, "tddate": null, "forum": "B1l8SsR9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning and Data Selection in Big Datasets", "abstract": "Finding a dataset of minimal cardinality to characterize the optimal parameters of a model is of paramount importance in machine learning and distributed optimization over a network. This paper investigates the compressibility of large datasets. More specifically, we propose a framework that jointly learns the input-output mapping as well as the most representative samples of the dataset (sufficient dataset). Our analytical results show that the cardinality of the sufficient dataset increases sub-linearly with respect to the original dataset size. Numerical evaluations of real datasets reveal a large compressibility, up to 95%, without a noticeable drop in the learnability performance, measured by the generalization error.\n", "paperhash": "anonymous|learning_and_data_selection_in_big_datasets", "authorids": ["ICLR.cc/2019/Conference/Paper88/Authors"], "authors": ["Anonymous"], "keywords": ["Data selection", "non-convex optimization", "learning theory", "active learning"], "pdf": "/pdf/950bfcaecf33e7b94f86ceaaed0ffa9947a63e11.pdf", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning and Data Selection in Big Datasets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l8SsR9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeLBj0qFQ", "original": "HJlaQEBtKQ", "number": 89, "cdate": 1538087741900, "ddate": null, "tcdate": 1538087741900, "tmdate": 1538156244595, "tddate": null, "forum": "ByeLBj0qFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Image to Sequence Translation with Canvas-Drawer Networks", "abstract": "Encoding images as a series of high-level constructs, such as brush strokes or discrete shapes, can often be key to both human and machine understanding. In many cases, however, data is only available in pixel form. We present a method for generating images directly in a high-level domain (e.g.  brush strokes), without the need for real pairwise data.  Specifically, we train a \u201dcanvas\u201d network to imitate the mapping of high-level constructs to pixels, followed by a high-level \u201ddrawing\u201d network which is optimized through this mapping towards solving a desired image recreation or translation task.  We successfully discover sequential vector representations of symbols,  large sketches,  and 3D objects,  utilizing only pixel data.  We display applications of our method in image segmentation, and present several ablation studies comparing various configurations.", "keywords": ["image", "translation", "unsupervised", "model-based"], "authorids": ["ICLR.cc/2019/Conference/Paper89/Authors"], "authors": ["Anonymous"], "TL;DR": "Recreate images as interpretable high-level sequences without the need for paired data.", "pdf": "/pdf/55a96902097a8ff59d5de05fdd624ac24a9ac6b4.pdf", "paperhash": "anonymous|unsupervised_image_to_sequence_translation_with_canvasdrawer_networks", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Image to Sequence Translation with Canvas-Drawer Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeLBj0qFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkeUrjCcYQ", "original": "BkxjWXrKKQ", "number": 90, "cdate": 1538087742087, "ddate": null, "tcdate": 1538087742087, "tmdate": 1538156244382, "tddate": null, "forum": "rkeUrjCcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Monge-Amp\\`ere Flow for Generative Modeling", "abstract": "We present a deep generative model, named Monge-Amp\\`ere flow, which builds on continuous-time gradient flow arising from the Monge-Amp\\`ere equation in optimal transport theory. The generative map from the latent space to the data space follows a dynamical system, where a learnable potential function guides a compressible fluid to flow towards the target density distribution. Training of the model amounts to solving an optimal control problem. The Monge-Amp\\`ere flow has tractable likelihoods and supports efficient sampling and inference. One can easily impose symmetry constraints in the generative model by designing suitable scalar potential functions. We apply the approach to unsupervised density estimation of the MNIST dataset and variational calculation of the two-dimensional Ising model at the critical point.  This approach brings insights and techniques from Monge-Amp\\`ere equation, optimal transport, and fluid dynamics into reversible flow-based generative models. ", "keywords": ["generative modeling", "Monge-Amp\\`ere equation", "dynamical system", "optimal transport", "density estimation", "free energy calculation"], "authorids": ["ICLR.cc/2019/Conference/Paper90/Authors"], "authors": ["Anonymous"], "TL;DR": "A gradient flow based dynamical system for invertible generative modeling", "pdf": "/pdf/5e2518bc5a2e28eab640ccbb84edbe13a4c1fcf6.pdf", "paperhash": "anonymous|mongeamp\\`ere_flow_for_generative_modeling", "_bibtex": "@inproceedings{    \nanonymous2019monge-amp\\`ere,    \ntitle={Monge-Amp\\`ere Flow for Generative Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeUrjCcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MUroRct7", "original": "HyxwG7IYF7", "number": 91, "cdate": 1538087742271, "ddate": null, "tcdate": 1538087742271, "tmdate": 1538156244174, "tddate": null, "forum": "B1MUroRct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Online Learning for Supervised Dimension Reduction", "abstract": " Online learning has attracted great attention due to the increasing demand for systems that have the ability of learning and evolving. When the data to be processed is also high dimensional and dimension reduction is necessary for visualization or prediction enhancement, online dimension reduction will play an essential role. The purpose of this paper is to propose new online learning approaches for supervised dimension reduction. Our first algorithm is motivated by adapting the sliced inverse regression (SIR), a pioneer and effective algorithm for supervised dimension reduction, and making it implementable in an incremental manner. The new algorithm, called incremental sliced inverse regression (ISIR), is able to update the subspace of significant factors with intrinsic lower dimensionality fast and efficiently when new observations come in. We also refine the algorithm by using an overlapping technique  and develop an incremental overlapping sliced inverse regression (IOSIR) algorithm. We verify the effectiveness and efficiency of both algorithms by simulations and real data applications.", "keywords": ["Online Learning", "Supervised Dimension Reduction", "Incremental Sliced Inverse Regression", "Effective Dimension Reduction Space"], "authorids": ["ICLR.cc/2019/Conference/Paper91/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed two new approaches,  the incremental sliced inverse regression and incremental overlapping sliced inverse regression, to implement supervised dimension reduction in an online learning manner.", "pdf": "/pdf/d13a831ec42dbd62b5cf904145014c0bfc59695a.pdf", "paperhash": "anonymous|online_learning_for_supervised_dimension_reduction", "_bibtex": "@inproceedings{    \nanonymous2019online,    \ntitle={Online Learning for Supervised Dimension Reduction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MUroRct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MIBs05F7", "original": "S1lGn7LYKQ", "number": 92, "cdate": 1538087742450, "ddate": null, "tcdate": 1538087742450, "tmdate": 1538156243974, "tddate": null, "forum": "B1MIBs05F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Ineffectiveness of Variance Reduced Optimization for Deep Learning", "abstract": "The application of stochastic variance reduction to optimization has shown remarkable recent theoretical and practical success. The applicability of these techniques to the hard non-convex optimization problems encountered during training of modern deep neural networks is an open problem. We show that naive application of the SVRG technique and related approaches fail, and explore why.", "keywords": ["machine learning", "optimization", "variance reduction"], "authorids": ["ICLR.cc/2019/Conference/Paper92/Authors"], "authors": ["Anonymous"], "TL;DR": "The SVRG method fails on modern deep learning problems", "pdf": "/pdf/97f529d6bf814a554ed365b23f5301d48c3902c6.pdf", "paperhash": "anonymous|on_the_ineffectiveness_of_variance_reduced_optimization_for_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Ineffectiveness of Variance Reduced Optimization for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MIBs05F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lwSsC5KX", "original": "SklUzKUKKm", "number": 93, "cdate": 1538087742621, "ddate": null, "tcdate": 1538087742621, "tmdate": 1538156243765, "tddate": null, "forum": "B1lwSsC5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "D\u00e9j\u00e0 Vu: An Empirical Evaluation of the Memorization Properties of Convnets", "abstract": "Convolutional neural networks memorize part of their training data, which is why strategies such as data augmentation and drop-out are employed to mitigate overfitting. This paper considers the related question of ``membership inference'', where the goal is to determine if an image was used during training.  We consider it under three complementary angles. We first analyze explicit memorization and extend classical random label experiments to the problem of learning a model that predicts if an image belongs to an arbitrary set. We then show how to detect if a dataset was used to train a model, and in particular whether some validation images were used at train time. Finally, we propose a new approach to infer membership when a few of the top layers are not available or have been fine-tuned, and show that lower layers still carry information about the training samples. To support our findings, we conduct large-scale experiments on Imagenet and subsets of YFCC-100M with modern architectures such as VGG and Resnet.", "keywords": ["membership inference", "memorization", "attack", "privacy"], "authorids": ["ICLR.cc/2019/Conference/Paper93/Authors"], "authors": ["Anonymous"], "TL;DR": "We analyze the memorization properties by a convnet of the training set and propose several use-cases where we can extract some information about the training set. ", "pdf": "/pdf/0ff16c0db416182ff3a6da3f177b19302b05cf6e.pdf", "paperhash": "anonymous|d\u00e9j\u00e0_vu_an_empirical_evaluation_of_the_memorization_properties_of_convnets", "_bibtex": "@inproceedings{    \nanonymous2019d\u00e9j\u00e0,    \ntitle={D\u00e9j\u00e0 Vu: An Empirical Evaluation of the Memorization Properties of Convnets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lwSsC5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxvSiCcFQ", "original": "S1lMnMEYtX", "number": 94, "cdate": 1538087742801, "ddate": null, "tcdate": 1538087742801, "tmdate": 1538156243559, "tddate": null, "forum": "SyxvSiCcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Network Cost Landscapes as Quantum States", "abstract": "Quantum computers promise significant advantages over classical computers for a number of different applications. We show that the complete loss function landscape of a neural network can be represented as the quantum state output by a quantum computer. We demonstrate this explicitly for a binary neural network and, further, show how a quantum computer can train the network by manipulating this state using a well-known algorithm known as quantum amplitude amplification. We further show that with minor adaptation, this method can also represent the meta-loss landscape of a number of neural network architectures simultaneously. We search this meta-loss landscape with the same method to simultaneously train and design a binary neural network. ", "keywords": ["quantum", "neural networks", "meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper94/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that NN parameter and hyperparamter cost landscapes can be generated as quantum states using a single quantum circuit and that these can be used for training and meta-training.", "pdf": "/pdf/8dedaacda4cd63b55237cf1ed6312a035eeb24d2.pdf", "paperhash": "anonymous|neural_network_cost_landscapes_as_quantum_states", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Network Cost Landscapes as Quantum States},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxvSiCcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJMvBjC5YQ", "original": "H1g-c-aHFQ", "number": 95, "cdate": 1538087742985, "ddate": null, "tcdate": 1538087742985, "tmdate": 1538156243351, "tddate": null, "forum": "BJMvBjC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cutting Down Training Memory by Re-fowarding", "abstract": "Deep Neutral Networks(DNNs) require huge GPU memory when training on modern image/video databases. Unfortunately, the GPU memory as a hardware resource is always finite, which limits the image resolution, batch size, and learning rate that could be used for better DNN performance. In this paper, we propose a novel training approach, called Re-forwarding, that substantially reduces memory usage in training. Our approach automatically finds a subset of layers in DNNs, and stores tensors only at these layers during the first forward. During backward, extra local forwards (called the Re-forwarding process) are conducted to compute the missing tensors between the subset of layers. The total memory cost becomes the sum of (1) the memory cost at the subset of layers and (2) the maximum memory cost among local re-forwards. Re-forwarding trades training time for memory and does not compromise any performance in testing. We propose theories and algorithms that achieve the optimal memory solutions for DNNs with either linear or arbitrary computation graphs. Experiments show that Re-forwarding cuts down up-to 80% of training memory on popular DNNs such as Alexnet, VGG, ResNet, Densenet and Inception net.", "keywords": ["deep learning", "training memory", "computation-memory trade off", "optimal solution"], "authorids": ["ICLR.cc/2019/Conference/Paper95/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes fundamental theory and optimal algorithms for DNN training, which reduce up to 80% of training memory for popular DNNs.", "pdf": "/pdf/0f014bf17579ea5850fe3ae72b0b68dc1189e8c6.pdf", "paperhash": "anonymous|cutting_down_training_memory_by_refowarding", "_bibtex": "@inproceedings{    \nanonymous2019cutting,    \ntitle={Cutting Down Training Memory by Re-fowarding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJMvBjC5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkMwHsCctm", "original": "rJeFi1OKtX", "number": 96, "cdate": 1538087743169, "ddate": null, "tcdate": 1538087743169, "tmdate": 1538156243139, "tddate": null, "forum": "HkMwHsCctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Principled Deep Neural Network Training through Linear Programming", "abstract": "Deep Learning has received significant attention due to its impressive performance in many state-of-the-art learning tasks. Unfortunately, while very powerful, Deep Learning is not well understood theoretically and in particular only recently results for the complexity of training deep neural networks have been obtained. In this work we show that large classes of deep neural networks with various architectures (e.g., DNNs, CNNs, Binary Neural Networks, and ResNets), activation functions (e.g., ReLUs and leaky ReLUs), and loss functions (e.g., Hinge loss, Euclidean loss, etc) can be trained to near optimality with desired target accuracy using linear programming in time that is exponential in the size of the architecture and polynomial in the size of the data set; this is the best one can hope for due to the NP-Hardness of the problem and in line with previous work. In particular, we obtain polynomial time algorithms for training for a given fixed network architecture. Our work applies more broadly to empirical risk minimization problems which allows us to generalize various previous results and obtain new complexity results for previously unstudied architectures in the proper learning setting.", "keywords": ["deep learning theory", "neural network training", "empirical risk minimization", "non-convex optimization", "treewidth"], "authorids": ["ICLR.cc/2019/Conference/Paper96/Authors"], "authors": ["Anonymous"], "TL;DR": "Using linear programming we show that the computational complexity of approximate Deep Neural Network training depends polynomially on the data size for several architectures", "pdf": "/pdf/ef76a730115f7ba8cc04b67e64471e0d9653de28.pdf", "paperhash": "anonymous|principled_deep_neural_network_training_through_linear_programming", "_bibtex": "@inproceedings{    \nanonymous2019principled,    \ntitle={Principled Deep Neural Network Training through Linear Programming},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkMwHsCctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1NDBsAqY7", "original": "SJeL5ldttQ", "number": 97, "cdate": 1538087743350, "ddate": null, "tcdate": 1538087743350, "tmdate": 1538156242931, "tddate": null, "forum": "r1NDBsAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Word Discovery with Segmental Neural Language Models", "abstract": "We propose a segmental neural language model that combines the representational power of neural networks and the structure learning mechanism of Bayesian nonparametrics, and show that it learns to discover semantically meaningful units (e.g., morphemes and words) from unsegmented character sequences. The model generates text as a sequence of segments, where each segment is generated either character-by-character from a sequence model or as a single draw from a lexical memory that stores multi-character units. Its parameters are fit to maximize the marginal likelihood of the training data, summing over all segmentations of the input, and its hyperparameters are likewise set to optimize held-out marginal likelihood.\nTo prevent the model from overusing the lexical memory, which leads to poor generalization and bad segmentation, we introduce a differentiable regularizer that penalizes based on the expected length of each segment. To our knowledge, this is the first demonstration of neural networks that have predictive distributions better than LSTM language models and also infer a segmentation into word-like units that are competitive with the best existing word discovery models.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper97/Authors"], "authors": ["Anonymous"], "TL;DR": "A LSTM language model that discovers words from unsegmented sequences of characters.", "pdf": "/pdf/e28755b019f2b6f54c02f81332378de81217cadc.pdf", "paperhash": "anonymous|unsupervised_word_discovery_with_segmental_neural_language_models", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Word Discovery with Segmental Neural Language Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1NDBsAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJg_roAcK7", "original": "Bkgsfj-FKm", "number": 98, "cdate": 1538087743530, "ddate": null, "tcdate": 1538087743530, "tmdate": 1538156242720, "tddate": null, "forum": "BJg_roAcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "INVASE: Instance-wise Variable Selection using Neural Networks", "abstract": "The advent of big data brings with it data with more and more dimensions and thus a growing need to be able to efficiently select which features to use for a variety of problems. While global feature selection has been a well-studied problem for quite some time, only recently has the paradigm of instance-wise feature selection been developed. In this paper, we propose a new instance-wise feature selection method, which we term INVASE. INVASE consists of 3 neural networks, a selector network, a predictor network and a baseline network which are used to train the selector network using the actor-critic methodology. Using this methodology, INVASE is capable of flexibly discovering feature subsets of a different size for each instance, which is a key limitation of existing state-of-the-art methods. We demonstrate through a mixture of synthetic and real data experiments that INVASE significantly outperforms state-of-the-art benchmarks.", "keywords": ["Instance-wise feature selection", "interpretability", "actor-critic methodology"], "authorids": ["ICLR.cc/2019/Conference/Paper98/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d0550965a172d414f288f7a516f769e51a77e410.pdf", "paperhash": "anonymous|invase_instancewise_variable_selection_using_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019invase:,    \ntitle={INVASE: Instance-wise Variable Selection using Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJg_roAcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eOHo09KX", "original": "r1ggdEZCuX", "number": 99, "cdate": 1538087743717, "ddate": null, "tcdate": 1538087743717, "tmdate": 1538156242511, "tddate": null, "forum": "S1eOHo09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data Streams", "abstract": "In many real-world learning scenarios, features are only acquirable at a cost constrained under a budget. In this paper, we propose a novel approach for cost-sensitive feature acquisition at the prediction-time. The suggested method acquires features incrementally based on a context-aware feature-value function. We formulate the problem in the reinforcement learning paradigm, and introduce a reward function based on the utility of each feature. Specifically, MC dropout sampling is used to measure expected variations of the model uncertainty which is used as a feature-value function. Furthermore, we suggest sharing representations between the class predictor and value function estimator networks. The suggested approach is completely online and is readily applicable to stream learning setups. The solution is evaluated on three different datasets including the well-known MNIST dataset as a benchmark as well as two cost-sensitive datasets: Yahoo Learning to Rank and a dataset in the medical domain for diabetes classification. According to the results, the proposed method is able to efficiently acquire features and make accurate predictions. ", "keywords": ["Cost-Aware Learning", "Feature Acquisition", "Reinforcement Learning", "Stream Learning", "Deep Q-Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper99/Authors"], "authors": ["Anonymous"], "TL;DR": "An online algorithm for cost-aware feature acquisition and prediction", "pdf": "/pdf/33230dc8c8a6c584f6ef02bb2bad4571fabf40b8.pdf", "paperhash": "anonymous|opportunistic_learning_budgeted_costsensitive_learning_from_data_streams", "_bibtex": "@inproceedings{    \nanonymous2019opportunistic,    \ntitle={Opportunistic Learning: Budgeted Cost-Sensitive Learning from Data Streams},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eOHo09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syx_Ss05tm", "original": "Syx7bTOtFQ", "number": 100, "cdate": 1538087743905, "ddate": null, "tcdate": 1538087743905, "tmdate": 1538156242302, "tddate": null, "forum": "Syx_Ss05tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Reprogramming of Neural Networks", "abstract": "Deep neural networks are susceptible to \\emph{adversarial} attacks. In computer vision, well-crafted perturbations to images can cause neural networks to make mistakes such as identifying a panda as a gibbon or confusing a cat with a computer. Previous adversarial examples have been designed to degrade performance of models or cause machine learning models to produce specific outputs chosen ahead of time by the attacker. We introduce adversarial attacks that instead {\\em reprogram} the target model to perform a task chosen by the attacker---without the attacker needing to specify or compute the desired output for each test-time input. This attack is accomplished by optimizing for a single adversarial perturbation, of unrestricted magnitude, that can be added to all test-time inputs to a machine learning model in order to cause the model to perform a task chosen by the adversary when processing these inputs---even if the model was not trained to do this task. These perturbations can be thus considered a program for the new task. We demonstrate adversarial reprogramming on six ImageNet classification models, repurposing these models to perform a counting task, as well as two classification tasks: classification of MNIST and CIFAR-10 examples presented within the input to the ImageNet model.", "keywords": ["Adversarial", "Neural Networks", "Machine Learning Security"], "authorids": ["ICLR.cc/2019/Conference/Paper100/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce the first instance of adversarial attacks that reprogram the target model to perform a task chosen by the attacker---without the attacker needing to specify or compute the desired output for each test-time input.", "pdf": "/pdf/1e85c6e6d52620be2a7e1df3824cba4b2644af0f.pdf", "paperhash": "anonymous|adversarial_reprogramming_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Reprogramming of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syx_Ss05tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxOHs0cKm", "original": "Syl0N-FYtm", "number": 101, "cdate": 1538087744082, "ddate": null, "tcdate": 1538087744082, "tmdate": 1538156242085, "tddate": null, "forum": "BJxOHs0cKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Identifying Generalization Properties in Neural Networks", "abstract": "While it has not yet been proven, empirical evidence suggests that model generalization is related to local properties of the optima which can be described via the Hessian. We connect model generalization with the local property of a solution under the PAC-Bayes paradigm. In particular, we prove that model generalization ability is related to the Hessian, the higher-order \"smoothness\" terms characterized by the Lipschitz constant of the Hessian, and the scales of the parameters. Guided by the proof, we propose a metric to score the generalization capability of the model, as well as an algorithm that optimizes the perturbed model accordingly. ", "keywords": ["generalization", "PAC-Bayes", "Hessian", "perturbation"], "authorids": ["ICLR.cc/2019/Conference/Paper101/Authors"], "authors": ["Anonymous"], "TL;DR": "a theory connecting Hessian of the solution and the generalization power of the model", "pdf": "/pdf/12577279f1e771a4562fc4b788924daab3708278.pdf", "paperhash": "anonymous|identifying_generalization_properties_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019identifying,    \ntitle={Identifying Generalization Properties in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxOHs0cKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzuHiA9tQ", "original": "SJgr24FFKQ", "number": 102, "cdate": 1538087744256, "ddate": null, "tcdate": 1538087744256, "tmdate": 1538156241872, "tddate": null, "forum": "SJzuHiA9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Adversarial Network Training is a Continual Learning Problem", "abstract": "Generative Adversarial Networks (GANs) have proven to be a powerful framework for learning to draw samples from complex distributions. However, GANs are also notoriously difficult to train, with mode collapse and oscillations a common problem. We hypothesize that this is at least in part due to the evolution of the generator distribution and the catastrophic forgetting tendency of neural networks, which leads to the discriminator losing the ability to remember synthesized samples from previous instantiations of the generator. Recognizing this, our contributions are twofold. First, we show that GAN training makes for a more interesting and realistic benchmark for continual learning methods evaluation than some of the more canonical datasets. Second, we propose leveraging continual learning techniques to augment the discriminator, preserving its ability to recognize previous generator samples. We show that the resulting methods add only a light amount of computation, involve minimal changes to the model, and result in better overall performance on the examined image and text generation tasks.", "keywords": ["Generative Adversarial Networks", "Continual Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper102/Authors"], "authors": ["Anonymous"], "TL;DR": "Generative Adversarial Network Training is a Continual Learning Problem.", "pdf": "/pdf/d6b39f3c1f5d6e3e74d600f0d48112bb8d9d357f.pdf", "paperhash": "anonymous|generative_adversarial_network_training_is_a_continual_learning_problem", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Adversarial Network Training is a Continual Learning Problem},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzuHiA9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgdHs05FQ", "original": "HJgUmdKtKQ", "number": 103, "cdate": 1538087744449, "ddate": null, "tcdate": 1538087744449, "tmdate": 1538156241663, "tddate": null, "forum": "rJgdHs05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Nonlinear Channels Aggregation Networks for Deep Action Recognition", "abstract": "We introduce the concept of channel aggregation in ConvNet architecture, a novel compact representation of CNN features useful for explicitly modeling the nonlinear channels encoding especially when the new unit is embedded inside of deep architectures for action recognition. The channel aggregation is based on multiple-channels features of ConvNet and aims to be at the spot finding the optical convergence path at fast speed. We name our proposed convolutional architecture \u201cnonlinear channels aggregation networks (NCAN)\u201d and its new layer \u201cnonlinear channels aggregation layer (NCAL)\u201d. We theoretically motivate channels aggregation functions and empirically study their effect on convergence speed and classification accuracy. Another contribution in this work is an efficient and effective implementation of the NCAL, speeding it up orders of magnitude. We evaluate its performance on standard benchmarks UCF101 and HMDB51, and experimental results demonstrate that this formulation not only obtains a fast convergence but stronger generalization capability without sacrificing performance.", "keywords": ["action recognition", "convolutional neural network", "network training"], "authorids": ["ICLR.cc/2019/Conference/Paper103/Authors"], "authors": ["Anonymous"], "TL;DR": "An architecture enables CNN trained on the video sequences converging rapidly ", "pdf": "/pdf/806c29ad0d911811b613044c2254ac129edda299.pdf", "paperhash": "anonymous|nonlinear_channels_aggregation_networks_for_deep_action_recognition", "_bibtex": "@inproceedings{    \nanonymous2019nonlinear,    \ntitle={Nonlinear Channels Aggregation Networks for Deep Action Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgdHs05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HketHo0qFm", "original": "rJxzwqFFt7", "number": 104, "cdate": 1538087744629, "ddate": null, "tcdate": 1538087744629, "tmdate": 1538156241450, "tddate": null, "forum": "HketHo0qFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hybrid Policies Using Inverse Rewards for Reinforcement Learning", "abstract": "This paper puts forward a broad-spectrum improvement for reinforcement learning algorithms, which combines the policies using original rewards and inverse (negative) rewards. The policies using inverse rewards are competitive with the original policies, and help the original policies correct their mis-actions. We have proved the convergence of the inverse policies. The experiments for some games in OpenAI gym show that the hybrid polices based on deep Q-learning, double Q-learning, and on-policy actor-critic obtain the rewards up to 63.8%, 97.8%, and 54.7% more than the original algorithms. The improved polices are more stable than the original policies as well.", "keywords": ["Reinforcement Learning", "Rewards"], "authorids": ["ICLR.cc/2019/Conference/Paper104/Authors"], "authors": ["Anonymous"], "TL;DR": "A broad-spectrum improvement for reinforcement learning algorithms, which combines the policies using original rewards and inverse (negative) rewards", "pdf": "/pdf/2c627441f7a0650c9a826b8196186312d882b7ad.pdf", "paperhash": "anonymous|hybrid_policies_using_inverse_rewards_for_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019hybrid,    \ntitle={Hybrid Policies Using Inverse Rewards for Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HketHo0qFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lKSjRcY7", "original": "rklCznKKtX", "number": 105, "cdate": 1538087744825, "ddate": null, "tcdate": 1538087744825, "tmdate": 1538156241243, "tddate": null, "forum": "S1lKSjRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improved Gradient Estimators for Stochastic Discrete Variables", "abstract": "In many applications we seek to optimize an expectation with respect to a distribution over discrete variables. Estimating gradients of such objectives with respect to the distribution parameters is a challenging problem. We analyze existing solutions including finite-difference (FD) estimators and continuous relaxation (CR) estimators in terms of bias and variance. We show that the commonly used Gumbel-Softmax estimator is biased and propose a simple method to reduce it. We also derive a simpler piece-wise linear continuous relaxation that also possesses reduced bias. We demonstrate empirically that reduced bias leads to a better performance in variational inference and on binary optimization tasks.", "keywords": ["continuous relaxation", "discrete stochastic variables", "reparameterization trick", "variational inference", "discrete optimization", "stochastic gradient estimation"], "authorids": ["ICLR.cc/2019/Conference/Paper105/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose simple ways to reduce bias and complexity of stochastic gradient estimators used for learning distributions over discrete variables.", "pdf": "/pdf/4ce59042b62849e269edb4ea09f66e7a574d789b.pdf", "paperhash": "anonymous|improved_gradient_estimators_for_stochastic_discrete_variables", "_bibtex": "@inproceedings{    \nanonymous2019improved,    \ntitle={Improved Gradient Estimators for Stochastic Discrete Variables},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lKSjRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eYHoC5FX", "original": "ryey_J9YFX", "number": 106, "cdate": 1538087745006, "ddate": null, "tcdate": 1538087745006, "tmdate": 1538156241036, "tddate": null, "forum": "S1eYHoC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DARTS: Differentiable Architecture Search", "abstract": "This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner. Unlike conventional approaches of applying evolution or reinforcement learning over a discrete and non-differentiable search space, our method is based on the continuous relaxation of the architecture representation, allowing efficient search of the architecture using gradient descent. Extensive experiments on CIFAR-10, ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques.", "keywords": ["deep learning", "autoML", "neural architecture search", "image classification", "language modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper106/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a differentiable architecture search algorithm for both convolutional and recurrent networks, achieving competitive performance with the state of the art using orders of magnitude less computation resources.", "pdf": "/pdf/030f0341a9252ecfde6d92bcee95d5ab050b891e.pdf", "paperhash": "anonymous|darts_differentiable_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019darts:,    \ntitle={DARTS: Differentiable Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eYHoC5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxFrs09YQ", "original": "HylHHXHOKm", "number": 107, "cdate": 1538087745187, "ddate": null, "tcdate": 1538087745187, "tmdate": 1538156240827, "tddate": null, "forum": "HJxFrs09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GENERALIZED ADAPTIVE MOMENT ESTIMATION", "abstract": "Adaptive gradient methods have experienced great success in training deep neural networks (DNNs). The basic idea of the methods is to track and properly make use of the first and/or second moments of the gradient for model-parameter updates over iterations for the purpose of removing the need for manual interference. In this work, we propose a new adaptive gradient method, referred to as generalized adaptive moment estimation (Game). From a high level perspective, the new method introduces two more parameters w.r.t. AMSGrad (S. J. Reddi & Kumar (2018)) and one more parameter w.r.t. PAdam (Chen & Gu (2018)) to enlarge the parameter- selection space for performance enhancement while reducing the memory cost per iteration compared to AMSGrad and PAdam. The saved memory space amounts to the number of model parameters, which is significant for large-scale DNNs. Our motivation for introducing additional parameters in Game is to provide algorithmic flexibility to facilitate a reduction of the performance gap between training and validation datasets when training a DNN. Convergence analysis is provided for applying Game to solve both convex optimization and smooth nonconvex optmization. Empirical studies for training four convolutional neural networks over MNIST and CIFAR10 show that under proper parameter selection, Game produces promising validation performance as compared to AMSGrad and PAdam.", "keywords": ["adaptive moment estimation", "SGD", "AMSGrad"], "authorids": ["ICLR.cc/2019/Conference/Paper107/Authors"], "authors": ["Anonymous"], "TL;DR": "A new adaptive gradient method is proposed for effectively training deep neural networks", "pdf": "/pdf/aced0aa1ea62e87c90a7dc43354eb539d1546668.pdf", "paperhash": "anonymous|generalized_adaptive_moment_estimation", "_bibtex": "@inproceedings{    \nanonymous2019generalized,    \ntitle={GENERALIZED ADAPTIVE MOMENT ESTIMATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxFrs09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeYHi0ctQ", "original": "BylpuqDvKX", "number": 108, "cdate": 1538087745357, "ddate": null, "tcdate": 1538087745357, "tmdate": 1538156240601, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["ICLR.cc/2019/Conference/Paper108/Authors"], "authors": ["Anonymous"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/b65e3ee997acac2352e242fc538bb7973403b0c6.pdf", "paperhash": "anonymous|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{    \nanonymous2019dpsnet:,    \ntitle={DPSNet: End-to-end Deep Plane Sweep Stereo},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeYHi0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bye5SiAqKX", "original": "r1l_DKvFY7", "number": 109, "cdate": 1538087745535, "ddate": null, "tcdate": 1538087745535, "tmdate": 1538156240388, "tddate": null, "forum": "Bye5SiAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Preconditioners on Lie Groups", "abstract": "We study two types of preconditioners and preconditioned stochastic gradient descent (SGD) methods in a unified framework. We call the first one the Newton type due to its close relationship to Newton method, and the second one the Fisher type as its preconditioner is closely related to the inverse of Fisher information matrix. Both preconditioners can be derived from one framework, and efficiently learned on any matrix Lie groups designated by the user using natural or relative gradient descent. Many existing preconditioners and methods are special cases of either the Newton type or the Fisher type ones. Experimental results on relatively large scale machine learning  problems are reported for performance study. ", "keywords": ["preconditioner", "stochastic gradient descent", "Newton method", "Fisher information", "natural gradient", "Lie group"], "authorids": ["ICLR.cc/2019/Conference/Paper109/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new framework for preconditioner learning, derive new forms of preconditioners and learning methods, and reveal the relationship to methods like RMSProp, Adam, Adagrad, ESGD, KFAC, batch normalization, etc.", "pdf": "/pdf/388d69fcfbfa14d87e595ffa29c9d67685fa1cd7.pdf", "paperhash": "anonymous|learning_preconditioners_on_lie_groups", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Preconditioners on Lie Groups},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bye5SiAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygqBiRcFQ", "original": "H1ebUtqFtQ", "number": 110, "cdate": 1538087745777, "ddate": null, "tcdate": 1538087745777, "tmdate": 1538156240166, "tddate": null, "forum": "BygqBiRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diffusion Scattering Transforms on Graphs", "abstract": "Stability is a key aspect of data analysis. In many applications, the natural notion of stability is geometric, as illustrated for example in computer vision. Scattering transforms construct deep convolutional representations which are certified stable to input deformations. This stability to deformations can be interpreted as stability with respect to changes in the metric structure of the domain. \n\nIn this work, we show that scattering transforms can be generalized to non-Euclidean domains using diffusion wavelets, while preserving a notion of stability with respect to metric changes in the domain, measured with diffusion maps. The resulting representation is stable to metric perturbations of the domain while being able to capture ''high-frequency'' information, akin to the Euclidean Scattering. ", "keywords": ["graph neural networks", "deep learning", "stability", "scattering transforms", "convolutional neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper110/Authors"], "authors": ["Anonymous"], "TL;DR": "Stability of scattering transform representations of graph data to deformations of the underlying graph support.", "pdf": "/pdf/828f5be1f22fb5c7e49d81bbbc55e3ceafa12fd0.pdf", "paperhash": "anonymous|diffusion_scattering_transforms_on_graphs", "_bibtex": "@inproceedings{    \nanonymous2019diffusion,    \ntitle={Diffusion Scattering Transforms on Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygqBiRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkG5SjR5YQ", "original": "rJxhUGDUKX", "number": 111, "cdate": 1538087745964, "ddate": null, "tcdate": 1538087745964, "tmdate": 1538156239953, "tddate": null, "forum": "BkG5SjR5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator", "abstract": "Measuring divergence between two distributions is essential in machine learning and statistics and has various applications including binary classification, change point detection, and two-sample test. Furthermore, in the era of big data, designing divergence measure that is interpretable and can handle high-dimensional and complex data becomes extremely important. In this paper, we propose a post selection inference (PSI) framework for divergence measure, which can select a set of statistically significant features that discriminate two distributions. Specifically, we employ an additive variant of maximum mean discrepancy (MMD) for features and introduce a general hypothesis test for PSI. A novel MMD estimator using the incomplete U-statistics, which has an asymptotically normal distribution (under mild assumptions) and gives high detection power in PSI, is also proposed and analyzed theoretically. Through synthetic and real-world feature selection experiments, we show that the proposed framework can successfully detect statistically significant features. Last, we propose a sample selection framework for analyzing different members in the Generative Adversarial Networks (GANs) family. ", "keywords": ["Maximum Mean Discrepancy", "Selective Inference", "Feature Selection", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper111/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/16311a8a91e8848bf105982702fcaa940dc6c200.pdf", "paperhash": "anonymous|post_selection_inference_with_incomplete_maximum_mean_discrepancy_estimator", "_bibtex": "@inproceedings{    \nanonymous2019post,    \ntitle={Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkG5SjR5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1GcHsAqtm", "original": "Hylz7FIYY7", "number": 112, "cdate": 1538087746141, "ddate": null, "tcdate": 1538087746141, "tmdate": 1538156239750, "tddate": null, "forum": "S1GcHsAqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Pruning of Neural Language Models for Mobile Devices", "abstract": "Neural language models (NLMs) exist in an accuracy-efficiency tradeoff space where better perplexity typically comes at the cost of greater computation complexity. In a software keyboard application on mobile devices, this translates into higher power consumption and shorter battery life. This paper represents the first attempt, to our knowledge, in exploring accuracy-efficiency tradeoffs for NLMs. Building on quasi-recurrent neural networks (QRNNs), we apply pruning techniques to provide a \"knob\" to select different operating points. In addition, we propose a simple technique to recover some perplexity using a negligible amount of memory. Our empirical evaluations consider both perplexity as well as energy consumption on a Raspberry Pi, where we demonstrate which methods provide the best perplexity-power consumption operating point. At one operating point, one of the techniques is able to provide energy savings of 40% over the state of the art with only a 17% relative increase in perplexity.", "keywords": ["Inference-time pruning", "Neural Language Models"], "authorids": ["ICLR.cc/2019/Conference/Paper112/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/21b1b885ef3751a7cdc351895dfd3d48d621cc3b.pdf", "paperhash": "anonymous|adaptive_pruning_of_neural_language_models_for_mobile_devices", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Pruning of Neural Language Models for Mobile Devices},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1GcHsAqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkEqro0ctQ", "original": "rkeJSn9KFm", "number": 113, "cdate": 1538087746319, "ddate": null, "tcdate": 1538087746319, "tmdate": 1538156239538, "tddate": null, "forum": "SkEqro0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper113/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/89bd60d48fef0cc6f0b239bda4028f24fca6b622.pdf", "paperhash": "anonymous|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical interpretations for neural network predictions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkEqro0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1goBoR9F7", "original": "SyxU3JiKKQ", "number": 114, "cdate": 1538087746560, "ddate": null, "tcdate": 1538087746560, "tmdate": 1538156239330, "tddate": null, "forum": "H1goBoR9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dynamic Sparse Graph for Efficient Deep Learning", "abstract": "We propose to execute deep neural networks (DNNs) with dynamic and sparse graph (DSG) structure for compressive memory and accelerative execution during both training and inference. The great success of DNNs motivates the pursuing of lightweight models for the deployment onto embedded devices. However, most of the previous studies optimize for inference while neglect training or even complicate it. Training is far more intractable, since (i) the neurons dominate the memory cost rather than the weights in inference; (ii) the dynamic activation makes previous sparse acceleration via one-off optimization on fixed weight invalid; (iii) batch normalization (BN) is critical for maintaining accuracy while its activation reorganization damages the sparsity. To address these issues, DSG activates only a small amount of neurons with high selectivity at each iteration via a dimension-reduction search (DRS) and obtains the BN compatibility via a double-mask selection (DMS). Experiments show significant memory saving (1.7-4.5x) and operation reduction (2.3-4.4x) with little accuracy loss on various benchmarks.", "keywords": ["Sparsity", "compression", "training", "acceleration"], "authorids": ["ICLR.cc/2019/Conference/Paper114/Authors"], "authors": ["Anonymous"], "TL;DR": "We construct dynamic sparse graph via dimension-reduction search to reduce compute and memory cost in both DNN training and inference.", "pdf": "/pdf/e143b5fe5d98778729dce5e7eab442f65ff10fac.pdf", "paperhash": "anonymous|dynamic_sparse_graph_for_efficient_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Sparse Graph for Efficient Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1goBoR9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1giro05t7", "original": "Hyl5Pf6Ht7", "number": 115, "cdate": 1538087746732, "ddate": null, "tcdate": 1538087746732, "tmdate": 1538156239122, "tddate": null, "forum": "S1giro05t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reducing Overconfident Errors outside the Known Distribution", "abstract": "Intuitively, unfamiliarity should lead to lack of confidence. In reality, current algorithms often make highly confident yet wrong predictions when faced with unexpected test samples from an unknown distribution different from training. Unlike domain adaptation methods, we cannot gather an \"unexpected dataset\" prior to test, and unlike novelty detection methods, a best-effort original task prediction is still expected. We propose two simple solutions that reduce overconfident errors of samples from an unknown novel distribution without drastically increasing evaluation time: (1) G-distillation, training an ensemble of classifiers and then distill into a single model using both labeled and unlabeled examples, or (2) NCR, reducing prediction confidence based on its novelty detection score. Experimentally, we investigate the overconfidence problem and evaluate our solution by creating \"familiar\" and \"novel\" test splits, where \"familiar\" are identically distributed with training and \"novel\" are not. We show that our solution yields more appropriate prediction confidences, on familiar and novel data, compared to single models and ensembles distilled on training data only. For example, our G-distillation reduces confident errors in gender recognition by 94% on demographic groups different from the training data.", "keywords": ["Machine learning safety", "confidence", "overconfidence", "unknown domain", "novel distribution", "generalization", "distillation", "ensemble", "underrepresentation"], "authorids": ["ICLR.cc/2019/Conference/Paper115/Authors"], "authors": ["Anonymous"], "TL;DR": "Deep networks are more likely to be confidently wrong when testing on unexpected data. We propose two methods to reduce confident errors on unknown input distributions, and an experimental methodology to study the problem.", "pdf": "/pdf/1232a1ec80766f26ecf0851eddda0191972e0735.pdf", "paperhash": "anonymous|reducing_overconfident_errors_outside_the_known_distribution", "_bibtex": "@inproceedings{    \nanonymous2019reducing,    \ntitle={Reducing Overconfident Errors outside the Known Distribution},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1giro05t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xsSjC9Ym", "original": "H1xvAyiKF7", "number": 116, "cdate": 1538087746909, "ddate": null, "tcdate": 1538087746909, "tmdate": 1538156238916, "tddate": null, "forum": "H1xsSjC9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Understand Goal Specifications by Modelling Reward", "abstract": "Recent work has shown that deep reinforcement-learning agents can learn to follow language-like instructions from infrequent environment rewards. However, this places on environment designers the onus of designing language-conditional reward functions which may not be easily or tractably implemented as the complexity of the environment and the language scales. To overcome this limitation, we present a framework within which instruction-conditional RL agents are trained using rewards obtained not from the environment, but from reward models which are jointly trained from expert examples. As reward models improve, they learn to accurately reward agents for completing tasks for environment configurations---and for instructions---not present amongst the expert data. This framework effectively separates the representation of what instructions require from how they can be executed. In a simple grid world, it enables an agent to learn a range of commands requiring interaction with blocks and understanding of spatial relations and underspecified abstract arrangements. We further show the method allows our agent to adapt to changes in the environment without requiring new expert examples.\n", "keywords": ["instruction following", "reward modelling", "language understanding"], "authorids": ["ICLR.cc/2019/Conference/Paper116/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose AGILE, a framework for training agents to perform instructions from examples of respective goal-states.", "pdf": "/pdf/2e66b4fbf44d3d11bda2730735f4df7aea42df04.pdf", "paperhash": "anonymous|learning_to_understand_goal_specifications_by_modelling_reward", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Understand Goal Specifications by Modelling Reward},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xsSjC9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkGsHj05tQ", "original": "BkeUZP9wtX", "number": 117, "cdate": 1538087747088, "ddate": null, "tcdate": 1538087747088, "tmdate": 1538156238707, "tddate": null, "forum": "HkGsHj05tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Batch Normalization Sampling", "abstract": "Deep Neural Networks (DNNs) thrive in recent years in which Batch Normalization (BN) plays an indispensable role. However, it has been observed that BN is costly due to the reduction operations. In this paper, we propose alleviating this problem through sampling only a small fraction of data for normalization at each iteration. Specifically, we model it as a statistical sampling problem and identify that by sampling less correlated data, we can largely reduce the requirement of the number of data for statistics estimation in BN, which directly simplifies the reduction operations. Based on this conclusion, we propose two sampling strategies, \u201cBatch Sampling\u201d (randomly select several samples from each batch) and \u201cFeature Sampling\u201d (randomly select a small patch from each feature map of all samples), that take both computational efficiency and sample correlation into consideration. Furthermore, we introduce an extremely simple variant of BN, termed as Virtual Dataset Normalization (VDN), that can normalize the activations well with few synthetical random samples. All the proposed methods are evaluated on various datasets and networks, where an overall training speedup by up to 20% on GPU is practically achieved without the support of any specialized libraries, and the loss on accuracy and convergence rate are negligible. Finally, we extend our work to the \u201cmicro-batch normalization\u201d problem and yield comparable performance with existing approaches at the case of tiny batch size.", "keywords": ["batch normalization", "acceleration", "correlation", "sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper117/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose accelerating Batch Normalization (BN) through sampling less correlated data for reduction operations  with regular execution pattern, which achieves up to 2x and 20% speedup for BN itself and the overall training, respectively.", "pdf": "/pdf/8cf476ce7c4407e18d0c92004887689e22632602.pdf", "paperhash": "anonymous|batch_normalization_sampling", "_bibtex": "@inproceedings{    \nanonymous2019batch,    \ntitle={Batch Normalization Sampling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGsHj05tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyzjBiR9t7", "original": "rkl7E8FtFQ", "number": 118, "cdate": 1538087747322, "ddate": null, "tcdate": 1538087747322, "tmdate": 1538156238504, "tddate": null, "forum": "SyzjBiR9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA", "abstract": "Developing deep neural networks (DNNs) for manifold-valued data sets\nhas gained much interest of late in the deep learning research\ncommunity.  Examples of manifold-valued data include data from\nomnidirectional cameras on automobiles, drones etc., diffusion\nmagnetic resonance imaging, elastography and others. In this paper, we\npresent a novel theoretical framework for DNNs to cope with\nmanifold-valued data inputs.  In doing this generalization, we draw\nparallels to the widely popular convolutional neural networks (CNNs).\nWe call our network the ManifoldNet.\n\nAs in vector spaces where convolutions are equivalent to computing the\nweighted mean of functions, an analogous definition for\nmanifold-valued data can be constructed involving the computation of\nthe weighted Fr\\'{e}chet Mean (wFM). To this end, we present a\nprovably convergent recursive computation of the wFM of the given\ndata, where the weights makeup the convolution mask, to be\nlearned. Further, we prove that the proposed wFM layer achieves a\ncontraction mapping and hence the ManifoldNet does not need the\nadditional non-linear ReLU unit used in standard CNNs. Operations such\nas pooling in traditional CNN are no longer necessary in this setting\nsince wFM is already a pooling type operation. Analogous to the\nequivariance of convolution in Euclidean space to translations, we\nprove that the wFM is equivariant to the action of the group of\nisometries admitted by the Riemannian manifold on which the data\nreside. This equivariance property facilitates weight sharing within\nthe network.  We present experiments, using the ManifoldNet framework,\nto achieve video classification and image reconstruction using an\nauto-encoder+decoder setting. Experimental results demonstrate the\nefficacy of ManifoldNet in the context of classification and\nreconstruction accuracy.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper118/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a07255f4a32442f013ddea56ada6ec4c2815a0f9.pdf", "paperhash": "anonymous|manifoldnet_a_deep_neural_network_for_manifoldvalued_data", "_bibtex": "@inproceedings{    \nanonymous2019manifoldnet:,    \ntitle={MANIFOLDNET: A DEEP NEURAL NETWORK FOR MANIFOLD-VALUED DATA},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyzjBiR9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJVorjCcKQ", "original": "HJxAxmiYt7", "number": 119, "cdate": 1538087747495, "ddate": null, "tcdate": 1538087747495, "tmdate": 1538156238291, "tddate": null, "forum": "rJVorjCcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware", "abstract": "As Machine Learning (ML) gets applied to security-critical or sensitive domains, there is a growing need for integrity and privacy for outsourced ML computations. \nA pragmatic solution comes from Trusted Execution Environments (TEEs), which use hardware and software protections to isolate sensitive computations from the untrusted software stack. However, these isolation guarantees come at a price in performance, compared to untrusted alternatives.\nThis paper initiates the study of high performance execution of Deep Neural Networks (DNNs) in TEEs by efficiently partitioning DNN computations between trusted and untrusted devices.\nBuilding upon an efficient outsourcing scheme for matrix multiplication, we propose Slalom, a framework that securely delegates execution of all linear layers in a DNN from a TEE (e.g., Intel SGX or Sanctum) to a faster, yet untrusted, co-located processor.\nWe evaluate Slalom by executing DNNs in an Intel SGX enclave, which selectively delegates work to an untrusted GPU. For two canonical DNNs, VGG16 and MobileNet, we obtain 20x and 6x increases in throughput for verifiable inference, and 11x and 4x for verifiable and private inference.", "keywords": ["Trusted hardware", "integrity", "privacy", "secure inference", "SGX"], "authorids": ["ICLR.cc/2019/Conference/Paper119/Authors"], "authors": ["Anonymous"], "TL;DR": "We accelerate secure DNN inference in trusted execution environments (by a factor 4x-20x) by selectively outsourcing the computation of linear layers to a faster yet untrusted co-processor.", "pdf": "/pdf/8f2d13b07ea8a43db44a75d2dddd2cefc6fe4776.pdf", "paperhash": "anonymous|slalom_fast_verifiable_and_private_execution_of_neural_networks_in_trusted_hardware", "_bibtex": "@inproceedings{    \nanonymous2019slalom:,    \ntitle={Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJVorjCcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkl2SjCcKQ", "original": "B1xeiUoFtX", "number": 120, "cdate": 1538087747672, "ddate": null, "tcdate": 1538087747672, "tmdate": 1538156238081, "tddate": null, "forum": "Bkl2SjCcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TequilaGAN: How To Easily Identify GAN Samples", "abstract": "In this paper we show strategies to easily identify fake samples generated with the Generative Adversarial Network framework. One strategy is based on the statistical analysis and comparison of raw pixel values and features extracted from them. The other strategy learns formal specifications from the real data and shows that fake samples violate the specifications of the real data. We show that fake samples produced with GANs have a universal signature that can be used to identify fake samples. We provide results on MNIST, CIFAR10, music and speech data.", "keywords": ["Generative Adversarial Networks", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper120/Authors"], "authors": ["Anonymous"], "TL;DR": "We show strategies to easily identify fake samples generated with the Generative Adversarial Network framework.", "pdf": "/pdf/22521a9da62f2b8a41e0ac04df7f6345b9a104c2.pdf", "paperhash": "anonymous|tequilagan_how_to_easily_identify_gan_samples", "_bibtex": "@inproceedings{    \nanonymous2019tequilagan:,    \ntitle={TequilaGAN: How To Easily Identify GAN Samples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkl2SjCcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkghBoR5FX", "original": "Hke-SPitY7", "number": 121, "cdate": 1538087747846, "ddate": null, "tcdate": 1538087747846, "tmdate": 1538156237873, "tddate": null, "forum": "SkghBoR5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers", "abstract": "The success of deep learning research has catapulted deep models into production\nsystems that our society is becoming increasingly dependent on, especially in the\nimage and video domains. However, recent work has shown that these largely\nuninterpretable models exhibit glaring security vulnerabilities in the presence of\nan adversary. In this work, we develop a powerful untargeted adversarial attack\nfor action recognition systems in both white-box and black-box settings. Action\nrecognition models differ from image-classification models in that their inputs\ncontain a temporal dimension, which we explicitly target in the attack. Drawing\ninspiration from image classifier attacks, we create new attacks which achieve\nstate-of-the-art success rates on a two-stream classifier trained on the UCF-101\ndataset. We find that our attacks can significantly degrade a model\u2019s performance\nwith sparsely and imperceptibly perturbed examples. We also demonstrate the\ntransferability of our attacks to black-box action recognition systems.", "keywords": ["adversarial attacks", "action recognition", "video classification"], "authorids": ["ICLR.cc/2019/Conference/Paper121/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper describes adversarial attacks for action recognition classifiers that explicitly attack along the time dimension.", "pdf": "/pdf/9fc73a1ac3c621f8c3d68fb7ae9a6e3614d074f2.pdf", "paperhash": "anonymous|adversarial_attacks_for_optical_flowbased_action_recognition_classifiers", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkghBoR5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJg3rjA5tQ", "original": "rkecIwiYKQ", "number": 122, "cdate": 1538087748027, "ddate": null, "tcdate": 1538087748027, "tmdate": 1538156237663, "tddate": null, "forum": "HJg3rjA5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Spread Divergences", "abstract": "For distributions $p$ and $q$ with different support, the divergence $\\div{p}{q}$ generally will not exist. We define a spread divergence $\\sdiv{p}{q}$ on modified $p$ and $q$ and describe sufficient conditions for the existence of such a divergence. We give examples of using a spread divergence to train implicit generative models, including linear models (Principal Components Analysis and Independent Components Analysis) and non-linear models (Deep Generative Networks).", "keywords": ["Generative Adversarial Network", "Divergence"], "authorids": ["ICLR.cc/2019/Conference/Paper122/Authors"], "authors": ["Anonymous"], "TL;DR": "Using noise to define the divergence between distributions with different support.", "pdf": "/pdf/f895ff6b459dd250af81204a4c6b4b6e6dba3880.pdf", "paperhash": "anonymous|spread_divergences", "_bibtex": "@inproceedings{    \nanonymous2019spread,    \ntitle={Spread Divergences},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJg3rjA5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJe3HiC5KX", "original": "BkxjxHotYm", "number": 123, "cdate": 1538087748218, "ddate": null, "tcdate": 1538087748218, "tmdate": 1538156237454, "tddate": null, "forum": "SJe3HiC5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper123/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9c5c8a9d446243652fb4eb34fddd9a654293d1e3.pdf", "paperhash": "anonymous|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJe3HiC5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkMnHjC5YQ", "original": "SJxUmuoFtX", "number": 124, "cdate": 1538087748389, "ddate": null, "tcdate": 1538087748389, "tmdate": 1538156237248, "tddate": null, "forum": "rkMnHjC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps", "abstract": "We propose a new algorithm to learn a one-hidden-layer convolutional neural network where both the convolutional weights and the outputs weights are parameters to be learned. Our algorithm works for a general class of (potentially overlapping) patches, including commonly used structures for computer vision tasks. Our algorithm draws ideas from (1) isotonic regression for learning neural networks and (2) landscape analysis of non-convex matrix factorization problems. We believe these findings may inspire further development in designing provable algorithms for learning neural networks and other complex models. While our focus is theoretical, we also present experiments that illustrate our theoretical findings.", "keywords": ["deep learning", "parameter recovery", "convolutional neural networks", "non-convex optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper124/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an algorithm for provably recovering parameters (convolutional and output weights) of a convolutional network with overlapping patches.", "pdf": "/pdf/f1520ba4734caf12e90b1938dd3e6969de0e7607.pdf", "paperhash": "anonymous|improved_learning_of_onehiddenlayer_convolutional_neural_networks_with_overlaps", "_bibtex": "@inproceedings{    \nanonymous2019improved,    \ntitle={Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMnHjC5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeTHsAqtX", "original": "rJxl1oMKY7", "number": 125, "cdate": 1538087748571, "ddate": null, "tcdate": 1538087748571, "tmdate": 1538156237043, "tddate": null, "forum": "ByeTHsAqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gradient Descent Happens in a Tiny Subspace", "abstract": "We show that in a variety of large-scale deep learning scenarios the gradient dynamically converges to a very small subspace after a short period of training. The subspace is spanned by a few top eigenvectors of the Hessian (equal to the number of classes in the dataset), and is mostly preserved over long periods of training. A simple argument then suggests that gradient descent may happen mostly in this subspace. We give an example of this effect in a solvable model of classification, and we comment on possible implications for optimization and learning.", "keywords": ["Gradient Descent", "Hessian", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper125/Authors"], "authors": ["Anonymous"], "TL;DR": "For classification problems with k classes, we show that the gradient tends to live in a tiny, slowly-evolving subspace spanned by the eigenvectors corresponding to the k-largest eigenvalues of the Hessian.", "pdf": "/pdf/e5653b474998aa375be6960cea7d8cfbb4bf7f54.pdf", "paperhash": "anonymous|gradient_descent_happens_in_a_tiny_subspace", "_bibtex": "@inproceedings{    \nanonymous2019gradient,    \ntitle={Gradient Descent Happens in a Tiny Subspace},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeTHsAqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylTHoR5Km", "original": "HJl0eAtxY7", "number": 126, "cdate": 1538087748748, "ddate": null, "tcdate": 1538087748748, "tmdate": 1538156236822, "tddate": null, "forum": "BylTHoR5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Isolating effects of age with fair representation learning when assessing dementia", "abstract": "One of the most prevalent symptoms among the elderly population, dementia, can be detected by classifiers trained on linguistic features extracted from narrative transcripts. However, these linguistic features are impacted in a similar but different fashion by the normal aging process. Aging is therefore a confounding factor, whose effects have been hard for machine learning classifiers to isolate. \n\nIn this paper, we show that deep neural network (DNN) classifiers can infer ages from linguistic features, which is an entanglement that could lead to unfairness across age groups. We show this problem is caused by undesired activations of v-structures in causality diagrams, and it could be addressed with fair representation learning. We build neural network classifiers that learn low-dimensional representations reflecting the impacts of dementia yet discarding the effects of age. To evaluate these classifiers, we specify a model-agnostic score $\\Delta_{eo}^{(N)}$ measuring how classifier results are disentangled from age. Our best models outperform baseline neural network classifiers in disentanglement, while compromising accuracy by as little as 2.56\\% and 2.25\\% on DementiaBank and the Famous People dataset respectively. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper126/Authors"], "authors": ["Anonymous"], "TL;DR": "Show that age confounds cognitive impairment detection + solve with fair representation learning + propose metrics and models.", "pdf": "/pdf/2f8c0d1cf927595218d57eb4cff726c65d05aa31.pdf", "paperhash": "anonymous|isolating_effects_of_age_with_fair_representation_learning_when_assessing_dementia", "_bibtex": "@inproceedings{    \nanonymous2019isolating,    \ntitle={Isolating effects of age with fair representation learning when assessing dementia},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylTHoR5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkxarj09Y7", "original": "Byx6mjSOYX", "number": 127, "cdate": 1538087748922, "ddate": null, "tcdate": 1538087748922, "tmdate": 1538156236614, "tddate": null, "forum": "Hkxarj09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unified recurrent network for many feature types", "abstract": "There are time series that are amenable to recurrent neural network (RNN) solutions when treated as sequences, but some series, e.g. asynchronous time series, provide a richer variation of feature types than current RNN cells take into account. In order to address such situations, we introduce a unified RNN that handles five different feature types, each in a different manner. Our RNN framework separates sequential features into two groups dependent on their frequency, which we call sparse and dense features, and which affect cell updates differently. Further, we also incorporate time features at the sequential level that relate to the time between specified events in the sequence and are used to modify the cell's memory state. We also include two types of static (whole sequence level) features, one related to time and one not, which are combined with the encoder output. The experiments show that the proposed modeling framework does increase performance compared to standard cells.", "keywords": ["sparse", "recurrent", "asynchronous", "time", "series"], "authorids": ["ICLR.cc/2019/Conference/Paper127/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a unified RNN that handles five different feature types, each in a different manner.", "pdf": "/pdf/9d62783dca37809eb9e2b0d45ec7ef28820787a1.pdf", "paperhash": "anonymous|unified_recurrent_network_for_many_feature_types", "_bibtex": "@inproceedings{    \nanonymous2019unified,    \ntitle={Unified recurrent network for many feature types},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkxarj09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxaSsActQ", "original": "SJe_wP2FYm", "number": 128, "cdate": 1538087749104, "ddate": null, "tcdate": 1538087749104, "tmdate": 1538156236344, "tddate": null, "forum": "ryxaSsActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dual Skew Divergence Loss for Neural Machine Translation", "abstract": "For neural sequence model training, maximum likelihood (ML) has been commonly adopted to optimize model parameters with respect to the corresponding objective. However, in the case of sequence prediction tasks like neural machine translation (NMT), training with the ML-based cross entropy loss would often lead to models that overgeneralize and plunge into local optima. In this paper, we propose an extended loss function called dual skew divergence (DSD), which aims to give a better tradeoff between generalization ability and error avoidance during NMT training. Our empirical study indicates that switching to DSD loss after the convergence of ML training helps the model skip the local optimum and stimulates a stable performance improvement. The evaluations on WMT 2014 English-German and English-French translation tasks demonstrate that the proposed loss indeed helps bring about better translation performance than several baselines.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper128/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/298ece9ec84c007295ee9df899333e31a6383327.pdf", "paperhash": "anonymous|dual_skew_divergence_loss_for_neural_machine_translation", "_bibtex": "@inproceedings{    \nanonymous2019dual,    \ntitle={Dual Skew Divergence Loss for Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxaSsActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyx6Bi0qYm", "original": "rJexke5FYX", "number": 129, "cdate": 1538087749281, "ddate": null, "tcdate": 1538087749281, "tmdate": 1538156236134, "tddate": null, "forum": "Hyx6Bi0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES", "abstract": "Brain-Machine Interfaces (BMIs) have recently emerged as a clinically viable option\nto restore voluntary movements after paralysis. These devices are based on the\nability to extract information about movement intent from neural signals recorded\nusing multi-electrode arrays chronically implanted in the motor cortices of the\nbrain. However, the inherent loss and turnover of recorded neurons requires repeated\nrecalibrations of the interface, which can potentially alter the day-to-day\nuser experience. The resulting need for continued user adaptation interferes with\nthe natural, subconscious use of the BMI. Here, we introduce a new computational\napproach that decodes movement intent from a low-dimensional latent representation\nof the neural data. We implement various domain adaptation methods\nto stabilize the interface over significantly long times. This includes Canonical\nCorrelation Analysis used to align the latent variables across days; this method\nrequires prior point-to-point correspondence of the time series across domains.\nAlternatively, we match the empirical probability distributions of the latent variables\nacross days through the minimization of their Kullback-Leibler divergence.\nThese two methods provide a significant and comparable improvement in the performance\nof the interface. However, implementation of an Adversarial Domain\nAdaptation Network trained to match the empirical probability distribution of the\nresiduals of the reconstructed neural signals outperforms the two methods based\non latent variables, while requiring remarkably few data points to solve the domain\nadaptation problem.", "keywords": ["Brain-Machine Interfaces", "Domain Adaptation", "Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper129/Authors"], "authors": ["Anonymous"], "TL;DR": "We implement an adversarial domain adaptation network to stabilize a fixed Brain-Machine Interface against gradual changes in the recorded neural signals.", "pdf": "/pdf/b6d7e1909f8d108aff90c351327ee9b44680efb0.pdf", "paperhash": "anonymous|adversarial_domain_adaptation_for_stable_brainmachine_interfaces", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={ADVERSARIAL DOMAIN ADAPTATION FOR STABLE BRAIN-MACHINE INTERFACES},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyx6Bi0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxTroR9F7", "original": "BkgY9KhtYm", "number": 130, "cdate": 1538087749467, "ddate": null, "tcdate": 1538087749467, "tmdate": 1538156235929, "tddate": null, "forum": "SJxTroR9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SUPERVISED POLICY UPDATE", "abstract": "We propose a new sample-efficient methodology, called Supervised Policy Update (SPU), for deep reinforcement learning. Starting with data generated by the current policy, SPU formulates and solves a constrained optimization problem in the non-parameterized proximal policy space. Using supervised regression, it then converts the optimal non-parameterized policy to a parameterized policy, from which it draws new samples. The methodology is general in that it applies to both discrete and continuous action spaces, and can handle a wide variety of proximity constraints for the non-parameterized optimization problem. We show how the Natural Policy Gradient and Trust Region Policy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization (PPO) problem can be addressed by this methodology. The SPU implementation is much simpler than TRPO. In terms of sample efficiency, our extensive experiments show SPU outperforms TRPO in Mujoco simulated robotic tasks and outperforms PPO in Atari video game tasks.", "keywords": ["Deep Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper130/Authors"], "authors": ["Anonymous"], "TL;DR": "first posing and solving the sample efficiency optimization problem in the non-parameterized policy space, and then solving a supervised regression problem to find a parameterized policy that is near the optimal non-parameterized policy.", "pdf": "/pdf/0435856f4b42dca176ef1f01e9f4689c96517b19.pdf", "paperhash": "anonymous|supervised_policy_update", "_bibtex": "@inproceedings{    \nanonymous2019supervised,    \ntitle={SUPERVISED POLICY UPDATE},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxTroR9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bke0rjR5F7", "original": "HJxEmRnKY7", "number": 131, "cdate": 1538087749644, "ddate": null, "tcdate": 1538087749644, "tmdate": 1538156235720, "tddate": null, "forum": "Bke0rjR5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness", "abstract": "Many notions of fairness may be expressed as linear constraints, and the resulting constrained objective is often optimized by transforming the problem into its Lagrangian dual with additive linear penalties. In non-convex settings, the resulting problem may be difficult to solve as the Lagrangian is not guaranteed to have a deterministic saddle-point equilibrium.  In this paper, we propose to modify the linear penalties to second-order ones, and we argue that this results in a more practical training procedure in non-convex, large-data settings. For one, the use of second-order penalties allows training the penalized objective with a fixed value of the penalty coefficient, thus avoiding the instability and potential lack of convergence associated with two-player min-max games. Secondly, we derive a method for efficiently computing the gradients associated with the second-order penalties in stochastic mini-batch settings. Our resulting algorithm performs well empirically, learning an appropriately fair classifier on a number of standard benchmarks.", "keywords": ["fairness"], "authorids": ["ICLR.cc/2019/Conference/Paper131/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method to stochastically optimize second-order penalties and show how this may apply to training fairness-aware classifiers.", "pdf": "/pdf/2a9a0cc149e898e4d6cf9cf5d60cd25f5913370b.pdf", "paperhash": "anonymous|stochastic_learning_of_additive_secondorder_penalties_with_applications_to_fairness", "_bibtex": "@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bke0rjR5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eRBoC9FX", "original": "B1edS0hKYm", "number": 132, "cdate": 1538087749828, "ddate": null, "tcdate": 1538087749828, "tmdate": 1538156235513, "tddate": null, "forum": "H1eRBoC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Meta-Learning for Reinforcement Learning", "abstract": "Meta-learning is a powerful tool that learns how to quickly adapt a model to new tasks. In the context of reinforcement learning, meta-learning algorithms can acquire reinforcement learning procedures to solve new problems more efficiently by meta-learning prior tasks. The performance of meta-learning algorithms critically depends on the tasks available for meta-training: in the same way that supervised learning algorithms generalize best to test points drawn from the same distribution as the training points, meta-learning methods generalize best to tasks from the same distribution as the meta-training tasks. In effect, meta-reinforcement learning offloads the design burden from algorithm design to task design. If we can automate the process of task design as well, we can devise a meta-learning algorithm that is truly automated. In this work, we take a step in this direction, proposing a family of unsupervised meta-learning algorithms for reinforcement learning. We describe a general recipe for unsupervised meta-reinforcement learning, and describe an effective instantiation of this approach based on a recently proposed unsupervised exploration technique and model-agnostic meta-learning. We also discuss practical and conceptual considerations for developing unsupervised meta-learning methods. Our experimental results demonstrate that unsupervised meta-reinforcement learning effectively acquires accelerated reinforcement learning procedures without the need for manual task design, significantly exceeds the performance of learning from scratch, and even matches performance of meta-learning methods that use hand-specified task distributions.", "keywords": ["Meta-Learning", "Reinforcement Learning", "Exploration", "Unsupervised"], "authorids": ["ICLR.cc/2019/Conference/Paper132/Authors"], "authors": ["Anonymous"], "TL;DR": "Remove the burden of task distribution specification in meta-reinforcement learning by using unsupervised exploration", "pdf": "/pdf/26f7291b33edc5e0996091ca71bcbc99acbc2082.pdf", "paperhash": "anonymous|unsupervised_metalearning_for_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Meta-Learning for Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eRBoC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1MAriC5F7", "original": "SJliZHaYYQ", "number": 133, "cdate": 1538087750000, "ddate": null, "tcdate": 1538087750000, "tmdate": 1538156235301, "tddate": null, "forum": "S1MAriC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Massively Parallel Hyperparameter Tuning", "abstract": "Modern learning models are characterized by large hyperparameter spaces. In order to adequately explore these large spaces, we must evaluate a large number of configurations, typically orders of magnitude more configurations than available parallel workers.   Given the growing costs of model training, we would ideally like to perform this search in roughly the same wall-clock time needed to train a single model. In this work, we tackle this challenge by introducing ASHA, a simple and robust hyperparameter tuning algorithm with solid theoretical underpinnings that exploits parallelism and aggressive early-stopping. Our extensive empirical results show that ASHA slightly outperforms Fabolas and Population Based Tuning, state-of-the hyperparameter tuning methods; scales linearly with the number of workers in distributed settings; converges to a high quality configuration in half the time taken by Vizier (Google's internal hyperparameter tuning service) in an experiment with 500 workers; and beats the published result for a near state-of-the-art LSTM architecture in under 2x the time to train a single model.", "keywords": ["hyperparameter optimization", "automl"], "authorids": ["ICLR.cc/2019/Conference/Paper133/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8a084a706c8e5126b3b33e48f76d652e58ea83d1.pdf", "paperhash": "anonymous|massively_parallel_hyperparameter_tuning", "_bibtex": "@inproceedings{    \nanonymous2019massively,    \ntitle={Massively Parallel Hyperparameter Tuning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1MAriC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJf0BjAqYX", "original": "HylJkiLDYm", "number": 134, "cdate": 1538087750190, "ddate": null, "tcdate": 1538087750190, "tmdate": 1538156235094, "tddate": null, "forum": "rJf0BjAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Like What You Like: Knowledge Distill via Neuron Selectivity Transfer", "abstract": "Despite deep neural networks have demonstrated extraordinary power in various applications, their superior performances are at expense of high storage and computational costs. Consequently, the acceleration and compression of neural networks have attracted much attention recently. Knowledge Transfer (KT), which aims at training a smaller student network by transferring knowledge from a larger teacher model, is one of the popular solutions. In this paper, we propose a novel knowledge transfer method by treating it as a distribution matching problem. Particularly, we match the distributions of neuron selectivity patterns between teacher and student networks. To achieve this goal, we devise a new KT loss function by minimizing the Maximum Mean Discrepancy (MMD) metric between these distributions. Combined with the original loss function, our method can significantly improve the performance of student networks. We validate the effectiveness of our method across several datasets, and further combine it with other KT methods to explore the best possible results. Last but not least, we fine-tune the model to other tasks such as object detection. The results are also encouraging, which confirm the transferability of the learned features.", "keywords": ["Knowledge Distill"], "authorids": ["ICLR.cc/2019/Conference/Paper134/Authors"], "authors": ["Anonymous"], "TL;DR": "We treat knowledge distill as a distribution matching problem and adopt Maximum Mean Discrepancy to minimize the distances between student features and teacher features.", "pdf": "/pdf/3f4fd0cca1cf1530bd1eb068eddb668ec8c2826e.pdf", "paperhash": "anonymous|like_what_you_like_knowledge_distill_via_neuron_selectivity_transfer", "_bibtex": "@inproceedings{    \nanonymous2019like,    \ntitle={Like What You Like: Knowledge Distill via Neuron Selectivity Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJf0BjAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJNRHiAcYX", "original": "rJgUBvpFtm", "number": 135, "cdate": 1538087750363, "ddate": null, "tcdate": 1538087750363, "tmdate": 1538156234888, "tddate": null, "forum": "SJNRHiAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Boosting Trust Region Policy Optimization by Normalizing flows Policy", "abstract": "We propose to improve trust region policy search with normalizing flows policy. We illustrate that when the trust region is constructed by KL divergence constraint, normalizing flows policy can generate samples far from the 'center' of the previous policy iterate, which potentially enables better exploration and helps avoid bad local optima. We show that normalizing flows policy significantly improves upon factorized Gaussian policy baseline, with both TRPO and ACKTR, especially on tasks with complex dynamics such as Humanoid.", "keywords": ["Reinforcement Learning", "Normalizing Flows"], "authorids": ["ICLR.cc/2019/Conference/Paper135/Authors"], "authors": ["Anonymous"], "TL;DR": "Normalizing flows policy to improve TRPO and ACKTR", "pdf": "/pdf/8b991440fdf07b52c83d568a760e3bd0e168a55c.pdf", "paperhash": "anonymous|boosting_trust_region_policy_optimization_by_normalizing_flows_policy", "_bibtex": "@inproceedings{    \nanonymous2019boosting,    \ntitle={Boosting Trust Region Policy Optimization by Normalizing flows Policy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJNRHiAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1g1LoAcFm", "original": "rylrEoxuKm", "number": 136, "cdate": 1538087750541, "ddate": null, "tcdate": 1538087750541, "tmdate": 1538156234674, "tddate": null, "forum": "r1g1LoAcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Using Ontologies To Improve Performance In Massively Multi-label Prediction", "abstract": "Massively multi-label prediction/classification problems arise in environments like health-care or biology where it is useful to make very precise predictions. One challenge with massively multi-label problems is that there is often a long-tailed frequency distribution for the labels, resulting in few positive examples for the rare labels. We propose a solution to this problem by modifying the output layer of a neural network to create a Bayesian network of sigmoids which takes advantage of ontology relationships between the labels to help share information between the rare and the more common labels.  We apply this method to the two massively multi-label tasks of disease prediction (ICD-9 codes) and protein function prediction (Gene Ontology terms) and obtain significant improvements in per-label AUROC and average precision.", "keywords": ["multi-label", "Bayesian network", "ontology"], "authorids": ["ICLR.cc/2019/Conference/Paper136/Authors"], "authors": ["Anonymous"], "TL;DR": " We propose a new method for using ontology information to improve performance on massively multi-label prediction/classification problems.", "pdf": "/pdf/b07819eea3c8449701c2d757debbf22976194a24.pdf", "paperhash": "anonymous|using_ontologies_to_improve_performance_in_massively_multilabel_prediction", "_bibtex": "@inproceedings{    \nanonymous2019using,    \ntitle={Using Ontologies To Improve Performance In Massively Multi-label Prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g1LoAcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xk8jAqKQ", "original": "HJghsfPttQ", "number": 137, "cdate": 1538087750724, "ddate": null, "tcdate": 1538087750724, "tmdate": 1538156234463, "tddate": null, "forum": "H1xk8jAqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Backplay: 'Man muss immer umkehren'", "abstract": "A long-standing problem in model-free reinforcement learning (RL) is that it requires a large number of trials to learn a good policy, especially in environments with sparse rewards. We explore a method to increase the sample efficiency of RL when we have access to demonstrations. Our approach, Backplay, uses a single demonstration to construct a curriculum for a given task. Rather than starting each training episode in the environment\u2019s fixed initial state, we start the agent near the end of the demonstration and move the starting point backwards during the course of training until we reach the initial state. We perform experiments in a competitive four-player game (Pommerman) and a path-finding maze game. We find that Backplay provides significant gains in sample complexity with a stark advantage in sparse reward settings. In some cases, it reached success rates greater than 50% and generalized to unseen initial conditions, while standard RL did not yield any improvement.", "keywords": ["Exploration", "Games", "Pommerman", "Bomberman", "AI", "Reinforcement Learning", "Machine Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper137/Authors"], "authors": ["Anonymous"], "TL;DR": "Learn by working backwards from a single demonstration, even an inefficient one, and progressively have the agent do more of the solving itself.", "pdf": "/pdf/fc691db0c8dfbf8d703374b6cc3ea0212ec4fc67.pdf", "paperhash": "anonymous|backplay_man_muss_immer_umkehren", "_bibtex": "@inproceedings{    \nanonymous2019backplay:,    \ntitle={Backplay: 'Man muss immer umkehren'},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xk8jAqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1z1UjA5FX", "original": "HygQ4rB4FX", "number": 138, "cdate": 1538087750902, "ddate": null, "tcdate": 1538087750902, "tmdate": 1538156234254, "tddate": null, "forum": "r1z1UjA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Defense Via Data Dependent Activation Function and  Total Variation Minimization", "abstract": "We improve the robustness of deep neural nets  to adversarial attacks by using an interpolating function as the output activation.   This data-dependent activation function remarkably improves both classification accuracy and stability to adversarial perturbations. Together with the total variation minimization of adversarial images and augmented training, under the strongest attack, we achieve up to 20.6%, 50.7%, and 68.7% accuracy improvement w.r.t.  the fast gradient sign method, iterative fast gradient sign method, and Carlini-WagnerL2attacks, respectively.  Our defense strategy is additive to many of the existing methods.  We give an intuitive explanation of our defense strategy via analyzing the geometry of the feature space. For reproducibility, the code will be available on GitHub.", "keywords": ["Adversarial Attack", "Adversarial Defense", "Data Dependent Activation Function", "Total Variation Minimization"], "authorids": ["ICLR.cc/2019/Conference/Paper138/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposal strategies for adversarial defense based on data dependent activation function, total variation minimization, and training data augmentation", "pdf": "/pdf/0af7d8595acd050aa1f5ed39386d3b23f2d3c516.pdf", "paperhash": "anonymous|adversarial_defense_via_data_dependent_activation_function_and_total_variation_minimization", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Defense Via Data Dependent Activation Function and  Total Variation Minimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1z1UjA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xkIjA9tX", "original": "H1eUrJRFt7", "number": 139, "cdate": 1538087751097, "ddate": null, "tcdate": 1538087751097, "tmdate": 1538156234045, "tddate": null, "forum": "r1xkIjA9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "q-Neurons: Neuron Activations based on Stochastic Jackson's Derivative Operators", "abstract": "We propose a new generic type of stochastic neurons, called $q$-neurons, that considers activation functions based on Jackson's $q$-derivatives, with stochastic parameters $q$. Our generalization of neural network architectures with $q$-neurons is shown to be both scalable and very easy to implement. We demonstrate experimentally consistently improved performances over state-of-the-art standard activation functions, both on training and testing loss functions.\n", "keywords": ["q-calculus", "neural activation function"], "authorids": ["ICLR.cc/2019/Conference/Paper139/Authors"], "authors": ["Anonymous"], "TL;DR": "q-calculus helps build simple and scalable neural activation functions", "pdf": "/pdf/e7eaffe9345c90bc41e728e2f31f9207e11168c1.pdf", "paperhash": "anonymous|qneurons_neuron_activations_based_on_stochastic_jacksons_derivative_operators", "_bibtex": "@inproceedings{    \nanonymous2019q-neurons:,    \ntitle={q-Neurons: Neuron Activations based on Stochastic Jackson's Derivative Operators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xkIjA9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyg1Ls0cKQ", "original": "SJgZ9V2Kt7", "number": 140, "cdate": 1538087751284, "ddate": null, "tcdate": 1538087751284, "tmdate": 1538156233819, "tddate": null, "forum": "Hyg1Ls0cKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Latent Semantic Representation from Pre-defined Generative Model", "abstract": "Learning representations of data is an important issue in machine learning. Though GAN has led to significant improvements in the data representations, it still has several problems such as unstable training, hidden manifold of data, and huge computational overhead. GAN tends to produce the data simply without any information about the manifold of the data, which hinders from controlling desired features to generate. Moreover, most of GAN\u2019s have a large size of manifold, resulting in poor scalability. In this paper, we propose a novel GAN to control the latent semantic representation, called LSC-GAN, which allows us to produce desired data to generate and learns a representation of the data efficiently. Unlike the conventional GAN models with hidden distribution of latent space, we define the distributions explicitly in advance that are trained to generate the data based on the corresponding features by inputting the latent variables that follow the distribution. As the larger scale of latent space caused by deploying various distributions in one latent space makes training unstable while maintaining the dimension of latent space, we need to separate the process of defining the distributions explicitly and operation of generation. We prove that a VAE is proper for the former and modify a loss function of VAE to map the data into the pre-defined latent space so as to locate the reconstructed data as close to the input data according to its characteristics. Moreover, we add the KL divergence to the loss function of LSC-GAN to include this process. The decoder of VAE, which generates the data with the corresponding features from the pre-defined latent space, is used as the generator of the LSC-GAN. Several experiments on the CelebA dataset are conducted to verify the usefulness of the proposed method to generate desired data stably and efficiently, achieving a high compression ratio that can hold about 24 pixels of information in each dimension of latent space. Besides, our model learns the reverse of features such as not laughing (rather frowning) only with data of ordinary and smiling facial expression.", "keywords": ["Latent space", "Generative adversarial network", "variational autoencoder", "conditioned generation"], "authorids": ["ICLR.cc/2019/Conference/Paper140/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a generative model that not only produces data with desired features from the pre-defined latent space but also fully understands the features of the data to create characteristics that are not in the dataset.", "pdf": "/pdf/35c7239a229fd9030f0d906a93428001abde9917.pdf", "paperhash": "anonymous|learning_latent_semantic_representation_from_predefined_generative_model", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Latent Semantic Representation from Pre-defined Generative Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyg1Ls0cKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJG1Uo09Fm", "original": "SylE1PAqYQ", "number": 141, "cdate": 1538087751466, "ddate": null, "tcdate": 1538087751466, "tmdate": 1538156233608, "tddate": null, "forum": "HJG1Uo09Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Reinforcement Learn by Imitation", "abstract": "Meta-reinforcement learning aims to learn fast reinforcement learning (RL) procedures that can be applied to new tasks or environments. While learning fast RL procedures holds promise for allowing agents to autonomously learn a diverse range of skills, existing methods for learning efficient RL are impractical for real world settings, as they rely on slow reinforcement learning algorithms for meta-training, even when the learned procedures are fast. In this paper, we propose to learn a fast reinforcement learning procedure through supervised imitation of an expert, such that, after meta-learning, an agent can quickly learn new tasks through trial-and-error. Through our proposed method, we show that it is possible to learn fast RL using demonstrations, rather than relying on slow RL, where expert agents can be trained quickly by using privileged information or off-policy RL methods. Our experimental evaluation on a number of complex simulated robotic domains demonstrates that our method can effectively learn to learn from spare rewards and is significantly more efficient than prior meta reinforcement learning algorithms.", "keywords": ["meta-learning", "reinforcement learning", "imitation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper141/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7b8c2aa28c5e0257e3815f510cced62a4dbf0e77.pdf", "paperhash": "anonymous|learning_to_reinforcement_learn_by_imitation", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Reinforcement Learn by Imitation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJG1Uo09Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1elIi09K7", "original": "B1lkDLCFFm", "number": 142, "cdate": 1538087751647, "ddate": null, "tcdate": 1538087751647, "tmdate": 1538156233405, "tddate": null, "forum": "r1elIi09K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning a Neural-network-based Representation for Open Set Recognition", "abstract": "In this paper, we present a neural network based representation for addressing the open set recognition problem. In this representation instances from the same class are close to each other while instances from different classes are further apart, resulting in statistically significant improvement when compared to other approaches on three datasets from two different domains.   \n", "keywords": ["open set recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper142/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper, we present a neural network based representation for addressing the open set recognition problem.", "pdf": "/pdf/7703a398450a0ba76e2ab321560e89e8e56585ce.pdf", "paperhash": "anonymous|learning_a_neuralnetworkbased_representation_for_open_set_recognition", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning a Neural-network-based Representation for Open Set Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1elIi09K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryggIs0cYQ", "original": "HJei3rRFY7", "number": 143, "cdate": 1538087751822, "ddate": null, "tcdate": 1538087751822, "tmdate": 1538156233201, "tddate": null, "forum": "ryggIs0cYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Differentiable Learning-to-Normalize via Switchable Normalization", "abstract": "We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network. SN employs three distinct scopes to compute statistics (means and variances) including a channel, a layer, and a minibatch. SN switches between them by learning their importance weights in an end-to-end manner. It has several good properties. First, it adapts to various network architectures and tasks (see Fig.1). Second, it is robust to a wide range of batch sizes, maintaining high performance even when small minibatch is presented (e.g. 2 images/GPU). Third, SN does not have sensitive hyper-parameter, unlike group normalization that searches the number of groups as a hyper-parameter. Without bells and whistles, SN outperforms its counterparts on various challenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, and Kinetics. Analyses of SN are also presented. We hope SN will help ease the usage and understand the normalization techniques in deep learning. The code of SN will be released.", "keywords": ["normalization", "deep learning", "CNN", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper143/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2d73712099a4d64189c804b3d335836c388343c3.pdf", "paperhash": "anonymous|differentiable_learningtonormalize_via_switchable_normalization", "_bibtex": "@inproceedings{    \nanonymous2019differentiable,    \ntitle={Differentiable Learning-to-Normalize via Switchable Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryggIs0cYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1ge8sCqFX", "original": "Hye2fF0YFX", "number": 144, "cdate": 1538087752000, "ddate": null, "tcdate": 1538087752000, "tmdate": 1538156232996, "tddate": null, "forum": "r1ge8sCqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Exhaustive Analysis of Lazy vs. Eager Learning Methods for Real-Estate Property Investment", "abstract": "Accurate rent prediction in real estate investment can help in generating capital gains and guaranty a financial success. In this paper, we carry out a comprehensive analysis and study of eleven machine learning algorithms for rent prediction, including Linear Regression, Multilayer Perceptron, Random Forest, KNN, ML-KNN, Locally Weighted Learning, SMO, SVM, J48, lazy Decision Tree (i.e., lazy DT), and KStar algorithms. \nOur contribution in this paper is twofold: (1) We present a comprehensive analysis of internal and external attributes of a real-estate housing dataset and their correlation with rental prices. (2) We use rental prediction as a platform to study and compare the performance of eager vs. lazy machine learning methods using myriad of ML algorithms.  \nWe train our rent prediction models using a Zillow data set of 4K real estate properties in Virginia State of the US, including three house types of single-family, townhouse, and condo. Each data instance in the dataset has 21 internal attributes (e.g., area space, price, number of bed/bath, rent, school rating, so forth). In addition to Zillow data, external attributes like walk/transit score, and crime rate are collected from online data sources. A subset of the collected features - determined by the PCA technique-  are selected to tune the parameters of the prediction models. We employ a hierarchical clustering approach to cluster the data based on two factors of house type, and average rent estimate of zip codes. We evaluate and compare the efficacy of the tuned prediction models based on two metrics of R-squared and Mean Absolute Error, applied on unseen data. Based on our study, lazy models like KStar lead to higher accuracy and lower prediction error compared to eager methods like J48 and LR. However, it is not necessarily found to be an overarching conclusion drawn from the comparison between all the lazy and eager methods in this work. ", "keywords": ["applied machine learning", "housing analytics", "eager learning", "lazy learning", "rent prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper144/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a484543d8d94b2430672f4f536f5e7683ac9a042.pdf", "paperhash": "anonymous|an_exhaustive_analysis_of_lazy_vs_eager_learning_methods_for_realestate_property_investment", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Exhaustive Analysis of Lazy vs. Eager Learning Methods for Real-Estate Property Investment},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1ge8sCqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxxIs0qY7", "original": "rJeAFRFbFX", "number": 145, "cdate": 1538087752182, "ddate": null, "tcdate": 1538087752182, "tmdate": 1538156232791, "tddate": null, "forum": "SkxxIs0qY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CoT: Cooperative Training for Generative Modeling of Discrete Data", "abstract": "We propose Cooperative Training (CoT) for training generative models that measure a tractable density for discrete data. CoT coordinately trains a generator G and an auxiliary predictive mediator M. The training target of M is to estimate a mixture density of the learned distribution G and the target distribution P, and that of G is to minimize the Jensen-Shannon divergence estimated through M. CoT achieves independent success without the necessity of pre-training via Maximum Likelihood Estimation or involving high-variance algorithms like REINFORCE. This low-variance algorithm is theoretically proved to be superior for both sample generation and likelihood prediction. We also theoretically and empirically show the superiority of CoT over most previous algorithms in terms of generative quality and diversity, predictive generalization ability and computational cost.", "keywords": ["Generative Models", "Sequence Modeling", "Text Generation"], "authorids": ["ICLR.cc/2019/Conference/Paper145/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed Cooperative Training, a novel training algorithm for generative modeling of discrete data.", "pdf": "/pdf/f5454016982caf98838d4718d3e0e8fd98f67ba0.pdf", "paperhash": "anonymous|cot_cooperative_training_for_generative_modeling_of_discrete_data", "_bibtex": "@inproceedings{    \nanonymous2019cot:,    \ntitle={CoT: Cooperative Training for Generative Modeling of Discrete Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxxIs0qY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkzeUiRcY7", "original": "HJl-LU6FYX", "number": 146, "cdate": 1538087752357, "ddate": null, "tcdate": 1538087752357, "tmdate": 1538156232588, "tddate": null, "forum": "BkzeUiRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "M^3RL: Mind-aware Multi-agent Management Reinforcement Learning", "abstract": "Most of the prior work on multi-agent reinforcement learning (MARL) achieves optimal collaboration by directly controlling the agents to maximize a common reward. In this paper, we aim to address this from a different angle. In particular, we consider scenarios where there are self-interested agents (i.e., worker agents) which have their own minds (preferences, intentions, skills, etc.) and can not be dictated to perform tasks they do not wish to do. For achieving optimal coordination among these agents, we train a super agent (i.e., the manager) to manage them by first inferring their minds based on both current and past observations and then initiating contracts to assign suitable tasks to workers and promise to reward them with corresponding bonuses so that they will agree to work together. The objective of the manager is maximizing the overall productivity as well as minimizing payments made to the workers for ad-hoc worker teaming. To train the manager, we propose Mind-aware Multi-agent Management Reinforcement Learning (M^3RL), which consists of agent modeling and policy learning. We have evaluated our approach in two environments,  Resource Collection and Crafting, to simulate multi-agent management problems with various task settings and multiple designs for the worker agents. The experimental results have validated the effectiveness of our approach in modeling worker agents' minds online, and in achieving optimal ad-hoc teaming with good generalization and fast adaptation.", "keywords": ["Multi-agent Reinforcement Learning", "Deep Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper146/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Mind-aware Multi-agent Management Reinforcement Learning (M^3RL) for training a manager to motivate self-interested workers to achieve optimal collaboration by assigning suitable contracts to them.", "pdf": "/pdf/ccd5034fa38af924778c26ee4da4212e9addb61d.pdf", "paperhash": "anonymous|m^3rl_mindaware_multiagent_management_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019m^3rl:,    \ntitle={M^3RL: Mind-aware Multi-agent Management Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkzeUiRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJeWUs05KQ", "original": "SkgwNOguFX", "number": 147, "cdate": 1538087752598, "ddate": null, "tcdate": 1538087752598, "tmdate": 1538156232376, "tddate": null, "forum": "BJeWUs05KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information", "abstract": "The use of imitation learning to learn a single policy for a complex task that has multiple modes or hierarchical structure can be challenging. In fact, previous work has shown that when the modes are known, learning separate policies for each mode or sub-task can greatly improve the performance of imitation learning. In this work, we discover the interaction between sub-tasks from their resulting state-action trajectory sequences using a directed graphical model. We propose a new algorithm based on the generative adversarial imitation learning framework which automatically learns sub-task policies from unsegmented demonstrations. Our approach maximizes the directed information flow in the graphical model between sub-task latent variables and their generated trajectories. We also show how our approach connects with the existing Options framework, which is commonly used to learn hierarchical policies.", "keywords": ["Imitation Learning", "Reinforcement Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper147/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information", "pdf": "/pdf/e25ef7b7318efa59f628bea7a85e3ca0d3b91fd0.pdf", "paperhash": "anonymous|directedinfo_gail_learning_hierarchical_policies_from_unsegmented_demonstrations_using_directed_information", "_bibtex": "@inproceedings{    \nanonymous2019directed-info,    \ntitle={Directed-Info GAIL: Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Information},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeWUs05KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1x-LjAcKX", "original": "H1lJ230FFX", "number": 148, "cdate": 1538087752779, "ddate": null, "tcdate": 1538087752779, "tmdate": 1538156232170, "tddate": null, "forum": "B1x-LjAcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Local Critic Training of Deep Neural Networks", "abstract": "This paper proposes a novel approach to train deep neural networks by unlocking the layer-wise dependency of backpropagation training. The approach employs additional modules called local critic networks besides the main network model to be trained, which are used to obtain error gradients without complete feedforward and backward propagation processes. We propose a cascaded learning strategy for these local networks. In addition, the approach is also useful from multi-model perspectives, including structural optimization of neural networks, computationally efficient progressive inference, and ensemble classification for performance improvement. Experimental results show the effectiveness of the proposed approach and suggest guidelines for determining appropriate algorithm parameters.", "keywords": ["inter-layer locking", "local critic network", "backpropagation", "convolutional neural network", "structural optimization", "progress inference", "ensemble inference"], "authorids": ["ICLR.cc/2019/Conference/Paper148/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new learning algorithm of deep neural networks, which unlocks the layer-wise dependency of backpropagation.", "pdf": "/pdf/a94f0f485515ba552c42e89a1fff5cf572ef81e5.pdf", "paperhash": "anonymous|local_critic_training_of_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019local,    \ntitle={Local Critic Training of Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1x-LjAcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hye-LiR5Y7", "original": "S1enJOHjdQ", "number": 149, "cdate": 1538087752954, "ddate": null, "tcdate": 1538087752954, "tmdate": 1538156231965, "tddate": null, "forum": "Hye-LiR5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels", "abstract": "We present SOSELETO (SOurce SELEction for Target Optimization), a new method for exploiting a source dataset to solve a classification problem on a target dataset.  SOSELETO is based on the following simple intuition: some source examples are more informative than others for the target problem.  To capture this intuition, source samples are each given weights; these weights are solved for jointly with the source and target classification problems via a bilevel optimization scheme.  The target therefore gets to choose the source samples which are most informative for its own classification task.  Furthermore, the bilevel nature of the optimization acts as a kind of regularization on the target, mitigating overfitting.  SOSELETO may be applied to both classic transfer learning, as well as the problem of training on datasets with noisy labels; we show state of the art results on both of these problems.", "keywords": ["transfer learning"], "authorids": ["ICLR.cc/2019/Conference/Paper149/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning with limited training data by exploiting \"helpful\" instances from a rich data source.  ", "pdf": "/pdf/6dc8d05f3821de1835434d6f7f77a67e9995ec88.pdf", "paperhash": "anonymous|soseleto_a_unified_approach_to_transfer_learning_and_training_with_noisy_labels", "_bibtex": "@inproceedings{    \nanonymous2019soseleto:,    \ntitle={SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hye-LiR5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lWUoA9FQ", "original": "SJlWmxsOuX", "number": 150, "cdate": 1538087753136, "ddate": null, "tcdate": 1538087753136, "tmdate": 1538156231759, "tddate": null, "forum": "r1lWUoA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Are adversarial examples inevitable?", "abstract": "A wide range of defenses have been proposed to harden neural networks against adversarial attacks. However, a pattern has emerged in which the majority of adversarial defenses are quickly broken by new attacks.  Given the lack of success at generating robust defenses, we are led to ask a fundamental question:  Are adversarial attacks inevitable?\nThis paper analyzes adversarial examples from a theoretical perspective, and identifies fundamental bounds on the susceptibility of a classifier to adversarial attacks.   We show that, for certain classes of problems, adversarial examples are inescapable.  Using experiments, we explore the implications of theoretical guarantees for real-world problems and discuss how factors such as dimensionality and image complexity limit a classifier's robustness against adversarial examples.\n\n", "keywords": ["adversarial examples", "neural networks", "security"], "authorids": ["ICLR.cc/2019/Conference/Paper150/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper identifies classes of problems for which adversarial examples are inescapable, and derives fundamental bounds on the susceptibility of any classifier to adversarial examples. ", "pdf": "/pdf/d5fb95ab1d3eb14840d6bd69fd08a638ecd91169.pdf", "paperhash": "anonymous|are_adversarial_examples_inevitable", "_bibtex": "@inproceedings{    \nanonymous2019are,    \ntitle={Are adversarial examples inevitable?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lWUoA9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJe-LiA5YX", "original": "BJxakHauK7", "number": 151, "cdate": 1538087753319, "ddate": null, "tcdate": 1538087753319, "tmdate": 1538156231550, "tddate": null, "forum": "rJe-LiA5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exponentially Decaying Flows for Optimization in Deep Learning", "abstract": "The field of deep learning has been craving for an optimization method that shows outstanding property for both optimization and generalization.  We propose a method for mathematical optimization based on flows along geodesics, that is, the shortest paths between two points, with respect to the Riemannian metric induced by a non-linear function. In our method, the flows refer to Exponentially Decaying Flows (EDF), as they can be designed to converge on the local solutions exponentially. In this paper, we conduct experiments to show its high performance on optimization benchmarks (i.e., convergence properties), as well as its potential for producing good machine learning benchmarks (i.e., generalization properties).", "keywords": ["optimization", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper151/Authors"], "authors": ["Anonymous"], "TL;DR": "Introduction of a new optimization method and its application to deep learning.", "pdf": "/pdf/749a496fdc031db1e1814571f105483892e23973.pdf", "paperhash": "anonymous|exponentially_decaying_flows_for_optimization_in_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019exponentially,    \ntitle={Exponentially Decaying Flows for Optimization in Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJe-LiA5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgz8sA5F7", "original": "Sye6ln3tFX", "number": 152, "cdate": 1538087753539, "ddate": null, "tcdate": 1538087753539, "tmdate": 1538156231346, "tddate": null, "forum": "rJgz8sA5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "HC-Net: Memory-based Incremental Dual-Network System for Continual learning", "abstract": "Training a neural network for a classification task typically assumes that the data to train are given from the beginning.\nHowever, in the real world, additional data accumulate gradually and the model requires additional training without accessing the old training data. This usually leads to the catastrophic forgetting problem which is inevitable for the traditional training methodology of neural networks.\nIn this paper, we propose a memory-based continual learning method that is able to learn additional tasks while retaining the performance of previously learned tasks.\nComposed of two complementary networks, the Hippocampus-Net (H-Net) and the Cortex-Net (C-Net), our model estimates the index of the corresponding task for an input sample and utilizes a particular portion of itself with the estimated index.\nThe C-Net guarantees no degradation in the performance of the previously learned tasks and the H-Net shows high confidence in finding the origin of an input sample.", "keywords": ["continual learning", "lifelong learning", "catastrophic forgetting"], "authorids": ["ICLR.cc/2019/Conference/Paper152/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper, we propose a network which efficiently increases its complexity without degrading the performance of previous tasks inspired by the brain system of human being", "pdf": "/pdf/44ed1c6d0ab6a71190c565c1794c37975bc36b22.pdf", "paperhash": "anonymous|hcnet_memorybased_incremental_dualnetwork_system_for_continual_learning", "_bibtex": "@inproceedings{    \nanonymous2019hc-net:,    \ntitle={HC-Net: Memory-based Incremental Dual-Network System for Continual learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgz8sA5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklzIjActX", "original": "rJxtmNxcKX", "number": 153, "cdate": 1538087753711, "ddate": null, "tcdate": 1538087753711, "tmdate": 1538156231141, "tddate": null, "forum": "SklzIjActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "HIGHLY EFFICIENT 8-BIT LOW PRECISION INFERENCE OF CONVOLUTIONAL NEURAL NETWORKS", "abstract": "High throughput and low latency inference of deep neural networks are critical for the deployment of deep learning applications. This paper presents a general technique toward 8-bit low precision inference of convolutional neural networks, including 1) channel-wise scale factors of weights, especially for depthwise convolution, 2) Winograd convolution, and 3) topology-wise 8-bit support. We experiment the techniques on top of a widely-used deep learning framework. The 8-bit optimized model is automatically generated with a calibration process from FP32 model without the need of fine-tuning or retraining. We perform a systematical and comprehensive study on 18 widely-used convolutional neural networks and demonstrate the effectiveness of 8-bit low precision inference across a wide range of applications and use cases, including image classification, object detection, image segmentation, and super resolution. We show that the inference throughput\nand latency are improved by 1.6X and 1.5X respectively with minimal within 0.6%1to no loss in accuracy from FP32 baseline. We believe the methodology can provide the guidance and reference design of 8-bit low precision inference for other frameworks. All the code and models will be publicly available soon.", "keywords": ["8-bit low precision inference", "convolutional neural networks", "statistical accuracy", "8-bit Winograd convolution"], "authorids": ["ICLR.cc/2019/Conference/Paper153/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a general technique toward 8-bit low precision inference of convolutional neural networks. ", "pdf": "/pdf/b9dd890039376e056a3498b29c2612b1fffa81e1.pdf", "paperhash": "anonymous|highly_efficient_8bit_low_precision_inference_of_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019highly,    \ntitle={HIGHLY EFFICIENT 8-BIT LOW PRECISION INFERENCE OF CONVOLUTIONAL NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklzIjActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkGzUjR5tQ", "original": "SJg5pzlqKm", "number": 154, "cdate": 1538087753889, "ddate": null, "tcdate": 1538087753889, "tmdate": 1538156230937, "tddate": null, "forum": "HkGzUjR5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DATNet: Dual Adversarial Transfer for Low-resource Named Entity Recognition", "abstract": "We propose a new architecture termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER). Specifically, two variants of DATNet, i.e., DATNet-F and DATNet-P, are proposed to explore effective feature fusion between high and low resource. To address the noisy and imbalanced training data, we propose a novel Generalized Resource-Adversarial Discriminator (GRAD). Additionally, adversarial training is adopted to boost model generalization. We examine the effects of different components in DATNet across domains and languages, and show that significant improvement can be obtained especially for low-resource data. Without augmenting any additional hand-crafted features, we achieve new state-of-the-art performances on CoNLL and Twitter NER---88.00% F1 for Spanish, 52.87% F1 for WNUT-2016, and 42.22% F1 for WNUT-2017.", "keywords": ["Low-resource", "Named Entity Recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper154/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new  architecture termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER) and achieve new state-of-the-art performances on CoNLL and Twitter NER.", "pdf": "/pdf/6f075143d86e3829577fef6a5256222ca3de8eee.pdf", "paperhash": "anonymous|datnet_dual_adversarial_transfer_for_lowresource_named_entity_recognition", "_bibtex": "@inproceedings{    \nanonymous2019datnet:,    \ntitle={DATNet: Dual Adversarial Transfer for Low-resource Named Entity Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGzUjR5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryfMLoCqtQ", "original": "SJetpdx9tX", "number": 155, "cdate": 1538087754067, "ddate": null, "tcdate": 1538087754067, "tmdate": 1538156230730, "tddate": null, "forum": "ryfMLoCqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An analytic theory of generalization dynamics and transfer learning in deep linear networks", "abstract": "Much attention has been devoted recently to the generalization puzzle in deep learning: large, deep networks can generalize well, but existing theories bounding generalization error are exceedingly loose, and thus cannot explain this striking performance. Furthermore, a major hope is that knowledge may transfer across tasks, so that multi-task learning can improve generalization on individual tasks. However we lack analytic theories that can quantitatively predict how the degree of knowledge transfer depends on the relationship between the tasks. We develop an analytic theory of the nonlinear dynamics of generalization in deep linear networks, both within and across tasks. In particular, our theory provides analytic solutions to the training and testing error of deep networks as a function of training time, number of examples, network size and initialization, and the task structure and SNR. Our theory reveals that deep networks progressively learn the most important task structure first, so that generalization error at the early stopping time primarily depends on task structure and is independent of network size. This suggests any tight bound on generalization error must take into account task structure, and explains observations about real data being learned faster than random data. Intriguingly our theory also reveals the existence of a learning algorithm that proveably out-performs neural network training through gradient descent. Finally, for transfer learning, our theory reveals that knowledge transfer depends sensitively, but computably, on the SNRs and input feature alignments of pairs of tasks.", "keywords": ["Generalization", "Theory", "Transfer", "Multi-task", "Linear"], "authorids": ["ICLR.cc/2019/Conference/Paper155/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide many insights into neural network generalization from the theoretically tractable linear case.", "pdf": "/pdf/0e06ca160c49705b35c04f8a20bd05bdd8c11ddf.pdf", "paperhash": "anonymous|an_analytic_theory_of_generalization_dynamics_and_transfer_learning_in_deep_linear_networks", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An analytic theory of generalization dynamics and transfer learning in deep linear networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryfMLoCqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyEGUi05Km", "original": "SJlSCQOPF7", "number": 156, "cdate": 1538087754247, "ddate": null, "tcdate": 1538087754247, "tmdate": 1538156230524, "tddate": null, "forum": "SyEGUi05Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CrystalGAN: Learning to Discover Crystallographic Structures with Generative Adversarial Networks", "abstract": "Our main motivation is to propose an efficient approach to generate novel multi-element stable chemical compounds that can be used in real world applications. This task can be formulated as a combinatorial problem, and it takes many hours of human experts to construct, and to evaluate new data. Unsupervised learning methods such as Generative Adversarial Networks (GANs) can be efficiently used to produce new data.  Cross-domain Generative Adversarial Networks were reported to achieve exciting results in image processing applications. However, in the domain of materials science, there is a need to synthesize data with higher order complexity compared to observed samples, and the state-of-the-art cross-domain GANs can not be adapted directly. \n\nIn this contribution, we propose a novel GAN called CrystalGAN which generates new chemically stable crystallographic structures with increased domain complexity. We introduce an original architecture, we provide the corresponding loss functions, and we show that the CrystalGAN generates very reasonable data. We illustrate the efficiency of the proposed method on a real original problem of novel hydrides discovery that can be further used in development of hydrogen storage materials.", "keywords": ["Generative Adversarial Nets", "Cross-Domain Learning", "Materials Science", "Higher-order Complexity"], "authorids": ["ICLR.cc/2019/Conference/Paper156/Authors"], "authors": ["Anonymous"], "TL;DR": "\"Generating new chemical materials using novel cross-domain GANs.\"", "pdf": "/pdf/939eaaf772cfe5eb581dc9ecefdd5c95debd2666.pdf", "paperhash": "anonymous|crystalgan_learning_to_discover_crystallographic_structures_with_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019crystalgan:,    \ntitle={CrystalGAN: Learning to Discover Crystallographic Structures with Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyEGUi05Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sy4G8sC9KX", "original": "rJxOK35FY7", "number": 157, "cdate": 1538087754423, "ddate": null, "tcdate": 1538087754423, "tmdate": 1538156230315, "tddate": null, "forum": "Sy4G8sC9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "No Pressure! Addressing Problem of Local Minima in Manifold Learning", "abstract": "Nonlinear embedding manifold learning methods provide invaluable visual in- sights into a structure of high-dimensional data. However, due to a complicated nonlinear objective function, these methods can easily get stuck in local minima and their embedding quality can be poor. We propose a natural extension to several manifold learning methods aimed at identifying pressured points, i.e. points that stuck in the poor local minima and have poor embedding quality. We show that the pressure can be decreased by temporarily allowing these points to make use of an extra dimension in the embedding space. In the evaluation we show that our method is able to improve the objective function value of existing methods even after they get stuck in a poor local minimum.", "keywords": ["manifold learning", "nonlinear optimization", "local minima"], "authorids": ["ICLR.cc/2019/Conference/Paper157/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fafeac7c813855223b4b15c1b68aed4aa3b922e5.pdf", "paperhash": "anonymous|no_pressure_addressing_problem_of_local_minima_in_manifold_learning", "_bibtex": "@inproceedings{    \nanonymous2019no,    \ntitle={No Pressure! Addressing Problem of Local Minima in Manifold Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sy4G8sC9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hygm8jC9FQ", "original": "r1eCVibOYQ", "number": 158, "cdate": 1538087754592, "ddate": null, "tcdate": 1538087754592, "tmdate": 1538156230113, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper158/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/d5c1775320755d55f023674405b13296adbd2683.pdf", "paperhash": "anonymous|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@inproceedings{    \nanonymous2019favae:,    \ntitle={FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygm8jC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklmIsC9Y7", "original": "BJeEDI0Kt7", "number": 159, "cdate": 1538087754767, "ddate": null, "tcdate": 1538087754767, "tmdate": 1538156229909, "tddate": null, "forum": "HklmIsC9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "UNSUPERVISED CONVOLUTIONAL NEURAL NETWORKS FOR ACCURATE VIDEO FRAME INTERPOLATION WITH INTEGRATION OF MOTION COMPONENTS", "abstract": "Optical flow and video frame interpolation are considered as a chicken-egg problem such that one problem affects the other and vice versa. This paper presents a deep neural network that integrates the flow network into the frame interpolation problem, with end-to-end learning. The proposed approach exploits the relationship between the two problems for quality enhancement of interpolation frames. Unlike recent convolutional neural networks, the proposed approach learns motions from natural video frames without graphical ground truth flows for training. This makes the network learn from extensive data and improve the performance. The motion information from the flow network guides interpolator networks to be trained to synthesize the interpolated frame accurately from motion scenarios. In addition, diverse datasets to cover various challenging cases that previous interpolations usually fail in is used for comparison. In all experimental datasets, the proposed network achieves better performance than state-of-art CNN based interpolations. With Middebury benchmark, compared with the top-ranked algorithm, the proposed network reduces an average interpolation error by about 9.3%. The proposed interpolation is ranked the 1st in Standard Deviation (SD) interpolation error, the 2nd in Average Interpolation Error among over 150 algorithms listed in the Middlebury interpolation benchmark.", "keywords": ["Frame Interpolation", "Frame Rate Up Conversion", "Convolutional Neural Networks", "CNN", "Unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper159/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/52f5e4ab36307d568022b7be50e01b5bcec9dc3b.pdf", "paperhash": "anonymous|unsupervised_convolutional_neural_networks_for_accurate_video_frame_interpolation_with_integration_of_motion_components", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={UNSUPERVISED CONVOLUTIONAL NEURAL NETWORKS FOR ACCURATE VIDEO FRAME INTERPOLATION WITH INTEGRATION OF MOTION COMPONENTS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklmIsC9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byx7LjRcYm", "original": "SygH1LW9YX", "number": 160, "cdate": 1538087754944, "ddate": null, "tcdate": 1538087754944, "tmdate": 1538156229706, "tddate": null, "forum": "Byx7LjRcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Human Action Recognition Based on Spatial-Temporal Attention", "abstract": "Many state-of-the-art methods of recognizing human action are based on attention mechanism, which shows the importance of attention mechanism in action recognition. With the rapid development of neural networks, human action recognition has been achieved great improvement by using convolutional neural networks (CNN) or recurrent neural networks (RNN). In this paper, we propose a model based on spatial-temporal attention weighted LSTM. This model pays attention to the key part in each video frame, and also focuses on the important frames in each video sequence, thus the most important theme for our model is how to find out the key point spatially and the key frames temporally. We show a feasible architecture which can solve those two problems effectively and achieve a satisfactory result. Our model is trained and tested on three datasets including UCF-11, UCF-101, and HMDB51. Those results demonstrate a high performance of our model in human action recognition.", "authorids": ["ICLR.cc/2019/Conference/Paper160/Authors"], "authors": ["Anonymous"], "keywords": [], "pdf": "/pdf/a24113535c32a25578b1449c4a53a9404dbc2978.pdf", "paperhash": "anonymous|httpsopenreviewnetactivatetokenbb601062c788d12731404c8759ec254374662c0893d756523834723b10402467", "_bibtex": "@inproceedings{    \nanonymous2019https://openreview.net/activate?token=bb601062c788d12731404c8759ec254374662c0893d756523834723b10402467,    \ntitle={https://openreview.net/activate?token=bb601062c788d12731404c8759ec254374662c0893d756523834723b10402467},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byx7LjRcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlXUsR5KQ", "original": "r1ep1T7FYm", "number": 161, "cdate": 1538087755120, "ddate": null, "tcdate": 1538087755120, "tmdate": 1538156229501, "tddate": null, "forum": "BJlXUsR5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Neuron Non-Linearities with Kernel-Based Deep Neural Networks", "abstract": "The effectiveness of deep neural architectures has been widely supported in terms of both experimental and foundational principles. There is also clear evidence that the activation function (e.g. the recti\ufb01er and the LSTM units) plays a crucial role in the complexity of learning. Based on this remark, this paper discusses an optimal selection of the neuron non-linearity in a functional framework that is inspired from classic regularization arguments. A representation theorem is given which indicates that the best activation function is a kernel expansion in the training set, that can be effectively approximated over an opportune set of points modeling 1-D clusters. The idea can be naturally extended to recurrent networks, where the expressiveness of kernel-based activation functions turns out to be a crucial ingredient to capture long-term dependencies. We give experimental evidence of this property by a set of challenging experiments, where we compare the results with neural architectures based on state of the art LSTM cells.", "keywords": ["Activation functions", "Kernel methods", "Recurrent networks"], "authorids": ["ICLR.cc/2019/Conference/Paper161/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a5813434d3fa840a35057f8dec6dcf1a4c7f1e40.pdf", "paperhash": "anonymous|learning_neuron_nonlinearities_with_kernelbased_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Neuron Non-Linearities with Kernel-Based Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlXUsR5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJg7IsC5KQ", "original": "HyeTtDCbKX", "number": 162, "cdate": 1538087755297, "ddate": null, "tcdate": 1538087755297, "tmdate": 1538156229298, "tddate": null, "forum": "SJg7IsC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Convergence and Robustness of Batch Normalization", "abstract": "Despite its empirical success, the theoretical underpinnings of the stability, convergence and acceleration properties of batch normalization (BN) remain elusive. In this paper, we attack this problem from a modelling approach, where we perform thorough theoretical analysis on BN applied to simplified model: ordinary least squares (OLS). We discover that gradient descent on OLS with BN has interesting properties, including a scaling law, convergence for arbitrary learning rates for the weights, asymptotic acceleration effects, as well as insensitivity to choice of learning rates. We then demonstrate numerically that these findings are not specific to the OLS problem and hold qualitatively for more complex supervised learning problems. This points to a new direction towards uncovering the mathematical principles that underlies batch normalization.", "keywords": ["Batch normalization", "Convergence analysis", "Gradient descent", "Ordinary least squares", "Deep neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper162/Authors"], "authors": ["Anonymous"], "TL;DR": "We mathematically analyze the effect of batch normalization on a simple model and obtain key new insights that applies to general supervised learning.", "pdf": "/pdf/524465a85372eee2c4d437195c1ca6a5ca4f75f8.pdf", "paperhash": "anonymous|on_the_convergence_and_robustness_of_batch_normalization", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Convergence and Robustness of Batch Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJg7IsC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1f78iAcFm", "original": "Byx8nwy5FX", "number": 163, "cdate": 1538087755470, "ddate": null, "tcdate": 1538087755470, "tmdate": 1538156229090, "tddate": null, "forum": "r1f78iAcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GRAPH TRANSFORMATION POLICY NETWORK FOR CHEMICAL REACTION PREDICTION", "abstract": "We address a fundamental problem in chemistry known as chemical reaction product prediction. Our main insight is that the input reactant and reagent molecules can be jointly represented as a graph and the process of generating product molecules from reactant molecules (reaction mechanism) can be formulated as a sequence of graph transformations. To this end, we propose Graph Transformation Policy Network (GTPN) \u2212 a novel generic method that combines the strengths of graph neural networks and reinforcement learning to learn the reaction mechanisms directly from known reactions with minimal chemical knowledge. Compared to previous methods, GTPN has some appealing properties such as: end-to-end learning, and making no assumption about the length or the order of graph transformations. In order to guide model search through the complex discrete space of sets of bond changes effectively, we extend the standard policy gradient loss by adding useful constraints. Evaluation results show that GTPN improves the top-1 accuracy over the current state-of-the-art method by about 3% on the large USPTO dataset, setting a new record of 83.2%. Our model\u2019s performances and prediction errors are also analyzed carefully in the paper.", "keywords": ["Chemical Reaction", "Graph Transformation", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper163/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9749999d145ffc9cc6936c06edeb77ce7a0f803a.pdf", "paperhash": "anonymous|graph_transformation_policy_network_for_chemical_reaction_prediction", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={GRAPH TRANSFORMATION POLICY NETWORK FOR CHEMICAL REACTION PREDICTION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1f78iAcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgE8sRcK7", "original": "Bkgut0kct7", "number": 164, "cdate": 1538087755642, "ddate": null, "tcdate": 1538087755642, "tmdate": 1538156228883, "tddate": null, "forum": "SkgE8sRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space", "abstract": "Current deep neuroevolution models are usually trained in a large parameter search space for complex learning tasks, e.g. playing video games, which needs billions of samples and thousands of search steps to obtain significant performance. This raises a question of whether we can make use of sequential data generated during evolution, encode input samples, and evolve in low dimensional parameter space with latent state input in a fast and efficient manner. Here we give an affirmative answer: we train a VAE to encode input samples, then an RNN to model environment dynamics and handle temporal information, and last evolve our low dimensional policy network in latent space. We demonstrate that this approach is surprisingly efficient: our experiments on Atari games show that within 10M frames and 30 evolution steps of training, our algorithm could achieve competitive result compared with ES, A3C, and DQN which need billions of frames.", "keywords": ["Neuroevolution", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper164/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/56396e3ca3b58a8f300427f463aba9f2236e97c7.pdf", "paperhash": "anonymous|sample_efficient_deep_neuroevolution_in_low_dimensional_latent_space", "_bibtex": "@inproceedings{    \nanonymous2019sample,    \ntitle={Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgE8sRcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlEUoR9Km", "original": "S1xYBjZqtQ", "number": 165, "cdate": 1538087755820, "ddate": null, "tcdate": 1538087755820, "tmdate": 1538156228675, "tddate": null, "forum": "HJlEUoR9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improved resistance of neural networks to adversarial images through generative pre-training", "abstract": "We train a feed forward neural network with increased robustness against adversarial attacks compared to conventional training approaches. This is achieved using a novel pre-trained building block based on a mean field description of a Boltzmann machine. On the MNIST dataset the method achieves strong adversarial resistance without data augmentation or adversarial training. We show that the increased adversarial resistance is correlated with the generative performance of the underlying Boltzmann machine.", "keywords": ["adversarial images", "Boltzmann machine", "mean field approximation"], "authorids": ["ICLR.cc/2019/Conference/Paper165/Authors"], "authors": ["Anonymous"], "TL;DR": "Generative pre-training with mean field Boltzmann machines increases robustness against adversarial images in neural networks.", "pdf": "/pdf/a552166d54f935a646e0799997488239cef417b4.pdf", "paperhash": "anonymous|improved_resistance_of_neural_networks_to_adversarial_images_through_generative_pretraining", "_bibtex": "@inproceedings{    \nanonymous2019improved,    \ntitle={Improved resistance of neural networks to adversarial images through generative pre-training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlEUoR9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJzVUj0qtQ", "original": "B1eQURBDKX", "number": 166, "cdate": 1538087756004, "ddate": null, "tcdate": 1538087756004, "tmdate": 1538156228466, "tddate": null, "forum": "BJzVUj0qtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Evading Defenses to Transferable Adversarial Examples by Mitigating Attention Shift", "abstract": "Deep neural networks are vulnerable to adversarial examples, which can mislead classifiers by adding imperceptible perturbations. An intriguing property of adversarial examples is their good transferability, making black-box attacks feasible in real-world applications. Due to the threat of adversarial attacks, many methods have been proposed to improve the robustness, and several state-of-the-art defenses are shown to be robust against transferable adversarial examples. In this paper, we identify the attention shift phenomenon, which may hinder the transferability of adversarial examples to the defense models. It indicates that the defenses rely on different discriminative regions to make predictions compared with normally trained models. Therefore, we propose an attention-invariant attack method to generate more transferable adversarial examples. Extensive experiments on the ImageNet dataset validate the effectiveness of the proposed method. Our best attack fools eight state-of-the-art defenses at an 82% success rate on average based only on the transferability, demonstrating the insecurity of the defense techniques. ", "keywords": ["adversarial examples", "black-box attack", "transferability"], "authorids": ["ICLR.cc/2019/Conference/Paper166/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an attention-invariant attack method to generate more transferable adversarial examples for black-box attacks, which can fool state-of-the-art defenses with a high success rate.", "pdf": "/pdf/4699f6c8f823181a4befe3ee1bbd8ce411a8245a.pdf", "paperhash": "anonymous|evading_defenses_to_transferable_adversarial_examples_by_mitigating_attention_shift", "_bibtex": "@inproceedings{    \nanonymous2019evading,    \ntitle={Evading Defenses to Transferable Adversarial Examples by Mitigating Attention Shift},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJzVUj0qtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeNIjA5Y7", "original": "SyeSC4f5FX", "number": 167, "cdate": 1538087756180, "ddate": null, "tcdate": 1538087756180, "tmdate": 1538156228242, "tddate": null, "forum": "HJeNIjA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Image Score: how to select useful samples", "abstract": "There has long been debates on how we could interpret neural networks and understand the decisions our models make. Specifically, why deep neural networks tend to be error-prone when dealing with samples that output low softmax scores. We present an efficient approach to measure the confidence of decision-making steps by statistically investigating each unit's contribution to that decision. Instead of focusing on how the models react on datasets, we study the datasets themselves given a pre-trained model. Our approach is capable of assigning a score to each sample within a dataset that measures the frequency of occurrence of that sample's chain of activation. We demonstrate with experiments that our method could select useful samples to improve deep neural networks in a semi-supervised leaning setting.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper167/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e953f47303981df37fea48b61d25b82f968726cb.pdf", "paperhash": "anonymous|image_score_how_to_select_useful_samples", "_bibtex": "@inproceedings{    \nanonymous2019image,    \ntitle={Image Score: how to select useful samples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeNIjA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklEUjR5tm", "original": "B1lesb6YKX", "number": 168, "cdate": 1538087756360, "ddate": null, "tcdate": 1538087756360, "tmdate": 1538156228034, "tddate": null, "forum": "rklEUjR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SHE2: Stochastic Hamiltonian Exploration and Exploitation for Derivative-Free Optimization", "abstract": "Derivative-free optimization (DFO) using trust region methods is frequently used for machine learning applications, such as (hyper-)parameter optimization without the derivatives of objective functions known.  Inspired by the recent work in continuous-time minimizers, our work models the common trust region methods with the exploration-exploitation using a dynamical system coupling a pair of dynamical processes. While the first exploration process searches the minimum of the blackbox function through minimizing a time-evolving surrogation function, another exploitation process updates the surrogation function time-to-time using the points traversed by the exploration process. The efficiency of derivative-free optimization thus depends on ways the two processes couple. In this paper, we propose a novel dynamical system, namely \\ThePrev---\\underline{S}tochastic \\underline{H}amiltonian \\underline{E}xploration and \\underline{E}xploitation, that surrogates the subregions of blackbox function using a time-evolving quadratic function, then explores and tracks the minimum of the quadratic functions using a fast-converging Hamiltonian system. The \\ThePrev\\ algorithm is later provided as a discrete-time numerical approximation to the system. To further accelerate optimization, we present \\TheName\\ that parallelizes multiple \\ThePrev\\ threads for concurrent exploration and exploitation. Experiment results based on a wide range of machine learning applications show that \\TheName\\ outperform a boarder range of derivative-free optimization algorithms with faster convergence speed under the same settings.", "keywords": ["derivative-free optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper168/Authors"], "authors": ["Anonymous"], "TL;DR": "a new derivative-free optimization algorithms derived from Nesterov's accelerated gradient methods and Hamiltonian dynamics", "pdf": "/pdf/d992337fef64d86fe17f155f0baca3b28fc9dc91.pdf", "paperhash": "anonymous|she2_stochastic_hamiltonian_exploration_and_exploitation_for_derivativefree_optimization", "_bibtex": "@inproceedings{    \nanonymous2019she2:,    \ntitle={SHE2: Stochastic Hamiltonian Exploration and Exploitation for Derivative-Free Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklEUjR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xHUiC5tm", "original": "BylFvucGKQ", "number": 169, "cdate": 1538087756542, "ddate": null, "tcdate": 1538087756542, "tmdate": 1538156227822, "tddate": null, "forum": "B1xHUiC5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Context-aware Forecasting for Multivariate Stationary Time-series", "abstract": "The domain of time-series forecasting has been extensively studied because it is of fundamental importance in many real-life applications. Weather prediction, traffic flow forecasting or sales are compelling examples of sequential phenomena. Predictive models generally make use of the relations between past and future values. However, in the case of stationary time-series, observed values also drastically depend on a number of exogenous features that can be used to improve forecasting quality. In this work, we propose a change of paradigm which consists in learning such features in embeddings vectors within recurrent neural networks. We apply our framework to forecast smart cards tap-in logs in the Parisian subway network. Results show that context-embedded models perform quantitatively better in one-step ahead and multi-step ahead forecasting.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper169/Authors"], "authors": ["Anonymous"], "TL;DR": "In order to forecast multivariate stationary time-series we learn embeddings containing contextual features within a RNN; we apply the framework on public transportation data", "pdf": "/pdf/67af12b4086d190130cecaebbe59b4339169fb3b.pdf", "paperhash": "anonymous|contextaware_forecasting_for_multivariate_stationary_timeseries", "_bibtex": "@inproceedings{    \nanonymous2019context-aware,    \ntitle={Context-aware Forecasting for Multivariate Stationary Time-series},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xHUiC5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgBLj05Y7", "original": "ryl9Scz5Y7", "number": 170, "cdate": 1538087756718, "ddate": null, "tcdate": 1538087756718, "tmdate": 1538156227606, "tddate": null, "forum": "HkgBLj05Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How Training Data Affect the Accuracy and Robustness of Image Classification Models", "abstract": "Recent work has demonstrated the lack of robustness of well-trained deep neural networks (DNNs) to adversarial examples.  For example,\nvisually indistinguishable perturbations, when mixed with an original\nimage, can easily lead deep learning models to misclassifications.  In\nlight of a recent study on the mutual influence between robustness and\naccuracy over 18 different ImageNet models, this paper investigates\nhow training data affect the accuracy and robustness of deep neural\nnetworks. We conduct extensive experiments on four different datasets,\nincluding CIFAR-10, MNIST, STL-10, and Tiny ImageNet, with several\nrepresentative neural networks. Our results reveal previously unknown\nphenomena that exist between the size of training data and\ncharacteristics of the resulting models. In particular, we find that\nmodel accuracy improves monotonically with increased training\ndata. Similarly, model robustness also improves, but starts to\ndeteriorate when training data continue to increase. The occurrence of\nturning points depends on the deep neural network as well as the\ndataset on which it is trained.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper170/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a1f290f683984155626b2a3aa9c7afb3837fad80.pdf", "paperhash": "anonymous|how_training_data_affect_the_accuracy_and_robustness_of_image_classification_models", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How Training Data Affect the Accuracy and Robustness of Image Classification Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgBLj05Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyMS8iRcK7", "original": "SkgSccnLFm", "number": 171, "cdate": 1538087756892, "ddate": null, "tcdate": 1538087756892, "tmdate": 1538156227396, "tddate": null, "forum": "HyMS8iRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sequence Modelling with Memory-Augmented Recurrent Neural Networks", "abstract": "Processing sequential data with long term dependencies is a major challenge in many deep learning applications. In this paper, we introduce a novel architecture, the Memory-Augmented RNN (MARNN) to address this issue. The MARNN explicitly stores previous hidden states and makes use of them by an efficient memory addressing mechanism at every time-step. Compared to existing memory networks, the MARNN is more light-weight and allows direct backpropagation from output to memory. Our network can be trained on small slices of long sequential data, and thus, can theoretically boost training speed. We test the MARNN on two typical sequential modelling tasks. We achieve a competitive 1.202 Bits- per-character on the Penn Treebank character-level language modelling task, and achieve state-of-the-art performance of recall at high tIoUs on the THUMOS\u2019 14 temporal action detection and proposal task.", "keywords": ["Memory Network", "RNN", "Sequence Modelling"], "authorids": ["ICLR.cc/2019/Conference/Paper171/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a light-weight Memory-Augmented RNN (MARNN) for sequence modelling.", "pdf": "/pdf/ebfe2f60a80c9a42ccbb20631ed2b95c70c20b41.pdf", "paperhash": "anonymous|sequence_modelling_with_memoryaugmented_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019sequence,    \ntitle={Sequence Modelling with Memory-Augmented Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMS8iRcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlHIo09KQ", "original": "SkgX6Af5tm", "number": 172, "cdate": 1538087757075, "ddate": null, "tcdate": 1538087757075, "tmdate": 1538156227185, "tddate": null, "forum": "rJlHIo09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gradient-based Training of Slow Feature Analysis by Differentiable Approximate Whitening", "abstract": "We propose Power Slow Feature Analysis, a gradient-based method to extract temporally slow features from a high-dimensional input stream that varies on a faster time-scale, as a variant of Slow Feature Analysis (SFA). While displaying performance comparable to hierarchical extensions to the SFA algorithm, such as Hierarchical Slow Feature Analysis, for a small number of output-features, our algorithm allows fully differentiable end-to-end training of arbitrary differentiable approximators (e.g., deep neural networks). We provide experimental evidence that PowerSFA is able to extract meaningful and informative low-dimensional features in the case of (a) synthetic low-dimensional data, (b) visual data, and also for (c) a general dataset for which symmetric non-temporal relations between points can be defined.", "keywords": ["Slow Feature Analysis", "Deep Learning", "Spectral Embedding", "Temporal Coherence"], "authorids": ["ICLR.cc/2019/Conference/Paper172/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a way to train Slow Feature Analysis with stochastic gradient descent eliminating the need for greedy layer-wise training.", "pdf": "/pdf/f31fbe2fc2c9eef19afd6d115ecbfa8e7156021f.pdf", "paperhash": "anonymous|gradientbased_training_of_slow_feature_analysis_by_differentiable_approximate_whitening", "_bibtex": "@inproceedings{    \nanonymous2019gradient-based,    \ntitle={Gradient-based Training of Slow Feature Analysis by Differentiable Approximate Whitening},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlHIo09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lS8oA5YQ", "original": "B1g7wjGUtm", "number": 173, "cdate": 1538087757248, "ddate": null, "tcdate": 1538087757248, "tmdate": 1538156226956, "tddate": null, "forum": "H1lS8oA5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Feature Attribution As Feature Selection", "abstract": "Feature attribution methods identify \"relevant\" features as an explanation of a complex machine learning model. Several feature attribution methods have been proposed; however, only a few studies have attempted to define the \"relevance\" of each feature mathematically. In this study, we formalize the feature attribution problem as a feature selection problem. In our proposed formalization, there arise two possible definitions of relevance. We name the feature attribution problems based on these two relevances as Exclusive Feature Selection (EFS) and Inclusive Feature Selection (IFS). We show that several existing feature attribution methods can be interpreted as approximation algorithms for EFS and IFS. Moreover, through exhaustive experiments, we show that IFS is better suited as the formalization for the feature attribution problem than EFS.", "keywords": ["feature attribution", "feature selection"], "authorids": ["ICLR.cc/2019/Conference/Paper173/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a0fca5765aa3122dd8d4019975f34354234c18d5.pdf", "paperhash": "anonymous|feature_attribution_as_feature_selection", "_bibtex": "@inproceedings{    \nanonymous2019feature,    \ntitle={Feature Attribution As Feature Selection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lS8oA5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyzrLjA5FQ", "original": "SJeHISGcYQ", "number": 174, "cdate": 1538087757421, "ddate": null, "tcdate": 1538087757421, "tmdate": 1538156226749, "tddate": null, "forum": "SyzrLjA5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Selective Self-Training for semi-supervised Learning", "abstract": "Most of the conventional semi-supervised learning (SSL) methods assume that the classes of unlabeled data are contained in the set of classes of labeled data. In addition, these methods do not discriminate unlabeled samples and use all the unlabeled data for learning, which is not suitable for realistic situations. In this paper, we propose an SSL method called selective self-training (SST), which selectively decides whether to include each unlabeled sample in the training process or not. It is also designed to be applied to a more realistic situation where classes of unlabeled data are different from the ones of the labeled data. For the conventional SSL problems of fixed classes, the proposed method not only performs comparable to other conventional SSL algorithms, but also can be combined with other SSL algorithms. For the new SSL problems of increased classes where the conventional methods cannot be applied, the proposed method does not show any performance degradation even if the classes of unlabeled data are different from those of the labeled data.", "keywords": ["deep learning", "image recognition", "semi-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper174/Authors"], "authors": ["Anonymous"], "TL;DR": "Our proposed algorithm does not use all of the unlabeled data for the training, and it rather uses them selectively.", "pdf": "/pdf/b440db01c50962c3c6abbba42631105637cecf59.pdf", "paperhash": "anonymous|selective_selftraining_for_semisupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019selective,    \ntitle={Selective Self-Training for semi-supervised Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyzrLjA5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylU8oRctX", "original": "rkxiRzXcKX", "number": 175, "cdate": 1538087757595, "ddate": null, "tcdate": 1538087757595, "tmdate": 1538156226535, "tddate": null, "forum": "rylU8oRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning with Little Data: Evaluation of Deep Learning Algorithms", "abstract": "Deep learning has become a widely used tool in many computational and classification problems. \nNevertheless obtaining and labeling data, which is needed for strong results, is often expensive or even not possible. \nIn this paper three different algorithmic approaches to deal with limited access to data are evaluated and compared to each other. \nWe show the drawbacks and benefits of each method. \nOne successful approach, especially in one-shot learning tasks, is the use of external data even after training during the classification task. \nAnother  successful approach, which achieves state of the art results in semi-supervised learning (SSL) benchmarks, is consistency regularization.\nEspecially virtual adversarial training (VAT) has shown strong results and will be investigated in this paper. \nThe aim of consistency regularization is to find a smooth manifold in which the data lies and therefore to increase the generalization capability. \nGenerative adversarial networks (GANs) have also shown strong empirical results. \nMainly the GAN architecture is used to create additional data and therefor to increase the generalization capability of the classification network.\nFurthermore we consider the use of unlabeled data for further performance improvement. \nThe use of unlabeled data is investigated both for GANs and VAT. ", "keywords": ["Semi-supervised Learning", "Generative Models", "Few shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper175/Authors"], "authors": ["Anonymous"], "TL;DR": "Comparison of siamese neural networks, GANs, and VAT for few shot learning. ", "pdf": "/pdf/024dde828ec9ebc1e34c3ce6c7333d823704b8ed.pdf", "paperhash": "anonymous|learning_with_little_data_evaluation_of_deep_learning_algorithms", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning with Little Data: Evaluation of Deep Learning Algorithms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylU8oRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eL8i0cFm", "original": "HkelP9CFK7", "number": 176, "cdate": 1538087757774, "ddate": null, "tcdate": 1538087757774, "tmdate": 1538156226330, "tddate": null, "forum": "S1eL8i0cFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cosine similarity-based Adversarial process", "abstract": "An adversarial process between two deep neural networks is a promising approach to train robust networks. In this study, we propose a framework for training networks that eliminates subsidiary information via the adversarial process. The objective of the proposed framework is to train a primary model that is robust to existing subsidiary information. This primary model can be used for various recognition tasks, such as digit recognition and speaker identification. Subsidiary information refers to the factors that might decrease the performance of the primary model such as channel information in speaker recognition and noise information in digit recognition.\nOur proposed framework comprises two discriminative models for the primary and subsidiary task, as well as an encoder network for feature representation. A subsidiary task is an operation associated with subsidiary information such as identifying the noise type. The discriminative model for the subsidiary task is trained for modeling the dependency of subsidiary class labels on codes from the encoder. Therefore, we expect that subsidiary information could be eliminated by training the encoder to reduce the dependency between the class labels and codes. In order to do so, we train the weight parameters of the subsidiary model; then, we develop the codes and the parameters of subsidiary model to make them orthogonal. For this purpose, we design a loss function to train the encoder based on cosine similarity between the weight parameters of the subsidiary model and codes. Finally, the proposed framework involves repeatedly performing the adversarial process of modeling the subsidiary information and eliminating it. Furthermore, we discuss possible applications of the proposed framework: reducing channel information for speaker identification and domain information for unsupervised domain adaptation.  ", "keywords": ["adversarial process", "cosine similarity", "speaker identification", "domain adaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper176/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ebda0b9bf2a23a70e3248a2379987d8ce425649d.pdf", "paperhash": "anonymous|cosine_similaritybased_adversarial_process", "_bibtex": "@inproceedings{    \nanonymous2019cosine,    \ntitle={Cosine similarity-based Adversarial process},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eL8i0cFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1fU8iAqKX", "original": "rJgtbDmqKm", "number": 177, "cdate": 1538087757950, "ddate": null, "tcdate": 1538087757950, "tmdate": 1538156226112, "tddate": null, "forum": "H1fU8iAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A rotation-equivariant convolutional neural network model of primary visual cortex", "abstract": "Classical models describe primary visual cortex (V1) as a filter bank of orientation-selective linear-nonlinear (LN) or energy models, but these models fail to predictneural responses to natural stimuli accurately.  Recent work shows that modelsbased on convolutional neural networks (CNNs) lead to much more accurate pre-dictions, but it remains unclear which features are extracted by V1 neurons beyondorientation selectivity and phase invariance. Here we work towards systematicallystudying V1 computations by categorizing neurons into groups that perform similarcomputations. We present a framework to identify common features independentof individual neurons\u2019 orientation selectivity by using a rotation-equivariant con-volutional neural network, which automatically extracts every feature at multipledifferent orientations. We fit this model to responses of a population of 6000 neu-rons to natural images recorded in mouse primary visual cortex using two-photonimaging. We show that our rotation-equivariant network not only outperforms aregular CNN with the same number of feature maps, but also reveals a numberof common features shared by many V1 neurons, which deviate from the typicaltextbook idea of V1 as a bank of Gabor filters. Our findings are a first step towardsa powerful new tool to study the nonlinear computations in V1.", "keywords": ["rotation equivariance", "equivariance", "primary visual cortex", "V1", "neuroscience", "system identification"], "authorids": ["ICLR.cc/2019/Conference/Paper177/Authors"], "authors": ["Anonymous"], "TL;DR": "A rotation-equivariant CNN model of V1 that outperforms previous models and suggest functional cell types in V1.", "pdf": "/pdf/201c773c874a994002f494b811c05d16ca876ed5.pdf", "paperhash": "anonymous|a_rotationequivariant_convolutional_neural_network_model_of_primary_visual_cortex", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A rotation-equivariant convolutional neural network model of primary visual cortex},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1fU8iAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryG8UsR5t7", "original": "HylownL_Ym", "number": 178, "cdate": 1538087758133, "ddate": null, "tcdate": 1538087758133, "tmdate": 1538156225898, "tddate": null, "forum": "ryG8UsR5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MERCI: A NEW METRIC TO EVALUATE THE CORRELATION BETWEEN PREDICTIVE UNCERTAINTY AND TRUE ERROR", "abstract": "As deep learning applications are becoming more and more pervasive, the question of evaluating the reliability of a prediction becomes a central question in the machine learning community. This domain, known as predictive uncertainty, has come under the scrutiny of research groups developing Bayesian approaches to deep learning such as Monte Carlo Dropout. Unfortunately, for the time being, the real goal of predictive uncertainty has been swept under the rug. Indeed, Bayesian approaches are solely evaluated in terms of raw performance of the prediction, while the quality of the estimated uncertainty is not assessed. One contribution of this article is to draw attention on existing metrics developed in the forecast community, designed to evaluate both the sharpness and the calibration of predictive uncertainty. Sharpness refers to the concentration of the predictive distributions and calibration to the consistency between the predicted uncertainty level and the actual errors. We further analyze the behavior of these metrics on regression problems when deep convolutional networks are involved and for several current predictive uncertainty approaches. A second contribution of this article is to propose an alternative metric that is more adapted to the evaluation of relative uncertainty assessment and directly applicable to regression with deep learning. This metric is evaluated and compared with existing ones on a toy dataset as well as on the problem of monocular depth estimation. ", "keywords": ["evaluation metric", "predictive uncertainty", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper178/Authors"], "authors": ["Anonymous"], "TL;DR": "We review existing metrics and propose a new one to evaluate predictive uncertainty in deep learning", "pdf": "/pdf/8c44fe7d1f0c356dfe91daf19fb9454683296a2a.pdf", "paperhash": "anonymous|merci_a_new_metric_to_evaluate_the_correlation_between_predictive_uncertainty_and_true_error", "_bibtex": "@inproceedings{    \nanonymous2019merci:,    \ntitle={MERCI: A NEW METRIC TO EVALUATE THE CORRELATION BETWEEN PREDICTIVE UNCERTAINTY AND TRUE ERROR},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryG8UsR5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkeILsRqFQ", "original": "H1l--AQYKm", "number": 179, "cdate": 1538087758311, "ddate": null, "tcdate": 1538087758311, "tmdate": 1538156225679, "tddate": null, "forum": "HkeILsRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An experimental study of layer-level training speed and its impact on generalization", "abstract": "How optimization influences the generalization ability of a DNN is still an active area of research. This work aims to unveil and study a factor of influence: we show that the speed at which each layer trains, measured by the rotation rate of each layer's weight vector (or layer rotation rate), has a consistent and substantial impact on generalization. We develop a visualization technique and an optimization algorithm to monitor and control the layer rotation rates during training, and show across multiple tasks and training settings that rotating all the layers' weights synchronously and at high rate repeatedly induces the best generalization performance. Going further, our experiments suggest that weight decay is an essential ingredient for inducing such beneficial layer rotation rates with SGD, and that the impact of adaptive gradient methods on training speed and generalization is solely due to the modifications they induce to each layer's training speed compared to SGD. Besides these fundamental findings, we also expect that the tools we introduce will reduce the meta-parameter tuning required to get the best generalization out of a deep network.", "keywords": ["generalization", "optimization", "vanishing gradients", "experimental", "fundamental research"], "authorids": ["ICLR.cc/2019/Conference/Paper179/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper provides empirical evidence that 1) the speed at which each layer trains influences generalization and 2) this phenomenon is at the root of weight decay's and adaptive gradient methods' impact on generalization.", "pdf": "/pdf/d3455c76da8ad2b994d9e67635c9a41631f998db.pdf", "paperhash": "anonymous|an_experimental_study_of_layerlevel_training_speed_and_its_impact_on_generalization", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An experimental study of layer-level training speed and its impact on generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkeILsRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxUIj09KX", "original": "S1xSNg5xFX", "number": 180, "cdate": 1538087758488, "ddate": null, "tcdate": 1538087758488, "tmdate": 1538156225471, "tddate": null, "forum": "HyxUIj09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "S-System, Geometry, Learning, and Optimization: A Theory of Neural Networks", "abstract": "We present a formal measure-theoretical theory of neural networks (NN) built on {\\it probability coupling theory}. Particularly, we present an algorithm framework, Hierarchical Measure Group and Approximate System (HMGAS), nicknamed S-System, of which NNs are special cases. In addition to many other results, the framework enables us to prove that 1) NNs implement {\\it renormalization group (RG)} using information geometry, which points out that the large scale property to renormalize is dual Bregman divergence and completes the analog between NNs and RG; 2) and under a set of {\\it realistic} boundedness and diversity conditions, for {\\it large size nonlinear deep} NNs with a class of losses, including the hinge loss, all local minima are global minima with zero loss errors, using random matrix theory.", "keywords": ["neural network theory", "probability measure theory", "probability coupling theory", "S-System", "optimization", "random matrix", "renormalization group", "information geometry", "coarse graining", "hierarchy", "activation function", "symmetry"], "authorids": ["ICLR.cc/2019/Conference/Paper180/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a formal measure-theoretical theory of neural networks (NN) that quantitatively shows NNs renormalize on semantic difference, and under practical conditions large size deep nonlinear NNs can optimize objective functions to zero losses.", "pdf": "/pdf/6fb1ea402d64528f6560a40defd9b9f1f5d709fc.pdf", "paperhash": "anonymous|ssystem_geometry_learning_and_optimization_a_theory_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019s-system,,    \ntitle={S-System, Geometry, Learning, and Optimization: A Theory of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxUIj09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lPUiRcYQ", "original": "SyedgfOPFX", "number": 181, "cdate": 1538087758666, "ddate": null, "tcdate": 1538087758666, "tmdate": 1538156225257, "tddate": null, "forum": "H1lPUiRcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Computing committor functions for the study of rare events using deep learning with importance sampling", "abstract": "The committor function is a central object of study in understanding transitions between metastable states in complex systems. However, computing the committor function for realistic systems at low temperatures is a challenging task, due to the curse of dimensionality and the scarcity of transition data. In this paper, we introduce a computational approach that overcomes these issues and achieves good performance on complex benchmark problems with rough energy landscapes. The new approach combines deep learning, importance sampling and feature engineering techniques. This establishes an alternative practical method for studying rare transition events among metastable states of complex, high dimensional systems.", "keywords": ["committor function", "rare event", "deep learning", "importance sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper181/Authors"], "authors": ["Anonymous"], "TL;DR": "Computing committor functions for rare events", "pdf": "/pdf/af6b79774d63f501c42c78d8987096511f8ba8dc.pdf", "paperhash": "anonymous|computing_committor_functions_for_the_study_of_rare_events_using_deep_learning_with_importance_sampling", "_bibtex": "@inproceedings{    \nanonymous2019computing,    \ntitle={Computing committor functions for the study of rare events using deep learning with importance sampling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lPUiRcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByePUo05K7", "original": "HkgCwjoYt7", "number": 182, "cdate": 1538087758842, "ddate": null, "tcdate": 1538087758842, "tmdate": 1538156225044, "tddate": null, "forum": "ByePUo05K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "What a difference a pixel makes: An empirical examination of features used by CNNs for categorisation", "abstract": "Convolutional neural networks (CNNs) were inspired by human vision and, in some settings, achieve a performance comparable to human object recognition. This has lead to the speculation that both systems use similar mechanisms to perform recognition. In this study, we conducted a series of simulations that indicate that there is a fundamental difference between human vision and CNNs: while object recognition in humans relies on analysing shape, CNNs do not have such a shape-bias. We teased apart the type of features selected by the model by modifying the CIFAR-10 dataset so that, in addition to containing objects with shape, the images concurrently contained non-shape features, such as a noise-like mask. When trained on these modified set of images, the model did not show any bias towards selecting shapes as features. Instead it relied on whichever feature allowed it to perform the best prediction -- even when this feature was a noise-like mask or a single predictive pixel amongst 50176 pixels. We also found that regularisation methods, such as batch normalisation or Dropout, did not change this behaviour and neither did past or concurrent experience with images from other datasets.", "keywords": ["deep learning", "shape bias", "vision", "feature selection"], "authorids": ["ICLR.cc/2019/Conference/Paper182/Authors"], "authors": ["Anonymous"], "TL;DR": "This study highlights a key difference between human vision and CNNs: while object recognition in humans relies on analysing shape, CNNs do not have such a shape-bias.", "pdf": "/pdf/5d08d7b80f03aeb929430c6dafc1f72921474395.pdf", "paperhash": "anonymous|what_a_difference_a_pixel_makes_an_empirical_examination_of_features_used_by_cnns_for_categorisation", "_bibtex": "@inproceedings{    \nanonymous2019what,    \ntitle={What a difference a pixel makes: An empirical examination of features used by CNNs for categorisation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByePUo05K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygPUoR9YQ", "original": "Skx-c3M9K7", "number": 183, "cdate": 1538087759023, "ddate": null, "tcdate": 1538087759023, "tmdate": 1538156224830, "tddate": null, "forum": "rygPUoR9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Compositional GAN: Learning Conditional Image Composition", "abstract": "Generative Adversarial Networks (GANs) can produce images of surprising complexity and realism, but are generally structured to sample from a single latent source ignoring the explicit spatial interaction between multiple entities that could be present in a scene. Capturing such complex interactions between different objects in the world, including their relative scaling, spatial layout, occlusion, or viewpoint transformation is a challenging problem. In this work, we propose to model object composition in a GAN framework as a self-consistent composition-decomposition network. Our model is conditioned on the object images from their marginal distributions and can generate a realistic image from their joint distribution. We evaluate our model through qualitative experiments and user evaluations in scenarios when either paired or unpaired examples for the individual object images and the joint scenes are given during training. Our results reveal that the learned model captures potential interactions between the two object domains given as input to output new instances of composed scene at test time in a reasonable fashion.", "keywords": ["Image Composition", "GAN", "Conditional Image generation"], "authorids": ["ICLR.cc/2019/Conference/Paper183/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a novel approach to model object compositionality in images in a GAN framework.", "pdf": "/pdf/2857583b841d73d9bafd705a55f1de5c4a26810a.pdf", "paperhash": "anonymous|compositional_gan_learning_conditional_image_composition", "_bibtex": "@inproceedings{    \nanonymous2019compositional,    \ntitle={Compositional GAN: Learning Conditional Image Composition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygPUoR9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkzDIiA5YQ", "original": "r1g4ZbV9F7", "number": 184, "cdate": 1538087759198, "ddate": null, "tcdate": 1538087759198, "tmdate": 1538156224621, "tddate": null, "forum": "rkzDIiA5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ANYTIME MINIBATCH: EXPLOITING STRAGGLERS IN ONLINE DISTRIBUTED OPTIMIZATION", "abstract": "Distributed optimization is vital in solving large-scale machine learning problems. A widely-shared feature of distributed optimization techniques is the requirement that all nodes complete their assigned tasks in each computational epoch before the system can proceed to the next epoch. In such settings, slow nodes, called stragglers, can greatly slow progress. To mitigate the impact of stragglers, we propose an online distributed optimization method called Anytime Minibatch. In this approach, all nodes are given a fixed time to compute the gradients of as many data samples as possible. The result is a variable per-node minibatch size. Workers then get a fixed communication time to average their minibatch gradients via several rounds of consensus, which are then used to update primal variables via dual averaging. Anytime Minibatch prevents stragglers from holding up the system without wasting the work that stragglers can complete. We present a convergence analysis and analyze the wall time performance. We evaluate the method empirically using the Amazon Elastic Compute Cloud (EC2) and observe a 30-50% improvement in convergence speed.", "keywords": ["distributed optimization", "gradient descent", "minibatch", "stragglers"], "authorids": ["ICLR.cc/2019/Conference/Paper184/Authors"], "authors": ["Anonymous"], "TL;DR": "Accelerate distributed optimization by exploiting stragglers.", "pdf": "/pdf/c0e6e7035199a140686777cadba87d94e7666942.pdf", "paperhash": "anonymous|anytime_minibatch_exploiting_stragglers_in_online_distributed_optimization", "_bibtex": "@inproceedings{    \nanonymous2019anytime,    \ntitle={ANYTIME MINIBATCH: EXPLOITING STRAGGLERS IN ONLINE DISTRIBUTED OPTIMIZATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkzDIiA5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxDUs05KQ", "original": "HJlb1wAOYm", "number": 185, "cdate": 1538087759372, "ddate": null, "tcdate": 1538087759372, "tmdate": 1538156224413, "tddate": null, "forum": "ryxDUs05KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Difference-Seeking Generative Adversarial Network", "abstract": "We propose a novel algorithm, Difference-Seeking Generative Adversarial Network (DSGAN), developed from traditional GAN. DSGAN considers the scenario that the training samples of target distribution, $p_{t}$, are difficult to collect.\n\nSuppose there are two distributions  $p_{\\bar{d}}$ and $p_{d}$ such that the density of the target distribution can be the differences between the densities of $p_{\\bar{d}}$ and $p_{d}$. We show how to learn the target distribution $p_{t}$ only via samples from $p_{d}$ and $p_{\\bar{d}}$ (relatively easy to obtain).\n\nDSGAN has the flexibility to produce samples from various target distributions (e.g. the out-of-distribution). Two key applications, semi-supervised learning and adversarial training, are taken as examples to validate the effectiveness of DSGAN. We also provide theoretical analyses about the convergence of DSGAN.", "keywords": ["Generative Adversarial Network", "Semi-Supervised Learning", "Adversarial Training"], "authorids": ["ICLR.cc/2019/Conference/Paper185/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed \"Difference-Seeking Generative Adversarial Network\" (DSGAN) model to learn the target distribution which is hard to collect training data.", "pdf": "/pdf/cfeaa60eddb12beac6373922174b7877b2c383ca.pdf", "paperhash": "anonymous|differenceseeking_generative_adversarial_network", "_bibtex": "@inproceedings{    \nanonymous2019difference-seeking,    \ntitle={Difference-Seeking Generative Adversarial Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxDUs05KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxOIsA5FQ", "original": "H1xErXE5Ym", "number": 186, "cdate": 1538087759552, "ddate": null, "tcdate": 1538087759552, "tmdate": 1538156224205, "tddate": null, "forum": "ryxOIsA5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stacking for Transfer Learning", "abstract": "In machine learning tasks, overtting frequently crops up when the number of samples of target domain is insuf\ufb01cient, for the generalization ability of the classi\ufb01er is poor in this circumstance. To solve this problem, transfer learning utilizes the knowledge of similar domains to improve the robustness of the learner. The main idea of existing transfer learning algorithms is to reduce the dierence between domains by sample selection or domain adaptation. However, no matter what transfer learning algorithm we use, the difference always exists and the hybrid training of source and target data leads to reducing \ufb01tting capability of the learner on target domain. Moreover, when the relatedness between domains is too low, negative transfer is more likely to occur. To tackle the problem, we proposed a two-phase transfer learning architecture based on ensemble learning, which uses the existing transfer learning algorithms to train the weak learners in the \ufb01rst stage, and uses the predictions of target data to train the \ufb01nal learner in the second stage. Under this architecture, the \ufb01tting capability and generalization capability can be guaranteed at the same time. We evaluated the proposed method on public datasets, which demonstrates the effectiveness and robustness of our proposed method.", "keywords": ["data diversi\ufb01cation", "domain adaptation", "transfer learning", "stacked generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper186/Authors"], "authors": ["Anonymous"], "TL;DR": "How to use stacked generalization to improve the performance of existing transfer learning algorithms when limited labeled data is available.", "pdf": "/pdf/6ebec4ecc69570439f20ee3e3a16433e0efd3721.pdf", "paperhash": "anonymous|stacking_for_transfer_learning", "_bibtex": "@inproceedings{    \nanonymous2019stacking,    \ntitle={Stacking for Transfer Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxOIsA5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1edIiA9KQ", "original": "H1xFQ_45Km", "number": 187, "cdate": 1538087759734, "ddate": null, "tcdate": 1538087759734, "tmdate": 1538156223997, "tddate": null, "forum": "H1edIiA9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generating Multiple Objects at Spatially Distinct Locations", "abstract": "Recent improvements to Generative Adversarial Networks (GANs) have made it possible to generate realistic images in high resolution based on natural language descriptions such as image captions. Furthermore, conditional GANs allow us to control the image generation process through labels or even natural language descriptions. However, fine-grained control of the image layout, i.e. where in the image specific objects should be located, is still difficult to achieve. This is especially true for images that should contain multiple distinct objects at different spatial locations. We introduce a new approach which allows us to control the location of arbitrarily many objects within an image by adding an object pathway to both the generator and the discriminator. Our approach does not need a detailed semantic layout but only bounding boxes and the respective labels of the desired objects are needed. The object pathway focuses solely on the individual objects and is iteratively applied at the locations specified by the bounding boxes. The global pathway focuses on the image background and the general image layout. We perform experiments on the Multi-MNIST, CLEVR, and the more complex MS-COCO data set. Our experiments show that through the use of the object pathway we can control object locations within images and can model complex scenes with multiple objects at various locations. We further show that the object pathway focuses on the individual objects and learns features relevant for these, while the global pathway focuses on global image characteristics and the image background.", "keywords": ["controllable image generation", "text-to-image synthesis", "generative model", "generative adversarial network", "gan"], "authorids": ["ICLR.cc/2019/Conference/Paper187/Authors"], "authors": ["Anonymous"], "TL;DR": "Extend GAN architecture to obtain control over locations and identities of multiple objects within generated images.", "pdf": "/pdf/c4fb3982d7eb947bf262e2fef60a5a1006167427.pdf", "paperhash": "anonymous|generating_multiple_objects_at_spatially_distinct_locations", "_bibtex": "@inproceedings{    \nanonymous2019generating,    \ntitle={Generating Multiple Objects at Spatially Distinct Locations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1edIiA9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxOIoRqFQ", "original": "S1eB6ftIYQ", "number": 188, "cdate": 1538087759917, "ddate": null, "tcdate": 1538087759917, "tmdate": 1538156223792, "tddate": null, "forum": "HyxOIoRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discrete flow posteriors for variational inference in discrete dynamical systems", "abstract": "Each training step for a variational autoencoder (VAE) requires us to sample from the approximate posterior, so we usually choose simple (e.g. factorised) approximate posteriors in which sampling is an efficient computation that fully exploits GPU parallelism.  However, such simple approximate posteriors are often insufficient, as they eliminate statistical dependencies in the posterior.  While it is possible to use normalizing flow approximate posteriors for continuous latents, there is nothing analogous for discrete latents. The most natural approach to model discrete dependencies is an autoregressive distribution, but sampling from such distributions is inherently sequential and thus slow.  We develop a fast, parallel sampling procedure for autoregressive distributions based on fixed-point iterations which enables efficient and accurate variational inference in discrete state-space models.  To optimize the variational bound, we considered two ways to evaluate probabilities: inserting the relaxed samples directly into the pmf for the discrete distribution, or converting to continuous logistic latent variables and interpreting the K-step fixed-point iterations as a normalizing flow.  We found that converting to continuous latent variables gave considerable additional scope for mismatch between the true and approximate posteriors, which resulted in biased inferences, we thus used the former approach.  We tested our approach on the neuroscience problem of inferring discrete spiking activity from noisy calcium-imaging data, and found that it gave accurate connectivity estimates in an order of magnitude less time.", "keywords": ["normalising flow", "variational inference", "discrete latent variable"], "authorids": ["ICLR.cc/2019/Conference/Paper188/Authors"], "authors": ["Anonymous"], "TL;DR": "We give a fast normalising-flow like sampling procedure for discrete latent variable models.", "pdf": "/pdf/23c6900cad7a39c3d5bca6e26ec50c7ec825f51e.pdf", "paperhash": "anonymous|discrete_flow_posteriors_for_variational_inference_in_discrete_dynamical_systems", "_bibtex": "@inproceedings{    \nanonymous2019discrete,    \ntitle={Discrete flow posteriors for variational inference in discrete dynamical systems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxOIoRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJguLo0cKQ", "original": "Bye1JPBtFQ", "number": 189, "cdate": 1538087760096, "ddate": null, "tcdate": 1538087760096, "tmdate": 1538156223578, "tddate": null, "forum": "HJguLo0cKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Strength in Numbers: Trading-off Robustness and Computation via Adversarially-Trained Ensembles", "abstract": "While deep learning has led to remarkable results on a number of challenging problems, researchers have discovered a vulnerability of neural networks in adversarial settings, where small but carefully chosen perturbations to the input can make the models produce extremely inaccurate outputs. This makes these models particularly unsuitable for safety-critical application domains (e.g. self-driving cars) where robustness is extremely important. Recent work has shown that augmenting training with adversarially generated data provides some degree of robustness against test-time attacks. In this paper we investigate how this approach scales as we increase the computational budget given to the defender. We show that increasing the number of parameters in adversarially-trained models increases their robustness, and in particular that ensembling smaller models while adversarially training the entire ensemble as a single model is a more efficient way of spending said budget than simply using a larger single model. Crucially, we show that it is the adversarial training of the ensemble, rather than the ensembling of adversarially trained models, which provides robustness.", "keywords": ["adversarial examples", "adversarial robustness", "visualisation", "ensembles"], "authorids": ["ICLR.cc/2019/Conference/Paper189/Authors"], "authors": ["Anonymous"], "TL;DR": "Adversarial training of ensembles provides robustness to adversarial examples beyond that observed in adversarially trained models and independently-trained ensembles thereof.", "pdf": "/pdf/0651bd0ecb72caa11cc977592b6d1b19d616ee8c.pdf", "paperhash": "anonymous|strength_in_numbers_tradingoff_robustness_and_computation_via_adversariallytrained_ensembles", "_bibtex": "@inproceedings{    \nanonymous2019strength,    \ntitle={Strength in Numbers: Trading-off Robustness and Computation via Adversarially-Trained Ensembles},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJguLo0cKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryM_IoAqYX", "original": "BJg21jE5Y7", "number": 190, "cdate": 1538087760277, "ddate": null, "tcdate": 1538087760277, "tmdate": 1538156223363, "tddate": null, "forum": "ryM_IoAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Analysis of Quantized Deep Networks", "abstract": "Weight-quantized networks have small storage and fast inference, but training can still be time-consuming. This can be improved with distributed learning. To reduce the high communication cost due to worker-server synchronization, recently gradient quantization has also been proposed to train networks with full-precision weights. In this paper, we theoretically study how the combination of both weight and gradient quantization affects convergence. We show that (i) weight-quantized networks converge to an error related to the weight quantization resolution and weight dimension; (ii) quantizing gradients slows convergence by a factor related to the gradient quantization resolution and dimension; and (iii) clipping the gradient before quantization renders this factor dimension-free, thus allowing the use of fewer bits for gradient quantization. Empirical experiments confirm the theoretical convergence results, and demonstrate that quantized networks can speed up training and have comparable performance as full-precision networks.", "keywords": ["weight quantization", "gradient quantization", "distributed learning"], "authorids": ["ICLR.cc/2019/Conference/Paper190/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1a659de6412daa034d912f0fdbbb11c50b29ad32.pdf", "paperhash": "anonymous|analysis_of_quantized_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019analysis,    \ntitle={Analysis of Quantized Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryM_IoAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1fO8oC9Y7", "original": "SylCR5lqtm", "number": 191, "cdate": 1538087760452, "ddate": null, "tcdate": 1538087760452, "tmdate": 1538156223140, "tddate": null, "forum": "r1fO8oC9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Semantic Parsing via Cross-Domain Schema", "abstract": "Semantic parsing which maps a natural language sentence into a formal machine-readable representation of its meaning, is highly constrained by the limited annotated training data. Inspired by the idea of coarse-to-fine, we propose a general-to-detailed neural network(GDNN) by incorporating cross-domain schema(CDS) among utterances and their logic forms. For utterances in different domains, the General Network will extract CDS using an encoder-decoder model in a multi-task learning setup. Then for some utterances in a specific domain, the Detailed Network will generate the detailed target parts using sequence-to-sequence architecture with advanced attention to both utterance and generated CDS. Our experiments show that compared to direct multi-task learning, CDS has improved the performance in semantic parsing task which converts users' requests into meaning representation language(MRL). We also use experiments to illustrate that CDS works by adding some constraints to the target decoding process, which further proves the effectiveness and rationality of CDS.", "keywords": ["semantic parsing", "natural language understanding", "machine learning"], "authorids": ["ICLR.cc/2019/Conference/Paper191/Authors"], "authors": ["Anonymous"], "TL;DR": "General-to-detailed neural network(GDNN) by incorporating cross-domain schema(CDS) for semantic parsing", "pdf": "/pdf/f114863cee78c8287866926ac3ee68b78c1b13ee.pdf", "paperhash": "anonymous|semantic_parsing_via_crossdomain_schema", "_bibtex": "@inproceedings{    \nanonymous2019semantic,    \ntitle={Semantic Parsing via Cross-Domain Schema},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1fO8oC9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxt8oC9FQ", "original": "rkeInEZuK7", "number": 192, "cdate": 1538087760635, "ddate": null, "tcdate": 1538087760635, "tmdate": 1538156222932, "tddate": null, "forum": "rkxt8oC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks", "abstract": "Learning representations for counterfactual inference from observational data is of high practical relevance for many domains, such as healthcare, public policy and economics. Counterfactual inference enables one to answer \"What if...?\" questions, such as \"What would be the outcome if we gave this patient treatment $t_1$?\". However, current methods for training neural networks for counterfactual inference on observational data are either overly complex, limited to settings with only two available treatment options, or both. Here, we present Perfect Match (PM), a method for training neural networks for counterfactual inference that is easy to implement, compatible with any architecture, does not add computational complexity or hyperparameters, and extends to any number of treatments. PM is based on the idea of augmenting samples within a minibatch with their propensity-matched nearest neighbours. Our experiments demonstrate that PM outperforms a number of more complex state-of-the-art methods in inferring counterfactual outcomes across several real-world and semi-synthetic datasets.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper192/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4fc33ac3c7353243e082ed7a46dab6f93620efa7.pdf", "paperhash": "anonymous|perfect_match_a_simple_method_for_learning_representations_for_counterfactual_inference_with_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019perfect,    \ntitle={Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxt8oC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgYIiAcFQ", "original": "SJgwvX45YQ", "number": 193, "cdate": 1538087760813, "ddate": null, "tcdate": 1538087760813, "tmdate": 1538156222724, "tddate": null, "forum": "BkgYIiAcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DecayNet: A Study on the Cell States of Long Short Term Memories", "abstract": "It is unclear whether the extensively applied long short term memory (LSTM) is an optimised architecture for recurrent neural networks. Its complicated design and opaque mechanics make the network hard to analyse and non-immediately clear for its utilities in real-world data. This paper studies LSTMs as systems of difference equations, and takes a theoretical mathematical approach to study consecutive transitions in network variables. Our study shows that the cell state propagation is predominantly controlled by the forget gate. Based on these mathematical insights, we introduce the DecayNet reformulation to calibrate cell state dynamics with a monotonically decreasing forget gate. The reformulation increases LSTM modelling power without the need for introducing new learnable parameters; and also yields more consistent results.", "keywords": ["Long short term memory", "Recurrent neural network", "Dynamical systems", "Difference equation"], "authorids": ["ICLR.cc/2019/Conference/Paper193/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a LSTM reformulation with a monotonically decreasing forget gate to increase LSTM interpretability and modelling power without introducing new learnable parameters.", "pdf": "/pdf/520eedd68108d0b24fc4d6c25143a54819ff0f0b.pdf", "paperhash": "anonymous|decaynet_a_study_on_the_cell_states_of_long_short_term_memories", "_bibtex": "@inproceedings{    \nanonymous2019decaynet:,    \ntitle={DecayNet: A Study on the Cell States of Long Short Term Memories},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgYIiAcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxKIiAqYQ", "original": "HkgcRoNqFm", "number": 194, "cdate": 1538087760989, "ddate": null, "tcdate": 1538087760989, "tmdate": 1538156222512, "tddate": null, "forum": "HyxKIiAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Context-adaptive Entropy Model for End-to-end Optimized Image Compression", "abstract": "We propose a context-adaptive entropy model for use in end-to-end optimized image compression. Our model exploits two types of contexts, bit-consuming contexts and bit-free contexts, distinguished based upon whether additional bit allocation is required. Based on these contexts, we allow the model to more accurately estimate the distribution of each latent representation with a more generalized form of the approximation models, which accordingly leads to an enhanced compression performance. Based on the experimental results, the proposed method outperforms the traditional image codecs, such as BPG and JPEG2000, as well as other previous artificial-neural-network (ANN) based approaches, in terms of the peak signal-to-noise ratio (PSNR) and multi-scale structural similarity (MS-SSIM) index.", "keywords": ["image compression", "deep learning", "entropy model"], "authorids": ["ICLR.cc/2019/Conference/Paper194/Authors"], "authors": ["Anonymous"], "TL;DR": "The first test results that outperform BPG, in terms of the PSNR, in the ANN-based image compression domain.", "pdf": "/pdf/7c99f31593916a21d2902239cc7c2a84de6c030e.pdf", "paperhash": "anonymous|contextadaptive_entropy_model_for_endtoend_optimized_image_compression", "_bibtex": "@inproceedings{    \nanonymous2019context-adaptive,    \ntitle={Context-adaptive Entropy Model for End-to-end Optimized Image Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxKIiAqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lFIiR9tQ", "original": "B1xPo34qtQ", "number": 195, "cdate": 1538087761178, "ddate": null, "tcdate": 1538087761178, "tmdate": 1538156222304, "tddate": null, "forum": "r1lFIiR9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Training generative latent models  by variational f-divergence minimization", "abstract": "Probabilistic models are often trained by maximum likelihood, which corresponds to minimizing a specific form of $\\f$-divergence between the model and data distribution. We derive an upper bound that holds for all $\\f$-divergences, showing the intuitive result that the divergence between two joint distributions is at least as great as the divergence between their corresponding marginals. Additionally, the $\\f$-divergence is not formally defined when two distributions have different supports. We thus propose a noisy version of $\\f$-divergence which is well defined in such situations. We demonstrate how the bound and the new version of $\\f$-divergence can be readily used to train complex probabilistic generative models of data and that the fitted model can depend significantly on the particular divergence used.", "keywords": ["variational inference", "generative model", "f divergence"], "authorids": ["ICLR.cc/2019/Conference/Paper195/Authors"], "authors": ["Anonymous"], "TL;DR": "Training generative models using an upper bound of the f divergence.", "pdf": "/pdf/5dd57c13cefced5fa35876ebb61ccaa55a3e6e9b.pdf", "paperhash": "anonymous|training_generative_latent_models_by_variational_fdivergence_minimization", "_bibtex": "@inproceedings{    \nanonymous2019training,    \ntitle={Training generative latent models  by variational f-divergence minimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lFIiR9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkeYUsRqKQ", "original": "ryxlBR45tm", "number": 196, "cdate": 1538087761417, "ddate": null, "tcdate": 1538087761417, "tmdate": 1538156222092, "tddate": null, "forum": "rkeYUsRqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Adversarial Learning Framework for a Persona-based Multi-turn Dialogue Model", "abstract": "In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq) neural network conversation model to a multi-turn dialogue scenario by modifying the state-of-the-art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on. The proposed system, phredGAN has a persona-based HRED generator (PHRED) and a conditional discriminator. We also explore two approaches to accomplish the conditional discriminator: (1) $phredGAN_a$, a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and (2) $phredGAN_d$, a dual discriminator system which in addition to the adversarial discriminator, collaboratively predicts the attribute(s) that generated the input utterance. To demonstrate the superior performance of phredGAN over the persona SeqSeq model, we experiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC) and TV series transcripts from the Big Bang Theory and Friends. Performance comparison is made with respect to a variety of quantitative measures, including BLEU, ROUGE, and perplexity scores. We also explore the trade-offs from using either variant of $phredGAN$ on datasets with many but weak attribute modalities (such as with Big Bang Theory and Friends) and ones with few but strong attribute modalities (customer-agent interactions in Ubuntu dataset).", "keywords": ["conversation model", "dialogue system", "adversarial net", "persona"], "authorids": ["ICLR.cc/2019/Conference/Paper196/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper develops an adversarial learning framework for neural conversation models with persona", "pdf": "/pdf/ad6f678bc2f7954cb414e5d28fd1aba130256380.pdf", "paperhash": "anonymous|an_adversarial_learning_framework_for_a_personabased_multiturn_dialogue_model", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Adversarial Learning Framework for a Persona-based Multi-turn Dialogue Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeYUsRqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJl98sR5tX", "original": "HygFldCtF7", "number": 197, "cdate": 1538087761609, "ddate": null, "tcdate": 1538087761609, "tmdate": 1538156221879, "tddate": null, "forum": "SJl98sR5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Interactive Agent Modeling by Learning to Probe", "abstract": "The ability of modeling the other agents, such as understanding their intentions and skills, is essential to an agent's interactions with other agents. Conventional agent modeling relies on passive observation from demonstrations. In this work, we propose an interactive agent modeling scheme enabled by encouraging an agent to learn to probe. In particular, the probing agent (i.e. a learner) learns to interact with the environment and with a target agent (i.e., a demonstrator) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. Our framework consists of two learning processes: i) imitation learning for an approximated agent model and ii) pure curiosity-driven reinforcement learning for an efficient probing policy to discover new behaviors that otherwise can not be observed. We have validated our approach in four different tasks. The experimental results suggest that the agent model learned by our approach i) generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiosity-driven approaches do, and ii) can be used for enhancing performance in multiple applications including distilling optimal planning to a policy net, collaboration, and competition. A video demo is available at https://www.dropbox.com/s/8mz6rd3349tso67/Probing_Demo.mov?dl=0", "keywords": ["Agent Modeling", "Theory of Mind", "Deep Reinforcement Learning", "Multi-agent Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper197/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an interactive agent modeling framework by learning a probing policy to diversify task settings and to incite new behaviors of a target agent for a better modeling of the target agent.", "pdf": "/pdf/e087e76c9e304daadd27bbab8dedae913f03ed11.pdf", "paperhash": "anonymous|interactive_agent_modeling_by_learning_to_probe", "_bibtex": "@inproceedings{    \nanonymous2019interactive,    \ntitle={Interactive Agent Modeling by Learning to Probe},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl98sR5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bye9LiR9YX", "original": "SylVeoNLtm", "number": 198, "cdate": 1538087761788, "ddate": null, "tcdate": 1538087761788, "tmdate": 1538156221660, "tddate": null, "forum": "Bye9LiR9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Remember and Forget for Experience Replay", "abstract": "Experience replay (ER) is crucial for attaining high data-efficiency in off-policy reinforcement learning (RL).  ER entails the recall of experiences obtained in past iterations to compute gradient estimates for the current policy. However, the accuracy of such updates may deteriorate when the policy diverges from past behaviors, possibly undermining the effectiveness of ER. Previous off-policy RL algorithms mitigated this issue by tuning hyper-parameters in order to abate policy changes. We propose a method for ER that relies on systematically Remembering and Forgetting past behaviors (ReF-ER). ReF-ER forgets experiences that would be too unlikely with the current policy and constrains policy changes within a trust region of the behaviors in the replay memory. We couple ReF-ER with Q-learning, deterministic policy gradient and off-policy gradient methods and we show that ReF-ER reliably improves the performance of continuous-action off-policy RL. We complement ReF-ER with a novel off-policy actor-critic algorithm (RACER) for continuous-action control. RACER employs a computationally efficient closed-form approximation of the action values and is shown to be highly competitive with state-of-the-art algorithms on benchmark problems, while being robust to large hyper-parameter variations.", "keywords": ["reinforcement learning", "experience replay", "policy gradients"], "authorids": ["ICLR.cc/2019/Conference/Paper198/Authors"], "authors": ["Anonymous"], "TL;DR": "ReF-ER is an Experience Replay algorithm to regulate the pace at which the control policy is allowed to deviate from past behaviors; it is shown to enhance the stability and performance of off-policy RL methods.", "pdf": "/pdf/e66cbbd8c30f5b39fd9d674067d01c828733fcbf.pdf", "paperhash": "anonymous|remember_and_forget_for_experience_replay", "_bibtex": "@inproceedings{    \nanonymous2019remember,    \ntitle={Remember and Forget for Experience Replay},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bye9LiR9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkGqLoR5tX", "original": "r1xG37H9KX", "number": 199, "cdate": 1538087761974, "ddate": null, "tcdate": 1538087761974, "tmdate": 1538156221448, "tddate": null, "forum": "rkGqLoR5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ODIN: Outlier Detection In Neural Networks", "abstract": "Adoption of deep learning in safety-critical systems raise the need for understanding what deep neural networks do not understand. Several methodologies to estimate model uncertainty have been proposed, but these methodologies constrain either how the neural network is trained or constructed. We present Outlier Detection In Neural networks (ODIN), an assumption-free method for detecting outlier observations during prediction, based on principles widely used in manufacturing process monitoring. By using a linear approximation of the hidden layer manifold, we add prediction-time outlier detection to models after training without altering architecture or training. We demonstrate that ODIN efficiently detect outliers during prediction on Fashion-MNIST, ImageNet-synsets and speech command recognition.", "keywords": ["Outlier Detection", "Model Uncertainty", "Safety"], "authorids": ["ICLR.cc/2019/Conference/Paper199/Authors"], "authors": ["Anonymous"], "TL;DR": "An add-on method for deep learning to detect outliers during prediction-time", "pdf": "/pdf/b9cdf844e8554e0805173a7fe19028e20a74f52d.pdf", "paperhash": "anonymous|odin_outlier_detection_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019odin:,    \ntitle={ODIN: Outlier Detection In Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkGqLoR5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkMqUiA5KX", "original": "BkeKhUr9Ym", "number": 200, "cdate": 1538087762160, "ddate": null, "tcdate": 1538087762160, "tmdate": 1538156221237, "tddate": null, "forum": "BkMqUiA5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving latent variable descriptiveness by modelling rather than ad-hoc factors", "abstract": "Powerful generative models, particularly in Natural Language Modelling, are commonly trained by maximizing a variational lower bound on the data log likelihood. These models often suffer from poor use of their latent variable, with ad-hoc annealing factors used to encourage retention of information in the latent variable. We discuss an alternative and general approach to latent variable modelling, based on an objective that encourages a perfect reconstruction by tying a stochastic autoencoder with a variational autoencoder (VAE). This ensures by design that the latent variable captures information about the observations, whilst retaining the ability to generate well. Interestingly, although our model is fundamentally different to a VAE, the lower bound attained is identical to the standard VAE bound but with the addition of a simple pre-factor; thus, providing a formal interpretation of the commonly used, ad-hoc pre-factors in training VAEs.", "keywords": ["generative modelling", "latent variable modelling", "variational autoencoders", "variational inference", "natural language processing"], "authorids": ["ICLR.cc/2019/Conference/Paper200/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces a novel generative modelling framework that avoids latent-variable collapse and clarifies the use of certain ad-hoc factors in training Variational Autoencoders.", "pdf": "/pdf/bf4881f9434a86e247d8a4e4e745389f0e7fce57.pdf", "paperhash": "anonymous|improving_latent_variable_descriptiveness_by_modelling_rather_than_adhoc_factors", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving latent variable descriptiveness by modelling rather than ad-hoc factors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMqUiA5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryE98iR5tm", "original": "H1eapj0dKQ", "number": 201, "cdate": 1538087762337, "ddate": null, "tcdate": 1538087762337, "tmdate": 1538156221029, "tddate": null, "forum": "ryE98iR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Practical lossless compression with latent variables using bits back coding", "abstract": "Deep latent variable models have seen recent success in many data domains. Lossless compression is an application of these models which, despite having the potential to be highly useful, has yet to be implemented in a practical manner. We present `Bits Back with ANS' (BB-ANS), a scheme to perform lossless compression with latent variable models. The scheme is an extension of bits back coding, and permits compression of large datasets at close to the optimal rate. We demonstrate this scheme by using it to compress the MNIST dataset with a variational auto-encoder model (VAE), achieving compression rates superior to standard methods with only a simple VAE. Given that the scheme is highly amenable to parallelization, we conclude that with a sufficiently high quality generative model this scheme could be used to achieve substantial improvements in compression rate with acceptable running time. We make our implementation available open source at https://github.com/bits-back/bits-back .", "keywords": ["compression", "variational auto-encoders", "deep latent gaussian models", "lossless compression", "latent variables", "approximate inference", "variational inference"], "authorids": ["ICLR.cc/2019/Conference/Paper201/Authors"], "authors": ["Anonymous"], "TL;DR": "We do lossless compression of large image datasets using a VAE, beat existing compression algorithms.", "pdf": "/pdf/94fc925478ebd470c2ed71653b37503a11a9026a.pdf", "paperhash": "anonymous|practical_lossless_compression_with_latent_variables_using_bits_back_coding", "_bibtex": "@inproceedings{    \nanonymous2019practical,    \ntitle={Practical lossless compression with latent variables using bits back coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryE98iR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkN5UoAqF7", "original": "B1xamrg5tQ", "number": 202, "cdate": 1538087762509, "ddate": null, "tcdate": 1538087762509, "tmdate": 1538156220811, "tddate": null, "forum": "BkN5UoAqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sample Efficient Imitation Learning for Continuous Control", "abstract": "The goal of imitation learning (IL) is to enable a learner to imitate expert behavior given expert demonstrations. Recently, generative adversarial imitation learning (GAIL) has shown significant progress on IL for complex continuous tasks. However, GAIL and its extensions require a large number of environment interactions during training. In real-world environments, the more an IL method requires the learner to interact with the environment for better imitation, the more training time it requires, and the more damage to the environments and the learner it causes. We believe that IL algorithms could be more applicable to real-world environments if the number of interactions could be reduced. In this paper, we propose a model-free, off-policy IL algorithm for continuous control. Experimental results show that our algorithm achieves competitive results with GAIL while significantly reducing the environment interactions. The reduction is made possible by mainly two proposed methods \u2013 Q-learning without IRL process, and the policy function representation in the same way as the generator of the conditional generative adversarial networks.", "keywords": ["Imitation Learning", "Continuous Control", "Reinforcement Learning", "Inverse Reinforcement Learning", "Conditional Generative Adversarial Network"], "authorids": ["ICLR.cc/2019/Conference/Paper202/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper, we proposed a model-free, off-policy IL algorithm for continuous control. Experimental results showed that our algorithm achieves competitive results with GAIL while significantly reducing the environment interactions.", "pdf": "/pdf/4e3d0a6642397ffb16231d16d4346f5cfe39f790.pdf", "paperhash": "anonymous|sample_efficient_imitation_learning_for_continuous_control", "_bibtex": "@inproceedings{    \nanonymous2019sample,    \ntitle={Sample Efficient Imitation Learning for Continuous Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkN5UoAqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByloIiCqYQ", "original": "BkgXmERtYX", "number": 203, "cdate": 1538087762684, "ddate": null, "tcdate": 1538087762684, "tmdate": 1538156220599, "tddate": null, "forum": "ByloIiCqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Maximal Divergence Sequential Autoencoder for Binary Software Vulnerability Detection", "abstract": "Due to the sharp increase in the severity of the threat imposed by software vulnerabilities, the detection of vulnerabilities in binary code has become an important concern in the software industry, such as the embedded systems industry, and in the field of computer security. However, most of the work in binary code vulnerability detection has relied on handcrafted features which are manually chosen by a select few, knowledgeable domain experts. In this paper, we attempt to alleviate this severe binary vulnerability detection bottleneck by leveraging recent advances in deep learning representations and propose the Maximal Divergence Sequential Auto-Encoder. In particular, latent codes representing vulnerable and non-vulnerable binaries are encouraged to be maximally divergent, while still being able to maintain crucial information from the original binaries. We conducted extensive experiments to compare and contrast our proposed methods with the baselines, and the results show that our proposed methods outperform the baselines in all performance measures of interest.", "keywords": ["Vulnerabilities Detection", "Sequential Auto-Encoder", "Separable Representation"], "authorids": ["ICLR.cc/2019/Conference/Paper203/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel method named Maximal Divergence Sequential Auto-Encoder that leverages Variational AutoEncoder representation for binary code vulnerability detection.", "pdf": "/pdf/b81bc33eebc5a9f1e1b950610dc32986e675af1c.pdf", "paperhash": "anonymous|maximal_divergence_sequential_autoencoder_for_binary_software_vulnerability_detection", "_bibtex": "@inproceedings{    \nanonymous2019maximal,    \ntitle={Maximal Divergence Sequential Autoencoder for Binary Software Vulnerability Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByloIiCqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1ej8o05tm", "original": "S1g4DFSqFX", "number": 204, "cdate": 1538087762916, "ddate": null, "tcdate": 1538087762916, "tmdate": 1538156220383, "tddate": null, "forum": "S1ej8o05tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Object detection deep learning networks for Optical Character Recognition", "abstract": "In this article, we show how we applied a simple approach coming from deep learning networks for object detection to the task of optical character recognition in order to build image features taylored for documents. In contrast to scene text reading in natural images using networks pretrained on ImageNet, our document reading is performed with small networks inspired by MNIST digit recognition challenge, at a small computational budget and a small stride. The object detection modern frameworks allow a direct end-to-end training, with no other algorithm than the deep learning and the non-max-suppression algorithm to filter the duplicate predictions. The trained weights can be used for higher level models, such as, for example, document classification, or document segmentation.\n", "keywords": ["OCR", "object detection", "RCNN", "Yolo"], "authorids": ["ICLR.cc/2019/Conference/Paper204/Authors"], "authors": ["Anonymous"], "TL;DR": "Yolo / RCNN neural network for object detection adapted to the task of OCR", "pdf": "/pdf/057e2f2740d9db6538c7ebb238c3b2a48bf9a11a.pdf", "paperhash": "anonymous|object_detection_deep_learning_networks_for_optical_character_recognition", "_bibtex": "@inproceedings{    \nanonymous2019object,    \ntitle={Object detection deep learning networks for Optical Character Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1ej8o05tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkzjUoAcFX", "original": "rJx8WtHcK7", "number": 205, "cdate": 1538087763102, "ddate": null, "tcdate": 1538087763102, "tmdate": 1538156220169, "tddate": null, "forum": "rkzjUoAcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sample Efficient Adaptive Text-to-Speech", "abstract": "We present a meta-learning approach for adaptive text-to-speech (TTS) with few data. During training, we learn a multi-speaker model using a shared conditional WaveNet core and independent learned embeddings for each speaker. The aim of training is not to produce a neural network with fixed weights, which is then deployed as a TTS system. Instead, the aim is to produce a network that requires few data at deployment time to rapidly adapt to new speakers. We introduce and benchmark three strategies:\n(i) learning the speaker embedding while keeping the WaveNet core fixed,\n(ii) fine-tuning the entire architecture with stochastic gradient descent, and\n(iii) predicting the speaker embedding with a trained neural network encoder.\nThe experiments show that these approaches are successful at adapting the multi-speaker neural network to new speakers, obtaining state-of-the-art results in both sample naturalness and voice similarity with merely a few minutes of audio data from new speakers.", "keywords": ["few shot", "meta learning", "text to speech", "wavenet"], "authorids": ["ICLR.cc/2019/Conference/Paper205/Authors"], "authors": ["Anonymous"], "TL;DR": "Sample efficient algorithms to adapt a text-to-speech model to a new voice style with the state-of-the-art performance.", "pdf": "/pdf/b9834f54ad5d1f0d573d8d923f7449aa99c0b989.pdf", "paperhash": "anonymous|sample_efficient_adaptive_texttospeech", "_bibtex": "@inproceedings{    \nanonymous2019sample,    \ntitle={Sample Efficient Adaptive Text-to-Speech},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkzjUoAcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1fsUiRcKQ", "original": "SJxkQ4M9tX", "number": 206, "cdate": 1538087763298, "ddate": null, "tcdate": 1538087763298, "tmdate": 1538156219958, "tddate": null, "forum": "H1fsUiRcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fast adversarial training for semi-supervised learning", "abstract": "In semi-supervised learning, Bad GAN approach is one of the most attractive method due to the intuitional simplicity and  powerful performances. Bad GAN learns a classifier with bad samples distributed on complement of the support of the input data. But Bad GAN needs additional architectures, a generator and a density estimation model, which involves huge computation and memory consumption cost. VAT is another good semi-supervised learning algorithm, which utilizes unlabeled data to improve the invariance of the classifier with respect to perturbation of inputs. In this study, we propose a new method \nby combining the ideas of Bad GAN and VAT. The proposed method generates bad samples of high-quality by use of the adversarial training used in VAT. We give theoretical explanations why the adversarial training is good at both generating bad samples and semi-supervised learning. An advantage of the proposed method is to achieve the competitive performances with much fewer computations. We demonstrate this advantage by analyzing three well known benchmark image datasets.", "keywords": ["Deep learning", "Semi-supervised learning", "Adversarial training"], "authorids": ["ICLR.cc/2019/Conference/Paper206/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a fast and efficient semi-supervised learning method using adversarial training.", "pdf": "/pdf/b83cc23d978e614032281197714910606f88d848.pdf", "paperhash": "anonymous|fast_adversarial_training_for_semisupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019fast,    \ntitle={Fast adversarial training for semi-supervised learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1fsUiRcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1EiIsCctm", "original": "HJl35hBqFQ", "number": 207, "cdate": 1538087763475, "ddate": null, "tcdate": 1538087763475, "tmdate": 1538156219748, "tddate": null, "forum": "B1EiIsCctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving Gaussian mixture latent variable model convergence with Optimal Transport", "abstract": "Generative models with both discrete and continuous latent variables are highly motivated by the structure of many real-world data sets. They present, however, subtleties in training often manifesting in the discrete latent variable not being leveraged. In this paper, we show why such models struggle to train using traditional log-likelihood maximization, and that they are amenable to training using the Optimal Transport framework of Wasserstein Autoencoders. We find our discrete latent variable to be fully leveraged by the model when trained, without any modifications to the objective function or significant fine tuning. Our model generates comparable samples to other approaches while using relatively simple neural networks, since the discrete latent variable carries much of the descriptive burden. Furthermore, the discrete latent provides significant control over generation.", "keywords": ["optimal transport", "wasserstein autoencoder", "variational autoencoder", "latent variable modeling", "generative modeling", "discrete latent variables"], "authorids": ["ICLR.cc/2019/Conference/Paper207/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper shows that the Wasserstein distance objective enables the training of latent variable models with discrete latents in a case where the Variational Autoencoder objective fails to do so.", "pdf": "/pdf/d5962a9d9764e42adf2ec4defea8c617f99f0803.pdf", "paperhash": "anonymous|improving_gaussian_mixture_latent_variable_model_convergence_with_optimal_transport", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Gaussian mixture latent variable model convergence with Optimal Transport},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1EiIsCctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkenUj0qYm", "original": "SJgGBxXFtm", "number": 208, "cdate": 1538087763652, "ddate": null, "tcdate": 1538087763652, "tmdate": 1538156219534, "tddate": null, "forum": "SkenUj0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings", "abstract": "Word embeddings are known to boost performance of many NLP tasks such as text classification, meanwhile they can be enhanced by labels at the document level to capture nuanced meaning such as sentiment and topic. Can one combine these two research directions to benefit from both? In this paper, we propose to jointly train a text classifier with a label-enhanced and domain-aware word embedding model, using an unlabeled corpus and only a few labeled data from non-target domains. The embeddings are trained on the unlabed corpus and enhanced by pseudo labels coming from the classifier, and at the same time are used by the classifier as input and training signals. We formalize this symbiotic cycle in a variational Bayes framework, and show that our method improves both the embeddings and the text classifier, outperforming state-of-the-art domain adaptation and semi-supervised learning techniques. We conduct detailed ablative tests to reveal gains from important components of our approach. The source code and experiment data will be publicly released.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper208/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8925b3f6eeeb8cc32b1117cb19a753b2bd7b80cc.pdf", "paperhash": "anonymous|semisupervised_learning_with_multidomain_sentiment_word_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019semi-supervised,    \ntitle={Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkenUj0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJx38iC5KX", "original": "BJlSE3MFK7", "number": 209, "cdate": 1538087763828, "ddate": null, "tcdate": 1538087763828, "tmdate": 1538156219328, "tddate": null, "forum": "HJx38iC5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Domain-Invariant Representation under Domain-Class Dependency", "abstract": "Learning domain-invariant representation is a dominant approach for domain generalization, where we need to build a classifier that is robust toward domain shifts induced by change of users, acoustic or lighting conditions, etc. However, prior domain-invariance-based methods overlooked the underlying dependency of classes (target variable) on domains during optimization, which causes the trade-off between classification accuracy and domain-invariance, and often interferes with the domain generalization performance. This study first provides the notion of domain generalization under domain-class dependency and elaborates on the importance of considering the dependency by expanding the analysis of Xie et al. (2017). We then propose a method, invariant feature learning under optimal classifier constrains (IFLOC), which explicitly considers the dependency and maintains accuracy while improving domain-invariance. Specifically, the proposed method regularizes the representation so that it has as much domain information as the class labels, unlike prior methods that remove all domain information. Empirical validations show the superior performance of IFLOC to baseline methods, supporting the importance of the domain-class dependency in domain generalization and the efficacy of the proposed method for overcoming the issue.", "keywords": ["domain generalization", "adversarial learning", "invariant feature learning"], "authorids": ["ICLR.cc/2019/Conference/Paper209/Authors"], "authors": ["Anonymous"], "TL;DR": "Address the trade-off caused by the dependency of classes on domains in domain generalization", "pdf": "/pdf/359ef0aadfd0acb370ffcddbe03f36e40801928b.pdf", "paperhash": "anonymous|learning_domaininvariant_representation_under_domainclass_dependency", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Domain-Invariant Representation under Domain-Class Dependency},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJx38iC5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkfhIo0qtQ", "original": "SylfCCH9Y7", "number": 210, "cdate": 1538087763999, "ddate": null, "tcdate": 1538087763999, "tmdate": 1538156219114, "tddate": null, "forum": "SkfhIo0qtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Volumetric Convolution: Automatic Representation Learning in Unit Ball", "abstract": "Convolution is an efficient technique to obtain abstract feature representations using hierarchical layers in deep networks. Although performing convolution in Euclidean geometries is fairly straightforward, its extension to other topological spaces---such as a sphere S^2 or a unit ball B^3---entails unique challenges. In this work, we propose a novel `\"volumetric convolution\" operation that can effectively convolve arbitrary functions in B^3. We develop a theoretical framework for \"volumetric convolution\" based on Zernike polynomials and efficiently implement it as a differentiable and an easily pluggable layer for deep networks. Furthermore, our formulation leads to derivation of a  novel formula to measure the symmetry of a function in B^3 around an arbitrary axis, that is useful in 3D shape analysis tasks. We demonstrate the efficacy of proposed volumetric convolution operation on a possible use-case i.e., 3D object recognition task.", "keywords": ["convolution", "unit sphere", "3D object recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper210/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel convolution operator for automatic representation learning inside unit ball", "pdf": "/pdf/903e84568dcb42687e59e25d1346eba62a1062bc.pdf", "paperhash": "anonymous|volumetric_convolution_automatic_representation_learning_in_unit_ball", "_bibtex": "@inproceedings{    \nanonymous2019volumetric,    \ntitle={Volumetric Convolution: Automatic Representation Learning in Unit Ball},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkfhIo0qtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyMhLo0qKQ", "original": "r1gNI7nDtQ", "number": 211, "cdate": 1538087764182, "ddate": null, "tcdate": 1538087764182, "tmdate": 1538156218903, "tddate": null, "forum": "SyMhLo0qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Distribution-Interpolation Trade off in Generative Models", "abstract": "We investigate the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. Our work revolves around the phenomena arising while decoding linear interpolations between two random latent vectors -- regions of latent space in close proximity to the origin of the space are oversampled, which restricts the usability of linear interpolations as a tool to analyse the latent space. We show that the distribution mismatch can be eliminated completely by a proper choice of the latent probability distribution or using non-linear interpolations. We prove that there is a trade off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. We use the multidimensional Cauchy distribution as an example of the prior distribution, and also provide a general method of creating non-linear interpolations, that is easily applicable to a large family of commonly used latent distributions.", "keywords": ["generative models", "latent distribution", "Cauchy distribution", "interpolations"], "authorids": ["ICLR.cc/2019/Conference/Paper211/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9ae91a2dca24b9e29dc4f6661c88d716f537b46d.pdf", "paperhash": "anonymous|distributioninterpolation_trade_off_in_generative_models", "_bibtex": "@inproceedings{    \nanonymous2019distribution-interpolation,    \ntitle={Distribution-Interpolation Trade off in Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyMhLo0qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJEhIjA9tQ", "original": "HklfIZ8qYm", "number": 212, "cdate": 1538087764357, "ddate": null, "tcdate": 1538087764357, "tmdate": 1538156218690, "tddate": null, "forum": "HJEhIjA9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Encoder Discriminator Networks for Unsupervised Representation Learning", "abstract": "Learning representations of data samples in an unsupervised way is needed whenever computers have to reason about unlabeled data. Applications range from compressing and denoising data to super-resolution, generating new samples from a given sample distribution and much more.\nIn this work, we use information entropy and a little game to motivate a new encoder discriminator architecture in order to learn unsupervised latent representations. Inspired by the game \"Taboo\", we train an encoder network to generate a meaningful representation of one particular sample of a dataset. Using this description, a discriminator network then has to retrieve the same sample from the whole dataset. We show that learning in this manner on many different samples repeatedly minimizes the information entropy given the latent description and, thus, forces the encoder network to make precise descriptions that can be interpreted by the discriminator.\nWe provide first results of this method on the MNIST and the Fashion MNIST dataset.", "keywords": ["representation learning", "unsupervised", "encoder discriminator"], "authorids": ["ICLR.cc/2019/Conference/Paper212/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/650ff29cd475b17a3b661d645286851874829a11.pdf", "paperhash": "anonymous|encoder_discriminator_networks_for_unsupervised_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019encoder,    \ntitle={Encoder Discriminator Networks for Unsupervised Representation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJEhIjA9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryepUj0qtX", "original": "rkxfO9NqY7", "number": 213, "cdate": 1538087764540, "ddate": null, "tcdate": 1538087764540, "tmdate": 1538156218479, "tddate": null, "forum": "ryepUj0qtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Conditional Network Embeddings", "abstract": "Network Embeddings (NEs) map the nodes of a given network into $d$-dimensional Euclidean space $\\mathbb{R}^d$. Ideally, this mapping is such that 'similar' nodes are mapped onto nearby points, such that the NE can be used for purposes such as link prediction (if 'similar' means being 'more likely to be connected') or classification (if 'similar' means 'being more likely to have the same label'). In recent years various methods for NE have been introduced, all following a similar strategy: defining a notion of similarity between nodes (typically some distance measure within the network), a distance measure in the embedding space, and a loss function that penalizes large distances for similar nodes and small distances for dissimilar nodes.\n\nA difficulty faced by existing methods is that certain networks are fundamentally hard to embed due to their structural properties: (approximate) multipartiteness, certain degree distributions, assortativity, etc. To overcome this, we introduce a conceptual innovation to the NE literature and propose to create \\emph{Conditional Network Embeddings} (CNEs); embeddings that maximally add information with respect to given structural properties (e.g. node degrees, block densities, etc.). We use a simple Bayesian approach to achieve this, and propose a block stochastic gradient descent algorithm for fitting it efficiently.\n\nWe demonstrate that CNEs are superior for link prediction and multi-label classification when compared to state-of-the-art methods, and this without adding significant mathematical or computational complexity. Finally, we illustrate the potential of CNE for network visualization.", "keywords": ["Network embedding", "graph embedding", "learning node representations", "link prediction", "multi-label classification of nodes"], "authorids": ["ICLR.cc/2019/Conference/Paper213/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a network embedding method that accounts for prior information about the network, yielding superior empirical performance.", "pdf": "/pdf/2d6ae5625749e57fd9b1b693842a06f36d70b011.pdf", "paperhash": "anonymous|conditional_network_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019conditional,    \ntitle={Conditional Network Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryepUj0qtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlpUiAcYX", "original": "HJl66zIqtm", "number": 214, "cdate": 1538087764719, "ddate": null, "tcdate": 1538087764719, "tmdate": 1538156218264, "tddate": null, "forum": "rJlpUiAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Holographic and other Point Set Distances for Machine Learning", "abstract": "We introduce an analytic distance function for moderately sized point sets of known cardinality that is shown to have very desirable properties, both as a loss function as well as a regularizer for machine learning applications. We compare our novel construction to other point set distance functions and show proof of concept experiments for training neural networks end-to-end on point set prediction tasks such as object detection.", "keywords": ["point set", "set", "permutation-invariant", "loss function"], "authorids": ["ICLR.cc/2019/Conference/Paper214/Authors"], "authors": ["Anonymous"], "TL;DR": "Permutation-invariant loss function for point set prediction.", "pdf": "/pdf/760c6a4f1a4af8529053ce3a0a20b0d2dd1ff191.pdf", "paperhash": "anonymous|holographic_and_other_point_set_distances_for_machine_learning", "_bibtex": "@inproceedings{    \nanonymous2019holographic,    \ntitle={Holographic and other Point Set Distances for Machine Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlpUiAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJlp8sA5Y7", "original": "BkgbI1P_K7", "number": 215, "cdate": 1538087764893, "ddate": null, "tcdate": 1538087764893, "tmdate": 1538156218047, "tddate": null, "forum": "SJlp8sA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Efficient Network for Predicting Time-Varying Distributions", "abstract": "While deep neural networks have achieved groundbreaking prediction results in many tasks, there is a class of data where existing architectures are not optimal -- sequences of probability distributions. Performing forward prediction on sequences of distributions has many important applications. However, there are two main challenges in designing a network model for this task. First, neural networks are unable to encode distributions compactly as each node encodes just a real value. A recent work of Distribution Regression Network (DRN) solved this problem with a novel network that encodes an entire distribution in a single node, resulting in improved accuracies while using much fewer parameters than neural networks. However, despite its compact distribution representation, DRN does not address the second challenge, which is the need to model time dependencies in a sequence of distributions. In this paper, we propose our Recurrent Distribution Regression Network (RDRN) which adopts a recurrent architecture for DRN. The combination of compact distribution representation and shared weights architecture across time steps makes RDRN suitable for modeling the time dependencies in a distribution sequence. Compared to neural networks and DRN, RDRN achieves the best prediction performance while keeping the network compact.", "keywords": ["Distribution regression", "Distribution sequence", "Forward prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper215/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an efficient recurrent network model for forward prediction on time-varying distributions.", "pdf": "/pdf/f899d9e4fdefc89604a3b354253217f4dbc35b11.pdf", "paperhash": "anonymous|an_efficient_network_for_predicting_timevarying_distributions", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Efficient Network for Predicting Time-Varying Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlp8sA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkeT8iR9Y7", "original": "rygcOcXqKX", "number": 216, "cdate": 1538087765075, "ddate": null, "tcdate": 1538087765075, "tmdate": 1538156217832, "tddate": null, "forum": "rkeT8iR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Directional Analysis of Stochastic Gradient Descent via von Mises-Fisher Distributions in Deep Learning", "abstract": "Although stochastic gradient descent (SGD) is a driving force behind the recent success of deep learning, our understanding of its dynamics in a high-dimensional parameter space is limited. In recent years, some researchers have used the stochasticity of minibatch gradients, or the signal-to-noise ratio, to better characterize the learning dynamics of SGD. Inspired from these work, we here analyze SGD from a geometrical perspective by inspecting the stochasticity of the norms and directions of minibatch gradients. We propose a model of the directional concentration for minibatch gradients through von Mises-Fisher (VMF) distribution, and show that the directional uniformity of minibatch gradients increases over the course of SGD. We empirically verify our result using deep convolutional networks and observe a higher correlation between the gradient stochasticity and the proposed directional uniformity than that against the gradient norm stochasticity, suggesting that the directional statistics of minibatch gradients is a major factor behind SGD.", "keywords": ["directional statistics", "deep learning", "SNR", "gradient stochasticity", "SGD", "stochastic gradient", "von Mises-Fisher", "angle"], "authorids": ["ICLR.cc/2019/Conference/Paper216/Authors"], "authors": ["Anonymous"], "TL;DR": "One of theoretical issues in deep learning", "pdf": "/pdf/1ac526d5ace3df90a4512b534c53fa8799b3f6c2.pdf", "paperhash": "anonymous|directional_analysis_of_stochastic_gradient_descent_via_von_misesfisher_distributions_in_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019directional,    \ntitle={Directional Analysis of Stochastic Gradient Descent via von Mises-Fisher Distributions in Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeT8iR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkfTIj0cKX", "original": "SJxq4k9ndQ", "number": 217, "cdate": 1538087765248, "ddate": null, "tcdate": 1538087765248, "tmdate": 1538156217622, "tddate": null, "forum": "SkfTIj0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Purchase as Reward : Session-based  Recommendation by Imagination Reconstruction", "abstract": "One of the key challenges of session-based recommender systems is to enhance users\u2019 purchase intentions. In this paper, we formulate the sequential interactions between user sessions and a recommender agent as a Markov Decision Process (MDP). In practice, the purchase reward is delayed and sparse, and may be buried by clicks, making it an impoverished signal for policy learning. Inspired by the prediction error minimization (PEM) and embodied cognition, we propose a simple architecture to augment reward, namely Imagination Reconstruction Network (IRN). Speci\ufb01cally, IRN enables the agent to explore its environment and learn predictive representations via three key components. The imagination core generates predicted trajectories, i.e., imagined items that users may purchase. The trajectory manager controls the granularity of imagined trajectories using the planning strategies, which balances the long-term rewards and short-term rewards. To optimize the action policy, the imagination-augmented executor minimizes the intrinsic imagination error of simulated trajectories by self-supervised reconstruction, while maximizing the extrinsic reward using model-free algorithms. Empirically, IRN promotes quicker adaptation to user interest, and shows improved robustness to the cold-start scenario and ultimately higher purchase performance compared to several baselines. Somewhat surprisingly, IRN using only the purchase reward achieves excellent next-click prediction performance, demonstrating that the agent can \"guess what you like\" via internal planning.", "keywords": ["recommender systems", "reinforcement learning", "predictive learning", "self-supervised RL", "model-based planning"], "authorids": ["ICLR.cc/2019/Conference/Paper217/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose the IRN architecture to augment sparse and delayed purchase reward for session-based recommendation.", "pdf": "/pdf/4887cb64b1a30819929a411bb1acc3cbd50cb3cf.pdf", "paperhash": "anonymous|purchase_as_reward_sessionbased_recommendation_by_imagination_reconstruction", "_bibtex": "@inproceedings{    \nanonymous2019purchase,    \ntitle={Purchase as Reward : Session-based  Recommendation by Imagination Reconstruction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkfTIj0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1GaLiAcY7", "original": "BJeAI6TFFQ", "number": 218, "cdate": 1538087765431, "ddate": null, "tcdate": 1538087765431, "tmdate": 1538156217404, "tddate": null, "forum": "H1GaLiAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Separate Domains in Generalized Zero-Shot and Open Set Learning: a probabilistic perspective", "abstract": " This paper studies the problem of domain division problem which aims to segment instances drawn from different probabilistic distributions. Such a problem exists in many previous recognition tasks, such as Open Set Learning (OSL) and Generalized Zero-Shot Learning (G-ZSL), where the testing instances come from either seen or novel/unseen classes of different probabilistic distributions. Previous works focused on either only calibrating the confident prediction of classifiers of seen classes (W-SVM), or taking unseen classes as outliers. In contrast, this paper proposes a probabilistic way of directly estimating and fine-tuning the decision boundary between seen and novel/unseen classes. In particular, we propose a domain division algorithm of learning to split the testing instances into known, unknown and uncertain domains, and then conduct recognize tasks in each domain. Two statistical tools, namely, bootstrapping and Kolmogorov-Smirnov (K-S) Test, for the first time, are introduced to discover and fine-tune the decision boundary of each domain. Critically, the uncertain domain is newly introduced in our framework to adopt those instances whose domain cannot be predicted confidently. Extensive experiments demonstrate that our approach achieved the state-of-the-art performance on OSL and G-ZSL benchmarks.", "keywords": ["Generalized zero-shot learning", "domain division", "bootstrapping", "Kolmogorov-Smirnov"], "authorids": ["ICLR.cc/2019/Conference/Paper218/Authors"], "authors": ["Anonymous"], "TL;DR": " This paper studies the problem of domain division problem by segmenting instances drawn from different probabilistic distributions.  ", "pdf": "/pdf/82d9dda004574a109e29d6675e42eba84fa3958e.pdf", "paperhash": "anonymous|learning_to_separate_domains_in_generalized_zeroshot_and_open_set_learning_a_probabilistic_perspective", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Separate Domains in Generalized Zero-Shot and Open Set Learning: a probabilistic perspective},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1GaLiAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eRIoA5Y7", "original": "SyxxVUUqtm", "number": 219, "cdate": 1538087765601, "ddate": null, "tcdate": 1538087765601, "tmdate": 1538156217190, "tddate": null, "forum": "H1eRIoA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Low-Cost Parameterizations of Deep Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) filter the input data using a series of spatial convolution operators with compactly supported stencils and point-wise nonlinearities.\nCommonly, the convolution operators couple features from all channels.\nFor wide networks, this leads to immense computational cost in the training of and prediction with CNNs.\nIn this paper, we present novel ways to parameterize the convolution more efficiently, aiming to decrease the number of parameters in CNNs and their computational complexity.\nWe propose new architectures that use a sparser coupling between the channels and thereby reduce both the number of trainable weights and the computational cost of the CNN.\nOur architectures arise as new types of residual neural network (ResNet) that can be seen as discretizations of a Partial Differential Equations (PDEs) and thus have predictable theoretical properties. Our first architecture involves a convolution operator with a special sparsity structure, and is applicable to a large class of CNNs. Next, we present an architecture that can be seen as a discretization of a diffusion reaction PDE, and use it with three different convolution operators. We outline in our experiments that the proposed architectures,  although considerably reducing the number of trainable weights, yield comparable accuracy to existing CNNs that are fully coupled in the channel dimension.\n", "keywords": ["Deep Learning", "Classification", "Partial Differential Equations"], "authorids": ["ICLR.cc/2019/Conference/Paper219/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces efficient and economic parametrizations of convolutional neural networks motivated by partial differential equations ", "pdf": "/pdf/d1d189e0c98c5097bf17c0bef05d88e749dd8937.pdf", "paperhash": "anonymous|lowcost_parameterizations_of_deep_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019low-cost,    \ntitle={Low-Cost Parameterizations of Deep Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eRIoA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1l08oAct7", "original": "HkgXkJ8qK7", "number": 220, "cdate": 1538087765785, "ddate": null, "tcdate": 1538087765785, "tmdate": 1538156216972, "tddate": null, "forum": "B1l08oAct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fixing Variational Bayes: Deterministic Variational Inference for Bayesian Neural Networks", "abstract": "Bayesian neural networks (BNNs) hold great promise as a flexible and principled solution to deal with uncertainty when learning from finite data. Among approaches to realize probabilistic inference in deep neural networks,  variational Bayes (VB) is theoretically grounded, generally applicable, and computationally efficient. With wide recognition of potential advantages, why is it that variational Bayes has seen very limited practical use for BNNs in real applications? We argue that variational inference in neural networks is fragile: successful implementations require careful initialization and tuning of prior variances, as well as controlling the variance of Monte Carlo gradient estimates. We fix VB and turn it into a robust inference tool for Bayesian neural networks. We achieve this with two innovations: first, we introduce a novel deterministic method to approximate moments in neural networks, eliminating gradient variance; second, we introduce a hierarchical prior for parameters and a novel Empirical Bayes procedure for automatically selecting prior variances. Combining these two innovations, the resulting method is highly efficient and robust. On the application of heteroscedastic regression we demonstrate strong predictive performance over alternative approaches.", "keywords": ["Bayesian neural network", "variational inference", "variational bayes", "variance reduction", "empirical bayes"], "authorids": ["ICLR.cc/2019/Conference/Paper220/Authors"], "authors": ["Anonymous"], "TL;DR": "A method for eliminating gradient variance and automatically tuning priors for effective training of bayesian neural networks", "pdf": "/pdf/1f875de3aae49de60cc1d37a72c8d2c177d0c2f8.pdf", "paperhash": "anonymous|fixing_variational_bayes_deterministic_variational_inference_for_bayesian_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019fixing,    \ntitle={Fixing Variational Bayes: Deterministic Variational Inference for Bayesian Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l08oAct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyMRUiC9YX", "original": "B1egmPLKt7", "number": 221, "cdate": 1538087765961, "ddate": null, "tcdate": 1538087765961, "tmdate": 1538156216753, "tddate": null, "forum": "HyMRUiC9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploring and Enhancing the Transferability of Adversarial Examples", "abstract": "  State-of-the-art deep neural networks are vulnerable to adversarial examples, formed by applying small but malicious perturbations to the original inputs. Moreover, the perturbations can \\textit{transfer across models}: adversarial examples generated for a specific model will often mislead other unseen models. Consequently  the adversary can leverage it to attack deployed systems without any query, which severely hinder the application of deep learning, especially in the areas where security is crucial.  In this work, we empirically study how two classes of factors that might influence the transferability of adversarial examples.  One is about model-specific factors, including network architecture, model capacity and test accuracy. The other is the local smoothness of loss surface for constructing adversarial examples.  We then propose a simple but effective strategy  to enhance the transferability, whose effectiveness is confirmed by a variety of experiments on both  CIFAR-10 and ImageNet datasets.", "keywords": ["Deep learning", "Adversarial example", "Transferability", "Smoothed gradient"], "authorids": ["ICLR.cc/2019/Conference/Paper221/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/34a2cd964a75681d2b9da498be5cff818ccecdf1.pdf", "paperhash": "anonymous|exploring_and_enhancing_the_transferability_of_adversarial_examples", "_bibtex": "@inproceedings{    \nanonymous2019exploring,    \ntitle={Exploring and Enhancing the Transferability of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMRUiC9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GAUs0cKQ", "original": "SkgocDLcK7", "number": 222, "cdate": 1538087766138, "ddate": null, "tcdate": 1538087766138, "tmdate": 1538156216535, "tddate": null, "forum": "B1GAUs0cKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variance Networks: When Expectation Does Not Meet Your Expectations", "abstract": "Ordinary stochastic neural networks mostly rely on the expected values of their weights to make predictions, whereas the induced noise is mostly used to capture the uncertainty, prevent overfitting and slightly boost the performance through test-time averaging. In this paper, we introduce variance layers, a different kind of stochastic layers. Each weight of a variance layer follows a zero-mean distribution and is only parameterized by its variance. It means that each object is represented by a zero-mean distribution in the space of the activations. We show that such layers can learn surprisingly well, can serve as an efficient exploration tool in reinforcement learning tasks and provide a decent defense against adversarial attacks. We also show that a number of conventional Bayesian neural networks naturally converge to such zero-mean posteriors. We observe that in these cases such zero-mean parameterization leads to a much better training objective than more flexible conventional parameterizations where the mean is being learned.", "keywords": ["deep learning", "variational inference", "variational dropout"], "authorids": ["ICLR.cc/2019/Conference/Paper222/Authors"], "authors": ["Anonymous"], "TL;DR": "It is possible to learn a zero-centered Gaussian distribution over the weights of a neural network by learning only variances, and it works surprisingly well.", "pdf": "/pdf/8434b8617a8ba6b5ab9f216a0175aba2fe55bd83.pdf", "paperhash": "anonymous|variance_networks_when_expectation_does_not_meet_your_expectations", "_bibtex": "@inproceedings{    \nanonymous2019variance,    \ntitle={Variance Networks: When Expectation Does Not Meet Your Expectations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GAUs0cKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lC8o0cKX", "original": "HkgoK2A_Km", "number": 223, "cdate": 1538087766304, "ddate": null, "tcdate": 1538087766304, "tmdate": 1538156216325, "tddate": null, "forum": "H1lC8o0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Emergence of Spatial Structure from Sensorimotor Prediction", "abstract": "Despite its omnipresence in robotics application, the nature of spatial knowledge and the mechanisms that underlie its emergence in autonomous agents are still poorly understood. Recent theoretical work suggests that the concept of space can be grounded by capturing invariants that space's structure induces in an agent's raw sensorimotor experience. Moreover, it is hypothesized that capturing these invariants is beneficial for a naive agent trying to predict its sensorimotor experience. Under certain exploratory conditions, spatial representations should thus emerge as a byproduct of learning to predict. We propose a simple sensorimotor predictive scheme, apply it to different agents and types of exploration, and evaluate the pertinence of this hypothesis. We show that a naive agent can capture the topology and metric regularity of its spatial configuration without any a priori knowledge, nor extraneous supervision.", "keywords": ["spatial perception", "grounding", "sensorimotor prediction", "unsupervised learning", "representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper223/Authors"], "authors": ["Anonymous"], "TL;DR": "A practical evaluation of hypotheses previously laid out about the unsupervised emergence of spatial representations from sensorimotor prediction.", "pdf": "/pdf/e43dd2b946fda5d94f20db4ac5edb9d2f2f576f1.pdf", "paperhash": "anonymous|unsupervised_emergence_of_spatial_structure_from_sensorimotor_prediction", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Emergence of Spatial Structure from Sensorimotor Prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lC8o0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkxAUjRqY7", "original": "BJgAUpe9F7", "number": 224, "cdate": 1538087766483, "ddate": null, "tcdate": 1538087766483, "tmdate": 1538156216113, "tddate": null, "forum": "BkxAUjRqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Information-Theoretic Metric of Transferability for Task Transfer Learning", "abstract": "An important question in task transfer learning is to determine task transferability, i.e. given a common input domain, estimating to what extent representations learned from a source task can help in learning a target task. Typically, transferability is either measured experimentally or inferred through task relatedness, which is often defined without a clear operational meaning. In this paper, we present a novel metric, H-score, an easily-computable evaluation function that estimates the performance of transferred representations from one task to another in classification problems. Inspired by a principled information theoretic approach, H-score has a direct connection to the asymptotic error probability of the decision function based on the transferred feature. This formulation of transferability can further be used to select a suitable set of source tasks in task transfer learning problems or to devise efficient transfer learning policies. Experiments using both synthetic and real image data show that not only our formulation of transferability is meaningful in practice, but also it can generalize to inference problems beyond classification, such as recognition tasks for 3D indoor-scene understanding.", "keywords": ["transfer learning", "task transfer learning", "H-score", "transferability"], "authorids": ["ICLR.cc/2019/Conference/Paper224/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a provable and easily-computable evaluation function that estimates the performance of transferred representations from one learning task to another in task transfer learning.", "pdf": "/pdf/60be8617fd0801d75fe81dfd157f6f2ef2fa4457.pdf", "paperhash": "anonymous|an_informationtheoretic_metric_of_transferability_for_task_transfer_learning", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Information-Theoretic Metric of Transferability for Task Transfer Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkxAUjRqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lJws05K7", "original": "ByghJqL9FQ", "number": 225, "cdate": 1538087766660, "ddate": null, "tcdate": 1538087766660, "tmdate": 1538156215898, "tddate": null, "forum": "H1lJws05K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Selection of Initialization and Activation Function for Deep Neural Networks", "abstract": "The weight initialization and the activation function of deep neural networks have a crucial impact on the performance of the training procedure. An inappropriate selection can lead to the loss of information of the input during forward propagation and the exponential vanishing/exploding of gradients during back-propagation. Understanding the theoretical properties of untrained random networks is key to identifying which deep networks may be trained successfully as recently demonstrated by Schoenholz et al. (2017) who showed that for deep feedforward neural networks only a specific choice of hyperparameters known as the `edge of chaos' can lead to good performance.\nWe complete this analysis by providing quantitative results showing that, for a class of ReLU-like activation functions, the information propagates indeed deeper for an initialization at the edge of chaos. By further extending this analysis, we identify a class of activation functions that improve the information propagation over ReLU-like functions. This class includes the Swish activation, $\\phi_{swish}(x) = x \\cdot \\text{sigmoid}(x)$, used in Hendrycks & Gimpel (2016),\nElfwing et al. (2017) and Ramachandran et al. (2017). This provides a theoretical grounding for the excellent empirical performance of $\\phi_{swish}$ observed in these contributions. We complement those previous results by illustrating the benefit of using a random initialization on the edge of chaos in this context.", "keywords": ["Deep Neural Networks", "Initialization", "Gaussian Processes"], "authorids": ["ICLR.cc/2019/Conference/Paper225/Authors"], "authors": ["Anonymous"], "TL;DR": "How to effectively choose Initialization and Activation function for deep neural networks", "pdf": "/pdf/8274f2183910c3f8c1c8ac0e4e7f083580826f7c.pdf", "paperhash": "anonymous|on_the_selection_of_initialization_and_activation_function_for_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Selection of Initialization and Activation Function for Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lJws05K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xywsC9tQ", "original": "H1gA15L5YQ", "number": 226, "cdate": 1538087766839, "ddate": null, "tcdate": 1538087766839, "tmdate": 1538156215689, "tddate": null, "forum": "r1xywsC9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mapping the hyponymy relation of wordnet onto vector Spaces", "abstract": " In this paper, we investigate mapping the hyponymy relation of\n wordnet to feature vectors.\n  We aim to model lexical knowledge in such a way that it can be used as\n  input in generic machine-learning models, such as phrase entailment\n  predictors.\n  We propose two models. The first one leverages an existing mapping of\n  words to feature vectors (fasttext), and attempts to classify\n  such vectors as within or outside of each class. The second model is fully supervised,\n  using solely wordnet as a ground truth. It maps each concept to an\n  interval or a disjunction thereof.\n  On the first model, we approach, but not quite attain state of the\n  art performance. The second model can achieve near-perfect accuracy.\n", "keywords": ["fasttext", "hyponymy", "wordnet"], "authorids": ["ICLR.cc/2019/Conference/Paper226/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate mapping the hyponymy relation of wordnet to feature vectors", "pdf": "/pdf/02fcd10e0c1e0a7a5e9ea671896bfafd8e11b770.pdf", "paperhash": "anonymous|mapping_the_hyponymy_relation_of_wordnet_onto_vector_spaces", "_bibtex": "@inproceedings{    \nanonymous2019mapping,    \ntitle={Mapping the hyponymy relation of wordnet onto vector Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xywsC9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJz1vo0cYX", "original": "SJlcuGf5KQ", "number": 227, "cdate": 1538087767014, "ddate": null, "tcdate": 1538087767014, "tmdate": 1538156215475, "tddate": null, "forum": "HJz1vo0cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Confidence Calibration in Deep Neural Networks through Stochastic Inferences", "abstract": "We propose a generic framework to calibrate accuracy and confidence (score) of a prediction through stochastic inferences in deep neural networks. We first analyze relation between variation of multiple model parameters for a single example inference and variance of the corresponding prediction scores by Bayesian modeling of stochastic regularization. Our empirical observation shows that accuracy and score of a prediction are highly correlated with variance of multiple stochastic inferences given by stochastic depth or dropout. Motivated by these facts, we design a novel variance-weighted confidence-integrated loss function that is composed of two cross-entropy loss terms with respect to ground-truth and uniform distribution, which are balanced by variance of stochastic prediction scores. The proposed loss function enables us to learn deep neural networks that predict confidence calibrated scores using a single inference. Our algorithm presents outstanding confidence calibration performance and improves classification accuracy with two popular stochastic regularization techniques---stochastic depth and dropout---in multiple models and datasets; it alleviates overconfidence issue in deep neural networks significantly by training networks to achieve prediction accuracy proportional to confidence of prediction.", "keywords": ["Variance-Weighted Confidence-Integrated loss", "Confidence Calibration", "Stochastic Regularization", "Stochastic Inferences"], "authorids": ["ICLR.cc/2019/Conference/Paper227/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a framework to learn confidence-calibrated networks by designing a novel loss function that incorporates predictive uncertainty estimated through stochastic inferences.", "pdf": "/pdf/16e2ba8f47176b816686301a6992a427b1be1792.pdf", "paperhash": "anonymous|confidence_calibration_in_deep_neural_networks_through_stochastic_inferences", "_bibtex": "@inproceedings{    \nanonymous2019confidence,    \ntitle={Confidence Calibration in Deep Neural Networks through Stochastic Inferences},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJz1vo0cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJG1wjRqFQ", "original": "r1eClnNqKQ", "number": 228, "cdate": 1538087767194, "ddate": null, "tcdate": 1538087767194, "tmdate": 1538156215264, "tddate": null, "forum": "SJG1wjRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discrete Structural Planning for Generating Diverse Translations", "abstract": "Planning is important for humans when producing complex languages, which is a missing part in current language generation models. In this work, we add a planning phase in neural machine translation to control the global sentence structure ahead of translation. Our approach learns discrete structural representations to encode syntactic information of target sentences. During translation, we can either let beam search to choose the structural codes automatically or specify the codes manually. The word generation is then conditioned on the selected discrete codes. Experiments show that the translation performance remains intact by learning the codes to capture pure structural variations. Through structural planning, we are able to control the global sentence structure by manipulating the codes. By evaluating with a proposed structural diversity metric, we found that the sentences sampled using different codes have much higher diversity scores. In qualitative analysis, we demonstrate that the sampled paraphrase translations have drastically different structures. ", "keywords": ["machine translation", "syntax", "diversity", "code learning"], "authorids": ["ICLR.cc/2019/Conference/Paper228/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning discrete structural representation to control sentence generation and obtain diverse outputs", "pdf": "/pdf/a644831b836e754acab8f4f0216ef6b0830153cd.pdf", "paperhash": "anonymous|discrete_structural_planning_for_generating_diverse_translations", "_bibtex": "@inproceedings{    \nanonymous2019discrete,    \ntitle={Discrete Structural Planning for Generating Diverse Translations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJG1wjRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJNJws0cF7", "original": "SkxbIly5K7", "number": 229, "cdate": 1538087767369, "ddate": null, "tcdate": 1538087767369, "tmdate": 1538156215058, "tddate": null, "forum": "HJNJws0cF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Convolutional Neural Networks combined with Runge-Kutta Methods", "abstract": "A convolutional neural network for image classification can be constructed mathematically since it is inspired by the ventral stream in visual cortex which can be regarded as a multi-period dynamical system. In this paper, a novel approach is proposed to construct network models from the dynamical systems view. Since a pre-activation residual network can be deemed an approximation of a time-dependent dynamical system using the Euler method, higher order Runge-Kutta methods (RK methods) can be utilized to build network models in order to achieve higher accuracy. The model constructed in such a way is referred to as the Runge-Kutta Convolutional Neural Network (RKNet). RK methods also provide an interpretation of Dense Convolutional Networks (DenseNets) and Convolutional Neural Networks with Alternately Updated Clique (CliqueNets) from the dynamical systems view. The proposed methods are evaluated on the benchmark datasets: CIFAR-10/100 and ImageNet. The experimental results are consistent with the theoretical properties of RK methods and support the dynamical systems interpretation. Moreover, the experimental results show that the RKNets are superior to the state-of-the-art network models on CIFAR-10 and be comparable with them on CIFAR-100 and ImageNet.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper229/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/01d168fa6fae31c4ca6ff190e182b24597dff2b0.pdf", "paperhash": "anonymous|convolutional_neural_networks_combined_with_rungekutta_methods", "_bibtex": "@inproceedings{    \nanonymous2019convolutional,    \ntitle={Convolutional Neural Networks combined with Runge-Kutta Methods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJNJws0cF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkglvsC9Ym", "original": "rJguiAbcYQ", "number": 230, "cdate": 1538087767545, "ddate": null, "tcdate": 1538087767545, "tmdate": 1538156214843, "tddate": null, "forum": "rkglvsC9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Log Hyperbolic Cosine Loss Improves Variational Auto-Encoder", "abstract": "In Variational Auto-Encoder (VAE), the default choice of reconstruction loss function between the decoded sample and the input is the squared $L_2$. We propose to replace it with the log hyperbolic cosine (log-cosh) loss, which behaves as  $L_2$ at small values and as $L_1$ at large values, and differentiable everywhere. Compared with $L_2$, the log-cosh loss improves the reconstruction without damaging the latent space optimization, thus automatically keeping a balance between the reconstruction and the generation. Extensive experiments on MNIST and CelebA datasets show that the log-cosh reconstruction loss significantly improves the performance of VAE and its variants in output quality, measured by sharpness and FID score. In addition, the gradient of the log-cosh is a simple tanh function, which makes the implementation of gradient descent as simple as adding one sentence in coding. ", "keywords": ["Unsupervised Generative Model", "VAE", "log hyperbolic cosine loss"], "authorids": ["ICLR.cc/2019/Conference/Paper230/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose to train VAE with a new reconstruction loss, the log hyperbolic cosine (log-cosh) loss, which can significantly improve the performance of VAE and its variants in output quality, measured by sharpness and FID score.", "pdf": "/pdf/5f5eefcd4d5501aa7113a7f42d6b923ea9c60f38.pdf", "paperhash": "anonymous|log_hyperbolic_cosine_loss_improves_variational_autoencoder", "_bibtex": "@inproceedings{    \nanonymous2019log,    \ntitle={Log Hyperbolic Cosine Loss Improves Variational Auto-Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkglvsC9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xlvi0qYm", "original": "BJeZEytdKm", "number": 231, "cdate": 1538087767719, "ddate": null, "tcdate": 1538087767719, "tmdate": 1538156214636, "tddate": null, "forum": "r1xlvi0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Remember More with Less Memorization", "abstract": "Memory-augmented neural networks consisting of a neural controller and an external memory have shown potentials in long-term sequential learning. Current RAM-like memory models maintain memory accessing every timesteps, thus they do not effectively leverage the short-term memory held in the controller. We hypothesize that this scheme of writing is suboptimal in memory utilization and introduces redundant computation. To validate our hypothesis, we derive a theoretical bound on the amount of information stored in a RAM-like system and formulate an optimization problem that maximizes the bound. The proposed solution dubbed Uniform Writing is proved to be optimal under the assumption of equal timestep contributions. To relax this assumption, we introduce modifications to the original solution, resulting in a solution termed Cached Uniform Writing. This method aims to balance between maximizing memorization and forgetting via overwriting mechanisms. Through an extensive set of experiments, we empirically demonstrate the advantages of our solutions over other recurrent architectures, claiming the state-of-the-arts in various sequential modeling tasks. ", "keywords": ["memory-augmented neural networks", "writing optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper231/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e10c9f6a37c46abadf381cb807eb74f7ebbfbbc9.pdf", "paperhash": "anonymous|learning_to_remember_more_with_less_memorization", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Remember More with Less Memorization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xlvi0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkelDoCqFX", "original": "H1x3qw8ut7", "number": 232, "cdate": 1538087767901, "ddate": null, "tcdate": 1538087767901, "tmdate": 1538156214431, "tddate": null, "forum": "rkelDoCqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transfer Learning via Unsupervised Task Discovery for Visual Question Answering", "abstract": "We study how to leverage off-the-shelf visual and linguistic data to cope with out-of-vocabulary answers in visual question answering. Existing large-scale visual data with annotations such as image class labels, bounding boxes and region descriptions are good sources for learning rich and diverse visual concepts. However, it is not straightforward how the visual concepts should be captured and transferred to visual question answering models due to missing link between question dependent answering models and visual data without question or task specification. We tackle this problem in two steps: 1) learning a task conditional visual classifier based on unsupervised task discovery and 2) transferring and adapting the task conditional visual classifier to visual question answering models. Specifically, we employ linguistic knowledge sources such as structured lexical database (e.g. Wordnet) and visual descriptions for unsupervised task discovery, and adapt a learned task conditional visual classifier to answering unit in a visual question answering model. We empirically show that the proposed algorithm generalizes to unseen answers successfully using the knowledge transferred from the visual data.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper232/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4404c4f77da8522419c85bc9325729d063c50690.pdf", "paperhash": "anonymous|transfer_learning_via_unsupervised_task_discovery_for_visual_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer Learning via Unsupervised Task Discovery for Visual Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkelDoCqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1GgDj0cKX", "original": "rklfed6FFX", "number": 233, "cdate": 1538087768077, "ddate": null, "tcdate": 1538087768077, "tmdate": 1538156214222, "tddate": null, "forum": "r1GgDj0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS", "abstract": "This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks. Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters. Our PiT algorithms can directly prune the network without any fine-tuning. The pruned networks can still achieve comparable performance to the original networks. In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network. We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet. The results validate the efficacy of our proposed methods. Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.", "keywords": ["Split LBI", "sparse penalty", "network pruning", "feature selection"], "authorids": ["ICLR.cc/2019/Conference/Paper233/Authors"], "authors": ["Anonymous"], "TL;DR": "we propose an algorithm of learning to prune network by enforcing structure sparsity penalties", "pdf": "/pdf/d2729e43481122474e30b5cb4ce4bc7bf837556d.pdf", "paperhash": "anonymous|pruning_in_training_learning_and_ranking_sparse_connections_in_deep_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019pruning,    \ntitle={PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GgDj0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1fevoAcKX", "original": "BJePdFI9tQ", "number": 234, "cdate": 1538087768289, "ddate": null, "tcdate": 1538087768289, "tmdate": 1538156214014, "tddate": null, "forum": "H1fevoAcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cumulative Saliency based Globally Balanced Filter Pruning For Efficient Convolutional Neural Networks", "abstract": "This paper propose a Cumulative Saliency based Globally Balanced Filter Pruning (GBFP) scheme to prune redundant filters of Convolutional Neural Networks (CNNs). Specifically, the GBFP adopts a balanced pruning method, which not only measures the global redundancy of the filter in the whole model but also considers the importance of the current layer. Secondly, in the model pruning recovery process, we use the cumulative saliency strategy to improve the accuracy of pruning. GBFP has two advantages over previous works: (1) More accurate pruning guidance. For a pre-trained CNN model, the saliency of the filter varies with different input data. Therefore, accumulating the saliency of the filter over the entire data set can provide more accurate guidance for pruning. (2) More balanced pruning results. Before globally pruning the unsalient filters across all layers, the proposed first normalizes the saliency of each layer, which prevents unbalanced pruning results due to uneven distribution of parameters in each layer.", "keywords": ["Filter Pruning", "Model Compression", "Efficient Convolutional Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper234/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4c135cb9b8011d883a0f2095505b8227758eeb33.pdf", "paperhash": "anonymous|cumulative_saliency_based_globally_balanced_filter_pruning_for_efficient_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019cumulative,    \ntitle={Cumulative Saliency based Globally Balanced Filter Pruning For Efficient Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1fevoAcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyVxPsC9tm", "original": "rJgxHi7tFX", "number": 235, "cdate": 1538087768473, "ddate": null, "tcdate": 1538087768473, "tmdate": 1538156213808, "tddate": null, "forum": "HyVxPsC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DynCNN: An Effective Dynamic Architecture on Convolutional Neural Network for Surveillance Videos", "abstract": "The large-scale surveillance video analysis becomes important as the development of intelligent city. The heavy computation resources neccessary for state-of-the-art deep learning model makes the real-time processing hard to be implemented. This paper exploits the characteristic of high scene similarity generally existing in surveillance videos and proposes dynamic convolution reusing the previous feature map to reduce the computation amount. We tested the proposed method on 45 surveillance videos with various scenes. The experimental results show that dynamic convolution can reduce up to 75.7% of FLOPs while preserving the precision within 0.7% mAP. Furthermore, the dynamic convolution can enhance the processing time up to 2.2 times.", "keywords": ["CNN optimization", "Reduction on convolution calculation", "dynamic convolution", "surveillance video"], "authorids": ["ICLR.cc/2019/Conference/Paper235/Authors"], "authors": ["Anonymous"], "TL;DR": "An optimizing architecture on CNN for surveillance videos with 75.7% reduction on FLOPs and 2.2 times improvement on FPS", "pdf": "/pdf/61635e98b377ec6686d0dc9478ca1e9c7a0616c1.pdf", "paperhash": "anonymous|dyncnn_an_effective_dynamic_architecture_on_convolutional_neural_network_for_surveillance_videos", "_bibtex": "@inproceedings{    \nanonymous2019dyncnn:,    \ntitle={DynCNN: An Effective Dynamic Architecture on Convolutional Neural Network for Surveillance Videos},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyVxPsC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxbDsR9Ym", "original": "S1eEW-w9Km", "number": 236, "cdate": 1538087768649, "ddate": null, "tcdate": 1538087768649, "tmdate": 1538156213601, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph.\nExisting methods for learning KGEs can be seen as a two-stage process where\n(a) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings, and\n(b) the entity and relation embeddings that optimise the scoring function are learnt.\nUnfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph.\nTo address this issue, we propose a generative account of the KGE learning task.\nSpecifically, given a knowledge graph represented by a set of relational triples $(h, R, t)$, where the semantic relation $R$ holds between the two entities $h$ and $t$, we extend the random walk model \\citep{Arora:TACL:2016} of word embeddings to KGE. \nWe derive a theoretical relationship between the joint probability $p(h,R,t)$ and the embeddings of $h$, $R$ and $t$.\nMoreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE,\nfollows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. Our goal in this paper is \\emph{not} to propose a state-of-the-art KGE method, but to provide a\ntheoretical understanding of the otherwise heuristically derived score functions.\nHowever, the KGEs learnt according to the theoretically-derived scoring function reports strong results on several standard benchmark datasets, providing empirical evidence to support the theory.", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["ICLR.cc/2019/Conference/Paper236/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/cb9dab4b16109ca6ac463be5df7ba3bd946dc07b.pdf", "paperhash": "anonymous|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@inproceedings{    \nanonymous2019relwalk,    \ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxbDsR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgbwsAcYm", "original": "SyxHmL_tFX", "number": 237, "cdate": 1538087768829, "ddate": null, "tcdate": 1538087768829, "tmdate": 1538156213391, "tddate": null, "forum": "rkgbwsAcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DELTA: DEEP LEARNING TRANSFER USING FEATURE MAP WITH ATTENTION FOR CONVOLUTIONAL NETWORKS", "abstract": "Transfer learning through fine-tuning a pre-trained neural network with an extremely large dataset, such as ImageNet, can significantly accel- erate training while the accuracy is frequently bottlenecked by the lim- ited dataset size of the new target task. To solve the problem, some regularization methods, constraining the outer layer weights of the tar- get network using the starting point as references (SPAR), have been studied. In this paper, we propose a novel regularized transfer learn- ing framework DELTA, namely DEep Learning Transfer using Fea- ture Map with Attention. Instead of constraining the weights of neu- ral network, DELTA aims to preserve the outer layer outputs of the target network. Specifically, in addition to minimizing the empirical loss, DELTA intends to align the outer layer outputs of two networks, through constraining a subset of feature maps that are precisely selected by attention that has been learned in an supervised learning manner. We evaluate DELTA with the state-of-the-art algorithms, including L2 and L2-SP. The experiment results show that our proposed method outper- forms these baselines with higher accuracy for new tasks.", "keywords": ["transfer learning", "deep learning", "regularization", "attention", "cnn"], "authorids": ["ICLR.cc/2019/Conference/Paper237/Authors"], "authors": ["Anonymous"], "TL;DR": "improving deep transfer learning with regularization using attention based feature maps", "pdf": "/pdf/b0bd41595db17b03ff7cfc001eeb42bda78227b3.pdf", "paperhash": "anonymous|delta_deep_learning_transfer_using_feature_map_with_attention_for_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019delta:,    \ntitle={DELTA: DEEP LEARNING TRANSFER USING FEATURE MAP WITH ATTENTION FOR CONVOLUTIONAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgbwsAcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJe-DsC5Fm", "original": "B1g1I7v9FQ", "number": 238, "cdate": 1538087769012, "ddate": null, "tcdate": 1538087769012, "tmdate": 1538156213176, "tddate": null, "forum": "BJe-DsC5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "signSGD via Zeroth-Order Oracle", "abstract": "In this paper, we design and analyze a new zeroth-order (ZO) stochastic optimization algorithm, ZO-signSGD, which enjoys dual advantages of gradient-free operations and signSGD. The latter requires only the sign information of  gradient estimates but is able to achieve a comparable  or even better convergence speed than SGD-type algorithms. Our study  shows that ZO signSGD requires $\\sqrt{d}$ times more iterations than signSGD, leading to a convergence rate of  $O(\\sqrt{d}/\\sqrt{T})$ under mild conditions, where $d$ is the number of optimization variables, and $T$ is the number of iterations. In addition, we analyze the effects of different types of gradient estimators on the convergence of ZO-signSGD, and propose two variants of ZO-signSGD that  at least  achieve $O(\\sqrt{d}/\\sqrt{T})$ convergence rate. On the application side we explore the connection between ZO-signSGD and  black-box adversarial attacks in robust deep learning.  Our empirical evaluations on image classification datasets MNIST and CIFAR-10 demonstrate the superior performance of ZO-signSGD on the generation of   adversarial examples from black-box neural networks.", "keywords": ["nonconvex optimization", "zeroth-order algorithm", "black-box adversarial attack"], "authorids": ["ICLR.cc/2019/Conference/Paper238/Authors"], "authors": ["Anonymous"], "TL;DR": "We design and analyze a new zeroth-order stochastic optimization algorithm, ZO-signSGD, and demonstrate its connection and application to black-box adversarial attacks in robust deep learning", "pdf": "/pdf/82d2b8b6574d0a5eca9e70ae12f1cbc2745843fb.pdf", "paperhash": "anonymous|signsgd_via_zerothorder_oracle", "_bibtex": "@inproceedings{    \nanonymous2019signsgd,    \ntitle={signSGD via Zeroth-Order Oracle},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe-DsC5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MbDj0ctQ", "original": "ryezOoM9t7", "number": 239, "cdate": 1538087769188, "ddate": null, "tcdate": 1538087769188, "tmdate": 1538156212964, "tddate": null, "forum": "B1MbDj0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Switching Linear Dynamics for Variational Bayes Filtering", "abstract": "System identification of complex and nonlinear systems is a central problem for model predictive control and model-based reinforcement learning. Despite their complexity, such systems can often be approximated well by a set of linear dynamical systems if broken into appropriate subsequences. This mechanism not only helps us find good approximations of dynamics, but also gives us deeper insight into the underlying system. Leveraging Bayesian inference and Variational Autoencoders, we show how to learn a richer and more meaningful state space, e.g. encoding joint constraints and collisions with walls in a maze, from partial and high-dimensional observations. This representation translates into a gain of accuracy of the learned dynamics which we showcase on various simulated tasks.", "keywords": ["sequence model", "switching linear dynamical systems", "variational bayes", "filter", "variational inference", "stochastic recurrent neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper239/Authors"], "authors": ["Anonymous"], "TL;DR": "A recurrent variational autoencoder with a latent transition function modeled by switching linear dynamical systems.", "pdf": "/pdf/2500deabf7a902f5707c3956bfb8b9f40a6867ce.pdf", "paperhash": "anonymous|switching_linear_dynamics_for_variational_bayes_filtering", "_bibtex": "@inproceedings{    \nanonymous2019switching,    \ntitle={Switching Linear Dynamics for Variational Bayes Filtering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MbDj0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1z-PsR5KX", "original": "ryl84XP5YX", "number": 240, "cdate": 1538087769360, "ddate": null, "tcdate": 1538087769360, "tmdate": 1538156212745, "tddate": null, "forum": "H1z-PsR5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Identifying and Controlling Important Neurons in Neural Machine Translation", "abstract": "Neural machine translation (NMT) models learn representations containing substantial linguistic information. However, it is not clear if such information is fully distributed or if some of it can be attributed to individual neurons. We develop unsupervised methods for discovering important neurons in NMT models. Our methods rely on the intuition that different models learn similar properties, and do not require any costly external supervision. We show experimentally that translation quality depends on the discovered neurons, and find that many of them capture common linguistic phenomena. Finally, we show how to control NMT translations in predictable ways, by modifying activations of individual neurons.", "keywords": ["neural machine translation", "individual neurons", "unsupervised", "analysis", "correlation", "translation control", "distributivity", "localization"], "authorids": ["ICLR.cc/2019/Conference/Paper240/Authors"], "authors": ["Anonymous"], "TL;DR": "Unsupervised methods for finding, analyzing, and controlling important neurons in NMT", "pdf": "/pdf/d9d6ebb2aef07d376214ce8a9290d2fd43a515d0.pdf", "paperhash": "anonymous|identifying_and_controlling_important_neurons_in_neural_machine_translation", "_bibtex": "@inproceedings{    \nanonymous2019identifying,    \ntitle={Identifying and Controlling Important Neurons in Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1z-PsR5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyezvsC5tX", "original": "SygACXw9tQ", "number": 241, "cdate": 1538087769535, "ddate": null, "tcdate": 1538087769535, "tmdate": 1538156212530, "tddate": null, "forum": "SyezvsC5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The loss landscape of overparameterized neural networks", "abstract": "We explore some mathematical features of the loss landscape of overparameterized neural networks.  A priori one might imagine that the loss function looks like a typical function from $\\mathbb{R}^n$ to $\\mathbb{R}$ - in particular, nonconvex, with discrete global minima.  In this paper, we prove that in at least one important way, the loss function of an overparameterized neural network does not look like a typical function.  If a neural net has $n$ parameters and is trained on $d$ data points, with $n>d$, we show that the locus $M$ of global minima of $L$ is usually not discrete, but rather an $n-d$ dimensional submanifold of $\\mathbb{R}^n$.  In practice, neural nets commonly have orders of magnitude more parameters than data points, so this observation implies that $M$ is typically a very high-dimensional subset of $\\mathbb{R}^n$. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper241/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4c6b42b9a39a8986ce7723ce2673cd42afd55fe9.pdf", "paperhash": "anonymous|the_loss_landscape_of_overparameterized_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The loss landscape of overparameterized neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyezvsC5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxzDiAcK7", "original": "ryxcxEDcF7", "number": 242, "cdate": 1538087769709, "ddate": null, "tcdate": 1538087769709, "tmdate": 1538156212309, "tddate": null, "forum": "HkxzDiAcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Classification of Building Noise Type/Position via Supervised Learning", "abstract": "This paper presents noise type/position classification of various impact noises generated in a building which is a serious conflict issue in apartment complexes. For this study, a collection of floor impact noise dataset is recorded with a single microphone. Noise types/positions are selected based on a report by the Floor Management Center under Korea Environmental Corporation. Using a convolutional neural networks based classifier, the impact noise signals converted to log-scaled Mel-spectrograms are classified into noise types or positions. Also, our model is evaluated on a standard environmental sound dataset ESC-50 to show extensibility on environmental sound classification.\n", "keywords": ["impact noise", "noise type classification", "noise position classification", "convolutional neural networks", "transfer learning"], "authorids": ["ICLR.cc/2019/Conference/Paper242/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents noise type/position classification of various impact noises generated in a building which is a serious conflict issue in apartment complexes", "pdf": "/pdf/1116ed60e7f575df2bd31ccd7f548e024328ba78.pdf", "paperhash": "anonymous|classification_of_building_noise_typeposition_via_supervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019classification,    \ntitle={Classification of Building Noise Type/Position via Supervised Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxzDiAcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxzPsAqFQ", "original": "S1xj47feKX", "number": 243, "cdate": 1538087769891, "ddate": null, "tcdate": 1538087769891, "tmdate": 1538156212041, "tddate": null, "forum": "SJxzPsAqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-turn Dialogue Response Generation in an Adversarial Learning Framework", "abstract": "We propose an adversarial learning approach to the generation of multi-turn dialogue responses. Our proposed framework, hredGAN, is based on conditional generative adversarial networks (GANs). The GAN's generator is a modified hierarchical recurrent encoder-decoder network (HRED) and the discriminator is a word-level bidirectional RNN that shares context and word embedding with the generator. During inference, noise samples conditioned on the dialogue history are used to perturb the generator's latent space to generate several possible responses. The final response is the one ranked best by the discriminator. The hredGAN shows major advantages over existing methods: (1) it generalizes better than networks trained using only the log-likelihood criterion, and (2) it generates longer, more informative and more diverse responses with high utterance and topic relevance even with limited training data. This superiority is demonstrated on the Movie triples and Ubuntu dialogue datasets in terms of perplexity, BLEU, ROUGE and Distinct n-gram scores.", "keywords": ["dialogue models", "adversarial networks", "dialogue generation"], "authorids": ["ICLR.cc/2019/Conference/Paper243/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/efe6d031c5b50b26005dbf83c45a124420a2e08e.pdf", "paperhash": "anonymous|multiturn_dialogue_response_generation_in_an_adversarial_learning_framework", "_bibtex": "@inproceedings{    \nanonymous2019multi-turn,    \ntitle={Multi-turn Dialogue Response Generation in an Adversarial Learning Framework},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxzPsAqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1zMDjAqKQ", "original": "B1g2MEvqFQ", "number": 244, "cdate": 1538087770081, "ddate": null, "tcdate": 1538087770081, "tmdate": 1538156211829, "tddate": null, "forum": "B1zMDjAqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Expectation Learning for Multisensory Binding", "abstract": "Expectation learning is a continuous learning process which uses known multisensory bindings to modulate unisensory perception. When perceiving an event, we have an expectation on what we should see or hear which affects our unisensory perception. Expectation learning is known to enhance the unisensory perception of previously known multisensory events. In this work, we present a novel hybrid deep recurrent model based on audio/visual autoencoders, for unimodal stimulus representation and reconstruction, and a recurrent self-organizing network for multisensory binding of the representations. The model adapts concepts of expectation learning to enhance the unisensory representation based on the learned bindings.\nWe demonstrate that the proposed model is capable of reconstructing signals from one modality by processing input of another modality for 43,500 Youtube videos in the animal subset of the AudioSet corpus. Our experiments also show that when using expectation learning, the proposed model presents state-of-the-art performance in representing and classifying unisensory stimuli.", "keywords": ["multisensory binding", "expectation learning", "unsupervised learning", "Deep autoencoder", "Growing-When-Required Network", "animal recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper244/Authors"], "authors": ["Anonymous"], "TL;DR": "A hybrid deep neural network which adapts concepts of expectation learning for improving unisensory recognition using multisensory binding. ", "pdf": "/pdf/b8fcf68920c706f3445f85e9e77f988fadcf5705.pdf", "paperhash": "anonymous|unsupervised_expectation_learning_for_multisensory_binding", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Expectation Learning for Multisensory Binding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1zMDjAqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GMDsR5tm", "original": "rygFOND9tQ", "number": 245, "cdate": 1538087770254, "ddate": null, "tcdate": 1538087770254, "tmdate": 1538156211618, "tddate": null, "forum": "B1GMDsR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Initialized Equilibrium Propagation for Backprop-Free Training", "abstract": "Deep neural networks are almost universally trained with reverse-mode automatic differentiation (a.k.a. backpropagation). Biological networks, on the other hand, appear to lack any mechanism for sending gradients back to their input neurons, and thus cannot be learning in this way. In response to this, Scellier & Bengio (2017) proposed Equilibrium Propagation - a method for gradient-based train- ing of neural networks which uses only local learning rules and, crucially, does not rely on neurons having a mechanism for back-propagating an error gradient. Equilibrium propagation, however, has a major practical limitation: inference involves doing an iterative optimization of neural activations to find a fixed-point, and the number of steps required to closely approximate this fixed point scales poorly with the depth of the network. In response to this problem, we propose Initialized Equilibrium Propagation, which trains a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. This feed-forward network learns to approximate the state of the fixed-point using a local learning rule. After training, we can simply use this initializing network for inference, resulting in a learned feedforward network. Our experiments show that this network appears to work as well or better than the original version of Equilibrium propagation. This shows how we might go about training deep networks without using backpropagation.", "keywords": ["credit assignment", "energy-based models", "biologically plausible learning"], "authorids": ["ICLR.cc/2019/Conference/Paper245/Authors"], "authors": ["Anonymous"], "TL;DR": "We train a feedforward network without backprop by using an energy-based model to provide local targets", "pdf": "/pdf/03167fbf8b66fd7df9b34bfb28e32c26a9907959.pdf", "paperhash": "anonymous|initialized_equilibrium_propagation_for_backpropfree_training", "_bibtex": "@inproceedings{    \nanonymous2019initialized,    \ntitle={Initialized Equilibrium Propagation for Backprop-Free Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GMDsR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJEGwo0cFX", "original": "rylrGRUctm", "number": 246, "cdate": 1538087770423, "ddate": null, "tcdate": 1538087770423, "tmdate": 1538156211410, "tddate": null, "forum": "rJEGwo0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Attention-Based Model for Learning Dynamic Interaction Networks", "abstract": "While machine learning models achieve human-comparable performance on sequential data, exploiting structured knowledge is still a challenging problem. Spatio-temporal graphs have been proved to be a useful tool to abstract interaction graphs and previous works exploits carefully designed feed-forward architecture to preserve such structure. We argue to scale such network design to real-world problem, a model needs to automatically learn a meaningful representation of the possible relations. Learning such interaction structure is not trivial: on the one hand, a model has to discover the hidden relations between different problem factors in an unsupervised way; on the other hand, the mined relations have to be interpretable. \n\nIn this paper, we propose an attention module able to project a graph sub-structure in a fixed size embedding, preserving the influence that the neighbours exert on a given vertex. On a comprehensive evaluation done on real-world as well as toy task, we found our model competitive against strong baselines.", "keywords": ["dynamic networks", "interaction graphs", "attention model"], "authorids": ["ICLR.cc/2019/Conference/Paper246/Authors"], "authors": ["Anonymous"], "TL;DR": "A graph neural network able to automatically learn and leverage a dynamic interactive graph structure", "pdf": "/pdf/8ea5a546c6f09eaae2aa017c0140f80798606ae7.pdf", "paperhash": "anonymous|an_attentionbased_model_for_learning_dynamic_interaction_networks", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Attention-Based Model for Learning Dynamic Interaction Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJEGwo0cFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklXvs0qt7", "original": "S1xPrgoStX", "number": 247, "cdate": 1538087770605, "ddate": null, "tcdate": 1538087770605, "tmdate": 1538156211201, "tddate": null, "forum": "SklXvs0qt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Curiosity-Driven Experience Prioritization via Density Estimation", "abstract": "In Reinforcement Learning (RL), an agent explores the environment and collects trajectories into the memory buffer for later learning. However, the collected trajectories can easily be imbalanced with respect to the achieved goal states. The problem of learning from imbalanced data is a well-known problem in supervised learning, but has not yet been thoroughly researched in RL. To address this problem, we propose a novel Curiosity-Driven Prioritization (CDP) framework to encourage the agent to over-sample those trajectories that have rare achieved goal states. The CDP framework mimics the human learning process and focuses more on relatively uncommon events. We evaluate our methods using the robotic environment provided by OpenAI Gym. The environment contains six robot manipulation tasks. In our experiments, we combined CDP with Deep Deterministic Policy Gradient (DDPG) with or without Hindsight Experience Replay (HER). The experimental results show that CDP improves both performance and sample-efficiency of reinforcement learning agents, compared to state-of-the-art methods.", "keywords": ["Curiosity-Driven", "Experience Prioritization", "Hindsight Experience", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper247/Authors"], "authors": ["Anonymous"], "TL;DR": "Our paper proposes a curiosity-driven prioritization framework for RL agents, which improves both performance and sample-efficiency.", "pdf": "/pdf/cb65b4946fec0924b0f2f757db5e936e6175c862.pdf", "paperhash": "anonymous|curiositydriven_experience_prioritization_via_density_estimation", "_bibtex": "@inproceedings{    \nanonymous2019curiosity-driven,    \ntitle={Curiosity-Driven Experience Prioritization via Density Estimation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklXvs0qt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygQvs0cFQ", "original": "rJlXheVqFQ", "number": 248, "cdate": 1538087770775, "ddate": null, "tcdate": 1538087770775, "tmdate": 1538156210995, "tddate": null, "forum": "SygQvs0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Smoothing in Recurrent Neural Network Language Models", "abstract": "We present a new theoretical perspective of data noising in recurrent neural network language models (Xie et al., 2017). We show that each variant of data noising is an instance of Bayesian recurrent neural networks with a particular variational distribution (i.e.,  a mixture of Gaussians whose weights depend on statistics derived from the corpus such as the unigram distribution). We use this insight to propose a more principled  method to apply at prediction time and propose natural extensions to data noising under the variational framework. In particular, we propose variational smoothing  with tied input and output embedding matrices and an element-wise variational smoothing method. We empirically verify our analysis on two benchmark language modeling datasets and demonstrate performance improvements over existing data noising methods.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper248/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/53c0c34fe29b9d1c18d3b7c699302199079bf4c1.pdf", "paperhash": "anonymous|variational_smoothing_in_recurrent_neural_network_language_models", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Smoothing in Recurrent Neural Network Language Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygQvs0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxXwo0qYm", "original": "B1e7uMw5Ym", "number": 249, "cdate": 1538087770958, "ddate": null, "tcdate": 1538087770958, "tmdate": 1538156210789, "tddate": null, "forum": "SkxXwo0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Automatic Operation Batching Strategy for the Backward Propagation of Neural Networks Having Dynamic Computation Graphs", "abstract": "Organizing the same operations in the computation graph of a neural network into batches is one of the important methods to improve the speed of training deep learning models and applications since it helps to execute operations with the same type in parallel and to make full use of the available hardware resources. This batching task is usually done by the developers manually and it becomes more dif- ficult when the neural networks have dynamic computation graphs because of the input data with varying structures or the dynamic flow control. Several automatic batching strategies were proposed and integrated into some deep learning toolkits so that the programmers don\u2019t have to be responsible for this task. These strategies, however, will miss some important opportunities to group the operations in the backward propagation of training neural networks. In this paper, we proposed a strategy which provides more efficient automatic batching and brings benefits to the memory access in the backward propagation. We also test our strategy on a variety of benchmarks with dynamic computation graphs. The result shows that it really brings further improvements in the training speed by cooperating with the existing automatic strategies.", "keywords": ["Automatic Operation Batching", "Dynamic Computation Graphs"], "authorids": ["ICLR.cc/2019/Conference/Paper249/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/015ee93c12f99fb9656922ee74b5dfeb9cd278aa.pdf", "paperhash": "anonymous|an_automatic_operation_batching_strategy_for_the_backward_propagation_of_neural_networks_having_dynamic_computation_graphs", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Automatic Operation Batching Strategy for the Backward Propagation of Neural Networks Having Dynamic Computation Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxXwo0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkGmDsR9YQ", "original": "r1lx4VMqtX", "number": 250, "cdate": 1538087771137, "ddate": null, "tcdate": 1538087771137, "tmdate": 1538156210583, "tddate": null, "forum": "HkGmDsR9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generalization and Regularization in DQN", "abstract": "Deep reinforcement learning (RL) algorithms have shown an impressive ability to learn complex control policies in high-dimensional environments. However, despite the ever-increasing performance on popular benchmarks like the Arcade Learning Environment (ALE), policies learned by deep RL algorithms can struggle to generalize when evaluated in remarkably similar environments. These results are unexpected given the fact that, in supervised learning, deep neural networks often learn robust features that generalize across tasks. In this paper, we study the generalization capabilities of DQN in order to aid in understanding this mismatch between generalization in deep RL and supervised learning methods. We provide evidence suggesting that DQN overspecializes to the domain it is trained on. We then comprehensively evaluate the impact of traditional methods of regularization from supervised learning, $\\ell_2$ and dropout, and of reusing learned representations to improve the generalization capabilities of DQN. We perform this study using different game modes of Atari 2600 games, a recently introduced modification for the ALE which supports slight variations of the Atari 2600 games used for benchmarking in the field. Despite regularization being largely underutilized in deep RL, we show that it can, in fact, help DQN learn more general features. These features can then be reused and fine-tuned on similar tasks, considerably improving the sample efficiency of DQN.", "keywords": ["generalization", "reinforcement learning", "dqn", "regularization", "transfer learning", "multitask"], "authorids": ["ICLR.cc/2019/Conference/Paper250/Authors"], "authors": ["Anonymous"], "TL;DR": "We study the generalization capabilities of DQN using the new modes and difficulties of Atari games. We show how regularization can improve DQN's ability to generalize across tasks, something it often fails to do.", "pdf": "/pdf/9c03b9e2e557da1e049ad5b1e79bee6a7338bf30.pdf", "paperhash": "anonymous|generalization_and_regularization_in_dqn", "_bibtex": "@inproceedings{    \nanonymous2019generalization,    \ntitle={Generalization and Regularization in DQN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGmDsR9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJl7DsR5YQ", "original": "SJlg7dvcFm", "number": 251, "cdate": 1538087771318, "ddate": null, "tcdate": 1538087771318, "tmdate": 1538156210374, "tddate": null, "forum": "SJl7DsR5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ReNeg and Backseat Driver: Learning from demonstration with continuous human feedback", "abstract": "Reinforcement learning (RL) is a powerful framework for solving problems by exploring and learning from mistakes. However, in the context of autonomous vehicle (AV) control, requiring an agent to make mistakes, or even allowing mistakes, can be quite dangerous and costly in the real world. For this reason, AV RL is generally only viable in simulation. Because these simulations have imperfect representations, particularly with respect to graphics, physics, and human interaction, we find motivation for a framework similar to RL, suitable to the real world. To this end, we formulate a learning framework that learns from restricted exploration by having a human demonstrator do the exploration. Existing work on learning from demonstration typically either assumes the collected data is performed by an optimal expert, or requires potentially dangerous exploration to find the optimal policy. We propose an alternative framework that learns continuous control from only safe behavior. One of our key insights is that the problem becomes tractable if the feedback score that rates the demonstration applies to the atomic action, as opposed to the entire sequence of actions. We use human experts to collect driving data as well as to label the driving data through a framework we call ``Backseat Driver'', giving us state-action pairs matched with scalar values representing the score for the action. We call the more general learning framework ReNeg, since it learns a regression from states to actions given negative as well as positive examples. We empirically validate several models in the ReNeg framework, testing on lane-following with limited data. We find that the best solution in this context outperforms behavioral cloning has strong connections to stochastic policy gradient approaches.", "TL;DR": "We introduce a novel framework for learning from demonstration that uses continuous human feedback; we evaluate this framework on continuous control for autonomous vehicles.", "authorids": ["ICLR.cc/2019/Conference/Paper251/Authors"], "authors": ["Anonymous"], "keywords": ["learning from demonstration", "imitation learning", "behavioral cloning", "reinforcement learning", "off-policy", "continuous control", "autonomous vehicles", "deep learning", "machine learning", "policy gradient"], "pdf": "/pdf/71f382c6c6edd89ab52ebf36cafba2a3e46270fe.pdf", "paperhash": "anonymous|reneg_and_backseat_driver_learning_from_demonstration_with_continuous_human_feedback", "_bibtex": "@inproceedings{    \nanonymous2019reneg,    \ntitle={ReNeg and Backseat Driver: Learning from demonstration with continuous human feedback},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl7DsR5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxXDsCqYX", "original": "HklUIDw9tm", "number": 252, "cdate": 1538087771494, "ddate": null, "tcdate": 1538087771494, "tmdate": 1538156210162, "tddate": null, "forum": "rJxXDsCqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sentence Encoding with Tree-Constrained Relation Networks", "abstract": "The meaning of a sentence is a function of the relations that hold between its words. We instantiate this relational view of semantics in a series of neural models based on variants of relation networks (RNs) which represent a set of objects (for us, words forming a sentence) in terms of representations of pairs of objects. We propose two extensions to the basic RN model for natural language. First, building on the intuition that not all word pairs are equally informative about the meaning of a sentence, we use constraints based on both supervised and unsupervised dependency syntax to control which relations influence the representation. Second, since higher-order relations are poorly captured by a sum of pairwise relations, we use a recurrent extension of RNs to propagate information so as to form representations of higher order relations. Experiments on sentence classification, sentence pair classification, and machine translation reveal that, while basic RNs are only modestly effective for sentence representation, recurrent RNs with latent syntax are a reliably powerful representational device.", "keywords": ["sentence encoder", "relation networks", "tree", "machine translation"], "authorids": ["ICLR.cc/2019/Conference/Paper252/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e258a613712fab714b9596e5f61c7e96dec069fb.pdf", "paperhash": "anonymous|sentence_encoding_with_treeconstrained_relation_networks", "_bibtex": "@inproceedings{    \nanonymous2019sentence,    \ntitle={Sentence Encoding with Tree-Constrained Relation Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxXDsCqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgNwi09Km", "original": "HyenSUDcKX", "number": 253, "cdate": 1538087771670, "ddate": null, "tcdate": 1538087771670, "tmdate": 1538156209955, "tddate": null, "forum": "SJgNwi09Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Latent Superstructures in Variational Autoencoders for Deep Multidimensional Clustering", "abstract": "We investigate a variant of variational autoencoders where there is a superstructure of discrete latent variables on top of the latent features. In general, our superstructure is a tree structure of multiple super latent variables and it is automatically learned from data. When there is only one latent variable in the superstructure, our model reduces to one that assumes the latent features to be generated from a Gaussian mixture model. We call our model the latent tree variational autoencoder (LTVAE). Whereas previous deep learning methods for clustering produce only one partition of data, LTVAE produces multiple partitions of data, each being given by one super latent variable. This is desirable because high dimensional data usually have many different natural facets and can be meaningfully partitioned in multiple ways.", "keywords": ["latent tree model", "variational autoencoder", "deep learning", "latent variable model", "bayesian network", "structure learning", "stepwise em", "message passing", "graphical model", "multidimensional clustering", "unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper253/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate a variant of variational autoencoders where there is a superstructure of discrete latent variables on top of the latent features.", "pdf": "/pdf/e3a5a22394dcaab01a366ee34eaa151f7f449826.pdf", "paperhash": "anonymous|learning_latent_superstructures_in_variational_autoencoders_for_deep_multidimensional_clustering", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Latent Superstructures in Variational Autoencoders for Deep Multidimensional Clustering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgNwi09Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xEwsR9FX", "original": "rkg7c_D9t7", "number": 254, "cdate": 1538087771848, "ddate": null, "tcdate": 1538087771848, "tmdate": 1538156209738, "tddate": null, "forum": "H1xEwsR9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Convolutional CRFs for Semantic Segmentation", "abstract": "For the challenging semantic image segmentation task the best performing models\nhave traditionally combined the structured modelling capabilities of Conditional\nRandom Fields (CRFs) with the feature extraction power of CNNs. In more recent\nworks however, CRF post-processing has fallen out of favour. We argue that this\nis mainly due to the slow training and inference speeds of CRFs, as well as the\ndifficulty of learning the internal CRF parameters. To overcome both issues we\npropose to add the assumption of conditional independence to the framework of\nfully-connected CRFs. This allows us to reformulate the inference in terms of\nconvolutions, which can be implemented highly efficiently on GPUs.Doing so\nspeeds up inference and training by two orders of magnitude. All parameters of\nthe convolutional CRFs can easily be optimized using backpropagation. Towards\nthe goal of facilitating further CRF research we have made our implementations\npublicly available.", "keywords": ["conditional random fields", "semantic segmentation", "computer vision", "structured learning"], "authorids": ["ICLR.cc/2019/Conference/Paper254/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Convolutional CRFs a fast, powerful and trainable alternative to Fully Connected CRFs.", "pdf": "/pdf/67ca75d6f9cf3582ebb05d59ef65b8dcb42854e2.pdf", "paperhash": "anonymous|convolutional_crfs_for_semantic_segmentation", "_bibtex": "@inproceedings{    \nanonymous2019convolutional,    \ntitle={Convolutional CRFs for Semantic Segmentation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xEwsR9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeNPi0qKX", "original": "HygZ_dVKtX", "number": 255, "cdate": 1538087772026, "ddate": null, "tcdate": 1538087772026, "tmdate": 1538156209531, "tddate": null, "forum": "ryeNPi0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Language Modeling Teaches You More Syntax than Translation Does: Lessons Learned Through Auxiliary Task Analysis", "abstract": "Recent work using auxiliary prediction task classifiers to investigate the properties of LSTM representations has begun to shed light on why pretrained representations, like ELMo (Peters et al., 2018) and CoVe (McCann et al., 2017), are so beneficial for neural language understanding models. We still, though, do not yet have a clear understanding of how the choice of pretraining objective affects the type of linguistic information that models learn. With this in mind, we compare four objectives - language modeling, translation, skip-thought, and autoencoding - on their ability to induce syntactic and part-of-speech information.  We make a fair comparison between the tasks by holding constant the quantity and genre of the training data, as well as the LSTM architecture. We find that representations from language models consistently perform best on our syntactic auxiliary prediction tasks, even when trained on relatively small amounts of data. These results suggest that language modeling may be the best data-rich pretraining task for transfer learning applications requiring syntactic information. We also find that the representations from randomly-initialized, frozen LSTMs perform strikingly well on our syntactic auxiliary tasks, but this effect disappears when the amount of training data for the auxiliary tasks is reduced.", "keywords": ["representation learning", "recurrent neural networks", "syntax", "part-of-speech tagging"], "authorids": ["ICLR.cc/2019/Conference/Paper255/Authors"], "authors": ["Anonymous"], "TL;DR": "We throughly compare several pretraining tasks on their ability to induce syntactic information and find that representations from language models consistently perform best, even when trained on relatively small amounts of data.", "pdf": "/pdf/b03626c8d77258d15ff2c9b08641a90352529c8f.pdf", "paperhash": "anonymous|language_modeling_teaches_you_more_syntax_than_translation_does_lessons_learned_through_auxiliary_task_analysis", "_bibtex": "@inproceedings{    \nanonymous2019language,    \ntitle={Language Modeling Teaches You More Syntax than Translation Does: Lessons Learned Through Auxiliary Task Analysis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeNPi0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1e4wo09K7", "original": "Skl-6uwctX", "number": 256, "cdate": 1538087772207, "ddate": null, "tcdate": 1538087772207, "tmdate": 1538156209316, "tddate": null, "forum": "B1e4wo09K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Invariant-covariant representation learning", "abstract": "Representations learnt through deep neural networks tend to be highly informative, but opaque in terms of what information they learn to encode. We introduce an approach to probabilistic modelling that learns to represent data with two separate deep representations: an invariant representation that encodes the information of the class from which the data belongs, and a covariant representation that encodes the symmetry transformation defining the particular data point within the class manifold (covariant in the sense that the representation varies naturally with symmetry transformations). This approach to representation learning is conceptually transparent, easy to implement, and in-principle generally applicable to any data comprised of discrete classes of continuous distributions (e.g. objects in images, topics in language, individuals in behavioural data). We demonstrate qualitatively compelling representation learning and competitive quantitative performance, in both supervised and semi-supervised settings, versus comparable modelling approaches in the literature with little fine tuning.", "keywords": ["representation learning", "semantic representations", "local vs global information", "latent variable modelling", "generative modelling", "semi-supervised learning", "variational autoencoders."], "authorids": ["ICLR.cc/2019/Conference/Paper256/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a novel latent-variable generative modelling technique that enables the representation of global information into one latent variable and local information into another latent variable.", "pdf": "/pdf/9530014222d3aac579f22b8f842c3e32afc563ed.pdf", "paperhash": "anonymous|invariantcovariant_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019invariant-covariant,    \ntitle={Invariant-covariant representation learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e4wo09K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklNwjCcYm", "original": "BJeeD5WFt7", "number": 257, "cdate": 1538087772385, "ddate": null, "tcdate": 1538087772385, "tmdate": 1538156209106, "tddate": null, "forum": "rklNwjCcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding and Improving Sequence-Labeling NER with Self-Attentive LSTMs", "abstract": "This paper improves upon the line of research that formulates named entity recognition (NER) as a sequence-labeling problem. We use so-called black-box long short-term memory (LSTM) encoders to achieve state-of-the-art results while providing insightful understanding of what the auto-regressive model learns with a parallel self-attention mechanism. Specifically, we decouple the sequence-labeling problem of NER into entity chunking, e.g., Barack_B Obama_E was_O elected_O, and entity typing, e.g., Barack_PERSON Obama_PERSON was_NONE elected_NONE, and analyze how the model learns to, or has difficulties in, capturing text patterns for each of the subtasks. The insights we gain then lead us to explore a more sophisticated deep cross-Bi-LSTM encoder, which proves better at capturing global interactions given both empirical results and a theoretical justification.", "keywords": ["interpretability", "sequence labeling", "named entity recognition", "LSTM", "attention"], "authorids": ["ICLR.cc/2019/Conference/Paper257/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide insightful understanding of sequence-labeling NER and propose to use two types of cross structures, both of which bring theoretical and empirical improvements.", "pdf": "/pdf/3c02dfa85c4088bf099ad163894f0f757eace74d.pdf", "paperhash": "anonymous|understanding_and_improving_sequencelabeling_ner_with_selfattentive_lstms", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding and Improving Sequence-Labeling NER with Self-Attentive LSTMs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklNwjCcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgHwi0ctm", "original": "r1ecjkI5t7", "number": 258, "cdate": 1538087772566, "ddate": null, "tcdate": 1538087772566, "tmdate": 1538156208897, "tddate": null, "forum": "HJgHwi0ctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Collaborative Low-Rank Reconstructive Layer for Domain Shift Problems", "abstract": "In many situations, the data one has access to at test time follows a different distribution from the training data. Over the years, this problem has been tackled by domain adaptation and domain generalization techniques. In this context, the most popular approach consists of learning features whose distributions are the same in all observed domains. However, with high-dimensional features, such as those of deep networks, we argue that matching distributions is an under-constrained problem; a network can learn to add noise in the representation to artificially achieve this goal. To address this, we propose to learn a collaborative low-rank representation of the data encoding information from all observed domains and well-suited for classification. We formulate this as a general layer that can either be used on its own within any standard base network, or incorporated into existing domain adaptation and generalization frameworks. We empirically show that it consistently boosts the performance of the baseline models that do not exploit our new layer, thus allowing us to achieve state-of-the-art results on several visual domain adaptation and generalization benchmark datasets.", "keywords": ["Domain Generalization", "Domain Adaptation", "Deep Learning", "Computer Vision"], "authorids": ["ICLR.cc/2019/Conference/Paper258/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2025e351794106ba81baa7f10ef2c18798bc5dc6.pdf", "paperhash": "anonymous|a_collaborative_lowrank_reconstructive_layer_for_domain_shift_problems", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Collaborative Low-Rank Reconstructive Layer for Domain Shift Problems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgHwi0ctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJerDj05tQ", "original": "HJxCSAfctQ", "number": 259, "cdate": 1538087772745, "ddate": null, "tcdate": 1538087772745, "tmdate": 1538156208689, "tddate": null, "forum": "HJerDj05tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimization on Multiple Manifolds", "abstract": "Optimization on manifold has been widely used in machine learning, to handle optimization problems with constraint. Most previous works focus on the case with a single manifold. However, in practice it is quite common that the optimization problem involves more than one constraints, (each constraint corresponding to one manifold). It is not clear in general how to optimize on multiple manifolds effectively and provably especially when the intersection of multiple manifolds is not a manifold or cannot be easily calculated. We propose a unified algorithm framework to handle the optimization on multiple manifolds. Specifically,  we integrate information from multiple manifolds and move along an ensemble direction by viewing the information from each manifold as a drift and adding them together. We prove the convergence properties of the proposed algorithms. We also apply the algorithms into  training neural network with batch normalization layers and achieve preferable empirical results.", "keywords": ["Optimization", "Multiple constraints", "Manifold"], "authorids": ["ICLR.cc/2019/Conference/Paper259/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces an algorithm to handle optimization problem with multiple constraints under vision of manifold.", "pdf": "/pdf/60f5791c370892574630a44e93bfd015619d4010.pdf", "paperhash": "anonymous|optimization_on_multiple_manifolds", "_bibtex": "@inproceedings{    \nanonymous2019optimization,    \ntitle={Optimization on Multiple Manifolds},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJerDj05tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkfrvsA9FX", "original": "Sye1cxk_Fm", "number": 260, "cdate": 1538087772918, "ddate": null, "tcdate": 1538087772918, "tmdate": 1538156208479, "tddate": null, "forum": "SkfrvsA9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reward Constrained Policy Optimization", "abstract": "Solving tasks in Reinforcement Learning is no easy feat. As the goal of the agent is to maximize the accumulated reward, it often learns to exploit loopholes and misspecifications in the reward signal resulting in unwanted behavior. While constraints may solve this issue, there is no closed form solution for general constraints. In this work we present a novel multi-timescale approach for constrained policy optimization, called `Reward Constrained Policy Optimization' (RCPO), which uses an alternative penalty signal to guide the policy towards a constraint satisfying one. We prove the convergence of our approach and provide empirical evidence of its ability to train constraint satisfying policies.", "keywords": ["reinforcement learning", "markov decision process", "constrained markov decision process", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper260/Authors"], "authors": ["Anonymous"], "TL;DR": "For complex constraints in which it is not easy to estimate the gradient, we use the discounted penalty as a guiding signal. We prove that under certain assumptions it converges to a feasible solution.", "pdf": "/pdf/df25e46c29fec6cf315d8e3d4b02233775e199db.pdf", "paperhash": "anonymous|reward_constrained_policy_optimization", "_bibtex": "@inproceedings{    \nanonymous2019reward,    \ntitle={Reward Constrained Policy Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkfrvsA9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByMHvs0cFQ", "original": "rJl2swNFKm", "number": 261, "cdate": 1538087773098, "ddate": null, "tcdate": 1538087773098, "tmdate": 1538156208266, "tddate": null, "forum": "ByMHvs0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Quaternion Recurrent Neural Networks", "abstract": "Recurrent neural networks (RNNs) are powerful architectures to model sequential data, due to their capability to learn short and long-term dependencies between the basic elements of a sequence.  Nonetheless, popular tasks such as speech or images recognition, involve multi-dimensional input features that are characterized by strong internal dependencies between the dimensions of the input vector. We propose a novel quaternion recurrent neural network (QRNN), alongside with a quaternion long-short term memory neural network (QLSTM), that take into account both the external relations and these  internal  structural  dependencies with the quaternion algebra. Similarly to capsules, quaternions allow the QRNN to code internal dependencies by composing and processing multidimensional features as single entities, while the recurrent operation reveals correlations between the elements composing the sequence.  We show that both QRNN and QLSTM achieve better performances than RNN and LSTM in a realistic application of automatic speech recognition. Finally, we show that QRNN and QLSTM reduce by a maximum factor of 3.3x the number of free parameters needed, compared to real-valued RNNs and LSTMs to reach better results, leading to a more compact representation of the relevant information.", "keywords": ["Quaternion recurrent neural networks", "quaternion numbers", "recurrent neural networks", "speech recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper261/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/360646ae85462d14f76ad71471cebaf93d20b541.pdf", "paperhash": "anonymous|quaternion_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019quaternion,    \ntitle={Quaternion Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByMHvs0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B14rPj0qY7", "original": "BkgzhhD5tQ", "number": 262, "cdate": 1538087773297, "ddate": null, "tcdate": 1538087773297, "tmdate": 1538156208054, "tddate": null, "forum": "B14rPj0qY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RETHINKING SELF-DRIVING : MULTI -TASK KNOWLEDGE FOR BETTER GENERALIZATION AND ACCIDENT EXPLANATION ABILITY", "abstract": "Current end-to-end deep learning driving models have two problems: (1) Poor\ngeneralization ability of unobserved driving environment when diversity of train-\ning driving dataset is limited (2) Lack of accident explanation ability when driving\nmodels don\u2019t work as expected. To tackle these two problems, rooted on the be-\nlieve that knowledge of associated easy task is benificial for addressing difficult\ntask, we proposed a new driving model which is composed of perception module\nfor see and think and driving module for behave, and trained it with multi-task\nperception-related basic knowledge and driving knowledge stepwisely.  Specifi-\ncally segmentation map and depth map (pixel level understanding of images) were\nconsidered as what & where and how far knowledge for tackling easier driving-\nrelated perception problems before generating final control commands for difficult\ndriving task. The results of experiments demonstrated the effectiveness of multi-\ntask perception knowledge for better generalization and accident explanation abil-\nity. With our method the average sucess rate of finishing most difficult navigation\ntasks in untrained city of CoRL test surpassed current benchmark method for 15\npercent in trained weather and 20 percent in untrained weathers.", "keywords": ["Autonomous car", "convolution network", "image segmentation", "depth estimation", "generalization ability", "explanation ability", "multi-task learning"], "authorids": ["ICLR.cc/2019/Conference/Paper262/Authors"], "authors": ["Anonymous"], "TL;DR": "we proposed a new self-driving model which is composed of perception module for see and think and driving module for behave to acquire better generalization  and accident explanation ability.", "pdf": "/pdf/71d4407475c16d3cd272915f752a8b6af7ce9efc.pdf", "paperhash": "anonymous|rethinking_selfdriving_multi_task_knowledge_for_better_generalization_and_accident_explanation_ability", "_bibtex": "@inproceedings{    \nanonymous2019rethinking,    \ntitle={RETHINKING SELF-DRIVING : MULTI -TASK KNOWLEDGE FOR BETTER GENERALIZATION AND ACCIDENT EXPLANATION ABILITY},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B14rPj0qY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgBvsC9FQ", "original": "SyegNTw9tQ", "number": 263, "cdate": 1538087773475, "ddate": null, "tcdate": 1538087773475, "tmdate": 1538156207851, "tddate": null, "forum": "BkgBvsC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder", "abstract": "Variational autoencoders (VAEs) have shown a promise in data-driven conversation modeling. However, most VAE conversation models match the approximate posterior distribution over the latent variables to a simple prior such as standard normal distribution, thereby restricting the generated responses to a relatively simple (e.g., single-modal) scope. In this paper, we propose DialogWAE, a conditional Wasserstein autoencoder (WAE) specially designed for dialogue modeling. Unlike VAEs that impose a simple distribution over the latent variables, DialogWAE models the distribution of data by training a GAN within the latent variable space. Specifically, our model samples from the prior and posterior distributions over the latent variables by transforming context-dependent random noise using neural networks and minimizes the Wasserstein distance between the two distributions. We further develop a Gaussian mixture prior network to enrich the latent space. Experiments on two popular datasets show that DialogWAE outperforms the state-of-the-art approaches in generating more coherent, informative and diverse responses.", "keywords": ["dialogue", "GAN", "VAE", "WAE", "chatbot"], "authorids": ["ICLR.cc/2019/Conference/Paper263/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e364c8769b1c0bb448380d1a5a2a6fed73c65892.pdf", "paperhash": "anonymous|dialogwae_multimodal_response_generation_with_conditional_wasserstein_autoencoder", "_bibtex": "@inproceedings{    \nanonymous2019dialogwae:,    \ntitle={DialogWAE: Multimodal Response Generation with Conditional Wasserstein Auto-Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgBvsC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl8viCqKQ", "original": "SJlppUX5YQ", "number": 264, "cdate": 1538087773648, "ddate": null, "tcdate": 1538087773648, "tmdate": 1538156207644, "tddate": null, "forum": "rJl8viCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Low Latency Privacy Preserving Inference", "abstract": "Using machine learning in domains such as medicine and finance requires tools that can preserve privacy and confidentiality. In this work, we focus on private inference with neural networks. Following the work of Dowlin et al. (2016), we use Homomorphic Encryption (HE) to allow neural networks to be applied to encrypted data and therefore make predictions while preserving privacy. We present 90x improvement in latency and 7x improvement in throughput compared to prior attempts. The improved performance is achieved via a modern implementation of the encryption scheme and a collection of methods to better represent the data during the computation. We also apply the method of transfer learning to provide private inference services using deep networks. We demonstrate the efficacy of our methods on several computer vision tasks.", "keywords": ["privacy", "classification", "homomorphic encryption", "neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper264/Authors"], "authors": ["Anonymous"], "TL;DR": "This work presents methods, combining neural-networks and encryptions, to make predictions while preserving the privacy of the data owner with low latency", "pdf": "/pdf/883170480c4e9a423b0ea6dc49050f7d4086fd46.pdf", "paperhash": "anonymous|low_latency_privacy_preserving_inference", "_bibtex": "@inproceedings{    \nanonymous2019low,    \ntitle={Low Latency Privacy Preserving Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl8viCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1e8wsCqYX", "original": "rJg7KKr9Y7", "number": 265, "cdate": 1538087773824, "ddate": null, "tcdate": 1538087773824, "tmdate": 1538156207433, "tddate": null, "forum": "H1e8wsCqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Laplacian Networks: Bounding Indicator Function Smoothness for Neural Networks Robustness", "abstract": "  For the past few years, Deep Neural Network (DNN) robustness has become a question of paramount importance. As a matter of fact, in sensitive settings misclassification can lead to dramatic consequences. Such misclassifications are likely to occur when facing adversarial attacks, hardware failures or limitations, and imperfect signal acquisition. To address this question, authors have proposed different approaches aiming at increasing the robustness of DNNs, such as adding regularizers or training using noisy examples. In this paper we propose a new regularizer built upon the Laplacian of similarity graphs obtained from the representation of training data at each layer of the DNN architecture. This regularizer penalizes large changes (across consecutive layers in the architecture) in the distance between examples of different classes, and as such enforces smooth variations of the class boundaries. Since it is agnostic to the type of deformations that are expected when predicting with the DNN, the proposed regularizer can be combined with existing ad-hoc methods. We provide theoretical justification for this regularizer and demonstrate its effectiveness to improve robustness of DNNs on classical supervised learning vision datasets.\n", "keywords": ["GSP", "robustness", "noise", "deep learning", "neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper265/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ad9fa7dcfd5ba3f66d2390eb24869bc88aec7436.pdf", "paperhash": "anonymous|laplacian_networks_bounding_indicator_function_smoothness_for_neural_networks_robustness", "_bibtex": "@inproceedings{    \nanonymous2019laplacian,    \ntitle={Laplacian Networks: Bounding Indicator Function Smoothness for Neural Networks Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1e8wsCqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJe8DsR9tm", "original": "rkxoFADcY7", "number": 266, "cdate": 1538087773996, "ddate": null, "tcdate": 1538087773996, "tmdate": 1538156207225, "tddate": null, "forum": "SJe8DsR9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dynamic Early Terminating of Multiply Accumulate Operations for Saving Computation Cost in Convolutional Neural Networks", "abstract": "Deep learning has been attracting enormous attention from academia as well as industry due to its great success in many artificial intelligence applications. As more applications are developed, the need for implementing a complex neural network model on an energy-limited edge device becomes more critical. To this end, this paper proposes a new optimization method to reduce the computation efforts of convolutional neural networks. The method takes advantage of the fact that some convolutional operations are actually wasteful since their outputs are pruned by the following activation or pooling layers. Basically, a convolutional filter conducts a series of multiply-accumulate (MAC) operations. We propose to set a checkpoint in the MAC process to determine whether a filter could terminate early based on the intermediate result. Furthermore, a fine-tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50% MAC operations with less than 1% accuracy drop for CIFAR-10 example model and Network in Network on the CIFAR-10 and CIFAR-100 datasets. Additionally, compared with the state-of- the-art method, the proposed method is more effective on the CIFAR-10 dataset and is competitive on the CIFAR-100 dataset.", "keywords": ["Convolutional neural network", "Early terminating", "Dynamic model optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper266/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b29fe6017dcb7ee6746aefba83b77d0e57dbc860.pdf", "paperhash": "anonymous|dynamic_early_terminating_of_multiply_accumulate_operations_for_saving_computation_cost_in_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Early Terminating of Multiply Accumulate Operations for Saving Computation Cost in Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJe8DsR9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyeUPi09Y7", "original": "r1eVD4k5tm", "number": 267, "cdate": 1538087774177, "ddate": null, "tcdate": 1538087774177, "tmdate": 1538156207013, "tddate": null, "forum": "HyeUPi09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Convolutional Gaussian Process", "abstract": "Gaussian Processes (GPs) are flexible priors over functions which are robust to over-fitting and able to provide well-calibrated predictive uncertainty. However, most of the existing GP models rely on local metrics like Euclidean distance to generalize. We introduce Deep Convolutional Gaussian Processes (DCGPs), a Bayesian nonparametric variant of the well-known Deep Convolutional Neural Networks (DCNNs), to make Gaussian Processes have more powerful non-local generalization abilities on images. The main contribution of our work is incorporating convolutional structures into Deep Gaussian Processes (DGPs). We achieve this by introducing patch-response functions in patch domain, which perform similar roles like convolutional filters in DCNNs. Inference in the patch domain is not tractable, so we introduce inter-domain approximation to conduct inference on DCGPs. Results on MNIST and CIFAR-10 outperform other existing GP models, which show the effectiveness of our model.\n", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper267/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7c13ac63a41d4e2293b8efb96ad52a5701193849.pdf", "paperhash": "anonymous|deep_convolutional_gaussian_process", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Convolutional Gaussian Process},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeUPi09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hke8Do0cF7", "original": "ryeSygd5tm", "number": 268, "cdate": 1538087774358, "ddate": null, "tcdate": 1538087774358, "tmdate": 1538156206803, "tddate": null, "forum": "Hke8Do0cF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep processing of structured data", "abstract": "We construct a general unified framework for learning representation of structured\ndata, i.e. data which cannot be represented as the fixed-length vectors (e.g. sets,\ngraphs, texts or images of varying sizes). The key factor is played by an intermediate\nnetwork called SAN (Set Aggregating Network), which maps a structured\nobject to a fixed length vector in a high dimensional latent space. Our main theoretical\nresult shows that for sufficiently large dimension of the latent space, SAN is\ncapable of learning a unique representation for every input example. Experiments\ndemonstrate that replacing pooling operation by SAN in convolutional networks\nleads to better results in classifying images with different sizes. Moreover, its direct\napplication to text and graph data allows to obtain results close to SOTA, by\nsimpler networks with smaller number of parameters than competitive models.", "keywords": ["structured data", "representation learning", "deep neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper268/Authors"], "authors": ["Anonymous"], "TL;DR": "General framework of learning representation of structured inputs.", "pdf": "/pdf/d35f16cffb07c6c0a82faee9f91dc1e905481a36.pdf", "paperhash": "anonymous|deep_processing_of_structured_data", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep processing of structured data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hke8Do0cF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklwwo05Ym", "original": "SylAZe_5tX", "number": 269, "cdate": 1538087774528, "ddate": null, "tcdate": 1538087774528, "tmdate": 1538156206586, "tddate": null, "forum": "rklwwo05Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pushing the bounds of dropout", "abstract": "We show that dropout training is best understood as performing MAP estimation concurrently for a family of conditional models whose objectives are themselves lower bounded by the original dropout objective. This discovery allows us to pick any model from this family after training, which leads to a substantial improvement on regularisation-heavy language modelling. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds than the fully stochastic dropout objective. We argue that since the deterministic subvariant's bound is equal to its objective, and the highest amongst these models, the predominant view of it as a good approximation to MC averaging is misleading. Rather, deterministic dropout is the best available approximation to the true objective.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper269/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/6d117d07246423d3e82fea732059ae170464890b.pdf", "paperhash": "anonymous|pushing_the_bounds_of_dropout", "_bibtex": "@inproceedings{    \nanonymous2019pushing,    \ntitle={Pushing the bounds of dropout},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklwwo05Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxwDiActX", "original": "rylqmc3Ytm", "number": 270, "cdate": 1538087774705, "ddate": null, "tcdate": 1538087774705, "tmdate": 1538156206379, "tddate": null, "forum": "HJxwDiActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "StrokeNet: A Neural Painting Environment", "abstract": "We've seen tremendous success of image generating models these years. Generating an image through a neural network is like ``dreaming'', which is fundamentally different from how humans create artwork using brushes. To imitate human drawing, interactions between the agent and the environment is required to allow trials from the agent. However, the environment is usually non-differentiable, leading to slow convergence and massive computation. In this paper we try to address the discrete nature of software environment with an intermediate, differentiable simulation, which can be interpreted as a neural perception of the surroundings of the upper agent. We present StrokeNet, a novel model where the agent is trained upon a well-crafted neural approximation of the painting environment. With this approach, our agent was able to learn to write characters such as MNIST digits very quickly in an unsupervised manner. Our primary contribution is the neural simulation of real-world environment. Furthermore, the agent trained with our approach can be directly transferred to real world with learned skills. To the best of our knowledge, StrokeNet is the first model to apply differentiable simulation to real-world learning problems and standard datasets.", "keywords": ["image generation", "differentiable model", "reinforcement learning", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper270/Authors"], "authors": ["Anonymous"], "TL;DR": "StrokeNet is a novel architecture where the agent is trained to draw by strokes on a differentiable simulation of the environment, which could effectively exploit the power of back-propagation.", "pdf": "/pdf/e350a8b8ccf3957f164b263cc513b3213f6aca69.pdf", "paperhash": "anonymous|strokenet_a_neural_painting_environment", "_bibtex": "@inproceedings{    \nanonymous2019strokenet:,    \ntitle={StrokeNet: A Neural Painting Environment},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxwDiActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzvDjAcK7", "original": "Skl_gFZYYQ", "number": 271, "cdate": 1538087774895, "ddate": null, "tcdate": 1538087774895, "tmdate": 1538156206167, "tddate": null, "forum": "SJzvDjAcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Intriguing Properties of Learned Representations", "abstract": "A key feature of neural networks, particularly deep convolutional neural networks, is their ability to learn useful representations from data. The very last layer of a neural network is then simply a linear model trained on these learned representations. Despite their numerous applications in other tasks such as classification, retrieval, clustering etc., a.k.a. transfer learning, not much work has been published that investigates the structure of these representations or indeed whether structure can be imposed on them during the training process.\n\nIn this paper, we study the effective dimensionality of the learned representations  by models that have proved highly successful for image classification.  We focus on ResNet-18, ResNet-50 and VGG-19 and  observe that when trained on CIFAR10 or CIFAR100, the learned representations exhibit a fairly low rank structure.  We propose a modification to the training procedure,  which further encourages low rank structure on learned activations.  Empirically, we show that this has implications for  robustness to adversarial examples  and compression.", "keywords": ["deep learning", "low rank representations", "adversarial robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper271/Authors"], "authors": ["Anonymous"], "TL;DR": "Imposing a low rank structure on learned representations in deep networks yields a lot of interesting benefits.", "pdf": "/pdf/97f2855ee4aa7dc91bce205584a45c7db57c7791.pdf", "paperhash": "anonymous|intriguing_properties_of_learned_representations", "_bibtex": "@inproceedings{    \nanonymous2019intriguing,    \ntitle={Intriguing Properties of Learned Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzvDjAcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzwvoCqF7", "original": "rJg66nb_Fm", "number": 272, "cdate": 1538087775070, "ddate": null, "tcdate": 1538087775070, "tmdate": 1538156205957, "tddate": null, "forum": "SJzwvoCqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Tighter Generalization Bounds for Deep Neural Networks: CNNs, ResNets, and Beyond", "abstract": "We propose a generalization error bound for a general family of deep neural networks based on the depth and width of the networks, as well as the spectral norm of weight matrices. Through introducing a novel characterization of the Lipschitz properties of neural network family, we achieve a tighter generalization error bound. We further obtain a result that is free of linear dependence on norms for bounded losses. Besides the general deep neural networks, our results can be applied to derive new bounds for several popular architectures, including convolutional neural networks (CNNs), residual networks (ResNets), and hyperspherical networks (SphereNets).  When achieving same generalization errors with previous arts, our bounds allow for the choice of much larger parameter spaces of weight matrices, inducing potentially stronger expressive ability for neural networks.", "keywords": ["deep learning", "generalization error bound", "convolutional neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper272/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/06a1cc524fa03cba2dd62dd8fc242dc2e4038c7d.pdf", "paperhash": "anonymous|on_tighter_generalization_bounds_for_deep_neural_networks_cnns_resnets_and_beyond", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Tighter Generalization Bounds for Deep Neural Networks: CNNs, ResNets, and Beyond},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzwvoCqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkVvwj0qFm", "original": "B1gkIeHFdQ", "number": 273, "cdate": 1538087775246, "ddate": null, "tcdate": 1538087775246, "tmdate": 1538156205745, "tddate": null, "forum": "BkVvwj0qFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Geometric Operator Convolutional Neural Network", "abstract": "The Convolutional Neural Network (CNN) has been successfully applied in many fields during recent decades; however it lacks the ability to utilize prior domain knowledge when dealing with many realistic problems. We present a framework called Geometric Operator Convolutional Neural Network (GO-CNN) that uses domain knowledge, wherein the kernel of the first convolutional layer is replaced with a kernel generated by a geometric operator function. This framework integrates many conventional geometric operators, which allows it to adapt to a diverse range of problems. Under certain conditions, we theoretically analyze the convergence and the bound of the generalization errors between GO-CNNs and common CNNs. Although the geometric operator convolution kernels have fewer trainable parameters than common convolution kernels, the experimental results indicate that GO-CNN performs more accurately than common CNN on CIFAR-10/100. Furthermore, GO-CNN reduces dependence on the amount of training examples and enhances adversarial stability.", "keywords": ["Convolutional Neural Network", "Geometric Operator", "Image Classification", "Theoretical Analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper273/Authors"], "authors": ["Anonymous"], "TL;DR": "Traditional image processing algorithms are combined with Convolutional Neural Networks\uff0ca new neural network.", "pdf": "/pdf/a85e09ffc3461f9c88386b6fe2d2be5daeb40710.pdf", "paperhash": "anonymous|geometric_operator_convolutional_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019geometric,    \ntitle={Geometric Operator Convolutional Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkVvwj0qFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJNwDjAqYX", "original": "S1lZH7dqKm", "number": 274, "cdate": 1538087775422, "ddate": null, "tcdate": 1538087775422, "tmdate": 1538156205535, "tddate": null, "forum": "rJNwDjAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Large-Scale Study of Curiosity-Driven Learning", "abstract": "Reinforcement learning algorithms rely on carefully engineered rewards from the environment that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is difficult and not scalable, motivating the need for developing reward functions that are intrinsic to the agent. \nCuriosity is such intrinsic reward function which uses prediction error as a reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. {\\em without any extrinsic rewards}, across $54$ standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance as well as a high degree of alignment between the intrinsic curiosity objective and the hand-designed extrinsic rewards of many games. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://doubleblindsupplementary.github.io/large-curiosity/.", "keywords": ["exploration", "curiosity", "intrinsic reward", "no extrinsic reward", "unsupervised", "no-reward", "skills"], "authorids": ["ICLR.cc/2019/Conference/Paper274/Authors"], "authors": ["Anonymous"], "TL;DR": "An agent trained only with curiosity, and no extrinsic reward, does surprisingly well on 54 popular environments, including the suite of Atari games, Mario etc.", "pdf": "/pdf/e43ec594e9db765f5e441285aa602b7c5cec9c86.pdf", "paperhash": "anonymous|largescale_study_of_curiositydriven_learning", "_bibtex": "@inproceedings{    \nanonymous2019large-scale,    \ntitle={Large-Scale Study of Curiosity-Driven Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJNwDjAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1edvs05Y7", "original": "rkeb1Av5F7", "number": 275, "cdate": 1538087775593, "ddate": null, "tcdate": 1538087775593, "tmdate": 1538156205322, "tddate": null, "forum": "B1edvs05Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication", "abstract": "Currently, progressively larger deep neural networks are trained on ever growing data corpora. In result, distributed training schemes are becoming increasingly relevant. A major issue in distributed training is the limited communication bandwidth between contributing nodes or prohibitive communication cost in general. \n%These challenges become even more pressing, as the number of computation nodes increases. \nTo mitigate this problem we propose Sparse Binary Compression (SBC), a compression framework that allows for a drastic reduction of communication cost for distributed training. SBC combines existing techniques of communication delay and gradient sparsification with a novel binarization method and optimal weight update encoding to push compression gains to new limits. By doing so, our method also allows us to smoothly trade-off gradient sparsity and temporal sparsity to adapt to the requirements of the learning task. \n%We use tools from information theory to reason why SBC can achieve the striking compression rates observed in the experiments.\nOur experiments show, that SBC can reduce the upstream communication on a variety of convolutional and recurrent neural network architectures by more than four orders of magnitude without significantly harming the convergence speed in terms of forward-backward passes. For instance, we can train ResNet50 on ImageNet in the same number of iterations to the baseline accuracy, using $\\times 3531$ less bits or train it to a $1\\%$ lower accuracy using $\\times 37208$ less bits. In the latter case, the total upstream communication required is cut from 125 terabytes to 3.35 gigabytes for every participating client. Our method also achieves state-of-the-art compression rates in a Federated Learning setting with 400 clients.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper275/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/79a831ab8097889e3fd0194e2ca435da6c069550.pdf", "paperhash": "anonymous|sparse_binary_compression_towards_distributed_deep_learning_with_minimal_communication", "_bibtex": "@inproceedings{    \nanonymous2019sparse,    \ntitle={Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1edvs05Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkx_Dj09tQ", "original": "HJlJtXu9KQ", "number": 276, "cdate": 1538087775764, "ddate": null, "tcdate": 1538087775764, "tmdate": 1538156205112, "tddate": null, "forum": "Bkx_Dj09tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Causal importance of orientation selectivity for generalization in image recognition", "abstract": "Although both our brain and deep neural networks (DNNs) can perform high-level sensory-perception tasks such as image or speech recognition, the inner mechanism of these hierarchical information-processing systems is poorly understood in both neuroscience and machine learning. Recently, Morcos et al. (2018) examined the effect of class-selective units in DNNs, i.e., units with high-level selectivity, on network generalization, concluding that hidden units that are selectively activated by specific input patterns may harm the network's performance. In this study, we revisit their hypothesis, considering units with selectivity for lower-level features, and argue that selective units are not always harmful to the network performance. Specifically, by using DNNs trained for image classification, we analyzed the orientation selectivity of individual units. Orientation selectivity is a low-level selectivity widely studied in visual neuroscience, in which, when images of bars with several orientations are presented to the eye, many neurons in the visual cortex respond selectively to a specific orientation. We found that orientation-selective units exist in both lower and higher layers of DNNs, as in our brain. In particular, units in the lower layers become more orientation-selective as the generalization performance improves during the course of training of the DNNs. Consistently, networks that generalize better are more orientation-selective in the lower layers. We finally reveal that ablating these selective units in the lower layers substantially degrades the generalization performance. These results suggest to the machine-learning community that, contrary to the triviality of units with high-level selectivity, lower-layer units with selectivity for low-level features are indispensable for generalization, and for neuroscientists, orientation selectivity does play a causally important role in object recognition.", "keywords": ["deep learning", "neuroscience"], "authorids": ["ICLR.cc/2019/Conference/Paper276/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a752d8113afe031c5afb9ce05d3238c8ef51108c.pdf", "paperhash": "anonymous|causal_importance_of_orientation_selectivity_for_generalization_in_image_recognition", "_bibtex": "@inproceedings{    \nanonymous2019causal,    \ntitle={Causal importance of orientation selectivity for generalization in image recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkx_Dj09tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkedwoC5t7", "original": "Hke1cQ_qtQ", "number": 277, "cdate": 1538087775945, "ddate": null, "tcdate": 1538087775945, "tmdate": 1538156204908, "tddate": null, "forum": "BkedwoC5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Formal Limitations on the Measurement of Mutual Information", "abstract": "Maximum mutual information (MMI) predictive coding has recently been proposed as a compelling approach to self-supervised learning. Maximizing mutual information also arises in INFOMAX and the information bottleneck. Recent papers have used the Donsker-Varadhan (DV) lower bound on KL divergence as a tractable training surrogate when maximizing mutual information. We show here that any distribution-free high-confidence lower bound on mutual information requires a sample size exponential in the value of the bound.  We also directly analyze the DV lower bound and show that the DV bound cannot be measured accurately without an exponential sample size. We propose instead to representing mutual information as a difference of entropies and of estimating entropies with cross-entropy upper bounds.  A sample estimate of a cross entropy converges to the true cross-entropy at the rate of $1/\\sqrt{N}$.", "keywords": ["mutual information", "predictive coding", "unsupervised learning", "predictive learning", "generalization bounds", "MINE", "DIM", "contrastive predictive coding"], "authorids": ["ICLR.cc/2019/Conference/Paper277/Authors"], "authors": ["Anonymous"], "TL;DR": "We give a theoretical analysis of the measurement and optimization of mutual information.", "pdf": "/pdf/cf51173553642eed578dd43c6016d143e444cb32.pdf", "paperhash": "anonymous|formal_limitations_on_the_measurement_of_mutual_information", "_bibtex": "@inproceedings{    \nanonymous2019formal,    \ntitle={Formal Limitations on the Measurement of Mutual Information},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkedwoC5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyl_vjC5KQ", "original": "S1gPflx5KQ", "number": 278, "cdate": 1538087776118, "ddate": null, "tcdate": 1538087776118, "tmdate": 1538156204697, "tddate": null, "forum": "Hyl_vjC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization", "abstract": "Real-world tasks are often highly structured. Hierarchical reinforcement learning (HRL) has attracted research interest as an approach for leveraging the hierarchical structure of a given task in reinforcement learning (RL).  However, identifying the hierarchical policy structure that enhances the performance of RL in not a trivial task. In this paper, we propose an HRL method that learns a latent variable of a hierarchical policy using mutual information maximization.  Our approach can be interpreted as a way to learn a discrete and latent representation of the state-action space in an unsupervised manner. To estimate the density of states and actions induced by the unknown optimal policy, we introduce advantage-weighted importance sampling. In our HRL method, the gating policy learns to select option policies based on an option-value function, and these option policies are optimized based on the deterministic policy gradient method. This framework is derived by leveraging the analogy between a monolithic policy in standard RL and a hierarchical policy in HRL by using a deterministic option policy. Experimental results indicate that our HRL approach can learn a diversity of options and that it can enhance the performance of RL in continuous control tasks.", "keywords": ["Hierarchical reinforcement learning", "Representation learning", "Continuous control"], "authorids": ["ICLR.cc/2019/Conference/Paper278/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a hierarchical reinforcement learning framework based on deterministic option policies and mutual information maximization. ", "pdf": "/pdf/d2ba51757cda58e9798e77a128a3caf047ea6a5a.pdf", "paperhash": "anonymous|hierarchical_reinforcement_learning_via_advantageweighted_information_maximization", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyl_vjC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgODj05KX", "original": "Hkg72m_5KX", "number": 279, "cdate": 1538087776295, "ddate": null, "tcdate": 1538087776295, "tmdate": 1538156204480, "tddate": null, "forum": "HJgODj05KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A preconditioned accelerated stochastic gradient descent algorithm", "abstract": "We propose a preconditioned accelerated stochastic gradient method suitable for large scale optimization. We derive sufficient convergence conditions for the minimization of convex functions using a generic class of diagonal preconditioners and provide a formal convergence proof based on a framework originally used for on-line learning. Inspired by recent popular adaptive per-feature algorithms, we propose a specific preconditioner based on the second moment of the gradient. The sufficient convergence conditions motivate a critical adaptation of the per-feature updates in order to ensure convergence. We show empirical results for the minimization of convex and non-convex cost functions, in the context of neural network training. The method compares favorably with respect to current, first order, stochastic optimization methods.", "keywords": ["stochastic optimization", "neural network", "preconditioned accelerated stochastic gradient descent"], "authorids": ["ICLR.cc/2019/Conference/Paper279/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a preconditioned accelerated gradient method that combines Nesterov\u2019s accelerated gradient descent with a class of diagonal preconditioners, in a stochastic setting.", "pdf": "/pdf/d88c2736e0868ec8f2874192f75bfac34872df1e.pdf", "paperhash": "anonymous|a_preconditioned_accelerated_stochastic_gradient_descent_algorithm", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A preconditioned accelerated stochastic gradient descent algorithm},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgODj05KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkMuPjRcKQ", "original": "H1l26CvqFX", "number": 280, "cdate": 1538087776464, "ddate": null, "tcdate": 1538087776464, "tmdate": 1538156204269, "tddate": null, "forum": "SkMuPjRcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Feed-forward Propagation in Probabilistic Neural Networks with Categorical and Max Layers", "abstract": "Probabilistic Neural Networks take into account various sources of stochasticity: input noise, dropout, stochastic neurons, parameter uncertainties modeled as random variables.\nIn this paper we revisit the feed-forward propagation method that allows one to estimate for each neuron its mean and variance w.r.t. mentioned sources of stochasticity. In contrast, standard NNs propagate only point estimates, discarding the uncertainty. Methods propagating also the variance have been proposed by several authors in different context. The presented view attempts to clarify the assumptions and derivation behind such methods, relate it to classical NNs and broaden the scope of its applicability.\nThe main technical innovations are new posterior approximations for argmax and max-related transforms, that allows for applicability in networks with softmax and max-pooling layers as well as leaky ReLU activations.\nWe evaluate the accuracy of the approximation and suggest a simple calibration. Applying the method to networks with dropout allows for faster training and gives improved test likelihoods without the need of sampling.", "keywords": ["probabilistic neural network", "uncertainty", "dropout", "bayesian", "softmax"], "authorids": ["ICLR.cc/2019/Conference/Paper280/Authors"], "authors": ["Anonymous"], "TL;DR": "Approximating mean and variance of the NN output over noisy input / dropout / uncertain parameters. Analytic approximations for argmax, softmax and max layers.", "pdf": "/pdf/ecf8462eca1e9485d7d04ce3124c2582161fdd5f.pdf", "paperhash": "anonymous|feedforward_propagation_in_probabilistic_neural_networks_with_categorical_and_max_layers", "_bibtex": "@inproceedings{    \nanonymous2019feed-forward,    \ntitle={Feed-forward Propagation in Probabilistic Neural Networks with Categorical and Max Layers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkMuPjRcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxYwiC5tm", "original": "BJlPFW_ctX", "number": 281, "cdate": 1538087776633, "ddate": null, "tcdate": 1538087776633, "tmdate": 1538156204064, "tddate": null, "forum": "HJxYwiC5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Why do deep convolutional networks generalize so poorly to small image transformations?", "abstract": "Deep convolutional network architectures are often assumed to guarantee generalization for small image translations and deformations. In this paper we show that modern CNNs (VGG16, ResNet50, and InceptionResNetV2) can drastically change their output when an image is translated in the image plane by a few pixels, and that this failure of generalization also happens with other realistic small image transformations. Furthermore,  we see these failures to generalize more frequently in more modern networks. We show that these failures are related to the fact that the architecture of modern CNNs ignores the classical sampling theorem so that generalization is not guaranteed. We also show that biases in the statistics of commonly used image datasets makes it unlikely that CNNs will learn to be invariant to these transformations. Taken together our results suggest that the performance of CNNs in object recognition falls far short of the generalization capabilities of humans.", "keywords": ["Convolutional neural networks", "The sampling theorem", "Sensitivity to small image transformations", "Dataset bias", "Shiftability"], "authorids": ["ICLR.cc/2019/Conference/Paper281/Authors"], "authors": ["Anonymous"], "TL;DR": "Modern deep CNNs are not invariant to translations, scalings and other realistic image transformations, and this lack of invariance is related to the subsampling operation and the biases contained in image datasets.", "pdf": "/pdf/67577627cc2bcea8d277f19807e77b576684c043.pdf", "paperhash": "anonymous|why_do_deep_convolutional_networks_generalize_so_poorly_to_small_image_transformations", "_bibtex": "@inproceedings{    \nanonymous2019why,    \ntitle={Why do deep convolutional networks generalize so poorly to small image transformations?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxYwiC5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgtDsCcKQ", "original": "B1lB6lvcK7", "number": 282, "cdate": 1538087776871, "ddate": null, "tcdate": 1538087776871, "tmdate": 1538156203854, "tddate": null, "forum": "BkgtDsCcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Function Space Particle Optimization for Bayesian Neural Networks", "abstract": "While Bayesian neural networks (BNNs) have drawn increasing attention, their posterior inference remains challenging, due to the high-dimensional and over-parameterized nature. To address this issue, several highly flexible and scalable variational inference procedures based on the idea of particle optimization have been proposed. These methods directly optimize a set of particles to approximate the target posterior. However, their application to BNNs often yields sub-optimal performance, as such methods have a particular failure mode on over-parameterized models. In this paper, we propose to solve this issue by performing particle optimization directly in the space of regression functions. We demonstrate through extensive experiments that our method successfully overcomes this issue, and outperforms strong baselines in a variety of tasks including prediction, defense against adversarial examples, and reinforcement learning.", "keywords": ["Bayesian neural networks", "uncertainty estimation", "variational inference"], "authorids": ["ICLR.cc/2019/Conference/Paper282/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cc21cac97e0db6da6d473bcc77b8118a2b297e4e.pdf", "paperhash": "anonymous|function_space_particle_optimization_for_bayesian_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019function,    \ntitle={Function Space Particle Optimization for Bayesian Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgtDsCcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJfYvo09Y7", "original": "SylwuHOcFX", "number": 283, "cdate": 1538087777041, "ddate": null, "tcdate": 1538087777041, "tmdate": 1538156203644, "tddate": null, "forum": "BJfYvo09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Visuomotor Control of Humanoids", "abstract": "We aim to build complex humanoid agents that integrate perception, motor control, and memory. In this work, we partly factor this problem into low-level motor control from proprioception and high-level coordination of the low-level skills informed by vision. We develop an architecture capable of surprisingly flexible, task-directed motor control of a relatively high-DoF humanoid body by combining pre-training of low-level motor controllers with a high-level, task-focused controller that switches among low-level sub-policies. The resulting system is able to control a physically-simulated humanoid body to solve tasks that require coupling visual perception from an unstabilized egocentric RGB camera during locomotion in the environment. Supplementary video link:  https://youtu.be/fBoir7PNxPk", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper283/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f57adc948019f975853164e0c649acd8b6b97659.pdf", "paperhash": "anonymous|hierarchical_visuomotor_control_of_humanoids", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Visuomotor Control of Humanoids},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfYvo09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1ztwiCcYQ", "original": "H1ewJ8ucKQ", "number": 284, "cdate": 1538087777218, "ddate": null, "tcdate": 1538087777218, "tmdate": 1538156203356, "tddate": null, "forum": "r1ztwiCcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "VARIATIONAL SGD: DROPOUT , GENERALIZATION AND CRITICAL POINT AT THE END OF CONVEXITY", "abstract": "The goal of the paper is to propose an algorithm for learning the most generalizable solution from given training data. It is shown that Bayesian approach leads to a solution that dependent on statistics of training data and not on particular\nsamples. The solution is stable under perturbations of training data because it is defined by an integral contribution of multiple maxima of the likelihood and not by a single global maximum. Specifically, the Bayesian probability distribution\nof parameters (weights) of a probabilistic model given by a neural network is estimated via recurrent variational approximations. Derived recurrent update rules correspond to SGD-type rules for finding a minimum of an effective loss that is an average of an original negative log-likelihood over the Gaussian distributions of weights, which makes it a function of means and variances. The effective loss is convex for large variances and non-convex in the limit of small variances. Among stationary solutions of the update rules there are trivial solutions with zero variances at local minima of the original loss and a single non-trivial solution with finite variances that is a critical point at the end of convexity of the effective loss\nin the mean-variance space. At the critical point both first- and second-order gradients of the effective loss w.r.t. means are zero. The empirical study confirms that the critical point represents the most generalizable solution. While the location of\nthe critical point in the weight space depends on specifics of the used probabilistic model some properties at the critical point are universal and model independent.", "keywords": ["Bayesian inference", "neural networks", "generalization", "critical point solution"], "authorids": ["ICLR.cc/2019/Conference/Paper284/Authors"], "authors": ["Anonymous"], "TL;DR": "Proposed method for finding the most generalizable solution that is stable w.r.t. perturbations of trainig data.", "pdf": "/pdf/4319369e2c213c4c7d07d1f8e9fd86e90f0b0adb.pdf", "paperhash": "anonymous|variational_sgd_dropout_generalization_and_critical_point_at_the_end_of_convexity", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={VARIATIONAL SGD: DROPOUT , GENERALIZATION AND CRITICAL POINT AT THE END OF CONVEXITY},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1ztwiCcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByEtPiAcY7", "original": "Ske6sUdcKm", "number": 285, "cdate": 1538087777392, "ddate": null, "tcdate": 1538087777392, "tmdate": 1538156203136, "tddate": null, "forum": "ByEtPiAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Characterizing the Accuracy/Complexity Landscape of Explanations of Deep Networks through Knowledge Extraction", "abstract": "Knowledge extraction techniques are used to convert neural networks into symbolic descriptions with the objective of producing more comprehensible learning models. The central challenge is to find an explanation which is more comprehensible than the original model while still representing that model faithfully. The distributed nature of deep networks has led many to believe that the hidden features of a neural network cannot be explained by logical descriptions simple enough to be understood by humans, and that decompositional knowledge extraction should be abandoned in favour of other methods. In this paper we examine this question systematically by proposing a knowledge extraction method using M-of-N rules which allows us to map the complexity/accuracy landscape of rules describing hidden features in a Convolutional Neural Network (CNN). Experiments reported in this paper show that the shape of this landscape reveals an optimal trade off between comprehensibility and accuracy, showing that each latent variable has an optimal M-of-N rule to describe its behaviour. We find that the rules with optimal tradeoff in the first and final layer have a high degree of explainability whereas the rules with the optimal tradeoff in the second and third layer are less explainable. Furthermore, we show that by replacing the final layer with the optimal extracted rules the network becomes more robust against adversarial examples. The results shed light on the feasibility of rule extraction from deep networks, and point to the value of decompositional knowledge extraction as a method of explainability and to improve robustness when applied selectively.", "keywords": ["Deep Networks", "Explainability", "Knowledge Extraction"], "authorids": ["ICLR.cc/2019/Conference/Paper285/Authors"], "authors": ["Anonymous"], "TL;DR": "Systematically examines how well we can explain the hidden features of a deep network in terms of logical rules.", "pdf": "/pdf/731f97d79b23915ff97d060d9a5c8b4cf474dc89.pdf", "paperhash": "anonymous|characterizing_the_accuracycomplexity_landscape_of_explanations_of_deep_networks_through_knowledge_extraction", "_bibtex": "@inproceedings{    \nanonymous2019characterizing,    \ntitle={Characterizing the Accuracy/Complexity Landscape of Explanations of Deep Networks through Knowledge Extraction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByEtPiAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sklqvo0qt7", "original": "rygIyeScKQ", "number": 286, "cdate": 1538087777559, "ddate": null, "tcdate": 1538087777559, "tmdate": 1538156202900, "tddate": null, "forum": "Sklqvo0qt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Priori Estimates  of the Generalization Error for Two-layer Neural Networks", "abstract": "New estimates for the generalization error are established for a nonlinear regression problem using a two-layer neural network model. These new estimates are a priori in nature in the sense that the bounds depend only on some norms of the underlying functions to be fitted,  not the parameters in the model.  In contrast,  most existing results for neural networks are a posteriori in nature in the sense that the bounds depend on some norms of the model parameters. The error rates are comparable to that of the Monte Carlo method in terms of the size of the dataset.  Moreover, these bounds are equally effective in the over-parametrized regime when the network size is much larger than the size of the dataset. ", "keywords": ["Over-parameterization", "A priori estimates", "Path norm", "Neural networks", "Generalization error", "Approximation error"], "authorids": ["ICLR.cc/2019/Conference/Paper286/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/650a6a2592059c697270c0570ecd48a2bae2a75b.pdf", "paperhash": "anonymous|a_priori_estimates_of_the_generalization_error_for_twolayer_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Priori Estimates  of the Generalization Error for Two-layer Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sklqvo0qt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJg9DoR9t7", "original": "rklvqGzYYX", "number": 287, "cdate": 1538087777732, "ddate": null, "tcdate": 1538087777732, "tmdate": 1538156202688, "tddate": null, "forum": "BJg9DoR9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds", "abstract": "Eliciting labels from crowds is a potential way to obtain large labeled data. Despite a variety of methods developed for learning from crowds, a key challenge remains unsolved: learning from crowds without knowing the information structure among the crowds a priori, when some people of the crowds make highly correlated mistakes and some of them label effortlessly (e.g. randomly). We propose an information theoretic approach, Max-MIG, for joint learning from crowds, with a common assumption: the crowdsourced labels and the data are independent conditioning on the ground truth. Max-MIG simultaneously aggregates the crowdsourced labels and learns an accurate data classifier. Furthermore, we devise an accurate data-crowds forecaster that employs both the data and the crowdsourced labels to forecast the ground truth. To the best of our knowledge, this is a very early algorithm that solves the aforementioned challenge of learning from crowds. In addition to the theoretical validation, we also empirically show that our algorithm achieve the new state-of-the-art results in most settings and is a very early algorithm that is robust to various information structures.", "keywords": ["crowdsourcing", "information theory"], "authorids": ["ICLR.cc/2019/Conference/Paper287/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/690744754c5aed63ea44437c26e63cd0818112d5.pdf", "paperhash": "anonymous|maxmig_an_information_theoretic_approach_for_joint_learning_from_crowds", "_bibtex": "@inproceedings{    \nanonymous2019max-mig:,    \ntitle={Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJg9DoR9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkzcvoA9YX", "original": "H1gEvvdcFQ", "number": 288, "cdate": 1538087777908, "ddate": null, "tcdate": 1538087777908, "tmdate": 1538156202479, "tddate": null, "forum": "rkzcvoA9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Few-Shot Learning by Exploiting Object Relation", "abstract": "\nFew-shot learning trains image classifiers over datasets with few examples per category. \nIt poses challenges for the optimization algorithms, which typically require many examples to fine-tune the model parameters for new categories. \nDistance-learning-based approaches avoid the optimization issue by embedding the images into a metric space and applying the nearest neighbor classifier for new categories. In this paper, we propose to exploit the object-level relation to learn the image relation feature, which is converted into a distance directly.\nFor a new category, even though its images are not seen by the model, some objects may appear in the training images. Hence, object-level relation is useful for inferring the relation of images from unseen categories. Consequently, our model generalizes well for new categories without fine-tuning.\nExperimental results on benchmark datasets show that our approach outperforms state-of-the-art methods.", "keywords": ["few-shot learning", "relation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper288/Authors"], "authors": ["Anonymous"], "TL;DR": "Few-shot learning by exploiting the object-level relation to learn the image-level relation (similarity)", "pdf": "/pdf/3f6bb2bf7a11626410dd7453f5b5b16d782af08c.pdf", "paperhash": "anonymous|fewshot_learning_by_exploiting_object_relation", "_bibtex": "@inproceedings{    \nanonymous2019few-shot,    \ntitle={Few-Shot Learning by Exploiting Object Relation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkzcvoA9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygcvsAcFX", "original": "ryx_S9FOY7", "number": 289, "cdate": 1538087778084, "ddate": null, "tcdate": 1538087778084, "tmdate": 1538156202271, "tddate": null, "forum": "HygcvsAcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimal margin Distribution Network", "abstract": "Recent research about margin theory has proved that maximizing the minimum margin like support vector machines does not necessarily lead to better performance, and instead, it is crucial to optimize the margin distribution. In the meantime, margin theory has been used to explain the empirical success of deep network in recent studies. In this paper, we present ODN (the Optimal margin Distribution Network), a network which embeds a loss function in regard to the optimal margin distribution. We give a theoretical analysis for our method using the PAC-Bayesian framework, which confirms the significance of the margin distribution for classification within the framework of deep networks. In addition, empirical results show that the ODN model always outperforms the baseline cross-entropy loss model consistently across different regularization situations. And our ODN model also outperforms the other three loss models in generalization task through limited training data.", "keywords": ["Optimal margin distribution", "Deep neural network", "Generalization bound"], "authorids": ["ICLR.cc/2019/Conference/Paper289/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a deep neural network embedding a loss function in regard to the optimal margin distribution, which alleviates the overfitting problem theoretically and empirically.", "pdf": "/pdf/c7c571e6f1d30567a1585bbc797ee50d4a5d4ba5.pdf", "paperhash": "anonymous|optimal_margin_distribution_network", "_bibtex": "@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal margin Distribution Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygcvsAcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eqviAqYX", "original": "rklh6v_9FX", "number": 290, "cdate": 1538087778259, "ddate": null, "tcdate": 1538087778259, "tmdate": 1538156202049, "tddate": null, "forum": "H1eqviAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Why Do Neural Response Generation Models Prefer Universal Replies?", "abstract": "Recent advances in neural Sequence-to-Sequence (Seq2Seq) models reveal a purely data-driven approach to the response generation task. Despite its diverse variants and applications, the existing Seq2Seq models are prone to producing short and generic replies, which blocks such neural network architectures from being utilized in practical open-domain response generation tasks. In this research, we analyze this critical issue from the perspective of the optimization goal of models and the specific characteristics of human-to-human conversational corpora. Our analysis is conducted by decomposing the goal of Neural Response Generation (NRG) into the optimizations of word selection and ordering. It can be derived from the decomposing that Seq2Seq based NRG models naturally tend to select common words to compose responses, and ignore the semantic of queries in word ordering. On the basis of the analysis, we propose a max-marginal ranking regularization term to avoid Seq2Seq models from producing the generic and uninformative responses. The empirical experiments on benchmarks with several metrics have validated our analysis and proposed methodology.", "keywords": ["Neural Response Generation", "Universal Replies", "Optimization Goal Analysis", "Max-Marginal Ranking Regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper290/Authors"], "authors": ["Anonymous"], "TL;DR": "Analyze the reason for neural response generative models preferring universal replies; Propose a method to avoid it.", "pdf": "/pdf/9845dfaedd957da7d16424345b1cf55258f9074e.pdf", "paperhash": "anonymous|why_do_neural_response_generation_models_prefer_universal_replies", "_bibtex": "@inproceedings{    \nanonymous2019why,    \ntitle={Why Do Neural Response Generation Models Prefer Universal Replies?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eqviAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ecDoR5Y7", "original": "HJeBkLGCO7", "number": 291, "cdate": 1538087778440, "ddate": null, "tcdate": 1538087778440, "tmdate": 1538156201846, "tddate": null, "forum": "H1ecDoR5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Local Stability and Performance of Simple Gradient Penalty $\\mu$-Wasserstein GAN", "abstract": "Wasserstein GAN(WGAN) is a model that minimizes the Wasserstein distance between a data distribution and sample distribution. Recent studies have proposed stabilizing the training process for the WGAN and implementing the Lipschitz constraint. In this study, we prove the local stability of optimizing the simple gradient penalty $\\mu$-WGAN(SGP $\\mu$-WGAN) under suitable assumptions regarding the equilibrium and penalty measure $\\mu$. The measure valued differentiation concept is employed to deal with the derivative of the penalty terms, which is helpful for handling abstract singular measures with lower dimensional support. Based on this analysis, we claim that penalizing the data manifold or sample manifold is the key to regularizing the original WGAN with a gradient penalty. Experimental results obtained with unintuitive penalty measures that satisfy our assumptions are also provided to support our theoretical results.", "keywords": ["WGAN", "gradient penalty", "stability", "measure valued differentiation"], "authorids": ["ICLR.cc/2019/Conference/Paper291/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper deals with stability of simple gradient penalty $\\mu$-WGAN optimization by introducing a concept of measure valued differentiation.", "pdf": "/pdf/0d68fea0ac4b89064883e8dd8ccca1b444c2f1bb.pdf", "paperhash": "anonymous|local_stability_and_performance_of_simple_gradient_penalty_\\muwasserstein_gan", "_bibtex": "@inproceedings{    \nanonymous2019local,    \ntitle={Local Stability and Performance of Simple Gradient Penalty $\\mu$-Wasserstein GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ecDoR5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeiPsAqK7", "original": "rklCRcYQYm", "number": 292, "cdate": 1538087778618, "ddate": null, "tcdate": 1538087778618, "tmdate": 1538156201632, "tddate": null, "forum": "SkeiPsAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Graph Embedding using Dynamic Routing Between Capsules", "abstract": "An important task in learning representations for graph-structured data is to learn node embeddings which are then used for node classification. Recent models, however, suffer from limitations in exploiting graph information in such a way that relative positions of nodes are preserved. In this paper, we propose a novel unsupervised embedding model, named CapsG, which is, to our best of knowledge, the first model using dynamic routing between capsules to overcome these limitations. Our CapsG is constructed with two capsule layers, wherein the first layer aims to encapsulate the raw features of nodes, while the second layer produces a vector output used to infer node embedding. Experimental results show that our proposed CapsG produces new state-of-the-art results on Cora, Citeseer and POS, and obtains very competitive results on Pubmed, PPI and BlogCatalog in comparison with existing state-of-the-art unsupervised and semi-supervised graph embedding models.", "keywords": ["Graph Embedding", "Node Embedding", "Node Classification", "Capsule Network"], "authorids": ["ICLR.cc/2019/Conference/Paper292/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0df02151f801ab0500fec2e642abc6848d2282ba.pdf", "paperhash": "anonymous|unsupervised_graph_embedding_using_dynamic_routing_between_capsules", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Graph Embedding using Dynamic Routing Between Capsules},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeiPsAqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgsvoA9K7", "original": "SJeNRdttKm", "number": 293, "cdate": 1538087778804, "ddate": null, "tcdate": 1538087778804, "tmdate": 1538156201424, "tddate": null, "forum": "rkgsvoA9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dirichlet Variational Autoencoder", "abstract": "This paper proposes Dirichlet Variational Autoencoder (DirVAE) using a Dirichlet prior for a continuous latent variable that exhibits the characteristic of the categorical probabilities. To infer the parameters of DirVAE, we utilize the stochastic gradient method by approximating the Gamma distribution, which is a component of the Dirichlet distribution, with the inverse Gamma CDF approximation. Additionally, we reshape the component collapsing issue by investigating two problem sources, which are decoder weight collapsing and latent value collapsing, and we show that DirVAE has no component collapsing; while Gaussian VAE exhibits the decoder weight collapsing and Stick-Breaking VAE shows the latent value collapsing. The experimental results show that 1) DirVAE models the latent representation result with the best log-likelihood compared to the baselines; and 2) DirVAE produces more interpretable latent values with no collapsing issues which the baseline models suffer from. Also, we show that the learned latent representation from the DirVAE achieves the best classification accuracy in the semi-supervised and the supervised classification tasks on MNIST, OMNIGLOT, and SVHN compared to the baseline VAEs. Finally, we demonstrated that the DirVAE augmented topic models show better performances in most cases.", "keywords": ["Variational autoencoder", "Unsupervised learning", "(Semi-)Supervised learning", "Topic modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper293/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d8d139aa7241179da6594e9d4194354ae259d1e6.pdf", "paperhash": "anonymous|dirichlet_variational_autoencoder", "_bibtex": "@inproceedings{    \nanonymous2019dirichlet,    \ntitle={Dirichlet Variational Autoencoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgsvoA9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ziPjC5Fm", "original": "H1l2U9TuYX", "number": 294, "cdate": 1538087778979, "ddate": null, "tcdate": 1538087778979, "tmdate": 1538156201215, "tddate": null, "forum": "H1ziPjC5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks", "abstract": "Visual Interpretation and explanation of deep models is critical towards wide adoption of systems that rely on them. In this paper, we propose a novel scheme for both interpretation as well as explanation in which, given a pretrained model, we automatically identify internal features relevant for the set of classes considered by the model, without relying on additional annotations. We interpret the model through average visualizations of this reduced set of features. Then, at test time, we explain the network prediction by accompanying the predicted class label with supporting visualizations derived from the identified features. In addition, we propose a method to address the artifacts introduced by strided operations in deconvNet-based visualizations. Moreover, we introduce an8Flower , a dataset specifically designed for objective quantitative evaluation of methods for visual explanation. Experiments on the MNIST , ILSVRC 12, Fashion 144k and an8Flower datasets show that our method produces detailed explanations with good coverage of relevant features of the classes of interest.", "keywords": ["model explanation", "model interpretation", "explainable ai", "evaluation"], "authorids": ["ICLR.cc/2019/Conference/Paper294/Authors"], "authors": ["Anonymous"], "TL;DR": "Interpretation by Identifying model-learned features that serve as indicators for the task of interest. Explain model decisions by highlighting the response of these features in test data. Evaluate explanations objectively with a controlled dataset.", "pdf": "/pdf/610935df95ca17ffc24dec7e5288c81efc47aec1.pdf", "paperhash": "anonymous|visual_explanation_by_interpretation_improving_visual_feedback_capabilities_of_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019visual,    \ntitle={Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ziPjC5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkloDjAqYm", "original": "SkeUG2mKK7", "number": 295, "cdate": 1538087779154, "ddate": null, "tcdate": 1538087779154, "tmdate": 1538156201000, "tddate": null, "forum": "SkloDjAqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper295/Authors"], "authors": ["Anonymous"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/dc728faddaaed4e4c8818a06a76f9cc2a7a42071.pdf", "paperhash": "anonymous|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{    \nanonymous2019lemonade:,    \ntitle={LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkloDjAqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJesDsA9t7", "original": "H1xkbkf9FX", "number": 296, "cdate": 1538087779336, "ddate": null, "tcdate": 1538087779336, "tmdate": 1538156200789, "tddate": null, "forum": "BJesDsA9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Better Accuracy with Quantified Privacy: Representations Learned via Reconstructive Adversarial Network", "abstract": "The remarkable success of machine learning, especially deep learning, has produced a variety of cloud-based services for mobile users. Such services require an end user to send data to the service provider, which presents a serious challenge to end-user privacy. To address this concern, prior works either add noise to the data or send features extracted from the raw data.  They struggle to balance between the utility and privacy because added noise reduces utility and raw data can be reconstructed from extracted features.\n\nThis work represents a methodical departure from prior works: we balance between a measure of privacy and another of utility by leveraging adversarial learning to find a sweeter tradeoff. We design an encoder that optimizes against the reconstruction error (a measure of privacy), adversarially by a Decoder, and the inference accuracy (a measure of utility) by a Classifier. The result is RAN, a novel deep model with a new training algorithm that automatically extracts features for classification that are both private and useful.  \n\nIt turns out that adversarially forcing the extracted features to only conveys the intended information required by classification leads to an implicit regularization leading to better classification accuracy than the original model which completely ignores privacy. Thus, we achieve better privacy with better utility, a surprising possibility in machine learning! We conducted extensive experiments on five popular datasets over four training schemes, and demonstrate the superiority of RAN compared with existing alternatives.", "keywords": ["end-user privacy", "utility", "feature learning", "adversarial training"], "authorids": ["ICLR.cc/2019/Conference/Paper296/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/62c40ddaf4914669e40fa6748fc17b3f15110442.pdf", "paperhash": "anonymous|better_accuracy_with_quantified_privacy_representations_learned_via_reconstructive_adversarial_network", "_bibtex": "@inproceedings{    \nanonymous2019better,    \ntitle={Better Accuracy with Quantified Privacy: Representations Learned via Reconstructive Adversarial Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJesDsA9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkGiPoC5FX", "original": "Bye9rTuVtX", "number": 297, "cdate": 1538087779506, "ddate": null, "tcdate": 1538087779506, "tmdate": 1538156200580, "tddate": null, "forum": "BkGiPoC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Convolutional Neural Network Training with Direct Feedback Alignment", "abstract": "There were many algorithms to substitute the back-propagation (BP) in the deep neural network (DNN) training. However, they could not become popular because their training accuracy and the computational efficiency were worse than BP. One of them was direct feedback alignment (DFA), but it showed low training performance especially for the convolutional neural network (CNN). In this paper, we overcome the limitation of the DFA algorithm by combining with the conventional BP during the CNN training. To improve the training stability, we also suggest the feedback weight initialization method by analyzing the patterns of the fixed random matrices in the DFA. Finally, we propose the new training algorithm, binary direct feedback alignment (BDFA) to minimize the computational cost while maintaining the training accuracy compared with the DFA. In our experiments, we use the CIFAR-10 and CIFAR-100 dataset to simulate the CNN learning from the scratch and apply the BDFA to the online learning based object tracking application to examine the fully-connected layer (FC) fine-tuning task. Our proposed algorithms show better performance than conventional BP in both two different training tasks, but they have lighter computations for the error propagation. ", "keywords": ["Direct Feedback Alignment", "Convolutional Neural Network", "DNN Training"], "authorids": ["ICLR.cc/2019/Conference/Paper297/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fac0a0d64efd0cf6ba9dcf83b412d156b2779aa5.pdf", "paperhash": "anonymous|efficient_convolutional_neural_network_training_with_direct_feedback_alignment", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Convolutional Neural Network Training with Direct Feedback Alignment},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkGiPoC5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxnDoRcK7", "original": "ryx8T5_9Ym", "number": 298, "cdate": 1538087779672, "ddate": null, "tcdate": 1538087779672, "tmdate": 1538156200370, "tddate": null, "forum": "ryxnDoRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Estimating Heterogeneous Treatment Effects Using Neural Networks With The Y-Learner", "abstract": "We develop the Y-learner for estimating heterogeneous treatment effects in experimental and observational studies. The Y-learner is designed to leverage the abilities of neural networks to optimize multiple objectives and continually update, which allows for better pooling of underlying feature information between treatment and control groups. We evaluate the Y-learner on three test problems: (1) A set of six simulated data benchmarks from the literature. (2) A real-world large-scale experiment on voter persuasion. (3) A task from the literature that estimates artificially generated treatment effects on MNIST didgits. The Y-learner achieves state of the art results on two of the three tasks. On the MNIST task, it gets the second best results. ", "keywords": ["causal inference", "CATE estimation", "ITE", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper298/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a CATE estimation strategy that takes advantage some of the intriguing properties of neural networks. ", "pdf": "/pdf/3bed67b4ba82c3df9c5b0f860ba6202fa25556ac.pdf", "paperhash": "anonymous|estimating_heterogeneous_treatment_effects_using_neural_networks_with_the_ylearner", "_bibtex": "@inproceedings{    \nanonymous2019estimating,    \ntitle={Estimating Heterogeneous Treatment Effects Using Neural Networks With The Y-Learner},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxnDoRcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xnPsA5KX", "original": "B1lLG0DqKQ", "number": 299, "cdate": 1538087779842, "ddate": null, "tcdate": 1538087779842, "tmdate": 1538156200163, "tddate": null, "forum": "B1xnPsA5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Modular Deep Probabilistic Programming", "abstract": "Modularity is a key feature of deep learning libraries but has not been fully exploited for probabilistic programming. We propose to improve modularity of probabilistic programming language by offering not only plain probabilistic distributions but also sophisticated probabilistic model such as Bayesian non-parametric models as fundamental building blocks. We demonstrate this idea by presenting a modular probabilistic programming language MXFusion, which includes a new type of re-usable building blocks, called probabilistic modules. A probabilistic module consists of a set of random variables with associated probabilistic distributions and dedicated inference methods. Under the framework of variational inference, the pre-specified inference methods of individual probabilistic modules can be transparently used for inference of the whole probabilistic model. We demonstrate the power and convenience of probabilistic modules in MXFusion with various examples of Gaussian process models, which are evaluated with experiments on real data.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper299/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2060b15e3a209688624c854d9a0d2c04d4a368f0.pdf", "paperhash": "anonymous|modular_deep_probabilistic_programming", "_bibtex": "@inproceedings{    \nanonymous2019modular,    \ntitle={Modular Deep Probabilistic Programming},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xnPsA5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxnvsAqFm", "original": "HJxjwX_qtm", "number": 300, "cdate": 1538087780014, "ddate": null, "tcdate": 1538087780014, "tmdate": 1538156199950, "tddate": null, "forum": "SyxnvsAqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Computation-Efficient Quantization Method for Deep Neural Networks", "abstract": "Deep Neural Networks, being memory and computation intensive, are a challenge to deploy in smaller devices. Numerous quantization techniques have been proposed to reduce the inference latency/memory consumption. However, these techniques impose a large overhead on the training procedure or need to change the training process. We present a non-intrusive quantization technique based on re-training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. We also propose a new loss function to regularize the weights, resulting in reduced quantization error. Combining both help us achieve full precision accuracy on CIFAR dataset using binary quantization. We also achieve full precision accuracy on WikiText-2 using 2 bit quantization. Comparable results are also shown for ImageNet. We also present a 1.5 bits hybrid model exceeding the performance of TWN LSTM model for WikiText-2.", "keywords": ["quantization", "binary", "ternary", "flat minima", "model compression", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper300/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple computation-efficient quantization training method for CNNs and RNNs.", "pdf": "/pdf/035b990269d26f6ff03fb3598b4d8313d1d788e3.pdf", "paperhash": "anonymous|computationefficient_quantization_method_for_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019computation-efficient,    \ntitle={Computation-Efficient Quantization Method for Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxnvsAqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkM3vjCcF7", "original": "S1ezf3_ct7", "number": 301, "cdate": 1538087780189, "ddate": null, "tcdate": 1538087780189, "tmdate": 1538156199739, "tddate": null, "forum": "HkM3vjCcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-Scale Stacked Hourglass Network for Human Pose Estimation", "abstract": "Stacked hourglass network has become an important model for Human pose estimation. The estimation of human body posture depends on the global information of the keypoints type and the local information of the keypoints location. The consistent processing of inputs and constraints makes it difficult to form differentiated and determined collaboration mechanisms for each stacked hourglass network. In this paper, we propose a Multi-Scale Stacked Hourglass (MSSH) network to high-light the differentiation capabilities of each Hourglass network for human pose estimation.  The pre-processing network forms feature maps of different scales,and dispatch them to various locations of the stack hourglass network, where the small-scale features reach the front of stacked hourglass network, and large-scale features reach the rear of stacked hourglass network.   And a new loss function is proposed for multi-scale stacked hourglass network.  Different keypoints have different weight coefficients of loss function at different scales, and the keypoints weight coefficients are dynamically adjusted from the top-level hourglass network to the bottom-level hourglass network.  Experimental results show that the pro-posed method is competitive with respect to the comparison algorithm on MPII and LSP datasets.", "keywords": ["Human pose estimation", "Hourglass network", "Multi-scale analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper301/Authors"], "authors": ["Anonymous"], "TL;DR": "Differentiated inputs cause functional differentiation of the network, and the interaction of loss functions between networks can affect the optimization process.", "pdf": "/pdf/854b825cd9f150eaa922fa4d93ff6029a9d577a7.pdf", "paperhash": "anonymous|multiscale_stacked_hourglass_network_for_human_pose_estimation", "_bibtex": "@inproceedings{    \nanonymous2019multi-scale,    \ntitle={Multi-Scale Stacked Hourglass Network for Human Pose Estimation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkM3vjCcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkg2viA5FQ", "original": "rJga2n_cFm", "number": 302, "cdate": 1538087780373, "ddate": null, "tcdate": 1538087780373, "tmdate": 1538156199529, "tddate": null, "forum": "Bkg2viA5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hindsight policy gradients", "abstract": "A reinforcement learning agent that needs to pursue different goals across episodes requires a goal-conditional policy. In addition to their potential to generalize desirable behavior to unseen goals, such policies may also enable higher-level planning based on subgoals. In sparse-reward environments, the capacity to exploit information about the degree to which an arbitrary goal has been achieved while another goal was intended appears crucial to enable sample efficient learning. However, reinforcement learning agents have only recently been endowed with such capacity for hindsight. In this paper, we demonstrate how hindsight can be introduced to policy gradient methods, generalizing this idea to a broad class of successful algorithms. Our experiments on a diverse selection of sparse-reward environments show that hindsight leads to a remarkable increase in sample efficiency.", "keywords": ["reinforcement learning", "policy gradients", "multi-goal reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper302/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce the capacity to exploit information about the degree to which an arbitrary goal has been achieved while another goal was intended to policy gradient methods.", "pdf": "/pdf/f26705621d7951a5e0edde367cde5d1d241f6f62.pdf", "paperhash": "anonymous|hindsight_policy_gradients", "_bibtex": "@inproceedings{    \nanonymous2019hindsight,    \ntitle={Hindsight policy gradients},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg2viA5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Ske6wiAcKQ", "original": "rJePDX_qK7", "number": 303, "cdate": 1538087780549, "ddate": null, "tcdate": 1538087780549, "tmdate": 1538156199310, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["ICLR.cc/2019/Conference/Paper303/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "anonymous|realtime_neuralbased_input_method", "_bibtex": "@inproceedings{    \nanonymous2019real-time,    \ntitle={Real-time Neural-based Input Method},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Ske6wiAcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxpDiC5tX", "original": "r1gKk2Eqt7", "number": 304, "cdate": 1538087780724, "ddate": null, "tcdate": 1538087780724, "tmdate": 1538156199099, "tddate": null, "forum": "HJxpDiC5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": " Large-Scale Visual Speech Recognition", "abstract": "This work presents a scalable solution to open-vocabulary visual speech recognition. To achieve this, we constructed the largest existing visual speech recognition dataset, consisting of pairs of text and video clips of faces speaking (3,886 hours of video). In tandem, we designed and trained an integrated lipreading system, consisting of a video processing pipeline that maps raw video to stable videos of lips and sequences of phonemes, a scalable deep neural network that maps the lip videos to sequences of phoneme distributions, and a production-level speech decoder that outputs sequences of words. The proposed system achieves a word error rate (WER) of 40.9% as measured on a held-out set. In comparison, professional lipreaders achieve either 86.4% or 92.9% WER on the same dataset when having access to additional types of contextual information. Our approach significantly improves on other lipreading approaches, including variants of LipNet and of Watch, Attend, and Spell (WAS), which are only capable of 89.8% and 76.8% WER respectively.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper304/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5cd03b195ab08da2725b403c0a5acf2eb5b1ff8b.pdf", "paperhash": "anonymous|largescale_visual_speech_recognition", "_bibtex": "@inproceedings{    \nanonymous2019,    \ntitle={ Large-Scale Visual Speech Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxpDiC5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1fpDsAqt7", "original": "B1gJqb3FK7", "number": 305, "cdate": 1538087780906, "ddate": null, "tcdate": 1538087780906, "tmdate": 1538156198891, "tddate": null, "forum": "B1fpDsAqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visual Reasoning by Progressive Module Networks", "abstract": "Humans learn to solve tasks of increasing complexity by building on top of previously acquired knowledge. Typically, there exists a natural progression in the tasks that we learn \u2013 most do not require completely independent solutions, but can be broken down into simpler subtasks. We propose to represent a solver for each task as a neural module that calls existing modules (solvers for simpler tasks) in a functional program-like manner. Lower modules are a black box to the calling module, and communicate only via a query and an output. Thus, a module for a new task learns to query existing modules and composes their outputs in order to produce its own output. Our model effectively combines previous skill-sets, does not suffer from forgetting, and is fully differentiable. We test our model in learning a set of visual reasoning tasks, and demonstrate improved performances in all tasks by learning progressively. By evaluating the reasoning process using human judges, we show that our model is more interpretable than an attention-based baseline.\n", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper305/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/6dacef408df3517aa2e13d27aa1e7aaec299f2c0.pdf", "paperhash": "anonymous|visual_reasoning_by_progressive_module_networks", "_bibtex": "@inproceedings{    \nanonymous2019visual,    \ntitle={Visual Reasoning by Progressive Module Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1fpDsAqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkGTwjCctm", "original": "rygoMj_5Km", "number": 306, "cdate": 1538087781095, "ddate": null, "tcdate": 1538087781095, "tmdate": 1538156198684, "tddate": null, "forum": "HkGTwjCctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pyramid Recurrent Neural Networks for Multi-Scale Change-Point Detection", "abstract": "Many real-world time series, such as in activity recognition, finance, or climate science, have changepoints where the system's structure or parameters change. Detecting changes is important as they may indicate critical events. However, existing methods for changepoint detection face challenges when (1) the patterns of change cannot be modeled using simple and predefined metrics, and (2) changes can occur gradually, at multiple time-scales. To address this, we show how changepoint detection can be treated as a supervised learning problem, and propose a new deep neural network architecture that can efficiently identify both abrupt and gradual changes at multiple scales. Our proposed method, pyramid recurrent neural network (PRNN), is designed to be scale-invariant, by incorporating wavelets and pyramid analysis techniques from multi-scale signal processing. Through experiments on synthetic and real-world datasets, we show that PRNN can detect abrupt and gradual changes with higher accuracy than the state of the art and can extrapolate to detect changepoints at novel timescales that have not been seen in training.", "keywords": ["changepoint detection", "multivariate time series data", "multiscale RNN"], "authorids": ["ICLR.cc/2019/Conference/Paper306/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a scale-invariant neural network architecture for changepoint detection in multivariate time series.", "pdf": "/pdf/ec126c90063c4d2f7f9abf3faf1d753d2107c849.pdf", "paperhash": "anonymous|pyramid_recurrent_neural_networks_for_multiscale_changepoint_detection", "_bibtex": "@inproceedings{    \nanonymous2019pyramid,    \ntitle={Pyramid Recurrent Neural Networks for Multi-Scale Change-Point Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGTwjCctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJN6DiAcKQ", "original": "HygNL6ucKQ", "number": 307, "cdate": 1538087781269, "ddate": null, "tcdate": 1538087781269, "tmdate": 1538156198469, "tddate": null, "forum": "HJN6DiAcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Engaging Image Captioning Via Personality", "abstract": "Standard image captioning tasks such as COCO and Flickr30k are factual, neutral in tone and (to a human) state the obvious (e.g., \u201ca man playing a guitar\u201d). While such tasks are useful to verify that a machine understands the content of an image,  they are not engaging to humans as captions.   With this in mind we define a new task, Personality-Captions, where the goal is to be as engaging to humans as possible by incorporating controllable style and personality traits.We collect and release a large dataset of 201,858 of such captions conditioned over 215 possible traits.  We build models that combine existing work from (i) sentence representations (Mazar\u00e9 et al., 2018) with Transformers trained on 1.7 billion dialogue examples; and (ii) image representations (Mahajan et al., 2018) with ResNets trained on 3.5 billion social media images.  We obtain state-of-the-art performance on Flickr30k and COCO, and strong performance on our new task. Finally, online evaluations validate that our task and models are engaging to humans, with our best model close to human performance.", "keywords": ["image", "captioning", "captions", "vision", "language"], "authorids": ["ICLR.cc/2019/Conference/Paper307/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop engaging image captioning models conditioned on personality that are also state of the art on regular captioning tasks.", "pdf": "/pdf/54bbd4c01aa9aa7912080d66be76b904448d6fa1.pdf", "paperhash": "anonymous|engaging_image_captioning_via_personality", "_bibtex": "@inproceedings{    \nanonymous2019engaging,    \ntitle={Engaging Image Captioning Via Personality},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJN6DiAcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkE6PjC9KX", "original": "S1egsd7FY7", "number": 308, "cdate": 1538087781445, "ddate": null, "tcdate": 1538087781445, "tmdate": 1538156198262, "tddate": null, "forum": "SkE6PjC9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Attentive Neural Processes", "abstract": "Neural Processes (NPs) (Garnelo et al., 2018) approach regression by learning to map a context set of observed input-output pairs to a distribution over regression functions. Each function models the distribution of the output given an input, conditioned on the context. NPs have the benefit of fitting observed data efficiently with linear complexity in the number of context input-output pairs, and can learn a wide family of conditional distributions; they learn predictive distributions conditioned on context sets of arbitrary size. Nonetheless, we show that NPs suffer a fundamental drawback of underfitting, giving inaccurate predictions at the inputs of the observed data they condition on. We address this issue by incorporating attention into NPs, allowing each input location to attend to the relevant context points for the prediction. We show that this greatly improves the accuracy of predictions, results in noticeably faster training, and expands the range of functions that can be modelled. ", "keywords": ["Neural Processes", "Conditional Neural Processes", "Stochastic Processes", "Regression", "Attention"], "authorids": ["ICLR.cc/2019/Conference/Paper308/Authors"], "authors": ["Anonymous"], "TL;DR": "A model for regression that learns conditional distributions of a stochastic process, by incorporating attention into Neural Processes.", "pdf": "/pdf/076ff3e8015451c8c8bc178207e06157024171b8.pdf", "paperhash": "anonymous|attentive_neural_processes", "_bibtex": "@inproceedings{    \nanonymous2019attentive,    \ntitle={Attentive Neural Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkE6PjC9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byg0DsCqYQ", "original": "SJe8Ucwqt7", "number": 309, "cdate": 1538087781618, "ddate": null, "tcdate": 1538087781618, "tmdate": 1538156198053, "tddate": null, "forum": "Byg0DsCqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RoC-GAN: Robust Conditional GAN", "abstract": "Conditional generative adversarial networks (cGAN) have led to large improvements in the task of conditional image generation, which lies at the heart of computer vision. The major focus so far has been on performance improvement, while there has been little effort in making cGAN more robust to noise or leveraging structure in the output space of the model. The end-to-end regression (of the generator) might lead to arbitrarily large errors in the output, which is unsuitable for the application of such networks to real-world systems. In this work, we introduce a novel conditional GAN model, called RoC-GAN, which adds implicit constraints to address the issue. Our model augments the generator with an unsupervised pathway, which promotes the outputs of the generator to span the target manifold even in the presence of large amounts of noise. We prove that RoC-GAN share similar theoretical properties as GAN and experimentally verify that our model outperforms existing state-of-the-art cGAN architectures by a large margin in a variety of domains including images from natural scenes and faces.", "keywords": ["conditional GAN", "unsupervised pathway", "autoencoder"], "authorids": ["ICLR.cc/2019/Conference/Paper309/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a new type of conditional GAN, which aims to leverage structure in the target space of the generator. We augment the generator with a new, unsupervised pathway to learn the target structure. ", "pdf": "/pdf/f6fc003c48bca03d08054111b1e02304c0447de1.pdf", "paperhash": "anonymous|rocgan_robust_conditional_gan", "_bibtex": "@inproceedings{    \nanonymous2019roc-gan:,    \ntitle={RoC-GAN: Robust Conditional GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byg0DsCqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lADsCcFQ", "original": "ryxI59StFm", "number": 310, "cdate": 1538087781790, "ddate": null, "tcdate": 1538087781790, "tmdate": 1538156197415, "tddate": null, "forum": "H1lADsCcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LEARNING ADVERSARIAL EXAMPLES WITH RIEMANNIAN GEOMETRY", "abstract": "Adversarial examples, referred to as augmented data points generated by imperceptible perturbation of input samples, have recently drawn much attention. Well-crafted adversarial examples may even mislead state-of-the-art deep models to make wrong predictions easily. To alleviate this problem, many studies focus on investigating how adversarial examples can be generated and/or resisted. All the existing work handles this problem in the Euclidean space, which may however be unable to describe data geometry. In this paper, we propose a generalized framework that addresses the learning problem of adversarial examples with Riemannian geometry. Specifically, we define the local coordinate systems on Riemannian manifold, develop a novel model called Adversarial Training with Riemannian Manifold, and design a series of theory that manages to learn the adversarial examples in the Riemannian space feasibly and efficiently. The proposed work is important in that (1) it is a generalized learning methodology since Riemmanian manifold space would be degraded to the Euclidean space in a special case; (2) it is the first work to tackle the adversarial example problem tractably through the perspective of geometry; (3) from the perspective of geometry, our method leads to the steepest direction of the loss function. We also provide a series of theory showing that our proposed method can truly find the decent direction for the loss function with a comparable computational time against traditional adversarial methods. Finally, the proposed framework demonstrates superior performance to the traditional counterpart methods on benchmark data including MNIST, CIFAR-10 and SVHN.", "keywords": ["Adversarial training", "Adversarial examples", "Riemannian Geometry", "Machine Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper310/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/10afb3bee37d9afd310eaff0d26a31ef6f8c9f40.pdf", "paperhash": "anonymous|learning_adversarial_examples_with_riemannian_geometry", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={LEARNING ADVERSARIAL EXAMPLES WITH RIEMANNIAN GEOMETRY},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lADsCcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJG0voC9YQ", "original": "BkxG7daDtm", "number": 311, "cdate": 1538087781962, "ddate": null, "tcdate": 1538087781962, "tmdate": 1538156196907, "tddate": null, "forum": "BJG0voC9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search", "abstract": "Learning policies on data synthesized by models can in principle quench the thirst of reinforcement learning algorithms for large amounts of real experience, which is often costly to acquire. However, simulating plausible experience de novo is a hard problem for many complex environments, often resulting in biases for model-based policy evaluation and search. Instead of de novo synthesis of data, here we assume logged, real experience and model alternative outcomes of this experience under counterfactual actions, i.e. actions that were not actually taken. Based on this, we propose the Counterfactually-Guided Policy Search (CF-GPS) algorithm for learning policies in POMDPs from off-policy experience. It leverages structural causal models for counterfactual evaluation of arbitrary policies on individual off-policy episodes. CF-GPS can improve on vanilla model-based RL algorithms by making use of available logged data to de-bias model predictions. In contrast to off-policy algorithms based on Importance Sampling which re-weight data, CF-GPS leverages a model to explicitly consider alternative outcomes, allowing the algorithm to make better use of experience data. We find empirically that these advantages translate into improved policy evaluation and search results on a non-trivial grid-world task. Finally, we show that CF-GPS generalizes the previously proposed Guided Policy Search and that reparameterization-based algorithms such Stochastic Value Gradient can be interpreted as counterfactual methods.", "keywords": ["reinforcement learning", "generative models", "model-based reinforcement learning", "causal inference"], "authorids": ["ICLR.cc/2019/Conference/Paper311/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a9799de1625b5b91e6b3d4bd7e295bd4f4d753ea.pdf", "paperhash": "anonymous|woulda_coulda_shoulda_counterfactuallyguided_policy_search", "_bibtex": "@inproceedings{    \nanonymous2019woulda,,    \ntitle={Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJG0voC9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMRvsAcK7", "original": "r1xC2LhvYQ", "number": 312, "cdate": 1538087782131, "ddate": null, "tcdate": 1538087782131, "tmdate": 1538156196268, "tddate": null, "forum": "HJMRvsAcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning", "abstract": "Dynamic pricing problem has been studied for decades and varieties of methodologies were developed under different assumptions. We developed an approach based on deep reinforcement learning (DRL) to address the dynamic pricing problem on an E-commerce platform with few assumptions. This paper first modeled dynamic pricing as a Markov Decision Process, defined various reward functions, with both discrete and continuous pricing action space. And then it introduced the methods to pre-train the model with the historical sales data. Offline evaluations and field experiments were designed and conducted to validate our approach. ", "keywords": ["reinforcement learning", "dynamic pricing", "e-commerce", "revenue management", "field experiment"], "authorids": ["ICLR.cc/2019/Conference/Paper312/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper describes a methodology for pre-training, evaluating and online dynamic pricing on E-commerce platform using deep reinforcement learning.", "pdf": "/pdf/d2f6f55abc10512db37d72e599b0ab24a7de7c3a.pdf", "paperhash": "anonymous|dynamic_pricing_on_ecommerce_platform_with_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMRvsAcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "By40DoAqtX", "original": "Hyxb6Qb5FX", "number": 313, "cdate": 1538087782306, "ddate": null, "tcdate": 1538087782306, "tmdate": 1538156195788, "tddate": null, "forum": "By40DoAqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Discriminators as Energy Networks in Adversarial Learning", "abstract": "We propose a novel framework for structured prediction via adversarial learning. Existing adversarial learning methods involve two separate networks, i.e., the structured prediction models and the discriminative models, in the training. The information captured by discriminative models complements that in the structured prediction models, but few existing researches have studied on utilizing such information to improve structured prediction models at the inference stage. In this work, we propose to refine the predictions of structured prediction models by effectively integrating discriminative models into the prediction. Discriminative models are treated as energy-based models. Similar to the adversarial learning, discriminative models are trained to estimate scores which measure the quality of predicted outputs, while structured prediction models are trained to predict contrastive outputs with maximal energy scores. In this way, the gradient vanishing problem is ameliorated, and thus we are able to perform inference by following the ascent gradient directions of discriminative models to refine structured prediction models. The proposed method is able to handle a range of tasks, \\emph{e.g.}, multi-label classification and image segmentation.  Empirical results on these two tasks validate the effectiveness of our learning method.", "keywords": ["adversarial learning", "structured prediction", "energy networks"], "authorids": ["ICLR.cc/2019/Conference/Paper313/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel adversarial learning framework for structured prediction, in which discriminative models can be used to refine structured prediction models at the inference stage. ", "pdf": "/pdf/a2532b9979c58ecbe0549950bb2388e91a472487.pdf", "paperhash": "anonymous|learning_discriminators_as_energy_networks_in_adversarial_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Discriminators as Energy Networks in Adversarial Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=By40DoAqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgRDjR9tQ", "original": "HJecFTGYKX", "number": 314, "cdate": 1538087782473, "ddate": null, "tcdate": 1538087782473, "tmdate": 1538156195304, "tddate": null, "forum": "BJgRDjR9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ROBUST ESTIMATION VIA GENERATIVE ADVERSARIAL NETWORKS", "abstract": "Robust estimation under Huber's $\\epsilon$-contamination model has become an important topic in statistics and theoretical computer science. Rate-optimal procedures such as Tukey's median and other estimators based on statistical depth functions are impractical because of their computational intractability. In this paper, we establish an intriguing connection between f-GANs and various depth functions through the lens of f-Learning. Similar to the derivation of f-GAN, we show that these depth functions that lead to rate-optimal robust estimators can all be viewed as variational lower bounds of the total variation distance in the framework of f-Learning. This connection opens the door of computing robust estimators using tools developed for training GANs. In particular, we show that a JS-GAN that uses a neural network discriminator with at least one hidden layer is able to achieve the minimax rate of robust mean estimation under Huber's $\\epsilon$-contamination model. Interestingly, the hidden layers of the neural net structure in the discriminator class are shown to be necessary for robust estimation.", "keywords": ["robust statistics", "neural networks", "minimax rate", "data depth", "contamination model", "Tukey median", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper314/Authors"], "authors": ["Anonymous"], "TL;DR": "GANs are shown to provide us a new effective robust mean estimate against agnostic contaminations with both statistical optimality and practical tractability.", "pdf": "/pdf/75cf2004f502997760acb77f481b936e1d5c03d0.pdf", "paperhash": "anonymous|robust_estimation_via_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019robust,    \ntitle={ROBUST ESTIMATION VIA GENERATIVE ADVERSARIAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgRDjR9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gJOoRcYQ", "original": "HkeIkWO5KX", "number": 315, "cdate": 1538087782646, "ddate": null, "tcdate": 1538087782646, "tmdate": 1538156194782, "tddate": null, "forum": "B1gJOoRcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "S3TA: A Soft, Spatial, Sequential, Top-Down Attention Model", "abstract": "We present a soft, spatial, sequential, top-down attention model (S3TA). This model uses a soft attention mechanism to bottleneck its view of the input. A recurrent core is used to generate query vectors, which actively select information from the input by correlating the query with input- and space-dependent key maps at different spatial locations.\n\nWe demonstrate the power and interpretabilty of this model under two settings. First, we build an agent which uses this attention model in RL environments and show that we can achieve performance competitive with state-of-the-art models while producing attention maps that elucidate some of the strategies used to solve the task. Second, we use this model in supervised learning tasks and show that it also achieves competitive performance and provides interpretable attention maps that show some of the underlying logic in the model's decision making.", "keywords": ["Attention", "RL", "Top-Down", "Interpretability"], "authorids": ["ICLR.cc/2019/Conference/Paper315/Authors"], "authors": ["Anonymous"], "TL;DR": "http://sites.google.com/view/s3ta", "pdf": "/pdf/8925c49fdc581efc402d85b3f37880978291dcaf.pdf", "paperhash": "anonymous|s3ta_a_soft_spatial_sequential_topdown_attention_model", "_bibtex": "@inproceedings{    \nanonymous2019s3ta:,    \ntitle={S3TA: A Soft, Spatial, Sequential, Top-Down Attention Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gJOoRcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryekdoCqF7", "original": "r1l7-n9YKX", "number": 316, "cdate": 1538087782815, "ddate": null, "tcdate": 1538087782815, "tmdate": 1538156194573, "tddate": null, "forum": "ryekdoCqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Incremental training of multi-generative adversarial networks", "abstract": "Generative neural networks map a standard, possibly distribution to a complex high-dimensional distribution, which represents the real world data set. However, a determinate input distribution as well as a specific architecture of neural networks may impose limitations on capturing the diversity in the high dimensional target space. To resolve this difficulty, we propose a training framework that greedily produce a series of generative adversarial networks that incrementally capture the diversity of the target space. We show theoretically and empirically that our training algorithm converges to the theoretically optimal distribution, the projection of the real distribution onto the convex hull of the network's distribution space.", "keywords": ["GAN", "Incremental training", "Information projection", "Mixture distribution"], "authorids": ["ICLR.cc/2019/Conference/Paper316/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new method to incrementally train a mixture generative model to approximate the information projection of the real data distribution.", "pdf": "/pdf/ba6cab96ae7bf3f7acc2539d7df2d02dad925b52.pdf", "paperhash": "anonymous|incremental_training_of_multigenerative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019incremental,    \ntitle={Incremental training of multi-generative adversarial networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryekdoCqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyG1_j0cYQ", "original": "H1eog46PK7", "number": 317, "cdate": 1538087782990, "ddate": null, "tcdate": 1538087782990, "tmdate": 1538156194368, "tddate": null, "forum": "HyG1_j0cYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pumpout: A Meta Approach for Robustly Training Deep Neural Networks with Noisy Labels", "abstract": "It is challenging to train deep neural networks robustly on the industrial-level data, since labels of such data are heavily noisy, and their label generation processes are normally agnostic. To handle these issues, by using the memorization effects of deep neural networks, we may train deep neural networks on the whole dataset only the first few iterations. Then, we may employ early stopping or the small-loss trick to train them on selected instances. However, in such training procedures, deep neural networks inevitably memorize some noisy labels, which will degrade their generalization. In this paper, we propose a meta algorithm called Pumpout to overcome the problem of memorizing noisy labels. By using scaled stochastic gradient ascent, Pumpout actively squeezes out the negative effects of noisy labels from the training model, instead of passively forgetting these effects. We leverage Pumpout to upgrade two representative methods: MentorNet and Backward Correction. Empirical results on benchmark datasets demonstrate that Pumpout can significantly improve the robustness of representative methods.", "keywords": ["Noisy Labels", "Deep Learning", "Meta Approach"], "authorids": ["ICLR.cc/2019/Conference/Paper317/Authors"], "authors": ["Anonymous"], "TL;DR": "Starting from tomorrow, never worry about your DNNs memorizing noisy labels---forget bad labels by Pumpout in an active manner!", "pdf": "/pdf/96a36984d88716fdaec01ffcb2d68a3fb8eaaa61.pdf", "paperhash": "anonymous|pumpout_a_meta_approach_for_robustly_training_deep_neural_networks_with_noisy_labels", "_bibtex": "@inproceedings{    \nanonymous2019pumpout:,    \ntitle={Pumpout: A Meta Approach for Robustly Training Deep Neural Networks with Noisy Labels},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyG1_j0cYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJl1ujCct7", "original": "ryxiyLhYu7", "number": 318, "cdate": 1538087783160, "ddate": null, "tcdate": 1538087783160, "tmdate": 1538156194151, "tddate": null, "forum": "HJl1ujCct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Multi-modal one-class generative adversarial network for anomaly detection in manufacturing", "abstract": "One class anomaly detection on high-dimensional data is one of the critical issue in both fundamental machine learning research area and manufacturing applica- tions. A good anomaly detection should accurately discriminate anomalies from normal data. Although most previous anomaly detection methods achieve good performances, they do not perform well on high-dimensional imbalanced data- set 1) with a limited amount of data; 2) multi-modal distribution; 3) few anomaly data. In this paper, we develop a multi-modal one-class generative adversarial net- work based detector (MMOC-GAN) to distinguish anomalies from normal data (products). Apart from a domain-specific feature extractor, our model leverage a generative adversarial network(GAN). The generator takes in a modified noise vector using a pseudo latent prior and generate samples at the low-density area of the given normal data to simulate the anomalies. The discriminator then is trained to distinguish the generate samples from the normal samples. Since the generated samples simulate the low density area for each modal, the discriminator could directly detect anomalies from normal data. Experiments demonstrate that our model outperforms the state-of-the-art one-class classification models and other anomaly detection methods on both normal data and anomalies accuracy, as well as the F1 score. Also, the generated samples can fully capture the low density area of different types of products.\n", "keywords": ["Anomaly detection", "one-class model", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper318/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/940902a9f1f46b99c9c58e207d5f3fce5b96a4ef.pdf", "paperhash": "anonymous|a_multimodal_oneclass_generative_adversarial_network_for_anomaly_detection_in_manufacturing", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Multi-modal one-class generative adversarial network for anomaly detection in manufacturing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJl1ujCct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hylyui09tm", "original": "Hyeh0Iy9K7", "number": 319, "cdate": 1538087783333, "ddate": null, "tcdate": 1538087783333, "tmdate": 1538156193943, "tddate": null, "forum": "Hylyui09tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "EMI: Exploration with Mutual Information Maximizing State and Action Embeddings", "abstract": "Policy optimization struggles when the reward feedback signal is very sparse and essentially becomes a random search algorithm until the agent stumbles upon a rewarding or the goal state. Recent works utilize intrinsic motivation to guide the exploration via generative models, predictive forward models, or more ad-hoc measures of surprise. We propose EMI, which is an exploration method that constructs embedding representation of states and actions that does not rely on generative decoding of the full observation but extracts predictive signals that can be used to guide exploration based on forward prediction in the representation space. Our experiments show the state of the art performance on challenging locomotion task with continuous control and on image-based exploration tasks with discrete actions on Atari.", "keywords": ["reinforcement learning", "exploration", "representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper319/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1171ff1053b768c3b05c9318bc0445abb8ac0748.pdf", "paperhash": "anonymous|emi_exploration_with_mutual_information_maximizing_state_and_action_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019emi:,    \ntitle={EMI: Exploration with Mutual Information Maximizing State and Action Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hylyui09tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxJus0cFX", "original": "BJgO3UGFFm", "number": 320, "cdate": 1538087783508, "ddate": null, "tcdate": 1538087783508, "tmdate": 1538156193732, "tddate": null, "forum": "rkxJus0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RedSync : Reducing Synchronization Traffic for Distributed Deep Learning", "abstract": "Data parallelism has become a dominant method to scale Deep Neural Network (DNN) training across multiple nodes.  Since the synchronization of the local models or gradients can be a bottleneck for large-scale distributed training, compressing communication traffic has gained widespread attention recently.  Among several recent proposed compression algorithms, \nResidual Gradient Compression (RGC) is one of the most successful approaches---it can significantly compress the transmitting message size (0.1% of the gradient size) of each node and still preserve accuracy. However, the literature on compressing deep networks focuses almost exclusively on achieving good compression rate, while the efficiency of RGC in real implementation has been less investigated. In this paper, we develop an RGC method that achieves significant training time improvement in real-world multi-GPU systems. Our proposed RGC system design called RedSync, introduces a set of optimizations to reduce communication bandwidth while introducing limited overhead. We examine the performance of RedSync on two different multiple GPU platforms, including a supercomputer and a multi-card server. Our test cases include image classification on Cifar10 and ImageNet, and language modeling tasks on Penn Treebank and Wiki2 datasets. For DNNs featured with high communication to computation ratio, which has long been considered with poor scalability, RedSync shows significant performance improvement.", "keywords": ["Data parallel", "Deep Learning", "Multiple GPU system", "Communication Compression", "Sparsification", "Quantization"], "authorids": ["ICLR.cc/2019/Conference/Paper320/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed an implementation to accelerate DNN data parallel training by reducing communication bandwidth requirement.", "pdf": "/pdf/86315f9a2f989e5fd7a4e26fed9f84dc9ab08e0b.pdf", "paperhash": "anonymous|redsync_reducing_synchronization_traffic_for_distributed_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019redsync,    \ntitle={RedSync : Reducing Synchronization Traffic for Distributed Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxJus0cFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJlgOjAqYQ", "original": "BJgYzDd5KQ", "number": 321, "cdate": 1538087783690, "ddate": null, "tcdate": 1538087783690, "tmdate": 1538156193522, "tddate": null, "forum": "SJlgOjAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A quantifiable testing of global translational invariance in Convolutional and Capsule Networks", "abstract": " We design simple and quantifiable testing of global translation-invariance in deep learning models trained on the MNIST dataset. Experiments on convolutional and capsules neural networks show that both models have poor performance in dealing with global translation-invariance; however, the performance improved by using data augmentation. Although the capsule network is better on the MNIST testing dataset, the convolutional neural network generally has better performance on the translation-invariance.", "keywords": ["Translational invariance", "CNN", "Capsule Network"], "authorids": ["ICLR.cc/2019/Conference/Paper321/Authors"], "authors": ["Anonymous"], "TL;DR": "Testing of global translational invariance in Convolutional and Capsule Networks", "pdf": "/pdf/1452b1e4370e690b624a123154fd502b39b9db06.pdf", "paperhash": "anonymous|a_quantifiable_testing_of_global_translational_invariance_in_convolutional_and_capsule_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A quantifiable testing of global translational invariance in Convolutional and Capsule Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlgOjAqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1ledo0ctX", "original": "rylhE3UcF7", "number": 322, "cdate": 1538087783870, "ddate": null, "tcdate": 1538087783870, "tmdate": 1538156193316, "tddate": null, "forum": "r1ledo0ctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Consistency-based anomaly detection with adaptive multiple-hypotheses predictions", "abstract": "In out-of-distribution classification tasks, only some classes - the normal cases - can be modeled with data, whereas the variation of all possible anomalies is too large to be described sufficiently by samples. Thus, the wide-spread discriminative approaches cannot cover such learning tasks and rather generative models, which attempt to learn the input density of the ordinary cases, are used. However, generative models suffer under a large input dimensionality (as in images) and are typically inefficient learners. Motivated by the Local-Outlier-Factor (LOF) method, in this work, we propose to allow the network to directly estimate the local density functions since, for the detection of outliers, the local neighborhood is more important than the global one. At the same time, we retain consistency in the sense that the model must not support areas of the input space that are not covered by samples. Our method allows the model to identify out-of-distribution samples reliably. For the anomaly detection task on CIFAR-10, our ConAD model results in up to 5% points improvement over previously reported results. ", "keywords": ["Anomaly detection", "outlier detection", "generative models", "VAE", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper322/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an anomaly-detection approach that combines modeling the foreground class via multiple local densities with adversarial training.", "pdf": "/pdf/4c2f58ea958e2faaf8c347ea1775651eecaa8fa9.pdf", "paperhash": "anonymous|consistencybased_anomaly_detection_with_adaptive_multiplehypotheses_predictions", "_bibtex": "@inproceedings{    \nanonymous2019consistency-based,    \ntitle={Consistency-based anomaly detection with adaptive multiple-hypotheses predictions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1ledo0ctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkMx_iC9K7", "original": "HkgMU1u9K7", "number": 323, "cdate": 1538087784049, "ddate": null, "tcdate": 1538087784049, "tmdate": 1538156193111, "tddate": null, "forum": "SkMx_iC9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DelibGAN: Coarse-to-Fine Text Generation via Adversarial Network", "abstract": "In this paper, we propose a novel adversarial learning framework, namely DelibGAN, for generating high-quality sentences without supervision. Our framework consists of a coarse-to-fine generator, which contains a first-pass decoder and a second-pass decoder, and a multiple instance discriminator. And we propose two training mechanisms DelibGAN-I and DelibGAN-II. The discriminator is used to fine-tune the second-pass decoder in DelibGAN-I and further evaluate the importance of each word and tune the first-pass decoder in DelibGAN-II. We compare our models with several typical and state-of-the-art unsupervised generic text generation models on three datasets (a synthetic dataset, a descriptive text dataset and a sentimental text dataset). Both qualitative and quantitative experimental results show that our models produce more realistic samples, and DelibGAN-II performs best.", "keywords": ["unsupervised text generation", "coarse-to-fine generator", "multiple instance discriminator", "GAN", "DelibGAN"], "authorids": ["ICLR.cc/2019/Conference/Paper323/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel adversarial learning framework, namely DelibGAN, is proposed for generating high-quality sentences without supervision.", "pdf": "/pdf/b5b08afed1fa2473c2a8db2feedd59ae47035382.pdf", "paperhash": "anonymous|delibgan_coarsetofine_text_generation_via_adversarial_network", "_bibtex": "@inproceedings{    \nanonymous2019delibgan:,    \ntitle={DelibGAN: Coarse-to-Fine Text Generation via Adversarial Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkMx_iC9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJfguoAcFm", "original": "S1epDySFKQ", "number": 324, "cdate": 1538087784223, "ddate": null, "tcdate": 1538087784223, "tmdate": 1538156192889, "tddate": null, "forum": "BJfguoAcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Kolmogorov Models for Binary Random Variables", "abstract": "We propose a framework for learning a Kolmogorov model, for a collection of binary random variables. More specifically, we derive conditions that link (in the sense of implications in mathematical logic) outcomes of specific random variables and extract valuable relations from the data. We also propose an efficient algorithm for computing the model and show its first-order optimality, despite the combinatorial nature of the learning problem. We exemplify our general framework to recommendation systems and gene expression data. We believe that the work is a significant step toward interpretable machine learning. ", "keywords": ["Kolmogorov model", "interpretable models", "causal relations mining", "non-convex optimization", "relaxations"], "authorids": ["ICLR.cc/2019/Conference/Paper324/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c3f2aab0c444f143b0cc538921775d41ee5a5b47.pdf", "paperhash": "anonymous|learning_kolmogorov_models_for_binary_random_variables", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Kolmogorov Models for Binary Random Variables},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfguoAcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1Vx_oA5YQ", "original": "HJgBkGK9YX", "number": 325, "cdate": 1538087784411, "ddate": null, "tcdate": 1538087784411, "tmdate": 1538156192684, "tddate": null, "forum": "r1Vx_oA5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Integrated Steganography and Steganalysis with Generative Adversarial Networks", "abstract": "Recently, generative adversarial network is the hotspot in research areas and industrial application areas. It's application on data generation in computer vision is most common usage. This paper extends its application to data hiding and security area. In this paper, we propose the novel framework to integrate steganography and steganalysis processes. The proposed framework applies generative adversarial networks as the core structure. The discriminative model simulate the steganalysis process, which can help us understand the sensitivity of cover images to semantic changes. The steganography generative model is to generate stego image which is aligned with the original cover image, and attempts to confuse steganalysis discriminative model. The introduction of cycle discriminative model and inconsistent loss can help to enhance the quality and security of generated stego image in the iterative training process. Training dataset is mixed with intact images as well as intentional attacked images. The mix training process can further improve the robustness and security of new framework. Through the qualitative, quantitative experiments and analysis, this novel framework shows compelling performance and advantages over the current state-of-the-art methods in steganography and steganalysis benchmarks.", "keywords": ["Steganography", "Steganography", "Security", "Generative Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper325/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b1858beeffc56c339c681852e391f3e87fa7db7d.pdf", "paperhash": "anonymous|integrated_steganography_and_steganalysis_with_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019integrated,    \ntitle={Integrated Steganography and Steganalysis with Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1Vx_oA5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkl-di09FQ", "original": "HyxmsyucYm", "number": 326, "cdate": 1538087784580, "ddate": null, "tcdate": 1538087784580, "tmdate": 1538156192477, "tddate": null, "forum": "Hkl-di09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics", "abstract": "Scaling end-to-end reinforcement learning to control real robots from vision presents a series of challenges, in particular in terms of sample efficiency. Against end-to-end learning, state representation learning can help learn a compact, efficient and relevant representation of states that speeds up policy learning, reducing the number of samples needed, and that is easier to interpret. We evaluate several state representation learning methods on goal based robotics tasks and propose a new unsupervised model that stacks representations and combines strengths of several of these approaches. This method encodes all the relevant features, performs on par or better than end-to-end learning, and is robust to hyper-parameters change.", "keywords": ["reinforcement learning", "state representation learning", "feature extraction", "robotics", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper326/Authors"], "authors": ["Anonymous"], "TL;DR": "We evaluate the benefits of decoupling feature extraction from policy learning in robotics and propose a new way of combining state representation learning methods.", "pdf": "/pdf/3c5dd9f78ffa9cd7cb66fc623504b2d603482434.pdf", "paperhash": "anonymous|decoupling_feature_extraction_from_policy_learning_assessing_benefits_of_state_representation_learning_in_goal_based_robotics", "_bibtex": "@inproceedings{    \nanonymous2019decoupling,    \ntitle={Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkl-di09FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxZdj09tX", "original": "BygnC_L-F7", "number": 327, "cdate": 1538087784756, "ddate": null, "tcdate": 1538087784756, "tmdate": 1538156192267, "tddate": null, "forum": "ByxZdj09tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "REVERSED NEURAL NETWORK - AUTOMATICALLY FINDING NASH EQUILIBRIUM", "abstract": "Contrary to most reinforcement learning studies emphasizing on approximating the output layer of a neural network to certain strategies, this paper proposes a reversed way for reinforcement learning. We call this \u201cReversed Neural Network\u201d. In short, after sufficiently training a canonical deep feed-forward neural network according to a strategy-and-environment-to-payoff table, we randomize part of the neurons in the input layer and propagate the error between the generated output and the desired output back to the part of the neurons in the \u201cinput layer\u201d of the trained deep neural network recurrently. And we view the final neurons in the \u201cinput layer\u201d as the fittest strategy for a neural network.", "keywords": ["Reinforcement Learning", "Deep Feed-forward Neural Network", "Game Theory", "Control Theory"], "authorids": ["ICLR.cc/2019/Conference/Paper327/Authors"], "authors": ["Anonymous"], "TL;DR": "REVERSED NEURAL NETWORK - A PRIMAL", "pdf": "/pdf/641943da559e7d93f1dcffa3a814aa400e4b6200.pdf", "paperhash": "anonymous|reversed_neural_network_automatically_finding_nash_equilibrium", "_bibtex": "@inproceedings{    \nanonymous2019reversed,    \ntitle={REVERSED NEURAL NETWORK - AUTOMATICALLY FINDING NASH EQUILIBRIUM},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxZdj09tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJeWOi09FQ", "original": "B1ezOXF9KX", "number": 328, "cdate": 1538087784928, "ddate": null, "tcdate": 1538087784928, "tmdate": 1538156192059, "tddate": null, "forum": "BJeWOi09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SHAMANN: Shared Memory Augmented Neural Networks", "abstract": "Current state-of-the-art methods for semantic segmentation use deep neural networks to learn the segmentation mask from the input image signal as an image-to-image mapping. While these methods effectively exploit global image context, the learning and computational complexities are high. We propose shared memory augmented neural network actors as a dynamically scalable alternative. Based on a decomposition of the image into a sequence of local patches, we train such actors to sequentially segment each patch. To further increase the robustness and better capture shape priors, an external memory module is shared between different actors, providing an implicit mechanism for image information exchange. Finally, the patch-wise predictions are aggregated to a complete segmentation mask. We demonstrate the benefits of the new paradigm on a challenging lung segmentation problem based on chest X-Ray images, as well as on two synthetic tasks based on the MNIST dataset. On the X-Ray data, our method achieves state-of-the-art accuracy with a significantly reduced model size compared to reference methods. In addition, we reduce the number of failure cases by at least half.", "keywords": ["memory networks", "deep learning", "medical image segmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper328/Authors"], "authors": ["Anonymous"], "TL;DR": "Multiple virtual actors cooperating through shared memory solve medical image segmentation.", "pdf": "/pdf/45eafa16ba64ffffd3a5f0aa884a777fb69fcde6.pdf", "paperhash": "anonymous|shamann_shared_memory_augmented_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019shamann:,    \ntitle={SHAMANN: Shared Memory Augmented Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeWOi09FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxZOsA9tX", "original": "BJePSQ-KFX", "number": 329, "cdate": 1538087785095, "ddate": null, "tcdate": 1538087785095, "tmdate": 1538156191853, "tddate": null, "forum": "SyxZOsA9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Accelerated Value Iteration via Anderson Mixing", "abstract": "Accelerating reinforcement learning methods is an important and challenging topic. We introduce the Anderson acceleration technique into the value iteration and develop an accelerated value iteration algorithm Anderson Accelerated Value Iteration (A2VI). We further apply our method to Deep Q-learning algorithm and propose Deep Anderson Accelerated Q-learning (DA2Q) algorithm. Our approach can be viewed as an approximation of the policy evaluation by interpolating on historical data. A2VI is more efficient than classical modified policy iteration methods. We provide a theoretical analysis of our algorithm and conduct experiments on both toy problems and Atari games. Both the theoretical and empirical results demonstrate the effectiveness of our algorithm. ", "keywords": ["Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper329/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8c2a67a306ee5075d8bc769656d39de5fbbc60fd.pdf", "paperhash": "anonymous|accelerated_value_iteration_via_anderson_mixing", "_bibtex": "@inproceedings{    \nanonymous2019accelerated,    \ntitle={Accelerated Value Iteration via Anderson Mixing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxZOsA9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeWdiR5Ym", "original": "HJlFWEKctm", "number": 330, "cdate": 1538087785266, "ddate": null, "tcdate": 1538087785266, "tmdate": 1538156191645, "tddate": null, "forum": "ByeWdiR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Convolutional Neural Networks", "abstract": "The quest for increased visual recognition performance has led to the development of highly complex neural networks with very deep topologies. To avoid high computing resource requirements of such complex networks and to enable operation on devices with limited resources, this paper introduces adaptive kernels for convolutional layers. Motivated by the non-linear perception response in human visual cells, the input image is used to define the weights of a dynamic kernel called Adaptive kernel. This new adaptive kernel is used to perform a second convolution of the input image generating the output pixel. Adaptive kernels enable accurate recognition with lower memory requirements; This is accomplished through reducing the number of kernels and the number of layers needed in the typical CNN configuration, in addition to reducing the memory used, increasing 2X the training speed and the number of activation function evaluations. Our experiments show a reduction of 70X in the memory used for MNIST, maintaining 99% accuracy and 16X memory reduction for CIFAR10 with 92.5% accuracy.", "keywords": ["Adaptive kernels", "Dynamic kernels", "Pattern recognition", "low memory CNNs"], "authorids": ["ICLR.cc/2019/Conference/Paper330/Authors"], "authors": ["Anonymous"], "TL;DR": "An adaptve convolutional kernel, that includes non-linear transformations obtaining similar results as the state of the art algorithms, while yielding a reduction in required memory up to 16x in the CIFAR10", "pdf": "/pdf/dcc0d0b72ce9b3d3a104bb09c3cf1e81d2dcd30b.pdf", "paperhash": "anonymous|adaptive_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeWdiR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlWOj0qF7", "original": "H1ldE4tqYm", "number": 331, "cdate": 1538087785448, "ddate": null, "tcdate": 1538087785448, "tmdate": 1538156191433, "tddate": null, "forum": "rJlWOj0qF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Encoding Category Trees Into Word-Embeddings Using Geometric Approach", "abstract": "We present a novel method to implicitly encode a tree-structured category information into word-embeddings, resulting in super-dimensional ball representations ($n$-ball embedding for short). Inclusion relations among $n$-balls precisely encode subordinate relations among categories. The cosine  similarity function is enriched by category information. A large $n$-ball dataset is constructed using geometrical method, which achieves zero energy cost in embedding tree structures into word embedding. A new benchmark dataset is created for predicting the category of unknown words. Experiments show that $n$-ball embeddings, carried with category information, significantly out-perform word-embeddings in the neighbourhood test, while only slightly change the original word-embeddings. Experiment results also show that $n$-ball embeddings demonstrate surprisingly good performance in validating the category of unknown word. Source codes and data-sets are free for public access \\url{https://github.com/gnodisnait/nball4tree.git} and \\url{https://github.com/gnodisnait/bp94nball.git}. ", "keywords": ["category tree", "word-embeddings", "geometry"], "authorids": ["ICLR.cc/2019/Conference/Paper331/Authors"], "authors": ["Anonymous"], "TL;DR": "we show a geometric method to perfectly encode categroy tree information into pre-trained word-embeddings.", "pdf": "/pdf/f03fea4bfe53510ca27d045711bd2e00b99313af.pdf", "paperhash": "anonymous|encoding_category_trees_into_wordembeddings_using_geometric_approach", "_bibtex": "@inproceedings{    \nanonymous2019encoding,    \ntitle={Encoding Category Trees Into Word-Embeddings Using Geometric Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlWOj0qF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlGdsC9Ym", "original": "SJxsYwD5Y7", "number": 332, "cdate": 1538087785621, "ddate": null, "tcdate": 1538087785621, "tmdate": 1538156191217, "tddate": null, "forum": "rJlGdsC9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning of Sophisticated Curriculums by viewing them as Graphs over Tasks", "abstract": "Curriculum learning consists in learning a difficult task by first training on an easy version of it, then on more and more difficult versions and finally on the difficult task. To make this learning efficient, given a curriculum and the current learning state of an agent, we need to find what are the good next tasks to train the agent on.\nTeacher-Student algorithms assume that the good next tasks are the ones on which the agent is making the fastest progress or digress. We first simplify and improve them. However, two problematic situations where the agent is mainly trained on tasks it can't learn yet or it already learnt may occur.\nTherefore, we introduce a new algorithm using min max ordered curriculums that assumes that the good next tasks are the ones that are learnable but not learnt yet. It outperforms Teacher-Student algorithms on small curriculums and significantly outperforms them on sophisticated ones with numerous tasks.", "keywords": ["learning", "curriculum learning", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper332/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a new algorithm for learning by curriculum based on the notion of mastering rate that outperforms previous algorithms.", "pdf": "/pdf/8e2b2c2206bfb2092e6edbd9ec5d9cfca1308db4.pdf", "paperhash": "anonymous|learning_of_sophisticated_curriculums_by_viewing_them_as_graphs_over_tasks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning of Sophisticated Curriculums by viewing them as Graphs over Tasks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlGdsC9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gfOiAqYm", "original": "HJluBQ4GtQ", "number": 333, "cdate": 1538087785790, "ddate": null, "tcdate": 1538087785790, "tmdate": 1538156191005, "tddate": null, "forum": "H1gfOiAqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Execution-Guided Neural Program Synthesis", "abstract": "Neural program synthesis from input-output examples has attracted an increasing interest from both the machine learning and the programming language community. Most existing neural program synthesis approaches employ an encoder-decoder architecture, which uses an encoder to compute the embedding of the given input-output examples, as well as a decoder to generate the program from the embedding following a given syntax. Although such approaches achieve a reasonable performance on simple tasks such as FlashFill, on more complex tasks such as Karel, the state-of-the-art approach can only achieve an accuracy of around 77%. We observe that the main drawback of existing approaches is that the semantic information is greatly under-utilized. In this work, we propose two simple yet principled techniques to better leverage the semantic information, which are execution-guided synthesis and synthesizer ensemble. These techniques are general enough to be combined with any existing encoder-decoder-style neural program synthesizer. Applying our techniques to the Karel dataset, we can boost the accuracy from around 77% to more than 90%, reducing the error rate by around 60%.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper333/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/33bf818117a168fbce323f9f3818ba1499ad613c.pdf", "paperhash": "anonymous|executionguided_neural_program_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019execution-guided,    \ntitle={Execution-Guided Neural Program Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gfOiAqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1ez_sRcFQ", "original": "r1gw-SKctQ", "number": 334, "cdate": 1538087785963, "ddate": null, "tcdate": 1538087785963, "tmdate": 1538156190796, "tddate": null, "forum": "r1ez_sRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pixel Redrawn For A Robust Adversarial Defense", "abstract": "Recently, an adversarial example becomes a serious problem to be aware of because it can fool trained neural networks easily.\nTo prevent the issue, many researchers have proposed several defense techniques such as adversarial training, input transformation, stochastic activation pruning, etc.\nIn this paper, we propose a novel defense technique, Pixel Redrawn (PR) method, which redraws every pixel of training images to convert them into distorted images.\nThe motivation for our PR method is from the observation that the adversarial attacks have redrawn some pixels of the original image with the known parameters of the trained neural network.\nMimicking these attacks, our PR method redraws the image without any knowledge of the trained neural network.\nThis method can be similar to the adversarial training method but our PR method can be used to prevent future attacks.\nExperimental results on several benchmark datasets indicate our PR method not only relieves the over-fitting issue when we train neural networks with a large number of epochs, but it also boosts the robustness of the neural network.", "keywords": ["adversarial machine learning", "deep learning", "adversarial example"], "authorids": ["ICLR.cc/2019/Conference/Paper334/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7f39757f40508500386770a944e80b09af71b0f0.pdf", "paperhash": "anonymous|pixel_redrawn_for_a_robust_adversarial_defense", "_bibtex": "@inproceedings{    \nanonymous2019pixel,    \ntitle={Pixel Redrawn For A Robust Adversarial Defense},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1ez_sRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lM_sA5Fm", "original": "Hkl5qrFcFm", "number": 335, "cdate": 1538087786133, "ddate": null, "tcdate": 1538087786133, "tmdate": 1538156190590, "tddate": null, "forum": "r1lM_sA5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Assumption Questioning: Latent Copying and Reward Exploitation in Question Generation", "abstract": "Question generation is an important task for improving our ability to process natural language data, with additional challenges over other sequence transformation tasks. Recent approaches use modifications to a Seq2Seq architecture inspired by advances in machine translation, but unlike translation the input and output vocabularies overlap significantly, and there are many different valid questions for each input. Approaches using copy mechanisms and reinforcement learning have shown promising results, but there are ambiguities in the exact implementation that have not yet been investigated. We show that by removing inductive bias from the model and allowing the choice of generation path to become latent, we achieve substantial improvements over implementations biased with both naive and smart heuristics. We perform a human evaluation to confirm these findings. We show that although policy gradient methods may be used to decouple training from the ground truth and optimise directly for quality metrics that have previously been assumed to be good choices, these objectives are poorly aligned with human judgement and the model simply learns to exploit the weaknesses of the reward source. Finally, we show that an adversarial objective learned directly from the ground truth data is not able to generate a useful training signal.", "keywords": ["question generation", "answer questioning", "pointer networks", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper335/Authors"], "authors": ["Anonymous"], "TL;DR": "An investigation into latent copy mechanisms for question generation and correlations of external reward models with human evaluation.", "pdf": "/pdf/91ba0e37b3c697f96d74d8e3910ae08c349d6a65.pdf", "paperhash": "anonymous|assumption_questioning_latent_copying_and_reward_exploitation_in_question_generation", "_bibtex": "@inproceedings{    \nanonymous2019assumption,    \ntitle={Assumption Questioning: Latent Copying and Reward Exploitation in Question Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lM_sA5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkzfuiA9F7", "original": "HyxE42g5KX", "number": 336, "cdate": 1538087786308, "ddate": null, "tcdate": 1538087786308, "tmdate": 1538156190379, "tddate": null, "forum": "rkzfuiA9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Projective Subspace Networks For Few Shot Learning", "abstract": "Generalization from limited examples, usually studied under the umbrella of meta-learning, equips learning techniques with the ability to adapt quickly in dynamical environments and proves to be an essential aspect of lifelong learning. In this paper, we introduce the Projective Subspace Networks (PSN), a deep learning paradigm that learns non-linear embeddings from limited supervision. In contrast to previous studies, the embedding in PSN deems samples of a given class to form an affine subspace. We will show that such modeling leads to robust solutions, yielding competitive results on supervised and semi-supervised few-shot classification. Moreover, our PSN approach has the ability of end-to-end learning. In contrast to previous works, our projective subspace can be thought of as a richer representation capturing higher-order information datapoints for modeling new concepts.", "keywords": ["few-shot", "one-shot", "semi-supervised", "meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper336/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed Projective Subspace Networks for few-shot and semi-supervised few-shot learning", "pdf": "/pdf/a0bb7b674ed126567717bd4b933507f2369d8600.pdf", "paperhash": "anonymous|projective_subspace_networks_for_few_shot_learning", "_bibtex": "@inproceedings{    \nanonymous2019projective,    \ntitle={Projective Subspace Networks For Few Shot Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkzfuiA9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGMOi05FQ", "original": "SJltVUF5tX", "number": 337, "cdate": 1538087786477, "ddate": null, "tcdate": 1538087786477, "tmdate": 1538156190170, "tddate": null, "forum": "SkGMOi05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": " Generating Text through Adversarial Training using Skip-Thought Vectors", "abstract": "In the past few years, various advancements have been made in generative models owing to the formulation of Generative Adversarial Networks (GANs). GANs have been shown to perform exceedingly well on a wide variety of tasks pertaining to image generation and style transfer. In the field of Natural Language Processing, word embeddings such as word2vec and GLoVe are state-of-the-art methods for applying neural network models on textual data. Attempts have been made for utilizing GANs with word embeddings for text generation. This work presents an approach to text generation using Skip-Thought sentence embeddings in conjunction with GANs based on gradient penalty functions and f-measures. The results of using sentence embeddings with GANs for generating text conditioned on input information are comparable to the approaches where word embeddings are used. ", "keywords": ["Natural Language Generation", "Computation and Language", "Machine Learning", "Generative Adversarial Networks", "Sentence Embeddings"], "authorids": ["ICLR.cc/2019/Conference/Paper337/Authors"], "authors": ["Anonymous"], "TL;DR": "Generating text using sentence embeddings from Skip-Thought Vectors with the help of Generative Adversarial Networks.", "pdf": "/pdf/3bcb1f3000c14da180bde44e4c06e4bae7c4b14f.pdf", "paperhash": "anonymous|generating_text_through_adversarial_training_using_skipthought_vectors", "_bibtex": "@inproceedings{    \nanonymous2019,    \ntitle={ Generating Text through Adversarial Training using Skip-Thought Vectors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGMOi05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1emus0qF7", "original": "r1x-x3OqFX", "number": 338, "cdate": 1538087786653, "ddate": null, "tcdate": 1538087786653, "tmdate": 1538156189964, "tddate": null, "forum": "H1emus0qF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Near-Optimal Representation Learning for Hierarchical Reinforcement Learning", "abstract": "We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning. In such hierarchical structures, a higher-level controller solves tasks by iteratively communicating goals which a lower-level policy is trained to reach. Accordingly, the choice of representation -- the mapping of observation space to goal space -- is crucial. To study this problem, we develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation. We derive expressions which bound the sub-optimality and show how these expressions can be translated to representation learning objectives which may be optimized in practice. Results on a number of difficult continuous-control tasks show that our approach to representation learning yields qualitatively better representations as well as quantitatively better hierarchical policies, compared to existing methods.", "keywords": ["representation hierarchy reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper338/Authors"], "authors": ["Anonymous"], "TL;DR": "We translate a bound on sub-optimality of representations to a practical training objective in the context of hierarchical reinforcement learning.", "pdf": "/pdf/ee5d66763d2fc8c590ac07b2649db017f08ce894.pdf", "paperhash": "anonymous|nearoptimal_representation_learning_for_hierarchical_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019near-optimal,    \ntitle={Near-Optimal Representation Learning for Hierarchical Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1emus0qF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkemdj09YQ", "original": "rJeAQn-GKm", "number": 339, "cdate": 1538087786840, "ddate": null, "tcdate": 1538087786840, "tmdate": 1538156189755, "tddate": null, "forum": "Hkemdj09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Rectified Gradient: Layer-wise Thresholding for Sharp and Coherent Attribution Maps", "abstract": "Saliency map, or the gradient of the score function with respect to the input, is the most basic means of interpreting deep neural network decisions. However, saliency maps are often visually noisy. Although several hypotheses were proposed to account for this phenomenon, there is no work that provides a rigorous analysis of noisy saliency maps. This may be a problem as numerous advanced attribution methods were proposed under the assumption that the existing hypotheses are true. In this paper, we identify the cause of noisy saliency maps. Then, we propose Rectified Gradient, a simple method that significantly improves saliency maps by alleviating that cause. Experiments showed effectiveness of our method and its superiority to other attribution methods. Codes and examples for the experiments will be released in public.", "keywords": ["Interpretability", "Attribution Method", "Attribution Map"], "authorids": ["ICLR.cc/2019/Conference/Paper339/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new attribution method that removes noise from saliency maps through layer-wise thresholding during backpropagation.", "pdf": "/pdf/68e0c150b88a2410997c7e8ac3e932c271c465a6.pdf", "paperhash": "anonymous|rectified_gradient_layerwise_thresholding_for_sharp_and_coherent_attribution_maps", "_bibtex": "@inproceedings{    \nanonymous2019rectified,    \ntitle={Rectified Gradient: Layer-wise Thresholding for Sharp and Coherent Attribution Maps},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkemdj09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syl7OsRqY7", "original": "rJeNyTcStm", "number": 340, "cdate": 1538087787015, "ddate": null, "tcdate": 1538087787015, "tmdate": 1538156189549, "tddate": null, "forum": "Syl7OsRqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering", "abstract": "End-to-end neural models have made significant progress in question answering, however recent studies show that these models implicitly assume the answer and evidence appear close together in a single document. In this work, we propose the Coarse-grain Fine-grain Coattention Network (CFC), a new question answering model that combines information from evidence across multiple documents. The CFC consists of a coarse-grain module that interprets documents with respect to the query then finds a relevant answer, and a fine-grain module which scores each candidate answer by comparing its occurrences across all of the documents with the query. We implement these modules using hierarchies of coattention and self-attention, which learn to emphasize different parts of the input. On the Qangaroo WikiHop multi-evidence question answering task, the CFC obtains a new state-of-the-art result of 70.6% on the blind test set, outperforming the previous best by 3% accuracy despite not using pretrained contextual encoders.", "keywords": ["question answering", "reading comprehension", "nlp", "natural language processing", "attention", "representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper340/Authors"], "authors": ["Anonymous"], "TL;DR": "A new state-of-the-art model for multi-evidence question answering using coarse-grain fine-grain hierarchical attention.", "pdf": "/pdf/18c0164b843e142c676db5383e18f5f9db74d7e8.pdf", "paperhash": "anonymous|coarsegrain_finegrain_coattention_network_for_multievidence_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019coarse-grain,    \ntitle={Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syl7OsRqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMXus0ct7", "original": "r1erddFqF7", "number": 341, "cdate": 1538087787188, "ddate": null, "tcdate": 1538087787188, "tmdate": 1538156189341, "tddate": null, "forum": "HJMXus0ct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "iRDA Method for Sparse Convolutional Neural Networks", "abstract": "We propose a new approach, known as the iterative regularized dual averaging (iRDA), to improve the efficiency of convolutional neural networks (CNN) by significantly reducing the redundancy of the model without reducing its accuracy.  The method has been tested for various data sets, and proven to be significantly more efficient than most existing compressing techniques in the deep learning literature.  For many popular data sets such as MNIST and CIFAR-10, more than 95% of the weights can be zeroed out without losing accuracy. In particular, we are able to make ResNet18 with 95% sparsity to have an accuracy that is comparable to that of a much larger model ResNet50 with the best 60% sparsity as reported in the literature.", "keywords": ["sparse convolutional neural networks", "regularized dual averaging"], "authorids": ["ICLR.cc/2019/Conference/Paper341/Authors"], "authors": ["Anonymous"], "TL;DR": "A sparse optimization algorithm for deep CNN models.", "pdf": "/pdf/0004a707ee4b203d4680d98350fbd9186ed49532.pdf", "paperhash": "anonymous|irda_method_for_sparse_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019irda,    \ntitle={iRDA Method for Sparse Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMXus0ct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGQujR5FX", "original": "S1lJ_ZAYYQ", "number": 342, "cdate": 1538087787360, "ddate": null, "tcdate": 1538087787360, "tmdate": 1538156189135, "tddate": null, "forum": "SkGQujR5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DANA: Scalable Out-of-the-box Distributed ASGD Without Retuning", "abstract": "Distributed computing can significantly reduce the training time of neural networks. Despite its potential, however, distributed training has not been widely adopted: scaling the training process is difficult, and existing SGD methods require substantial tuning of hyperparameters and learning schedules to achieve sufficient accuracy when increasing the number of workers. In practice, such tuning can be prohibitively expensive given the huge number of potential hyperparameter configurations and the effort required to test each one.\n    \nWe propose DANA, a novel approach that scales out-of-the-box to large clusters using the same hyperparameters and learning schedule optimized for training on a single worker, while maintaining similar final accuracy without additional overhead. DANA estimates the future value of model parameters by adapting Nesterov Accelerated Gradient to a distributed setting, and so mitigates the effect of gradient staleness, one of the main difficulties in scaling SGD to more workers.\n\nEvaluation on three state-of-the-art network architectures and three datasets shows that DANA scales as well as or better than existing work without having to tune any hyperparameters or tweak the learning schedule. For example, DANA achieves 75.73% accuracy on ImageNet when training ResNet-50 with 16 workers, similar to the non-distributed baseline.", "keywords": ["distributed", "asynchronous", "gradient staleness", "nesterov", "optimization", "out-of-the-box", "stochastic gradient descent", "sgd", "imagenet", "distributed training", "neural networks", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper342/Authors"], "authors": ["Anonymous"], "TL;DR": "A new distributed asynchronous SGD algorithm that achieves state-of-the-art accuracy on existing architectures without any additional tuning or overhead.", "pdf": "/pdf/330b9894608a67e79045067dd6ca116ba895f3f4.pdf", "paperhash": "anonymous|dana_scalable_outofthebox_distributed_asgd_without_retuning", "_bibtex": "@inproceedings{    \nanonymous2019dana:,    \ntitle={DANA: Scalable Out-of-the-box Distributed ASGD Without Retuning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGQujR5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syx4_iCqKQ", "original": "H1xc_OYqtX", "number": 343, "cdate": 1538087787537, "ddate": null, "tcdate": 1538087787537, "tmdate": 1538156188929, "tddate": null, "forum": "Syx4_iCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Polar Prototype Networks", "abstract": "This paper proposes a neural network for classification and regression, without the need to learn layout structures in the output space. Standard solutions such as soft-max cross-entropy and mean squared error are effective but parametric, meaning that known inductive structures such as maximum margin separation and simplicity (Occam\u2019s Razor) need to be learned for the task at hand.  Instead, we propose polar prototype networks, a class of networks that explicitly states the structure, i.e. the layout, of the output. The structure is defined by polar prototypes, points on the hypersphere of the output space. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares on the hypersphere.  Classes are assigned to prototypes randomly or based on semantic priors and training becomes a matter of minimizing angular distances between examples and their class prototypes. For regression, we show that training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher-dimensional outputs. From empirical analysis, we find that polar prototype networks benefit from large margin separation and semantic class structure, while having a minimal description length in the output space.  While the structure is simple, the performance is on par with (classification) or better than (regression) standard network methods.  Moreover, we show that we gain the ability to perform regression and classification jointly in the same space, which is disentangled and interpretable by design.", "keywords": ["prototype networks", "polar prototypes", "output structure"], "authorids": ["ICLR.cc/2019/Conference/Paper343/Authors"], "authors": ["Anonymous"], "TL;DR": "This work proposes a class of networks that can jointly perform classification and regression by imposing layout structures in the network output space.", "pdf": "/pdf/ac9bc5e1d4bd6535daff76bc12dc3d180f951616.pdf", "paperhash": "anonymous|polar_prototype_networks", "_bibtex": "@inproceedings{    \nanonymous2019polar,    \ntitle={Polar Prototype Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syx4_iCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eEdj0cK7", "original": "Bye4agXYKm", "number": 344, "cdate": 1538087787714, "ddate": null, "tcdate": 1538087787714, "tmdate": 1538156188723, "tddate": null, "forum": "S1eEdj0cK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Relationship between Neural Machine Translation and Word Alignment", "abstract": "Prior researches suggest that attentional neural machine translation (NMT) is able to capture word alignment by attention, however, to our surprise, it almost fails for NMT models with multiple layers except for those with a single layer. This paper proposes two methods to induce word alignment from general neural machine translation models. Experiments verify that both methods obtain much better word alignment than the method by attention. Furthermore, based on one of the proposed method, we design a criterion to divide target words into two categories (i.e. those mostly contributed from source \"CFS\" words and the other words mostly contributed from target \"CFT\" words), and analyze word alignment under these two categories in depth. We find that although NMT models are difficult to capture word alignment for CFT words but these words do not sacrifice translation quality significantly, which provides an explanation why NMT is more successful for translation yet worse for word alignment compared to statistical machine translation. We further demonstrate that word alignment errors for CFS words are responsible for translation errors in some extent by measuring the correlation between word alignment and translation for several NMT systems.", "keywords": ["Neural Machine Translation", "Word Alignment", "Neural Network", "Pointwise Mutual Information"], "authorids": ["ICLR.cc/2019/Conference/Paper344/Authors"], "authors": ["Anonymous"], "TL;DR": "It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.", "pdf": "/pdf/ea67018fa794b5da3e3b046ecf8025e0ee34d548.pdf", "paperhash": "anonymous|on_the_relationship_between_neural_machine_translation_and_word_alignment", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Relationship between Neural Machine Translation and Word Alignment},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eEdj0cK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1MVuoCctX", "original": "Skx3foftY7", "number": 345, "cdate": 1538087787892, "ddate": null, "tcdate": 1538087787892, "tmdate": 1538156188517, "tddate": null, "forum": "r1MVuoCctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MAJOR-MINOR LSTMS FOR WORD-LEVEL LANGUAGE MODEL", "abstract": "As a widely-accepted evaluation criterion, complexity has attracted more and more attention in the design of language models. The parameter count is a proxy for complexity, which is often reported and compared in research papers. In general, more parameters means better model performance, but higher complexity. Therefore, reconciling the contradiction between the complexity and the model performance is necessary. In this paper, we propose a simple method to make use of model parameters more effectively, so that the LSTM-based language models can reach better results without the cost of increasing parameters. The method constructs another small-scale LSTM with a part of parameters originally belonging to the vanilla LSTM in each layer, whose output can assist the next layer in processing the output of the vanilla LSTM. We name these two LSTMs Major Minor LSTMs. In experiments, we demonstrate the language model with Major Minor LSTMs surpasses the existing state-of-the-art model on Penn Treebank and WikiText-2 with fewer parameters.", "keywords": ["Language model", "LSTM", "Deep Learning", "NLP"], "authorids": ["ICLR.cc/2019/Conference/Paper345/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/687d3a13ec7c8cae60f3fdb3d7b4549f86045de5.pdf", "paperhash": "anonymous|majorminor_lstms_for_wordlevel_language_model", "_bibtex": "@inproceedings{    \nanonymous2019major-minor,    \ntitle={MAJOR-MINOR LSTMS FOR WORD-LEVEL LANGUAGE MODEL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1MVuoCctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByGVui0ctm", "original": "SJlMk0PGF7", "number": 346, "cdate": 1538087788067, "ddate": null, "tcdate": 1538087788067, "tmdate": 1538156188309, "tddate": null, "forum": "ByGVui0ctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative replay with feedback connections as a general strategy for continual learning", "abstract": "Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning problematic. Recently, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more meaningful comparisons, we identified three distinct continual learning scenarios based on whether task identity is known and, if it is not, whether it needs to be inferred. Performing the split and permuted MNIST task protocols according to each of these scenarios, we found that regularization-based approaches (e.g., elastic weight consolidation) failed when task identity needed to be inferred. In contrast, generative replay combined with distillation (i.e., using class probabilities as ''soft targets'') achieved superior performance in all three scenarios. In addition, we reduced the computational cost of generative replay by integrating the generative model into the main model by equipping it with generative feedback connections. This Replay-through-Feedback approach substantially shortened training time with no or negligible loss in performance. We believe this to be an important first step towards making the powerful technique of generative replay scalable to real-world continual learning applications.", "keywords": ["continual learning", "generative models", "replay", "distillation", "feedback connections"], "authorids": ["ICLR.cc/2019/Conference/Paper346/Authors"], "authors": ["Anonymous"], "TL;DR": "A structured comparison of recent methods for continual learning that turns into an argument for and extension of generative replay.", "pdf": "/pdf/471c36ba139dacce099ccfad6de9ba6b88ae750a.pdf", "paperhash": "anonymous|generative_replay_with_feedback_connections_as_a_general_strategy_for_continual_learning", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative replay with feedback connections as a general strategy for continual learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByGVui0ctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r14EOsCqKX", "original": "SkxY3CPKFX", "number": 347, "cdate": 1538087788235, "ddate": null, "tcdate": 1538087788235, "tmdate": 1538156188099, "tddate": null, "forum": "r14EOsCqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation", "abstract": "The convergence rate and final performance of common deep learning models have significantly benefited from recently proposed heuristics such as learning rate schedules, knowledge distillation, skip connections and normalization layers. In the absence of theoretical underpinnings, controlled experiments aimed at explaining the efficacy of these strategies can aid our understanding of deep learning landscapes and the training dynamics. Existing approaches for empirical analysis rely on tools of linear interpolation and visualizations with dimensionality reduction, each with their limitations. Instead, we revisit the empirical analysis of heuristics through the lens of recently proposed methods for loss surface and representation analysis, viz. mode connectivity and canonical correlation analysis (CCA), and hypothesize reasons why the heuristics succeed. In particular, we explore knowledge distillation and learning rate heuristics of (cosine) restarts and warmup using mode connectivity and CCA.  Our empirical analysis suggests that: (a) the reasons often quoted for the success of cosine annealing are not evidenced in practice; (b) that the effect of learning rate warmup is to prevent the deeper layers from creating training instability; and (c) that the latent knowledge shared by the teacher is primarily disbursed in the deeper layers.", "keywords": ["deep learning heuristics", "learning rate restarts", "learning rate warmup", "knowledge distillation", "mode connectivity", "SVCCA"], "authorids": ["ICLR.cc/2019/Conference/Paper347/Authors"], "authors": ["Anonymous"], "TL;DR": "We use empirical tools of mode connectivity and SVCCA to investigate neural network training heuristics of learning rate restarts, warmup and knowledge distillation.", "pdf": "/pdf/ccf5c28794f528c0cb292f3d80b56462dff728fe.pdf", "paperhash": "anonymous|a_closer_look_at_deep_learning_heuristics_learning_rate_restarts_warmup_and_distillation", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r14EOsCqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkVVOi0cFX", "original": "B1lGa6X9K7", "number": 348, "cdate": 1538087788426, "ddate": null, "tcdate": 1538087788426, "tmdate": 1538156187888, "tddate": null, "forum": "BkVVOi0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Denoise while Aggregating: Collaborative Learning in Open-Domain Question Answering", "abstract": "The open-domain question answering (OpenQA) task aims to extract answers that match specific questions from a distantly supervised corpus. Unlike supervised reading comprehension (RC) datasets where questions are designed for particular paragraphs, background sentences in OpenQA datasets are more prone to noise. We observe that most existing OpenQA approaches are vulnerable to noise since they simply regard those sentences that contain the answer span as ground truths and ignore the plausible correlation between the sentences and the question. To address this deficiency, we introduce a unified and collaborative model that leverages alignment information from query-sentence pairs in a small-scale supervised RC dataset and aggregates relevant evidence from distantly supervised corpus to answer open-domain questions. We evaluate our model on several real-world OpenQA datasets, and experimental results show that our collaborative learning methods outperform the existing baselines significantly.", "keywords": ["natural language processing", "open-domain question answering", "semi-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper348/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose denoising strategies to leverage information from supervised RC datasets to handle the noise issue in the open-domain QA task.", "pdf": "/pdf/331a04b9b54096dd4c9904025a9a3ba2a01c8a18.pdf", "paperhash": "anonymous|denoise_while_aggregating_collaborative_learning_in_opendomain_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019denoise,    \ntitle={Denoise while Aggregating: Collaborative Learning in Open-Domain Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkVVOi0cFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkeSusCcYm", "original": "BkeP-5F5tm", "number": 349, "cdate": 1538087788596, "ddate": null, "tcdate": 1538087788596, "tmdate": 1538156187670, "tddate": null, "forum": "BkeSusCcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Combining Global Sparse Gradients with Local Gradients", "abstract": "Data-parallel neural network training is network-intensive, so gradient dropping was designed to exchange only large gradients.  However, gradient dropping has been shown to slow convergence.  We propose to improve convergence by having each node combine its locally computed gradient with the sparse global gradient exchanged over the network. We empirically confirm with machine translation tasks that gradient dropping with local gradients approaches convergence 48% faster than non-compressed multi-node training and 28% faster compared to vanilla gradient dropping. We also show that gradient dropping with a local gradient update does not reduce the model's final quality.", "keywords": ["Distributed training", "stochastic gradient descent", "machine translation"], "authorids": ["ICLR.cc/2019/Conference/Paper349/Authors"], "authors": ["Anonymous"], "TL;DR": "We improve gradient dropping (a technique of only exchanging large gradients on distributed training) by incorporating local gradients while doing a parameter update to reduce quality loss and further improve the training time.", "pdf": "/pdf/628263e418804077a88ad78582f60809ff0899bb.pdf", "paperhash": "anonymous|combining_global_sparse_gradients_with_local_gradients", "_bibtex": "@inproceedings{    \nanonymous2019combining,    \ntitle={Combining Global Sparse Gradients with Local Gradients},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeSusCcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeSdsC9Km", "original": "HJxadct9FQ", "number": 350, "cdate": 1538087788771, "ddate": null, "tcdate": 1538087788771, "tmdate": 1538156187466, "tddate": null, "forum": "ByeSdsC9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Posterior Learning", "abstract": "The ability to generalize quickly from few observations is crucial for intelligent systems. In this paper we introduce APL, an algorithm that approximates probability distributions by remembering the most surprising observations it has encountered. These past observations are recalled from an external memory module and processed by a decoder network that can combine information from different memory slots to generalize beyond direct recall. We show this algorithm can perform as well as state of the art baselines on few-shot classification benchmarks with a smaller memory footprint.  In addition, its memory compression allows it to scale to thousands of unknown labels.  Finally, we introduce a meta-learning reasoning task which is more challenging than direct classification. In this setting, APL is able to generalize with fewer than one example per class via deductive reasoning.", "keywords": ["metalearning", "memory", "few-shot", "relational", "self-attention", "classification", "sequential", "reasoning", "working memory", "episodic memory"], "authorids": ["ICLR.cc/2019/Conference/Paper350/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a model which generalizes quickly from few observations by storing surprising information and attending over the most relevant data at each time point.", "pdf": "/pdf/f4c0af2c174e65611cb28fd6cba5d30442f492a7.pdf", "paperhash": "anonymous|adaptive_posterior_learning", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Posterior Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeSdsC9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGBdo0qFm", "original": "rkld3_qFtQ", "number": 351, "cdate": 1538087788941, "ddate": null, "tcdate": 1538087788941, "tmdate": 1538156187254, "tddate": null, "forum": "HyGBdo0qFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Turing Completeness of Modern Neural Network Architectures", "abstract": "Alternatives to recurrent neural networks, in particular, architectures based on attention or convolutions, have been gaining momentum for processing input sequences. In spite of their relevance, the computational properties of these alternatives have not yet been fully explored. We study the computational power of two of the most paradigmatic architectures exemplifying these mechanisms: the Transformer (Vaswani et al., 2017) and the Neural GPU (Kaiser & Sutskever, 2016). We show both models to be Turing complete exclusively based on their capacity to compute and access internal dense representations of the data. In particular, neither the Transformer nor the Neural GPU requires access to an external memory to become Turing complete. Our study also reveals some minimal sets of elements needed to obtain these completeness results.", "keywords": ["Transformer", "NeuralGPU", "Turing completeness"], "authorids": ["ICLR.cc/2019/Conference/Paper351/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that the Transformer architecture and the Neural GPU are Turing complete.", "pdf": "/pdf/738d09dd2ece69378973054cd32095604ae9e5cd.pdf", "paperhash": "anonymous|on_the_turing_completeness_of_modern_neural_network_architectures", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Turing Completeness of Modern Neural Network Architectures},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGBdo0qFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1MBuiAqtX", "original": "BkeUG8m8tX", "number": 352, "cdate": 1538087789116, "ddate": null, "tcdate": 1538087789116, "tmdate": 1538156187044, "tddate": null, "forum": "H1MBuiAqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unicorn: Continual learning with a universal, off-policy agent", "abstract": "Some real-world domains are best characterized as a single task, but for others this perspective is limiting. Instead, some tasks continually grow in complexity, in tandem with the agent's competence. In continual learning there are no explicit task boundaries or curricula. As learning agents have become more powerful, continual learning remains one of the frontiers that has resisted quick progress. To test continual learning capabilities we consider a challenging 3D domain with an implicit sequence of tasks and sparse rewards.  We propose a novel agent architecture called Unicorn, which demonstrates strong continual learning and outperforms several baseline agents on the proposed domain. The agent achieves this by jointly representing and efficiently learning multiple policies for multiple goals, using a parallel off-policy learning setup. ", "keywords": ["reinforcement learning", "continual learning", "universal value functions", "off-policy learning", "multi-task"], "authorids": ["ICLR.cc/2019/Conference/Paper352/Authors"], "authors": ["Anonymous"], "TL;DR": "Agents learning jointly and off-policy about many tasks make progress on challenging continual learning domains.", "pdf": "/pdf/42c93bdda130b7bfc7a651eb3d09fe0df3d34169.pdf", "paperhash": "anonymous|unicorn_continual_learning_with_a_universal_offpolicy_agent", "_bibtex": "@inproceedings{    \nanonymous2019unicorn:,    \ntitle={Unicorn: Continual learning with a universal, off-policy agent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1MBuiAqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1EHOsC9tX", "original": "rylP2pxKYQ", "number": 353, "cdate": 1538087789291, "ddate": null, "tcdate": 1538087789291, "tmdate": 1538156186839, "tddate": null, "forum": "S1EHOsC9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards the first adversarially robust neural network model on MNIST", "abstract": "Despite much effort, deep neural networks remain highly susceptible to tiny input perturbations and even for MNIST, one of the most common toy datasets in computer vision, no neural network model exists for which adversarial perturbations are large and make semantic sense to humans. We show that even the widely recognized and by far most successful L-inf defense by Madry et~al. (1) has lower L0 robustness than undefended networks and still highly susceptible to L2 perturbations, (2) classifies unrecognizable images with high certainty, (3) performs not much better than simple input binarization and (4) features adversarial perturbations that make little sense to humans. These results suggest that MNIST is far from being solved in terms of adversarial robustness. We present a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. We derive bounds on the robustness and go to great length to empirically evaluate our model using maximally effective adversarial attacks by (a) applying decision-based, score-based, gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of our defended model and (c) by devising a novel decision-based attack that seeks to minimize the number of perturbed pixels (L0). The results suggest that our approach yields state-of-the-art robustness on MNIST against L0, L2 and L-inf perturbations and we demonstrate that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class.", "keywords": ["adversarial examples", "MNIST", "robustness", "deep learning", "security"], "authorids": ["ICLR.cc/2019/Conference/Paper353/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/94fb836a75aa0971ce61aa8e1216449211a3a759.pdf", "paperhash": "anonymous|towards_the_first_adversarially_robust_neural_network_model_on_mnist", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards the first adversarially robust neural network model on MNIST},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1EHOsC9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkNSOjR9Y7", "original": "Byxymjt9KX", "number": 354, "cdate": 1538087789469, "ddate": null, "tcdate": 1538087789469, "tmdate": 1538156186634, "tddate": null, "forum": "SkNSOjR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Training Variational Auto Encoders with Discrete Latent Representations using Importance Sampling", "abstract": "The Variational Auto Encoder (VAE) is a popular generative \nlatent variable model that is often \napplied for representation learning.\nStandard VAEs assume continuous valued \nlatent variables and are trained by maximization\nof the evidence lower bound (ELBO). Conventional methods obtain a \ndifferentiable estimate of the ELBO with reparametrized sampling and\noptimize it with Stochastic Gradient Descend (SGD). However, this is not possible if \nwe want to train VAEs with discrete valued latent variables, \nsince reparametrized sampling is not possible. Till now, there\nexist no simple solutions to circumvent this problem.\nIn this paper, we propose an easy method to train VAEs \nwith binary or categorically valued latent representations. Therefore, we use a differentiable\nestimator for the ELBO which is based on importance sampling. In experiments, we verify the approach and\ntrain two different VAEs architectures with Bernoulli and \nCategorically distributed latent representations on two different benchmark\ndatasets.\t", "keywords": ["Variational Auto Encoder", "Importance Sampling", "Discrete latent representation"], "authorids": ["ICLR.cc/2019/Conference/Paper354/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an easy method to train Variational Auto Encoders (VAE) with discrete latent representations, using importance sampling", "pdf": "/pdf/318f07aca7c3f09bb812679921111173d672668c.pdf", "paperhash": "anonymous|training_variational_auto_encoders_with_discrete_latent_representations_using_importance_sampling", "_bibtex": "@inproceedings{    \nanonymous2019training,    \ntitle={Training Variational Auto Encoders with Discrete Latent Representations using Importance Sampling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkNSOjR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xL_iR9Km", "original": "HkgvyzAYKm", "number": 355, "cdate": 1538087789637, "ddate": null, "tcdate": 1538087789637, "tmdate": 1538156186418, "tddate": null, "forum": "H1xL_iR9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GradMix: Multi-source Transfer across Domains and Tasks", "abstract": "The machine learning and computer vision community is witnessing an unprecedented rate of new tasks being proposed and addressed, thanks to the power of deep convolutional networks to find complex mappings from X to Y. The advent of each task often accompanies the release of a large-scale human-labeled dataset, for supervised training of the deep network. However, it is expensive and time-consuming to manually label sufficient amount of training data. Therefore, it is important to develop algorithms that can leverage off-the-shelf labeled dataset to learn useful knowledge for the target task. While previous works mostly focus on transfer learning from a single source, we study multi-source transfer across domains and tasks (MS-DTT), in a semi-supervised setting. We propose GradMix, a model-agnostic method applicable to any model trained with gradient-based learning rule. GradMix transfers knowledge via gradient descent, by weighting and mixing the gradients from all sources during training. Our method follows a meta-learning objective, by assigning layer-wise weights to the source gradients, such that the combined gradient follows the direction that can minimize the loss for a small set of samples from the target dataset. In addition, we propose to adaptively adjust the learning rate for each mini-batch based on its importance to the target task, and a pseudo-labeling method to leverage the unlabeled samples in the target domain. We perform experiments on two MS-DTT tasks: digit recognition and action recognition, and demonstrate the advantageous performance of the proposed method against multiple baselines.", "keywords": ["Transfer Learning", "Domain Adaptation", "Multi-source Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper355/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a gradient-based method to transfer knowledge from multiple sources across different domains and tasks.", "pdf": "/pdf/73e74ed3a04009ef370558aa7dd1107b30affd13.pdf", "paperhash": "anonymous|gradmix_multisource_transfer_across_domains_and_tasks", "_bibtex": "@inproceedings{    \nanonymous2019gradmix:,    \ntitle={GradMix: Multi-source Transfer across Domains and Tasks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xL_iR9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygUOoC5KX", "original": "B1eYSWKtFm", "number": 356, "cdate": 1538087789814, "ddate": null, "tcdate": 1538087789814, "tmdate": 1538156186201, "tddate": null, "forum": "HygUOoC5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Are Generative Classifiers More Robust to Adversarial Attacks?", "abstract": "There is a rising interest in studying the robustness of deep neural network classifiers against adversaries, with both advanced attack and defence techniques being actively developed. However, most recent work focuses on discriminative classifiers, which only model the conditional distribution of the labels given the inputs. In this paper, we propose and investigate the deep Bayes classifier, which improves classical naive Bayes with conditional deep generative models. We further develop detection methods for adversarial examples, which reject inputs with low likelihood under the generative model. Experimental results suggest that deep Bayes classifiers are more robust than deep discriminative classifiers, and that the proposed detection methods are effective against many recently proposed attacks.", "keywords": ["generative models", "adversarial attack", "defence", "detection", "Bayes' rule"], "authorids": ["ICLR.cc/2019/Conference/Paper356/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed a generative classifier based on deep generative models, and show improved robustness and detection results against adversarial attacks. ", "pdf": "/pdf/d7430b448c77bf8c89585cffcb61ed8561bd022f.pdf", "paperhash": "anonymous|are_generative_classifiers_more_robust_to_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019are,    \ntitle={Are Generative Classifiers More Robust to Adversarial Attacks?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygUOoC5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lUOsA9Fm", "original": "S1xqm9KqY7", "number": 357, "cdate": 1538087789983, "ddate": null, "tcdate": 1538087789983, "tmdate": 1538156185988, "tddate": null, "forum": "H1lUOsA9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Synthnet: Learning synthesizers end-to-end", "abstract": "Learning synthesizers and generating music in the raw audio domain is a challenging task. We investigate the learned representations of convolutional autoregressive generative models. Consequently, we show that mappings between musical notes and the harmonic style (instrument timbre) can be learned based on the raw audio music recording and the musical score (in binary piano roll format). Our proposed architecture, SynthNet uses minimal training data (9 minutes), is substantially better in quality and converges 6 times faster than the baselines. The quality of the generated waveforms (generation accuracy) is sufficiently high that they are almost identical to the ground truth. Therefore, we are able to directly measure generation error during training, based on the RMSE of the Constant-Q transform. Mean opinion scores are also provided. We validate our work using 7 distinct harmonic styles and also provide visualizations and links to all generated audio.", "keywords": ["audio", "synthesizers", "music", "convolutional neural networks", "generative models", "autoregressive models"], "authorids": ["ICLR.cc/2019/Conference/Paper357/Authors"], "authors": ["Anonymous"], "TL;DR": "A convolutional autoregressive generative model that generates high fidelity audio, behchmarked on music", "pdf": "/pdf/b1807c2afdc4c7fefda7d69088b9fb18f9e23295.pdf", "paperhash": "anonymous|synthnet_learning_synthesizers_endtoend", "_bibtex": "@inproceedings{    \nanonymous2019synthnet:,    \ntitle={Synthnet: Learning synthesizers end-to-end},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lUOsA9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkx8OiRcYX", "original": "ByeIosY5tX", "number": 358, "cdate": 1538087790153, "ddate": null, "tcdate": 1538087790153, "tmdate": 1538156185775, "tddate": null, "forum": "Bkx8OiRcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Countdown Regression: Sharp and Calibrated Survival Predictions", "abstract": "Personalized probabilistic forecasts of time to event (such as mortality) can be crucial in decision making, especially in the clinical setting. Inspired by ideas from the meteorology literature, we approach this problem through the paradigm of maximizing sharpness of prediction distributions, subject to calibration. In regression problems, it has been shown that optimizing the continuous ranked probability score (CRPS) instead of maximum likelihood leads to sharper prediction distributions while maintaining calibration. We introduce the Survival-CRPS, a generalization of the CRPS to the time to event setting, and present right-censored and interval-censored variants. To holistically evaluate the quality of predicted distributions over time to event, we present the scale agnostic Survival-AUPRC evaluation metric, an analog to area under the precision-recall curve. We apply these ideas by building a recurrent neural network for mortality prediction, using an Electronic Health Record dataset covering millions of patients. We demonstrate signi\ufb01cant bene\ufb01ts in models trained by the Survival-CRPS objective instead of maximum likelihood.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper358/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4596e93bfa8e629eedcd1acf6666efd8c279c8ca.pdf", "paperhash": "anonymous|countdown_regression_sharp_and_calibrated_survival_predictions", "_bibtex": "@inproceedings{    \nanonymous2019countdown,    \ntitle={Countdown Regression: Sharp and Calibrated Survival Predictions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkx8OiRcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJzLdjR9FX", "original": "HJe0iJ8qt7", "number": 359, "cdate": 1538087790324, "ddate": null, "tcdate": 1538087790324, "tmdate": 1538156185568, "tddate": null, "forum": "HJzLdjR9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DeepTwist: Learning Model Compression via Occasional Weight Distortion", "abstract": "Model compression has been introduced to reduce the required hardware resources while maintaining the model accuracy. Lots of techniques for model compression, such as pruning, quantization, and low-rank approximation, have been suggested along with different inference implementation characteristics. Adopting model compression is, however, still challenging because the design complexity of model compression is rapidly increasing due to additional hyper-parameters and computation overhead in order to achieve a high compression ratio. In this paper, we propose a simple and efficient model compression framework called DeepTwist which distorts weights in an occasional manner without modifying the underlying training algorithms. The ideas of designing weight distortion functions are intuitive and straightforward given formats of compressed weights. We show that our proposed framework improves compression rate significantly for pruning, quantization, and low-rank approximation techniques while the efforts of additional retraining and/or hyper-parameter search are highly reduced. Regularization effects of DeepTwist are also reported.", "keywords": ["deep learning", "model compression", "pruning", "quantization", "SVD", "regularization", "framework"], "authorids": ["ICLR.cc/2019/Conference/Paper359/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a unified model compression framework for performing a variety of model compression techniques.", "pdf": "/pdf/6aac6a633567daaaaf9b203c091801b317547dc5.pdf", "paperhash": "anonymous|deeptwist_learning_model_compression_via_occasional_weight_distortion", "_bibtex": "@inproceedings{    \nanonymous2019deeptwist:,    \ntitle={DeepTwist: Learning Model Compression via Occasional Weight Distortion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJzLdjR9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGIdiRqtm", "original": "H1ejKjYqYX", "number": 360, "cdate": 1538087790488, "ddate": null, "tcdate": 1538087790488, "tmdate": 1538156185365, "tddate": null, "forum": "HyGIdiRqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Evaluating Robustness of Neural Networks with Mixed Integer Programming", "abstract": "Neural networks trained only to optimize for training accuracy can often be fooled by adversarial examples --- slightly perturbed inputs misclassified with high confidence. Verification of networks enables us to gauge their vulnerability to such adversarial examples. We formulate verification of piecewise-linear neural networks as a mixed integer program. On a representative task of finding minimum adversarial distortions, our verifier is two to three orders of magnitude quicker than the state-of-the-art. We achieve this computational speedup via tight formulations for non-linearities, as well as a novel presolve algorithm that makes full use of all information available. The computational speedup allows us to verify properties on convolutional and residual networks with over 100,000 ReLUs --- several orders of magnitude more than networks previously verified by any complete verifier. In particular, we determine for the first time the exact adversarial accuracy of an MNIST classifier to perturbations with bounded l-\u221e norm \u03b5=0.1: for this classifier, we find an adversarial example for 4.38% of samples, and a certificate of robustness to norm-bounded perturbations for the remainder. Across all robust training procedures and network architectures considered, and for both the MNIST and CIFAR-10 datasets, we are able to certify more samples than the state-of-the-art and find more adversarial examples than a strong first-order attack.", "keywords": ["verification", "adversarial robustness", "adversarial examples", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper360/Authors"], "authors": ["Anonymous"], "TL;DR": "We efficiently verify the robustness of deep neural models with over 100,000 ReLUs, certifying more samples than the state-of-the-art and finding more adversarial examples than a strong first-order attack.", "pdf": "/pdf/bb01ba2730326074e1074cb8e6fd20adb206b1ca.pdf", "paperhash": "anonymous|evaluating_robustness_of_neural_networks_with_mixed_integer_programming", "_bibtex": "@inproceedings{    \nanonymous2019evaluating,    \ntitle={Evaluating Robustness of Neural Networks with Mixed Integer Programming},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGIdiRqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgw_sRqFQ", "original": "Hkgkn2KcKm", "number": 361, "cdate": 1538087790662, "ddate": null, "tcdate": 1538087790662, "tmdate": 1538156185153, "tddate": null, "forum": "SJgw_sRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Unusual Effectiveness of Averaging in GAN Training", "abstract": "We examine two different techniques for parameter averaging in GAN training. Moving Average (MA) computes the time-average of parameters, whereas Exponential Moving Average (EMA) computes an exponentially discounted sum. Whilst MA is known to lead to convergence in bilinear settings, we provide the first to our knowledge theoretical arguments in support of EMA. We show that EMA converges to limit cycles around the equilibrium with vanishing amplitude as the discount parameter approaches one. We establish experimentally that both techniques are strikingly effective in the non convex-concave GAN setting as well. Both improve inception and FID scores on different architectures and for different GAN objectives. We provide comprehensive experimental results across a range of datasets -- mixture of Gaussians, CIFAR-10, STL-10, CelebA and ImageNet -- to demonstrate its effectiveness. We achieve state-of-the-art results on CIFAR-10 and produce clean CelebA face images.", "keywords": ["Generative Adversarial Networks (GANs)", "Moving Average", "Exponential Moving Average", "Convergence", "Limit Cycles"], "authorids": ["ICLR.cc/2019/Conference/Paper361/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/21aec697f17f8285bfb2efc628a5a88f38f62888.pdf", "paperhash": "anonymous|the_unusual_effectiveness_of_averaging_in_gan_training", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Unusual Effectiveness of Averaging in GAN Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgw_sRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgwuiA9F7", "original": "rkgdw9u9t7", "number": 362, "cdate": 1538087790834, "ddate": null, "tcdate": 1538087790834, "tmdate": 1538156184945, "tddate": null, "forum": "rkgwuiA9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cramer-Wold AutoEncoder", "abstract": "Assessing distance betweeen the true and the sample distribution is a key component of many state of the art generative models, such as Wasserstein Autoencoder (WAE). Inspired by prior work on Sliced-Wasserstein Autoencoders (SWAE) and\nkernel smoothing we construct a new generative model \u2013 Cramer-Wold AutoEncoder (CWAE). CWAE cost function, based on introduced Cramer-Wold distance between samples, has a simple closed-form in the case of normal prior. As a consequence, while simplifying the optimization procedure (no need of sampling necessary to evaluate the distance function in the training loop), CWAE performance matches quantitatively and qualitatively that of WAE-MMD (WAE using maximum mean discrepancy based distance function) and often improves upon SWAE.", "keywords": ["autoencoder", "generative models", "deep neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper362/Authors"], "authors": ["Anonymous"], "TL;DR": "Inspired by prior work on Sliced-Wasserstein Autoencoders (SWAE) and kernel smoothing we construct a new generative model \u2013 Cramer-Wold AutoEncoder (CWAE).", "pdf": "/pdf/4c78d2c26f47643dd7106de279401b633c98de31.pdf", "paperhash": "anonymous|cramerwold_autoencoder", "_bibtex": "@inproceedings{    \nanonymous2019cramer-wold,    \ntitle={Cramer-Wold AutoEncoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgwuiA9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ewdiR5tQ", "original": "HkeuD5y9Ym", "number": 363, "cdate": 1538087791005, "ddate": null, "tcdate": 1538087791005, "tmdate": 1538156184733, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform does not require matrix eigendecomposition with high computational cost. Moreover, wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph semi-supervised classification, on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper363/Authors"], "authors": ["Anonymous"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/646941123cd5d1f0019354cf139385acaf7e5c8b.pdf", "paperhash": "anonymous|graph_wavelet_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Wavelet Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ewdiR5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1ePui0ctQ", "original": "HJxOseNctQ", "number": 364, "cdate": 1538087791174, "ddate": null, "tcdate": 1538087791174, "tmdate": 1538156184524, "tddate": null, "forum": "B1ePui0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SnapQuant: A Probabilistic and Nested Parameterization for Binary Networks", "abstract": "In this paper, we study the problem of training real binary weight networks (without layer-wise or filter-wise scaling factors) from scratch under the Bayesian deep learning perspective, meaning that the final objective is to approximate the posterior distribution of binary weights rather than reach a point estimation. The proposed method, named as SnapQuant, has two intriguing features: (1) The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. During the training phase, we generate binary weights on-the-fly since what we actually maintain is the policy network, and all the binary weights are used in a burn-after-reading style. At the testing phase, we can sample binary weight instances for a given recognition architecture from the learnt policy network. (2) The policy network, which has a nested parameter structure consisting of layer-wise, filter-wise and kernel-wise parameter sharing designs, is applicable to any neural network architecture. Such a nested parameterization explicitly and hierarchically models the joint posterior distribution of binary weights. The performance of SnapQuant is evaluated with several visual recognition tasks including ImageNet. The code will be made publicly available.", "keywords": ["Binary weight networks", "neural network quantization", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper364/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose SnapQuant, a reinforcement learning method for training binary weight networks from scratch under the Bayesian deep learning perspective, which approximates the posterior distribution of binary weights instead of a single point estimation.", "pdf": "/pdf/f7b3bc57b6782065c6b8e0ba325a402bb83f1eaa.pdf", "paperhash": "anonymous|snapquant_a_probabilistic_and_nested_parameterization_for_binary_networks", "_bibtex": "@inproceedings{    \nanonymous2019snapquant:,    \ntitle={SnapQuant: A Probabilistic and Nested Parameterization for Binary Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1ePui0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGDdsCcFQ", "original": "BJg0_FCtFX", "number": 365, "cdate": 1538087791350, "ddate": null, "tcdate": 1538087791350, "tmdate": 1538156184312, "tddate": null, "forum": "HyGDdsCcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Better Generalization with On-the-fly Dataset Denoising", "abstract": "Memorization in over-parameterized neural networks can severely hurt generalization in the presence of mislabeled examples. However, mislabeled examples are to hard avoid in extremely large datasets. We address this problem using the implicit regularization effect of stochastic gradient descent with large learning rates, which we find to be able to separate clean and mislabeled examples with remarkable success using loss statistics. We leverage this to identify and on-the-fly discard mislabeled examples using a threshold on their losses. This leads to On-the-fly Data Denoising (ODD), a simple yet effective algorithm that is robust to mislabeled examples, while introducing almost zero computational overhead. Empirical results demonstrate the effectiveness of ODD on several datasets containing artificial and real-world mislabeled examples.", "keywords": ["dataset denoising", "supervised learning", "implicit regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper365/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a fast and easy-to-implement algorithm that is robust to dataset noise.", "pdf": "/pdf/daf530ffdae253479114119c28fb055e72183d47.pdf", "paperhash": "anonymous|better_generalization_with_onthefly_dataset_denoising", "_bibtex": "@inproceedings{    \nanonymous2019better,    \ntitle={Better Generalization with On-the-fly Dataset Denoising},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGDdsCcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1eO_oCqtQ", "original": "Hye9C3t9KQ", "number": 366, "cdate": 1538087791522, "ddate": null, "tcdate": 1538087791522, "tmdate": 1538156184106, "tddate": null, "forum": "r1eO_oCqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gaussian-gated LSTM: Improved convergence by reducing state updates", "abstract": "Recurrent neural networks can be difficult to train on long sequence data due to the well-known vanishing gradient problem. Some architectures incorporate methods to reduce RNN state updates, therefore allowing the network to preserve memory over long temporal intervals. To address these problems of convergence, this paper proposes a timing-gated LSTM RNN model, called the Gaussian-gated LSTM (g-LSTM). The time gate controls when a neuron can be updated during training, enabling longer memory persistence and better error-gradient flow. This model captures long-temporal dependencies better than an LSTM and the time gate parameters can be learned even from non-optimal initialization values. Because the time gate limits the updates of the neuron state, the number of computes needed for the network update is also reduced. By adding a computational budget term to the training loss, we can obtain a network which further reduces the number of computes by at least 10x. Finally, by employing a temporal curriculum learning schedule for the g-LSTM, we can reduce the convergence time of the equivalent LSTM network on long sequences.", "keywords": ["time gate", "faster convergence", "trainability", "rnn", "computational budget"], "authorids": ["ICLR.cc/2019/Conference/Paper366/Authors"], "authors": ["Anonymous"], "TL;DR": "Gaussian-gated LSTM is a novel time-gated LSTM RNN network that enables faster and better training on long sequence data.", "pdf": "/pdf/4a52cf3b1b4dbcb18fd4fedc9ee3bc298cc8b3f1.pdf", "paperhash": "anonymous|gaussiangated_lstm_improved_convergence_by_reducing_state_updates", "_bibtex": "@inproceedings{    \nanonymous2019gaussian-gated,    \ntitle={Gaussian-gated LSTM: Improved convergence by reducing state updates},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eO_oCqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeuOiRqKQ", "original": "HkxudfwtK7", "number": 367, "cdate": 1538087791762, "ddate": null, "tcdate": 1538087791762, "tmdate": 1538156183898, "tddate": null, "forum": "HJeuOiRqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pooling Is Neither Necessary nor Sufficient for Appropriate Deformation Stability in CNNs", "abstract": "Many of our core assumptions about how neural networks operate remain empirically untested. One common assumption is that convolutional neural networks need to be stable to small translations and deformations to solve image recognition tasks. For many years, this stability was baked into CNN architectures by incorporating interleaved pooling layers. Recently, however, interleaved pooling has largely been abandoned. This raises a number of questions: Are our intuitions about deformation stability right at all? Is it important? Is pooling necessary for deformation invariance? If not, how is deformation invariance achieved in its absence? In this work, we rigorously test these questions, and find that deformation stability in convolutional networks is more nuanced than it first appears: (1) Deformation invariance is not a binary property, but rather that different tasks require different degrees of deformation stability at different layers. (2) Deformation stability is not a fixed property of a network and is heavily adjusted over the course of training, largely through the smoothness of the convolutional filters. (3) Interleaved pooling layers are neither necessary nor sufficient for achieving the optimal form of deformation stability for natural image classification. (4) Pooling confers \\emph{too much} deformation stability for image classification at initialization, and during training, networks have to learn to \\emph{counteract} this inductive bias. Together, these findings provide new insights into the role of interleaved pooling and deformation invariance in CNNs, and demonstrate the importance of rigorous empirical testing of even our most basic assumptions about the working of neural networks.", "keywords": ["Convolutional Neural Networks", "Deformation Stability", "Pooling", "Transformation Invariance"], "authorids": ["ICLR.cc/2019/Conference/Paper367/Authors"], "authors": ["Anonymous"], "TL;DR": "We find that pooling alone does not determine deformation stability in CNNs and that filter smoothness plays an important role in determining stability. ", "pdf": "/pdf/930e3f89091c3300dc9a1118398cc05c26618802.pdf", "paperhash": "anonymous|pooling_is_neither_necessary_nor_sufficient_for_appropriate_deformation_stability_in_cnns", "_bibtex": "@inproceedings{    \nanonymous2019pooling,    \ntitle={Pooling Is Neither Necessary nor Sufficient for Appropriate Deformation Stability in CNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeuOiRqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByGOuo0cYm", "original": "S1xhUvuct7", "number": 368, "cdate": 1538087791946, "ddate": null, "tcdate": 1538087791946, "tmdate": 1538156183691, "tddate": null, "forum": "ByGOuo0cYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta Domain Adaptation: Meta-Learning for Few-Shot Learning under Domain Shift", "abstract": "Few-Shot Learning (learning with limited labeled data) aims to overcome the limitations of traditional machine learning approaches which require thousands of labeled examples to train an effective model. Considered as a hallmark of human intelligence, the community has recently witnessed several contributions on this topic, in particular through meta-learning, where a model learns how to learn an effective model for few-shot learning. The main idea is to acquire prior knowledge from a set of training tasks, which is then used to perform (few-shot) test tasks. Most existing work assumes that both training and test tasks are drawn from the same distribution, and a large amount of labeled data is available in the training tasks. This is a very strong assumption which restricts the usage of meta-learning strategies in the real world where ample training tasks following the same distribution as test tasks may not be available. In this paper, we propose a novel meta-learning paradigm wherein a few-shot learning model is learnt, which simultaneously overcomes domain shift between the train and test tasks via adversarial domain adaptation. We demonstrate the efficacy the proposed method through extensive experiments.", "keywords": ["Meta-Learning", "Few-Shot Learning", "Domain Adaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper368/Authors"], "authors": ["Anonymous"], "TL;DR": "Meta Learning for Few Shot learning assumes that training tasks and test tasks are drawn from the same distribution. What do you do if they are not? Meta Domain Adaptation!", "pdf": "/pdf/c505b3bda8f70c49c0607ab59d19ed16be15eb29.pdf", "paperhash": "anonymous|meta_domain_adaptation_metalearning_for_fewshot_learning_under_domain_shift", "_bibtex": "@inproceedings{    \nanonymous2019meta,    \ntitle={Meta Domain Adaptation: Meta-Learning for Few-Shot Learning under Domain Shift},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByGOuo0cYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJG__i0qF7", "original": "rklIFAt9Ym", "number": 369, "cdate": 1538087792120, "ddate": null, "tcdate": 1538087792120, "tmdate": 1538156183486, "tddate": null, "forum": "BJG__i0qF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to encode spatial relations from natural language", "abstract": "Natural language processing has made significant inroads into learning the semantics of words through distributional approaches, however representations learnt via these methods fail to capture certain kinds of information implicit in the real world. In particular, spatial relations are encoded in a way that is inconsistent with human spatial reasoning and lacking invariance to viewpoint changes. We present a system capable of capturing the semantics of spatial relations such as behind, left of, etc from natural language. Our key contributions are a novel multi-modal objective based on generating images of scenes from their textual descriptions, and a new dataset on which to train it. We demonstrate that internal representations are robust to meaning preserving transformations of descriptions (paraphrase invariance), while viewpoint invariance is an emergent property of the system.", "keywords": ["generative model", "grounded language", "scene understanding", "natural language"], "authorids": ["ICLR.cc/2019/Conference/Paper369/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a system capable of capturing the semantics of spatial relations by grounding representation learning in vision.", "pdf": "/pdf/d32d75aba7bac2c452d66f92b85bd271973eb086.pdf", "paperhash": "anonymous|learning_to_encode_spatial_relations_from_natural_language", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to encode spatial relations from natural language},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJG__i0qF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJEOOsCqKm", "original": "BkxwqAtcF7", "number": 370, "cdate": 1538087792342, "ddate": null, "tcdate": 1538087792342, "tmdate": 1538156183284, "tddate": null, "forum": "BJEOOsCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Psychophysical vs. learnt texture representations in novelty detection", "abstract": "Parametric texture models have been applied successfully to synthesize artificial images. Psychophysical studies show that under defined conditions observers are unable to differentiate between model-generated and original natural textures. In industrial applications the reverse case is of interest: a texture analysis system should decide if human observers are able to discriminate between a reference and a novel texture. For example, in case of inspecting decorative surfaces the de- tection of visible texture anomalies without any prior knowledge is required. Here, we implemented a human-vision-inspired novelty detection approach. Assuming that the features used for texture synthesis are important for human texture percep- tion, we compare psychophysical as well as learnt texture representations based on activations of a pretrained CNN in a novelty detection scenario. Additionally, we introduce a novel objective function to train one-class neural networks for novelty detection and compare the results to standard one-class SVM approaches. Our experiments clearly show the differences between human-vision-inspired texture representations and learnt features in detecting visual anomalies. Based on a dig- ital print inspection scenario we show that psychophysical texture representations are able to outperform CNN-encoded features.", "keywords": ["novelty detection", "learnt texture representation", "one-class neural network", "human-vision-inspired anomaly detection"], "authorids": ["ICLR.cc/2019/Conference/Paper370/Authors"], "authors": ["Anonymous"], "TL;DR": "Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.", "pdf": "/pdf/d3b8ba69ac8f3cb3e17b5f592e57e42c05bfd029.pdf", "paperhash": "anonymous|psychophysical_vs_learnt_texture_representations_in_novelty_detection", "_bibtex": "@inproceedings{    \nanonymous2019psychophysical,    \ntitle={Psychophysical vs. learnt texture representations in novelty detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJEOOsCqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gFuiA9KX", "original": "BJeMjCtqK7", "number": 371, "cdate": 1538087792572, "ddate": null, "tcdate": 1538087792572, "tmdate": 1538156183091, "tddate": null, "forum": "H1gFuiA9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Skip-gram word embeddings in hyperbolic space", "abstract": "Embeddings of tree-like graphs in hyperbolic space were recently shown to surpass their Euclidean counterparts in performance by a large margin.\nInspired by these results, we present an algorithm for learning word embeddings in hyperbolic space from free text. An objective function based on the hyperbolic distance is derived and included in the skip-gram negative-sampling architecture from word2vec. The hyperbolic word embeddings are then evaluated on word similarity and analogy benchmarks. The results demonstrate the potential of hyperbolic word embeddings, particularly in low dimensions, though without clear superiority over their Euclidean counterparts. We further discuss subtleties in the formulation of the analogy task in curved spaces.", "keywords": ["word embeddings", "hyperbolic", "skip-gram"], "authorids": ["ICLR.cc/2019/Conference/Paper371/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/104a0474c2192cba0b7a77922b939efb59ebe93f.pdf", "paperhash": "anonymous|skipgram_word_embeddings_in_hyperbolic_space", "_bibtex": "@inproceedings{    \nanonymous2019skip-gram,    \ntitle={Skip-gram word embeddings in hyperbolic space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gFuiA9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxYOiCqKX", "original": "S1gX6RY5YQ", "number": 372, "cdate": 1538087792744, "ddate": null, "tcdate": 1538087792744, "tmdate": 1538156182890, "tddate": null, "forum": "SkxYOiCqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pixel Chem: A Representation for Predicting Material Properties with Neural Network", "abstract": "In this work we developed a new representation of the chemical information for the machine learning models, with benefits from both the real space (R-space) and energy space (K-space). Different from the previous symmetric matrix presentations, the charge transfer channel based on Pauling\u2019s electronegativity is derived from the dependence on real space distance and orbitals for the hetero atomic structures.  This representation can work for the bulk materials as well as the low dimensional nano materials, and can map the R-space and K-space into the pixel space (P-space) by training and testing 130k structures. P-space can well reproduce the R-space quantities within error 0.53. This new asymmetric matrix representation double the information storage than the previous symmetric representations.This work provides a new dimension for the computational chemistry towards the machine learning architecture. ", "keywords": ["material property prediction", "neural network", "material structure representation", "chemistry"], "authorids": ["ICLR.cc/2019/Conference/Paper372/Authors"], "authors": ["Anonymous"], "TL;DR": "Proposed a unified, physics based representation of material structures to predict various properties with neural netwoek.", "pdf": "/pdf/25b46c3e5eca827cc4803c0ed02d6eb52c87d5b6.pdf", "paperhash": "anonymous|pixel_chem_a_representation_for_predicting_material_properties_with_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019pixel,    \ntitle={Pixel Chem: A Representation for Predicting Material Properties with Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxYOiCqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzYdsAqY7", "original": "S1gUENCYYX", "number": 373, "cdate": 1538087792921, "ddate": null, "tcdate": 1538087792921, "tmdate": 1538156182694, "tddate": null, "forum": "SJzYdsAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["ICLR.cc/2019/Conference/Paper373/Authors"], "authors": ["Anonymous"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "anonymous|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@inproceedings{    \nanonymous2019spatial-winograd,    \ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzYdsAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkfYOoCcYX", "original": "S1ldXiDcYQ", "number": 374, "cdate": 1538087793118, "ddate": null, "tcdate": 1538087793118, "tmdate": 1538156182485, "tddate": null, "forum": "HkfYOoCcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Double Viterbi: Weight Encoding for High Compression Ratio and Fast On-Chip Reconstruction for Deep Neural Network", "abstract": "Weight pruning has been introduced as an efficient model compression technique. Even though pruning removes significant amount of weights in a network, memory requirement reduction was limited since conventional sparse matrix formats require significant amount of memory to store index-related information. Moreover, computations associated with such sparse matrix formats are slow because sequential sparse matrix decoding process does not utilize highly parallel computing systems efficiently. As an attempt to compress index information while keeping the decoding process parallelizable, Viterbi-based pruning was suggested. Decoding non-zero weights, however, is still sequential in Viterbi-based pruning. In this paper, we propose a new sparse matrix format in order to enable a highly parallel decoding process of the entire sparse matrix. The proposed sparse matrix is constructed by combining pruning and weight quantization. For the latest RNN models on PTB and WikiText-2 corpus, LSTM parameter storage requirement is compressed 19x using the proposed sparse matrix format compared to the baseline model. Compressed weight and indices can be reconstructed into a dense matrix fast using Viterbi encoders. Simulation results show that the proposed scheme can feed parameters to processing elements 30.9 % to 59.6 % faster than the case where the dense matrix values directly come from DRAM.", "keywords": ["quantization", "pruning", "memory footprint", "model compression", "sparse matrix"], "authorids": ["ICLR.cc/2019/Conference/Paper374/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a new weight encoding scheme which enables high compression ratio and fast sparse-to-dense matrix conversion.", "pdf": "/pdf/03e125d1f2f6fcd7c3bfda71669bfbad957b35f6.pdf", "paperhash": "anonymous|double_viterbi_weight_encoding_for_high_compression_ratio_and_fast_onchip_reconstruction_for_deep_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019double,    \ntitle={Double Viterbi: Weight Encoding for High Compression Ratio and Fast On-Chip Reconstruction for Deep Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkfYOoCcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklKui0ct7", "original": "SklWQCxcKQ", "number": 375, "cdate": 1538087793292, "ddate": null, "tcdate": 1538087793292, "tmdate": 1538156182281, "tddate": null, "forum": "HklKui0ct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy", "abstract": " When learning from a batch of logged bandit feedback, the discrepancy between the policy to be learned and the off-policy training data imposes statistical and computational challenges. Unlike classical supervised learning and online learning settings, in batch contextual bandit learning, one only has access to a collection of logged feedback from the actions taken by a historical policy, and expect to learn a policy that takes good actions in possibly unseen contexts. Such a batch learning setting is ubiquitous in online and interactive systems, such as ad platforms and recommendation systems. Existing approaches based on inverse propensity weights, such as Inverse Propensity Scoring (IPS) and Policy Optimizer for Exponential Models (POEM), enjoy unbiasedness but often suffer from large mean squared error. In this work, we introduce a new approach named Maximum Likelihood Inverse Propensity Scoring (MLIPS) for batch learning from logged bandit feedback. Instead of using the given historical policy as the proposal in inverse propensity weights, we estimate a maximum likelihood surrogate policy based on the logged action-context pairs, and then use this surrogate policy as the proposal. We prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. Such an error reduction phenomenon is somewhat surprising as the estimated surrogate policy is less accurate than the given historical policy. Results on multi-label classification problems and a large-scale ad placement dataset demonstrate the empirical effectiveness of MLIPS. Furthermore, the proposed surrogate policy technique is complementary to existing error reduction techniques, and when combined, is able to consistently boost the performance of several widely used approaches.", "keywords": ["Causal inference", "Policy Optimization", "Non-asymptotic analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper375/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ab4ded7d5cc8d6bc936e32e2c404e011f2c53634.pdf", "paperhash": "anonymous|offpolicy_evaluation_and_learning_from_logged_bandit_feedback_error_reduction_via_surrogate_policy", "_bibtex": "@inproceedings{    \nanonymous2019off-policy,    \ntitle={Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklKui0ct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxY_oCqKQ", "original": "rJe1bw2YK7", "number": 376, "cdate": 1538087793462, "ddate": null, "tcdate": 1538087793462, "tmdate": 1538156182080, "tddate": null, "forum": "rJxY_oCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Forensic Representation to Detect Non-Trivial Image Duplicates, and How it Applies to Semantic Segmentation", "abstract": "Manipulation and re-use of images in scientific publications is a recurring problem, at present lacking a scalable solution.  Existing tools for detecting image duplication are mostly manual or semi-automated, despite the fact that generating data for a learning-based approach is straightforward, as we here illustrate. This paper addresses the problem of determining if, given two images, one is a manipulated version of the other by means of certain geometric and statistical manipulations, e.g. copy, rotation, translation, scale, perspective transform, histogram adjustment, partial erasing, and compression artifacts. We propose a solution based on a 3-branch Siamese Convolutional Neural Network. The ConvNet model is trained to map images into a 128-dimensional space, where the Euclidean distance between duplicate (respectively, unique) images is no greater (respectively, greater) than 1. Our results suggest that such an approach can serve as tool to improve surveillance of the published and in-peer-review literature for image manipulation. We also show that as a byproduct the network learns useful representations for semantic segmentation, with performance comparable to that of domain-specific models.", "keywords": ["metric learning", "image similarity", "image forensics", "siamese network", "semantic segmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper376/Authors"], "authors": ["Anonymous"], "TL;DR": "A forensic metric to determine if a given image is a copy (with possible manipulation) of another image from a given dataset.", "pdf": "/pdf/89f1555b903d4767c41ec92f855c181478f4e642.pdf", "paperhash": "anonymous|a_forensic_representation_to_detect_nontrivial_image_duplicates_and_how_it_applies_to_semantic_segmentation", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Forensic Representation to Detect Non-Trivial Image Duplicates, and How it Applies to Semantic Segmentation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxY_oCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bye5OiR5F7", "original": "SJgL3pKFFQ", "number": 377, "cdate": 1538087793639, "ddate": null, "tcdate": 1538087793639, "tmdate": 1538156181878, "tddate": null, "forum": "Bye5OiR5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Wasserstein proximal of GANs", "abstract": "We introduce a new method for training GANs by applying the Wasserstein-2 metric proximal on the generators. \nThe approach is based on the gradient operator induced by optimal transport, which connects the geometry of sample space and parameter space in implicit deep generative models. From this theory, we obtain an easy-to-implement regularizer for the parameter updates. Our experiments demonstrate that this method improves the speed and stability in training GANs in terms of wall-clock time and Fr\\'echet Inception Distance (FID) learning curves. ", "keywords": ["Optimal transport", "Wasserstein gradient", "Generative adversarial network", "Unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper377/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose the Wasserstein proximal method for training GANs. ", "pdf": "/pdf/9df0392be5f34787936b348563f3e8e10c62af7c.pdf", "paperhash": "anonymous|wasserstein_proximal_of_gans", "_bibtex": "@inproceedings{    \nanonymous2019wasserstein,    \ntitle={Wasserstein proximal of GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bye5OiR5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkecOj09FQ", "original": "B1eNqe55tm", "number": 378, "cdate": 1538087793811, "ddate": null, "tcdate": 1538087793811, "tmdate": 1538156181603, "tddate": null, "forum": "HkecOj09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal Marginalizer for Amortised Inference and Embedding of Generative Models", "abstract": "Probabilistic graphical models are powerful tools which allow us to formalise our knowledge about the world and reason about its inherent uncertainty. There exist a considerable number of methods for performing inference in probabilistic graphical models, however, they can be computational costly due to significant time burden, storage requirements or they lack theoretical guarantees of convergence and accuracy when applied to very large graphical models. We propose the Universal Marginaliser Importance Sampler (UM-IS) -- a hybrid inference scheme that combines the flexibility of a deep neural network trained on samples from the model and it inherits the asymptotic guarantees of importance sampling. We show how combining samples drawn from the graphical model with an appropriate masking function allows us to train a single neural network to approximate any of the corresponding conditional marginal distributions, and thus amortise the cost of inference. We demonstrate that the efficiency of importance sampling is significantly improved by using as the proposal distribution samples from the neural network. We also use the embeddings obtained from the proposed neural network and utilise them for different tasks such as clustering, classification and interpretation of relationships between the nodes. Finally, we benchmark the method on a large graph (>1000 nodes), showing that UM-IS outperforms sampling-based based methods by a large margin while being computationally efficient.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper378/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d6b4931776925f37c7522ece3015ffec987c718b.pdf", "paperhash": "anonymous|universal_marginalizer_for_amortised_inference_and_embedding_of_generative_models", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Marginalizer for Amortised Inference and Embedding of Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkecOj09FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJMcdsA5FX", "original": "HylHD-95tQ", "number": 379, "cdate": 1538087794001, "ddate": null, "tcdate": 1538087794001, "tmdate": 1538156181388, "tddate": null, "forum": "rJMcdsA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Accurate Evaluation of GANs for Language Generation", "abstract": "Generative Adversarial Networks (GANs) are a promising approach to language generation. The latest works introducing novel GAN models for language generation use n-gram based metrics for evaluation and only report single scores of the best run. In this paper, we argue that this often misrepresents the true picture and does not tell the full story, as GAN models can be extremely sensitive to the random initialization and small deviations from the best hyperparameter choice. In particular, we demonstrate that the previously used BLEU score is not sensitive to semantic deterioration of generated texts and propose alternative metrics that better capture the quality and diversity of the generated samples. We also conduct a set of experiments comparing a number of GAN models for text with a conventional Language Model (LM) and find that none of the considered models performs convincingly better than the LM.", "keywords": ["GANs", "Evaluation", "Generative Models"], "authorids": ["ICLR.cc/2019/Conference/Paper379/Authors"], "authors": ["Anonymous"], "TL;DR": "We discuss how to evaluate GANs for language generation, propose a protocol and show that simple Language Models achieve results as good as GANs.", "pdf": "/pdf/ae11f08823b4d0773a0362e8b5d6245a228d853c.pdf", "paperhash": "anonymous|on_accurate_evaluation_of_gans_for_language_generation", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Accurate Evaluation of GANs for Language Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJMcdsA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1G9doA9F7", "original": "rJgOuG-cK7", "number": 380, "cdate": 1538087794171, "ddate": null, "tcdate": 1538087794171, "tmdate": 1538156181182, "tddate": null, "forum": "B1G9doA9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Augmented Cyclic Adversarial Learning for Domain Adaptation", "abstract": "Training a model to perform a task typically requires a large amount of data from the domains in which the task will be applied. However, it is often the case that data are abundant in some domains but scarce in others. Domain adaptation deals with the challenge of adapting a model trained from a data-rich source domain to perform well in a data-poor target domain. In general, this requires learning plausible mappings between domains. CycleGAN is a powerful framework that efficiently learns to map inputs from one domain to another using adversarial training and a cycle-consistency constraint. However, the conventional approach of enforcing cycle-consistency via reconstruction may be overly restrictive in cases where one or more domains have limited training data. In this paper, we propose an augmented cyclic adversarial learning model that enforces the cycle-consistency constraint via an external task specific model, which encourages the preservation of task-relevant content as opposed to exact reconstruction. We explore digit classification in a low-resource setting in supervised, semi and unsupervised situation, as well as high resource unsupervised. In low-resource supervised setting, the results show that our approach improves absolute performance by 14% and 4% when adapting SVHN to MNIST and vice versa, respectively, which outperforms unsupervised domain adaptation methods that require high-resource unlabeled target domain. Moreover, using only few unsupervised target data, our approach can still outperforms many high-resource unsupervised models. Our model also outperforms on USPS to MNIST and synthetic digit to SVHN for high resource unsupervised adaptation. In speech domains, we similarly adopt a speech recognition model from each domain as the task specific model. Our approach improves absolute performance of speech recognition by 2% for female speakers in the TIMIT dataset, where the majority of training samples are from male voices.", "keywords": ["Domain adaptation", "generative adversarial network", "cyclic adversarial learning", "speech"], "authorids": ["ICLR.cc/2019/Conference/Paper380/Authors"], "authors": ["Anonymous"], "TL;DR": "A new cyclic adversarial learning augmented with auxiliary task model which improves domain adaptation performance in low resource supervised and unsupervised situations ", "pdf": "/pdf/96a3ddeb3725d71be87f849c69353b50f58f8806.pdf", "paperhash": "anonymous|augmented_cyclic_adversarial_learning_for_domain_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019augmented,    \ntitle={Augmented Cyclic Adversarial Learning for Domain Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1G9doA9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryEquiR9KX", "original": "rJlN0BFqYm", "number": 381, "cdate": 1538087794342, "ddate": null, "tcdate": 1538087794342, "tmdate": 1538156180973, "tddate": null, "forum": "ryEquiR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Applications of Gaussian Processes in Finance", "abstract": "Estimating covariances between financial assets plays an important role in risk management. In practice, when the sample size is small compared to the number of variables, the empirical estimate is known to be very unstable. Here, we propose a novel covariance estimator based on the Gaussian Process Latent Variable Model (GP-LVM). Our estimator can be considered as a non-linear extension of standard factor models with readily interpretable parameters reminiscent of market betas. Furthermore, our Bayesian treatment naturally shrinks the sample covariance matrix towards a more structured matrix given by the prior and thereby systematically reduces estimation errors. Finally, we discuss some financial applications of the GP-LVM model.", "keywords": ["Gaussian Processes", "Latent Variable Model", "Variational Bayes", "Stan", "Asset Pricing", "Portfolio Allocation", "Finance", "CAPM"], "authorids": ["ICLR.cc/2019/Conference/Paper381/Authors"], "authors": ["Anonymous"], "TL;DR": "Covariance matrix estimation of financial assets with Gaussian Process Latent Variable Models", "pdf": "/pdf/a6f5c8dafb8bfd4cef9b8ac512b360a7bcc20e3b.pdf", "paperhash": "anonymous|applications_of_gaussian_processes_in_finance", "_bibtex": "@inproceedings{    \nanonymous2019applications,    \ntitle={Applications of Gaussian Processes in Finance},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryEquiR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJequsCqKQ", "original": "H1l2Tx5qKX", "number": 382, "cdate": 1538087794505, "ddate": null, "tcdate": 1538087794505, "tmdate": 1538156180767, "tddate": null, "forum": "SJequsCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cautious Deep Learning", "abstract": "Most classifiers operate by selecting the maximum of an estimate of the conditional distribution $p(y|x)$ where $x$ stands for the features of the instance to be classified and $y$ denotes its label. This often results in a hubristic bias: overconfidence in the assignment of a definite label. Usually, the observations are concentrated on a small volume but the classifier provides definite predictions for the entire space. We propose constructing conformal prediction sets which contain a set of labels rather than a single label. These conformal prediction sets contain the true label with probability $1-\\alpha$. Our construction is based on $p(x|y)$ rather than $p(y|x)$ which results in a classifier that is very cautious: it outputs the null set --- meaning ``I don't know'' --- when the object does not resemble the training examples. An important property of our approach is that classes can be added or removed without having to retrain the classifier. We demonstrate the performance on the ImageNet ILSVRC dataset and the CelebA and IMDB-Wiki facial datasets using high dimensional features obtained from state of the art convolutional neural networks. ", "keywords": ["Deep Learning", "Classification", "Prediction", "Cautious Methods"], "authorids": ["ICLR.cc/2019/Conference/Paper382/Authors"], "authors": ["Anonymous"], "TL;DR": "New way to do classification using P(X|Y) instead P(Y|X) which results with cautious prediciton outputing \"I don't know\" for outliers. ", "pdf": "/pdf/ea7beb25994d32da1563fb428ad8e696304f00bd.pdf", "paperhash": "anonymous|cautious_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019cautious,    \ntitle={Cautious Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJequsCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkeoOo09YX", "original": "HJeCew8KY7", "number": 383, "cdate": 1538087794730, "ddate": null, "tcdate": 1538087794730, "tmdate": 1538156180557, "tddate": null, "forum": "HkeoOo09YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning For Stochastic Gradient MCMC", "abstract": "Stochastic gradient Markov chain Monte Carlo (SG-MCMC) has become increasingly popular for simulating posterior samples in large-scale Bayesian modeling. However, existing SG-MCMC schemes are not tailored to any specific probabilistic model, even a simple modification of the underlying dynamical system requires significant physical intuition. This paper presents the first meta-learning algorithm that allows automated design for the underlying continuous dynamics of an SG-MCMC sampler. The learned sampler generalizes Hamiltonian dynamics with state-dependent drift and diffusion, enabling fast traversal and efficient exploration of energy landscapes. Experiments validate the proposed approach on Bayesian fully connected neural network, Bayesian convolutional neural network and Bayesian recurrent neural network tasks, showing that the learned sampler outperforms generic, hand-designed SG-MCMC algorithms, and generalizes to different datasets and larger architectures.", "keywords": ["Meta Learning", "MCMC"], "authorids": ["ICLR.cc/2019/Conference/Paper383/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes a method to automate the design of stochastic gradient MCMC proposal using meta learning approach. ", "pdf": "/pdf/364b08e2944fe7e35018c2e954c1775aee0a7407.pdf", "paperhash": "anonymous|metalearning_for_stochastic_gradient_mcmc", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning For Stochastic Gradient MCMC},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkeoOo09YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xiOjC9F7", "original": "rJxCN_4cYQ", "number": 384, "cdate": 1538087794905, "ddate": null, "tcdate": 1538087794905, "tmdate": 1538156180338, "tddate": null, "forum": "S1xiOjC9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["ICLR.cc/2019/Conference/Paper384/Authors"], "authors": ["Anonymous"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/afb38ce596c21246db8c81d5dfe8e004cce28843.pdf", "paperhash": "anonymous|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xiOjC9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJGjOi09t7", "original": "SylKn7ccKQ", "number": 385, "cdate": 1538087795082, "ddate": null, "tcdate": 1538087795082, "tmdate": 1538156180130, "tddate": null, "forum": "BJGjOi09t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Variational Autoencoder for Probabilistic Non-Negative Matrix Factorisation", "abstract": "We introduce and demonstrate the variational autoencoder for probabilistic non-negative matrix factorisation (PAE-NMF). We design a network which can perform NMF and add in aspects of a VAE to make the coefficients of the latent space probabilistic. By restricting the weights in the final layer of the network to be non-negative and using the non-negative Weibull distribution we produce a probabilistic form of NMF which allows us to generate new data and find a probability distribution that effectively links the latent and input variables. We demonstrate the effectiveness of PAE-NMF on three heterogeneous datasets: images, financial time series and genomic.", "keywords": ["Non-negative matrix factorisation", "Variational autoencoder", "Probabilistic"], "authorids": ["ICLR.cc/2019/Conference/Paper385/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4c7043c9dd2a6ad9191166a28cf9fd2d2b07e6dd.pdf", "paperhash": "anonymous|a_variational_autoencoder_for_probabilistic_nonnegative_matrix_factorisation", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Variational Autoencoder for Probabilistic Non-Negative Matrix Factorisation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJGjOi09t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJzoujRct7", "original": "BJlhaQqctX", "number": 386, "cdate": 1538087795260, "ddate": null, "tcdate": 1538087795260, "tmdate": 1538156179922, "tddate": null, "forum": "rJzoujRct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Solution to China Competitive Poker Using Deep Learning", "abstract": "Recently, deep neural networks have achieved superhuman performance in various games such as Go, chess and Shogi. Compared to Go, China Competitive Poker, also known as Dou dizhu, is a type of imperfect information game, including hidden information, randomness, multi-agent cooperation and competition. It has become widespread and is now a national game in China. We introduce an approach to play China Competitive Poker using Convolutional Neural Network (CNN) to predict actions. This network is trained by supervised learning from human game records. Without any search, the network already beats the best AI program by a large margin, and also beats the best human amateur players in duplicate mode.", "keywords": ["artificial intelligence", "China competitive poker", "Dou dizhu", "CNN", "imperfect information game"], "authorids": ["ICLR.cc/2019/Conference/Paper386/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces a method to play China competitive poker using deep neural network, gets the state of the art performance.", "pdf": "/pdf/6bd5dc3c8fd0f148ceafc85f824209321289bb49.pdf", "paperhash": "anonymous|a_solution_to_china_competitive_poker_using_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Solution to China Competitive Poker Using Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJzoujRct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xjdoC9Fm", "original": "S1gnEm55tm", "number": 387, "cdate": 1538087795429, "ddate": null, "tcdate": 1538087795429, "tmdate": 1538156179709, "tddate": null, "forum": "S1xjdoC9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep models calibration with bayesian neural networks", "abstract": "We apply Bayesian Neural Networks to improve calibration of state-of-the-art deep\nneural networks. We show that, even with the most basic amortized approximate\nposterior distribution, and fast fully connected neural network for the likelihood,\nthe Bayesian framework clearly outperforms other simple maximum likelihood\nbased solutions that have recently shown very good performance, as temperature\nscaling. As an example, we reduce the Expected Calibration\nError (ECE) from 0.52 to 0.24 on CIFAR-10 and from 4.28 to 2.456 on CIFAR-100\non two Wide ResNet with 96.13% and 80.39% accuracy respectively, which are\namong the best results published for this task. We demonstrate our robustness and\nperformance with experiments on a wide set of state-of-the-art computer vision\nmodels. Moreover, our approach acts off-line, and thus can be applied to any\nprobabilistic model regardless of the limitations that the model may present during\ntraining. This make it suitable to calibrate systems that make use of pre-trained\ndeep neural networks that are expensive to train for a specific task, or to directly\ntrain a calibrated deep convolutional model with Monte Carlo Dropout approximations, among others. However,\nour method is still complementary with any Bayesian Neural Network for further\nimprovement.", "keywords": ["calibration", "deep models", "bayesian neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper387/Authors"], "authors": ["Anonymous"], "TL;DR": "We apply bayesian neural networks to improve calibration", "pdf": "/pdf/5990812bdad5a48cc75479290418427bfb25c221.pdf", "paperhash": "anonymous|deep_models_calibration_with_bayesian_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep models calibration with bayesian neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xjdoC9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sye2doC9tX", "original": "B1gfHxP5Ym", "number": 388, "cdate": 1538087795597, "ddate": null, "tcdate": 1538087795597, "tmdate": 1538156179495, "tddate": null, "forum": "Sye2doC9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploration by Uncertainty in Reward Space", "abstract": "Efficient exploration plays a key role in reinforcement learning tasks. Commonly used dithering strategies, such as\u000f-greedy, try to explore the action-state space randomly; this can lead to large demand for samples. In this paper, We propose an exploration method based on the uncertainty in reward space. There are two policies in this approach, the exploration policy is used for exploratory sampling in the environment, then the benchmark policy try to update by the data proven by the exploration policy. Benchmark policy is used to provide the uncertainty in reward space, e.g. td-error, which guides the exploration policy updating. We apply our method on two grid-world environments and four Atari games. Experiment results show that our method improves learning speed and have a better performance than baseline policies", "keywords": ["Policy Exploration", "Uncertainty in Reward Space"], "authorids": ["ICLR.cc/2019/Conference/Paper388/Authors"], "authors": ["Anonymous"], "TL;DR": "Exploration by Uncertainty in Reward Space", "pdf": "/pdf/5d0758db0c8a5ab2f365bfee891eba7010a67d2f.pdf", "paperhash": "anonymous|exploration_by_uncertainty_in_reward_space", "_bibtex": "@inproceedings{    \nanonymous2019exploration,    \ntitle={Exploration by Uncertainty in Reward Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sye2doC9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxhusA9Fm", "original": "rklMN4O9FX", "number": 389, "cdate": 1538087795780, "ddate": null, "tcdate": 1538087795780, "tmdate": 1538156179289, "tddate": null, "forum": "HyxhusA9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Talk The Walk: Navigating Grids in New York City through Grounded Dialogue", "abstract": "We introduce `\"Talk The Walk\", the first large-scale dialogue dataset grounded in action and perception. The task involves two agents (a 'guide' and a 'tourist') that communicate via natural language in order to achieve a common goal: having the tourist navigate to a given target location. The task and dataset, which are described in detail, are challenging and their full solution is an open problem that we pose to the community. We (i) focus on the task of tourist localization and develop the novel Masked Attention for Spatial Convolutions (MASC) mechanism that allows for grounding tourist utterances into the guide's map, (ii) show it yields significant improvements for both emergent and natural language communication, and (iii) using this method, we establish non-trivial baselines on the full task. ", "keywords": ["Dialogue", "Navigation", "Grounded Language Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper389/Authors"], "authors": ["Anonymous"], "TL;DR": "First large-scale dialogue dataset grounded in action and perception", "pdf": "/pdf/605b68d392e90921e6add89fb759f37b3f74fe72.pdf", "paperhash": "anonymous|talk_the_walk_navigating_grids_in_new_york_city_through_grounded_dialogue", "_bibtex": "@inproceedings{    \nanonymous2019talk,    \ntitle={Talk The Walk: Navigating Grids in New York City through Grounded Dialogue},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxhusA9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryx3_iAcY7", "original": "S1xXrCoOF7", "number": 390, "cdate": 1538087795953, "ddate": null, "tcdate": 1538087795953, "tmdate": 1538156179077, "tddate": null, "forum": "ryx3_iAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["ICLR.cc/2019/Conference/Paper390/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "anonymous|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@inproceedings{    \nanonymous2019contextualized,    \ntitle={Contextualized Role Interaction for Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryx3_iAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkMhusC5Y7", "original": "S1xQTBpDt7", "number": 391, "cdate": 1538087796130, "ddate": null, "tcdate": 1538087796130, "tmdate": 1538156178867, "tddate": null, "forum": "rkMhusC5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation", "abstract": "We propose a method to efficiently learn diverse strategies in reinforcement learning for query reformulation in the tasks of document retrieval and question answering. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as an ensemble of agents trained on the full data. We show that the improved performance is due to the increased diversity of reformulation strategies. ", "keywords": ["Reinforcement Learning", "Multi-agent", "Information Retrieval", "Question-Answering", "Query Reformulation", "Query Expansion"], "authorids": ["ICLR.cc/2019/Conference/Paper391/Authors"], "authors": ["Anonymous"], "TL;DR": "Multiple diverse query reformulation agents trained with reinforcement learning to improve search engines.", "pdf": "/pdf/81ae6fc1d91f7c65f9259f5619e53c76ed920d6b.pdf", "paperhash": "anonymous|learning_to_coordinate_multiple_reinforcement_learning_agents_for_diverse_query_reformulation", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMhusC5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkf2_sC5FX", "original": "r1lYDHPctm", "number": 392, "cdate": 1538087796305, "ddate": null, "tcdate": 1538087796305, "tmdate": 1538156178657, "tddate": null, "forum": "Hkf2_sC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Lifelong Learning with A-GEM", "abstract": "In lifelong learning, the learner is presented with a sequence of tasks, incrementally building a data-driven prior which may be leveraged to speed up learning of a new task. In this work, we investigate the efficiency of current lifelong approaches, in terms of sample complexity, computational and memory cost. Towards this end, we first introduce a new and a more realistic evaluation protocol, whereby learners observe each example only once and hyper-parameter selection is done on a small and disjoint set of tasks, which is not used for the actual learning experience and evaluation. Second, we introduce a new metric measuring how quickly a learner acquires a new skill. Third, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017), dubbed Averaged GEM (A-GEM), which enjoys the same or even better performance as GEM, while being almost as computationally and memory efficient as EWC (Kirkpatrick et al., 2016) and other regularization-based methods. Finally, we show that all algorithms including A-GEM can learn even more quickly if they are provided with task descriptors specifying the classification tasks under consideration. Our experiments on several standard lifelong learning benchmarks demonstrate that A-GEM has the best trade-off between accuracy and efficiency.", "keywords": ["Lifelong Learning", "Continual Learning", "Catastrophic Forgetting", "Few-shot Transfer"], "authorids": ["ICLR.cc/2019/Conference/Paper392/Authors"], "authors": ["Anonymous"], "TL;DR": "An efficient lifelong learning algorithm that provides a better trade-off between accuracy and time/ memory complexity compared to other algorithms. ", "pdf": "/pdf/78758029d126e64e36b17a7139fcd547c033351a.pdf", "paperhash": "anonymous|efficient_lifelong_learning_with_agem", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Lifelong Learning with A-GEM},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkf2_sC5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gh_sC9tm", "original": "SJeDSUK5F7", "number": 393, "cdate": 1538087796478, "ddate": null, "tcdate": 1538087796478, "tmdate": 1538156178449, "tddate": null, "forum": "H1gh_sC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Prior Networks for Detection of Adversarial Attacks", "abstract": "Adversarial examples are considered a serious issue for safety critical applications of AI,  such as finance, autonomous vehicle control and medicinal applications. Though significant work has resulted in increased robustness of systems to these attacks, systems are still vulnerable to well-crafted attacks. To address this problem\nseveral adversarial attack detection methods have been proposed. However, system can still be vulnerable to adversarial samples that are designed to specifically evade these detection methods. One recent detection scheme that has shown good performance is based on uncertainty estimates derived from Monte-Carlo dropout ensembles. Prior Networks, a new method of estimating predictive uncertainty, have been shown to outperform Monte-Carlo dropout on a range of tasks. One of the advantages of this approach is that the behaviour of a Prior Network can be explicitly tuned to, for example, predict high uncertainty in regions where there are no training data samples. In this work Prior Networks are applied to adversarial attack detection using measures of uncertainty in a similar fashion to Monte-Carlo Dropout. Detection based on measures of uncertainty derived from DNNs and Monte-Carlo dropout ensembles are used as a baseline. Prior Networks are shown to significantly out-perform these baseline approaches over a range of adversarial attacks in both detection of whitebox and blackbox configurations. Even when the adversarial attacks are constructed with full knowledge of the detection mechanism, it is shown to be highly challenging to successfully generate an adversarial sample.", "keywords": ["Uncertainty", "Prior Networks", "Adversarial Attacks", "Detection"], "authorids": ["ICLR.cc/2019/Conference/Paper393/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that it is possible to successfully detect a range of adversarial attacks using measures of uncertainty derived from Prior Networks.", "pdf": "/pdf/93e047185ca753efd395a498d2383689d063c739.pdf", "paperhash": "anonymous|prior_networks_for_detection_of_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019prior,    \ntitle={Prior Networks for Detection of Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gh_sC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hye6uoC9tm", "original": "HJgNi45qt7", "number": 394, "cdate": 1538087796650, "ddate": null, "tcdate": 1538087796650, "tmdate": 1538156178241, "tddate": null, "forum": "Hye6uoC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Incremental Hierarchical Reinforcement Learning with Multitask LMDPs", "abstract": "Exploration is a well known challenge in Reinforcement Learning. One principled way of overcoming this challenge is to find a hierarchical abstraction of the base problem and explore at these higher levels, rather than in the space of primitives. However, discovering a deep abstraction autonomously remains a largely unsolved problem, with practitioners typically hand-crafting these hierarchical control architectures. Recent work with multitask linear Markov decision processes, allows for the autonomous discovery of deep hierarchical abstractions, but operates exclusively in the offline setting. By extending this work, we develop an agent that is capable of incrementally growing a hierarchical representation, and using its experience to date to improve exploration.", "keywords": ["Reinforcement learning", "hierarchy", "linear markov decision process", "lmdl", "subtask discovery", "incremental"], "authorids": ["ICLR.cc/2019/Conference/Paper394/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop an agent capable of incrementally growing a hierarchical representation, and using its experience to date to improve exploration.", "pdf": "/pdf/9705b6ec7657158f7d433b7b6df194ba813c0028.pdf", "paperhash": "anonymous|incremental_hierarchical_reinforcement_learning_with_multitask_lmdps", "_bibtex": "@inproceedings{    \nanonymous2019incremental,    \ntitle={Incremental Hierarchical Reinforcement Learning with Multitask LMDPs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hye6uoC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eadi0cFQ", "original": "Hke7FFKctX", "number": 395, "cdate": 1538087796821, "ddate": null, "tcdate": 1538087796821, "tmdate": 1538156178034, "tddate": null, "forum": "H1eadi0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Magic Tunnels", "abstract": "Hierarchically embedding smaller networks in larger networks, e.g.~by increasing the number of hidden units, has been studied since the 1990s. The main interest was in understanding possible redundancies in the parameterization, as well as in studying  how such embeddings affect critical points. We take these results as a point of departure to devise a novel strategy for escaping from flat regions of the error surface and to address the slow-down of gradient-based methods experienced in plateaus of saddle points. The idea is to expand the dimensionality of a network in a way that guarantees the existence of new escape directions. We call this operation the opening of a tunnel. One may then continue with the larger network either temporarily, i.e.~closing the tunnel later, or permanently, i.e.~iteratively growing the network, whenever needed. We develop our method for fully-connected as well as convolutional layers.   Moreover, we present a practical version of our algorithm that requires no network structure modification and can be deployed as plug-and-play into any current deep learning framework. Experimentally, our method shows significant speed-ups.", "keywords": ["deep learning", "cnn", "structural modification", "optimization", "saddle point"], "authorids": ["ICLR.cc/2019/Conference/Paper395/Authors"], "authors": ["Anonymous"], "TL;DR": "If optimization gets stuck in a saddle, we add a filter to a CNN in a specific way in order to escape the saddle.", "pdf": "/pdf/2506723bab12123f0ab5547fcbe467f775afbb00.pdf", "paperhash": "anonymous|magic_tunnels", "_bibtex": "@inproceedings{    \nanonymous2019magic,    \ntitle={Magic Tunnels},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eadi0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxpuoCqtQ", "original": "H1glnwHctQ", "number": 396, "cdate": 1538087797002, "ddate": null, "tcdate": 1538087797002, "tmdate": 1538156177826, "tddate": null, "forum": "rJxpuoCqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Likelihood-based Permutation Invariant Loss Function for Probability Distributions", "abstract": "We propose a permutation-invariant loss function designed for the neural networks reconstructing a set of elements without considering the order within its vector representation. Unlike popular approaches for encoding and decoding a set, our work does not rely on a carefully engineered network topology nor by any additional sequential algorithm. The proposed method, Set Cross Entropy, has a natural information-theoretic interpretation and is related to the metrics defined for sets. We evaluate the proposed approach in two object reconstruction tasks and a rule learning task.", "keywords": ["Set Autoencoding"], "authorids": ["ICLR.cc/2019/Conference/Paper396/Authors"], "authors": ["Anonymous"], "TL;DR": "The proposed method, Set Cross Entropy, measures the information-theoretic similarity of sets in a permutation-invariant manner.", "pdf": "/pdf/5ee3908909ca7f7bbfd20d67a7563dd21f2414d0.pdf", "paperhash": "anonymous|likelihoodbased_permutation_invariant_loss_function_for_probability_distributions", "_bibtex": "@inproceedings{    \nanonymous2019likelihood-based,    \ntitle={Likelihood-based Permutation Invariant Loss Function for Probability Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxpuoCqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJeT_oRcY7", "original": "BJlEGrccK7", "number": 397, "cdate": 1538087797180, "ddate": null, "tcdate": 1538087797180, "tmdate": 1538156177620, "tddate": null, "forum": "SJeT_oRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Localized random projections challenge benchmarks for bio-plausible deep learning", "abstract": "Similar to models of brain-like computation, artificial deep neural networks rely\non distributed coding, parallel processing and plastic synaptic weights. Training\ndeep neural networks with the error-backpropagation algorithm, however, is\nconsidered bio-implausible. An appealing alternative to training deep neural networks\nis to use one or a few hidden layers with fixed random weights or trained\nwith an unsupervised, local learning rule and train a single readout layer with a\nsupervised, local learning rule. We find that a network of leaky-integrate-andfire\nneurons with fixed random, localized receptive fields in the hidden layer and\nspike timing dependent plasticity to train the readout layer achieves 98.1% test\naccuracy on MNIST, which is close to the optimal result achievable with error-backpropagation\nin non-convolutional networks of rate neurons with one hidden\nlayer. To support the design choices of the spiking network, we systematically\ncompare the classification performance of rate networks with a single hidden\nlayer, where the weights of this layer are either random and fixed, trained with\nunsupervised Principal Component Analysis or Sparse Coding, or trained with\nthe backpropagation algorithm. This comparison revealed, first, that unsupervised\nlearning does not lead to better performance than fixed random projections for\nlarge hidden layers on digit classification (MNIST) and object recognition (CIFAR10);\nsecond, networks with random projections and localized receptive fields\nperform significantly better than networks with all-to-all connectivity and almost\nreach the performance of networks trained with the backpropagation algorithm.\nThe performance of these simple random projection networks is comparable to\nmost current models of bio-plausible deep learning and thus provides an interesting\nbenchmark for future approaches.", "keywords": ["deep learning", "bio-plausibility", "random projections", "spiking networks", "unsupervised learning", "MNIST", "spike timing dependent plasticity"], "authorids": ["ICLR.cc/2019/Conference/Paper397/Authors"], "authors": ["Anonymous"], "TL;DR": "Spiking networks using localized random projections and STDP challenge current MNIST benchmark models for bio-plausible deep learning", "pdf": "/pdf/8328494c5d217bda8468467da8e145609b15c351.pdf", "paperhash": "anonymous|localized_random_projections_challenge_benchmarks_for_bioplausible_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019localized,    \ntitle={Localized random projections challenge benchmarks for bio-plausible deep learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJeT_oRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklpOo09tQ", "original": "BkgDGr59Km", "number": 398, "cdate": 1538087797353, "ddate": null, "tcdate": 1538087797353, "tmdate": 1538156177412, "tddate": null, "forum": "BklpOo09tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEEP NEURAL NETWORKS", "abstract": "In recent years, deep neural networks have demonstrated outstanding performancein many machine learning tasks. However, researchers have discovered that thesestate-of-the-art models are vulnerable to adversarial examples:  legitimate examples added by small perturbations which are unnoticeable to human eyes. Adversarial training, which augments the training data with adversarial examples duringthe training process,  is a well known defense to improve the robustness of themodel against adversarial attacks.  However, this robustness is only effective tothe same attack method used for adversarial training.  Madry et al. (2017) suggest that effectiveness of iterative multi-step adversarial attacks and particularlythat projected gradient descent (PGD) may be considered the universal first order adversary and applying the adversarial training with PGD implies resistanceagainst many other first order attacks.   However,  the computational cost of theadversarial training with PGD and other multi-step adversarial examples is muchhigher than that of the adversarial training with other simpler attack techniques.In this paper, we show how strong adversarial examples can be generated only ata cost similar to that of two runs of the fast gradient sign method (FGSM), allowing defense against adversarial attacks with a robustness level comparable to thatof the adversarial training with multi-step adversarial examples.  We empiricallydemonstrate the effectiveness of the proposed two-step defense approach againstdifferent attack methods and its improvements over existing defense strategies.", "keywords": ["Adversarial Examples", "Adversarial Training", "FGSM", "IFGSM", "Robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper398/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed a time-efficient defense method against one-step and iterative adversarial attacks.", "pdf": "/pdf/2241b2f1da22d62445f417640b85fbb4117314d2.pdf", "paperhash": "anonymous|efficient_twostep_adversarial_defense_for_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={EFFICIENT TWO-STEP ADVERSARIAL DEFENSE FOR DEEP NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklpOo09tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklCusRct7", "original": "rygFESq9tQ", "number": 399, "cdate": 1538087797531, "ddate": null, "tcdate": 1538087797531, "tmdate": 1538156177209, "tddate": null, "forum": "BklCusRct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimal Transport Maps For Distribution Preserving Operations on Latent Spaces of Generative Models", "abstract": "Generative models such as Variational Auto Encoders (VAEs) and Generative Adversarial Networks (GANs) are typically trained for a fixed prior distribution in the latent space, such as uniform or Gaussian. After a trained model is obtained, one can sample the Generator in various forms for exploration and understanding, such as interpolating between two samples, sampling in the vicinity of a sample or exploring differences between a pair of samples applied to a third sample. However, the latent space operations commonly used in the literature so far induce a distribution mismatch between the resulting outputs and the prior distribution the model was trained on. Previous works have attempted to reduce this mismatch with heuristic modification to the operations or by changing the latent distribution and re-training models. In this paper, we propose a framework for modifying the latent space operations such that the distribution mismatch is fully eliminated. Our approach is based on optimal transport maps, which adapt the latent space operations such that they fully match the prior distribution, while minimally modifying the original operation. Our matched operations are readily obtained for the commonly used operations and distributions and require no adjustment to the training procedure.", "keywords": ["generative models", "optimal transport", "distribution preserving operations"], "authorids": ["ICLR.cc/2019/Conference/Paper399/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a framework for modifying the latent space operations such that the distribution mismatch between the resulting outputs and the prior distribution the generative model was trained on is fully eliminated.", "pdf": "/pdf/acfb908d879f28b9260ce4094360300812f9af34.pdf", "paperhash": "anonymous|optimal_transport_maps_for_distribution_preserving_operations_on_latent_spaces_of_generative_models", "_bibtex": "@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal Transport Maps For Distribution Preserving Operations on Latent Spaces of Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklCusRct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxAOoR5K7", "original": "rJgf8sFqK7", "number": 400, "cdate": 1538087797700, "ddate": null, "tcdate": 1538087797700, "tmdate": 1538156177002, "tddate": null, "forum": "ByxAOoR5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "POLICY GENERALIZATION IN CAPACITY-LIMITED REINFORCEMENT LEARNING", "abstract": "Motivated by the study of generalization in biological intelligence, we examine\nreinforcement learning (RL) in settings where there are information-theoretic\nconstraints placed on the learner\u2019s ability to represent a behavioral policy. We\nfirst show that the problem of optimizing expected utility within capacity-limited\nlearning agents maps naturally to the mathematical field of rate-distortion (RD)\ntheory. Applying the RD framework to the RL setting, we develop a new online\nRL algorithm, Capacity-Limited Actor-Critic, that learns a policy that optimizes\na tradeoff between utility maximization and information processing costs. Using\nthis algorithm in a 2D gridworld environment, we demonstrate two novel empirical\nresults. First, at high information rates (high channel capacity), the algorithm\nachieves faster learning and discovers better policies compared to the standard\ntabular actor-critic algorithm. Second, we demonstrate that agents with capacity-limited\npolicy representations exhibit superior transfer to novel environments\ncompared to policies learned by agents with unlimited information processing\nresources. Our work provides a principled framework for the development of\ncomputationally rational RL agents.", "keywords": ["reinforcement learning", "generalization", "capacity constraints", "information theory"], "authorids": ["ICLR.cc/2019/Conference/Paper400/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper describes the application of rate-distortion theory to the learning of efficient (capacity limited) policy representations in the reinforcement learning setting.", "pdf": "/pdf/b32ddc32d17265f0792e0bdcf2e4ce089ac88f52.pdf", "paperhash": "anonymous|policy_generalization_in_capacitylimited_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019policy,    \ntitle={POLICY GENERALIZATION IN CAPACITY-LIMITED REINFORCEMENT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxAOoR5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMCdsC5tX", "original": "SkxupM_9FX", "number": 401, "cdate": 1538087797871, "ddate": null, "tcdate": 1538087797871, "tmdate": 1538156176796, "tddate": null, "forum": "HJMCdsC5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A fully automated periodicity detection in time series", "abstract": "This paper presents a method to autonomously find periodicities in a signal. It is based on the same idea of using Fourier Transform and autocorrelation function presented in Vlachos et al. 2005. While showing interesting results this method does not perform well on noisy signals or signals with multiple periodicities. Thus, our method adds several new extra steps (hints clustering, filtering and detrending) to fix these issues. Experimental results show that the proposed method outperforms the state of the art algorithms. ", "keywords": ["Time series", "feature engineering", "period detection", "machine learning"], "authorids": ["ICLR.cc/2019/Conference/Paper401/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a method to autonomously find multiple periodicities in a signal, using FFT and ACF and add three news steps (clustering/filtering/detrending)", "pdf": "/pdf/002cedfe0eb81c22661f1b9535da822b7ab19e0a.pdf", "paperhash": "anonymous|a_fully_automated_periodicity_detection_in_time_series", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A fully automated periodicity detection in time series},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMCdsC5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMC_iA5tm", "original": "BJeic0ucFm", "number": 402, "cdate": 1538087798046, "ddate": null, "tcdate": 1538087798046, "tmdate": 1538156176589, "tddate": null, "forum": "HJMC_iA5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["ICLR.cc/2019/Conference/Paper402/Authors"], "authors": ["Anonymous"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/0c1055ac39c02650ebcbf6cf12d84c03066346ad.pdf", "paperhash": "anonymous|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning a SAT Solver from Single-Bit Supervision},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMC_iA5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1E0OsA9tX", "original": "SJg3g3tcFX", "number": 403, "cdate": 1538087798218, "ddate": null, "tcdate": 1538087798218, "tmdate": 1538156176380, "tddate": null, "forum": "r1E0OsA9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks", "abstract": "Learning deep neural networks could be understood as the combination of representation learning and learning halfspaces. While most previous work aims to diversify representation learning by data augmentations and regularizations, we explore the opposite direction through the lens of empirical Bayes method. Specifically, we propose a matrix-variate normal prior whose covariance matrix has a Kronecker product structure to capture the correlations in learning different neurons through backpropagation. The prior encourages neurons to learn from the experience of others, hence it provides an effective regularization when training large networks on small datasets. To optimize the model, we design an efficient block coordinate descent algorithm with analytic solutions. Empirically, we show that the proposed method helps the network converge to better local optima that also generalize better, and we verify the effectiveness of the approach on both multiclass classification and multitask regression problems with various network structures. ", "keywords": ["Empirical Bayes", "Bayesian Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper403/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9c10b3c09a562279ca40b09226a2e36a59c3a21b.pdf", "paperhash": "anonymous|learning_from_the_experience_of_others_approximate_empirical_bayes_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning From the Experience of Others: Approximate Empirical Bayes in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1E0OsA9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklR_iCcYm", "original": "SJg27I9cFQ", "number": 404, "cdate": 1538087798389, "ddate": null, "tcdate": 1538087798389, "tmdate": 1538156176168, "tddate": null, "forum": "SklR_iCcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Faster Training by Selecting Samples Using Embeddings", "abstract": "Long training times have increasingly become a burden for researchers by slowing down the pace of innovation, with some models taking days or weeks to train. In this paper, a new, general technique is presented that aims to speed up the training process by using a thinned-down training dataset. By leveraging autoencoders and the unique properties of embedding spaces, we are able to filter training datasets to include only those samples that matter the most. Through evaluation on a standard CIFAR-10 image classification task, this technique is shown to be effective. With this technique, training times can be reduced with a minimal loss in accuracy. Conversely, given a fixed training time budget, the technique was shown to improve accuracy by over 50%. This technique is a practical tool for achieving better results with large datasets and limited computational budgets.", "keywords": ["Machine Learning", "Embeddings", "Training Time", "Optimization", "Autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper404/Authors"], "authors": ["Anonymous"], "TL;DR": "Training is sped up by using a dataset that has been subsampled through embedding analysis.", "pdf": "/pdf/fc9bbe659f1844daeb44394d8f15efb061870d4a.pdf", "paperhash": "anonymous|faster_training_by_selecting_samples_using_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019faster,    \ntitle={Faster Training by Selecting Samples Using Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklR_iCcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxJtiRqt7", "original": "Byg7mzt9tQ", "number": 405, "cdate": 1538087798567, "ddate": null, "tcdate": 1538087798567, "tmdate": 1538156175957, "tddate": null, "forum": "SJxJtiRqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generating Images from Sounds Using Multimodal Features and GANs", "abstract": "Although generative adversarial networks (GANs) have enabled us to convert images from one domain to another similar one, converting between different sensory modalities, such as images and sounds, has been difficult. This study aims to propose a network that reconstructs images from sounds. First, video data with both images and sounds are labeled with pre-trained classifiers. Second, image and sound features are extracted from the data using pre-trained classifiers. Third, multimodal layers are introduced to extract features that are common to both the images and sounds. These layers are trained to extract similar features regardless of the input modality, such as images only, sounds only, and both images and sounds. Once the multimodal layers have been trained, features are extracted from input sounds and converted into image features using a feature-to-feature GAN. Finally, the generated image features are used to reconstruct images. Experimental results show that this method can successfully convert from the sound domain into the image domain. When we applied a pre-trained classifier to both the generated and original images, 31.9% of the examples had at least one of their top 10 labels in common, suggesting reasonably good image generation. Our results suggest that common representations can be learned for different modalities, and that proposed method can be applied not only to sound-to-image conversion but also to other conversions, such as from images to sounds.", "keywords": ["deep learning", "machine learning", "multimodal", "generative adversarial networks"], "authorids": ["ICLR.cc/2019/Conference/Paper405/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method of converting from the sound domain into the image domain based on multimodal features and stacked GANs.", "pdf": "/pdf/4ceae2e37f600b40c20a1109ee3721196cc32e73.pdf", "paperhash": "anonymous|generating_images_from_sounds_using_multimodal_features_and_gans", "_bibtex": "@inproceedings{    \nanonymous2019generating,    \ntitle={Generating Images from Sounds Using Multimodal Features and GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxJtiRqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeyti0qKX", "original": "r1xBuU5qtX", "number": 406, "cdate": 1538087798738, "ddate": null, "tcdate": 1538087798738, "tmdate": 1538156175745, "tddate": null, "forum": "ryeyti0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Statistical and Information Theoretical Characteristics of DNN Representations", "abstract": "It has been common to argue or imply that a regularizer can be used to alter a statistical property of a hidden layer's representation and thus improve generalization or performance of deep networks. For instance, dropout has been known to improve performance by reducing co-adaptation, and representational sparsity has been argued as a good characteristic because many data-generation processes have only a small number of factors that are independent. In this work, we analytically and empirically investigate the popular characteristics of learned representations, including correlation, sparsity, dead unit, rank, and mutual information, and disprove many of the \\textit{conventional wisdom}. We first show that infinitely many Identical Output Networks (IONs) can be constructed for any deep network with a linear layer, where any invertible affine transformation can be applied to alter the layer's representation characteristics. The existence of ION proves that the correlation characteristics of representation can be either low or high for a well-performing network. Extensions to ReLU layers are provided, too. Then, we consider sparsity, dead unit, and rank to show that only loose relationships exist among the three characteristics. It is shown that a higher sparsity or additional dead units do not imply a better or worse performance when the rank of representation is fixed. We also develop a rank regularizer and show that neither representation sparsity nor lower rank is helpful for improving performance even when the data-generation process has only a small number of independent factors. Mutual information $I(\\z_l;\\x)$ and $I(\\z_l;\\y)$ are investigated as well, and we show that regularizers can affect $I(\\z_l;\\x)$ and thus indirectly influence the performance. Finally, we explain how a rich set of regularizers can be used as a powerful tool for performance tuning. ", "keywords": ["learned representation", "statistical characteristics", "information theoretical characteristics", "deep network"], "authorids": ["ICLR.cc/2019/Conference/Paper406/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0a1530e51dc082457cbba8cf9dfb78255f52382e.pdf", "paperhash": "anonymous|on_the_statistical_and_information_theoretical_characteristics_of_dnn_representations", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Statistical and Information Theoretical Characteristics of DNN Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeyti0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkf1tjR9KQ", "original": "r1gL1rYYFm", "number": 407, "cdate": 1538087798916, "ddate": null, "tcdate": 1538087798916, "tmdate": 1538156175538, "tddate": null, "forum": "Bkf1tjR9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DVOLVER: Efficient Pareto-Optimal Neural Network Architecture Search", "abstract": "Automatic search of neural network architectures is a standing research topic. In addition to the fact that it presents a faster alternative to hand-designed architectures, it can improve their efficiency and for instance generate Convolutional Neural Networks (CNN) adapted for mobile devices. In this paper, we present a multi-objective neural architecture search method to find a family of CNN models with the best accuracy and computational resources tradeoffs, in a search space inspired by the state-of-the-art findings in neural search. Our work, called Dvolver, evolves a population of architectures and iteratively improves an approximation of the optimal Pareto front. Applying Dvolver on the model accuracy and on the number of floating points operations as objective functions, we are able to find, in only 2.5 days 1 , a set of competitive mobile models on ImageNet. Amongst these models one architecture has the same Top-1 accuracy on ImageNet as NASNet-A mobile with 8% less floating point operations and another one has a Top-1 accuracy of 75.28% on ImageNet exceeding by 0.28% the best MobileNetV2 model for the same computational resources.", "keywords": ["architecture search", "Pareto optimality", "multi-objective", "optimization", "cnn", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper407/Authors"], "authors": ["Anonymous"], "TL;DR": "Multi-objective Neural architecture search as an efficient way to find fast and accurate architecture for mobile devices.", "pdf": "/pdf/23f9e71c4b74df23098a1f0fc75f99ccf3552809.pdf", "paperhash": "anonymous|dvolver_efficient_paretooptimal_neural_network_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019dvolver:,    \ntitle={DVOLVER: Efficient Pareto-Optimal Neural Network Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkf1tjR9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJGyFiRqK7", "original": "S1ljaQu5Ym", "number": 408, "cdate": 1538087799088, "ddate": null, "tcdate": 1538087799088, "tmdate": 1538156175337, "tddate": null, "forum": "SJGyFiRqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Decoupling Gating from Linearity", "abstract": "The gap between the empirical success of deep learning and the lack of strong theoretical guarantees calls for studying simpler models. By observing that a ReLU neuron is a product of a linear function with a gate (the latter determines whether the neuron is active or not), where both share a jointly trained weight vector, we propose to decouple the two. We introduce GaLU networks \u2014 networks in which each neuron is a product of a Linear Unit, defined by a weight vector which is being trained, with a Gate, defined by a different weight vector which is not being trained. Generally speaking, given a base model and a simpler version of it, the two parameters that determine the quality of the simpler version are whether its practical performance is close enough to the base model and whether it is easier to analyze it theoretically. We show that GaLU networks perform similarly to ReLU networks on standard datasets and we initiate a study of their theoretical properties, demonstrating that they are indeed easier to analyze. We believe that further research of GaLU networks may be fruitful for the development of a theory of deep learning.", "keywords": ["Artificial Neural Networks", "Neural Networks", "ReLU", "GaLU", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper408/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Gated Linear Unit networks \u2014 a model that performs similarly to ReLU networks on real data while being much easier to analyze theoretically.", "pdf": "/pdf/692ed15150f994737dc37adfb71c45ac8519e277.pdf", "paperhash": "anonymous|decoupling_gating_from_linearity", "_bibtex": "@inproceedings{    \nanonymous2019decoupling,    \ntitle={Decoupling Gating from Linearity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJGyFiRqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylJtiRqYQ", "original": "Sygi1bI5tQ", "number": 409, "cdate": 1538087799259, "ddate": null, "tcdate": 1538087799259, "tmdate": 1538156175129, "tddate": null, "forum": "HylJtiRqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "VECTORIZATION METHODS IN RECOMMENDER SYSTEM", "abstract": "The most used recommendation method is collaborative filtering, and the key part of collaborative filtering is to compute the similarity. The similarity based on co-occurrence of similar event is easy to implement and can be applied to almost all the situation. So when the word2vec model reach the state-of-art at a lower computation cost in NLP. An correspond model in recommender system item2vec is proposed and reach state-of-art in recommender system. It is easy to see that the position of user and item is interchangeable when their count size gap is not too much, we proposed a user2vec model and show its performance. The similarity based on co-occurrence information suffers from cold start, we proposed a content based similarity model based on doc2vec which is another technology in NLP.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper409/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/237c15df764a9021d1e650ac418d8b114ea5c941.pdf", "paperhash": "anonymous|vectorization_methods_in_recommender_system", "_bibtex": "@inproceedings{    \nanonymous2019vectorization,    \ntitle={VECTORIZATION METHODS IN RECOMMENDER SYSTEM},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylJtiRqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkg1YiAcK7", "original": "Byg8hfmct7", "number": 410, "cdate": 1538087799430, "ddate": null, "tcdate": 1538087799430, "tmdate": 1538156174922, "tddate": null, "forum": "Hkg1YiAcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Implicit Generative Models by Teaching Explicit Ones", "abstract": "Implicit generative models are difficult to train as no explicit probability density functions are defined. Generative adversarial nets (GANs) propose a minimax framework to train such models, which suffer from mode collapse in practice. In contrast, we propose a learning by teaching (LBT) framework to learn implicit models, which intrinstically avoid the  mode collapse problem. In LBT, an auxiliary explicit model is introduced to learn the distribution defined by the implicit model while the later one's goal is to teach the explicit model to match the data distribution. LBT is formulated as a bilevel optimization problem, whose optimum implies that we obtain the maximum likelihood estimation of the implicit model. We adopt an unrolling approach to solve the challenging learning problem. Experimental results demonstrate the effectiveness of our method.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper410/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5c58eef21ed02688b1f6b09f0f48d63155ff4852.pdf", "paperhash": "anonymous|learning_implicit_generative_models_by_teaching_explicit_ones", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Implicit Generative Models by Teaching Explicit Ones},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkg1YiAcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyleYiC9FX", "original": "Hkg1QuqqKX", "number": 411, "cdate": 1538087799597, "ddate": null, "tcdate": 1538087799597, "tmdate": 1538156174720, "tddate": null, "forum": "HyleYiC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Text Embeddings for Retrieval from a Large Knowledge Base", "abstract": "Text embedding representing natural language documents in a semantic vector space can be used for document retrieval using nearest neighbor lookup. In order to study the feasibility of neural models specialized for retrieval in a semantically meaningful way, we suggest the use of the Stanford Question Answering Dataset (SQuAD) in an open-domain question answering context, where the first task is to find paragraphs useful for answering a given question. First, we compare the quality of various text-embedding methods on the performance of retrieval and give an extensive empirical comparison on the performance of various non-augmented base embedding with, and without IDF weighting. Our main results are that by training deep residual neural models specifically for retrieval purposes can yield significant gains when it is used to augment existing embeddings. We also establish that deeper models are superior to this task. The best base baseline embeddings augmented by our learned neural approach improves the top-1 recall of the system by 14% in terms of the question side, and by 8% in terms of the paragraph side.", "keywords": ["Text Embeddings", "Document Ranking", "Improving Retrieval", "Question-Answering", "Learning to Rank"], "authorids": ["ICLR.cc/2019/Conference/Paper411/Authors"], "authors": ["Anonymous"], "TL;DR": "The new attempt for creating semantically meaningful text embeddings via improved language modeling and utilizing an extra knowledge base", "pdf": "/pdf/6c873d89e0a8eb1c2a37c6b6607377462fd65063.pdf", "paperhash": "anonymous|text_embeddings_for_retrieval_from_a_large_knowledge_base", "_bibtex": "@inproceedings{    \nanonymous2019text,    \ntitle={Text Embeddings for Retrieval from a Large Knowledge Base},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyleYiC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1glKiCqtm", "original": "rJl_CWc9t7", "number": 412, "cdate": 1538087799770, "ddate": null, "tcdate": 1538087799770, "tmdate": 1538156174512, "tddate": null, "forum": "H1glKiCqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using an extreme summarization task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.8x speedup, 5% relative performance improvement, and resistance to over-fitting. We also show that the choice of programming language used for the embeddings does not have to match that of the task to achieve these benefits.  ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["ICLR.cc/2019/Conference/Paper412/Authors"], "authors": ["Anonymous"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/c23b0ddbcf44b148058369d3e41e65410633c40f.pdf", "paperhash": "anonymous|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Effectiveness of Pre-Trained Code Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1glKiCqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygxYoC5FX", "original": "HklImKqcFm", "number": 413, "cdate": 1538087799939, "ddate": null, "tcdate": 1538087799939, "tmdate": 1538156174305, "tddate": null, "forum": "SygxYoC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating", "abstract": "Different kinds of representation learning techniques on graph have shown significant effect in downstream machine learning tasks. Recently, in order to inductively learn representations for graph structures that is unobservable during training, a general framework with sampling and aggregating (GraphSAGE) was proposed by Hamilton and Ying and had been proved more efficient than transductive methods on fileds like transfer learning or evolving dataset. However, GraphSAGE is uncapable of selective neighbor sampling and lack of memory of known nodes that've been trained. To address these problems, we present an unsupervised method that samples neighborhood information attended by co-occurring structures and optimizes a trainable global bias as a representation expectation for each node in the given graph. Experiments show that our approach outperforms the state-of-the-art inductive and unsupervised methods for representation learning on graphs.", "keywords": ["network embedding", "unsupervised learning", "inductive learning"], "authorids": ["ICLR.cc/2019/Conference/Paper413/Authors"], "authors": ["Anonymous"], "TL;DR": "For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively", "pdf": "/pdf/f7a58568ddb09df2b9eaf3d9b412cede79872a03.pdf", "paperhash": "anonymous|bigsage_unsupervised_inductive_representation_learning_of_graph_via_biattended_sampling_and_globalbiased_aggregating", "_bibtex": "@inproceedings{    \nanonymous2019bigsage:,    \ntitle={BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygxYoC5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkfxKj09Km", "original": "H1xLYt9qFQ", "number": 414, "cdate": 1538087800113, "ddate": null, "tcdate": 1538087800113, "tmdate": 1538156174092, "tddate": null, "forum": "BkfxKj09Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DiffraNet: Automatic Classification of Serial Crystallography Diffraction Patterns", "abstract": "Serial crystallography is the field of science that studies the structure and properties of crystals via diffraction patterns. In this paper, we introduce a new serial crystallography dataset generated through the use of a simulator; the synthetic images are labeled and they are both scalable and accurate. The resulting synthetic dataset is called DiffraNet, and it is composed of 25,000 512x512 grayscale labeled images. We explore several computer vision approaches for classification on DiffraNet such as standard feature extraction algorithms associated with Random Forests and Support Vector Machines but also an end-to-end CNN topology dubbed DeepFreak tailored to work on this new dataset. All implementations are publicly available and have been fine-tuned using off-the-shelf AutoML optimization tools for a fair comparison. Our best model achieves 98.5% accuracy. We believe that the DiffraNet dataset and its classification methods will have in the long term a positive impact in accelerating discoveries in many disciplines, including chemistry, geology, biology, materials science, metallurgy, and physics.", "keywords": ["Serial Crystallography", "Deep Learning", "Image Classification"], "authorids": ["ICLR.cc/2019/Conference/Paper414/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a new synthetic dataset for serial crystallography that can be used to train image classification models and explore computer vision and deep learning approaches to classify them.", "pdf": "/pdf/8b6b5a68e85b1eff1574d3a5856c0d5aefcd16b1.pdf", "paperhash": "anonymous|diffranet_automatic_classification_of_serial_crystallography_diffraction_patterns", "_bibtex": "@inproceedings{    \nanonymous2019diffranet:,    \ntitle={DiffraNet: Automatic Classification of Serial Crystallography Diffraction Patterns},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkfxKj09Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJGgFjA9FQ", "original": "SkxM3wWNY7", "number": 415, "cdate": 1538087800298, "ddate": null, "tcdate": 1538087800298, "tmdate": 1538156173881, "tddate": null, "forum": "rJGgFjA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks", "abstract": "This paper presents two methods to disentangle and interpret contextual effects that are encoded in a pre-trained deep neural network. Unlike convolutional studies that visualize image appearances corresponding to the network output or a neural activation from a global perspective, our research aims to clarify how a certain input unit (dimension) collaborates with other units (dimensions) to constitute inference patterns of the neural network and thus contribute to the network output. The analysis of local contextual effects w.r.t. certain input units is of special values in real applications. In particular, we used our methods to explain the gaming strategy of the alphaGo Zero model in experiments, and our method successfully disentangled the rationale of each move during the game.", "keywords": ["Interpretability", "Deep learning", "alphaGo"], "authorids": ["ICLR.cc/2019/Conference/Paper415/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents methods to disentangle and interpret contextual effects that are encoded in a deep neural network.", "pdf": "/pdf/313879d2d9eca2d9e7bc764b0b039c6bbda90f98.pdf", "paperhash": "anonymous|explaining_alphago_interpreting_contextual_effects_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019explaining,    \ntitle={Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJGgFjA9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkElFj0qYQ", "original": "rJev9qcqKQ", "number": 416, "cdate": 1538087800467, "ddate": null, "tcdate": 1538087800467, "tmdate": 1538156173671, "tddate": null, "forum": "HkElFj0qYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PPD: Permutation Phase Defense Against Adversarial Examples in Deep Learning", "abstract": "Deep neural networks have demonstrated cutting edge performance on various tasks including classification. However, it is well known that adversarially designed imperceptible perturbation of the input can mislead advanced classifiers. In this paper, Permutation Phase Defense (PPD), is proposed as a novel method to resist adversarial attacks. PPD combines random permutation of the image with phase component of its Fourier transform. The basic idea behind this approach is to turn adversarial defense problems analogously into symmetric cryptography, which relies solely on safekeeping of the keys for security. In PPD, safe keeping of the selected permutation ensures effectiveness against adversarial attacks. Testing PPD on MNIST and CIFAR-10 datasets yielded state-of-the-art robustness against the most powerful adversarial attacks currently available.", "keywords": ["permutation phase defense", "adversarial attacks", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper416/Authors"], "authors": ["Anonymous"], "TL;DR": "Permutation phase defense is proposed as a novel method to guard against adversarial attacks in deep learning.", "pdf": "/pdf/87b109b4bd7eda350a1ffd2f9e11da125f1a5b18.pdf", "paperhash": "anonymous|ppd_permutation_phase_defense_against_adversarial_examples_in_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019ppd:,    \ntitle={PPD: Permutation Phase Defense Against Adversarial Examples in Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkElFj0qYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxZFoAqtQ", "original": "ByeQL6fcKm", "number": 417, "cdate": 1538087800636, "ddate": null, "tcdate": 1538087800636, "tmdate": 1538156173465, "tddate": null, "forum": "SkxZFoAqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning", "abstract": "Various NLP problems -- such as the prediction of sentence similarity, entailment, and discourse relations -- are all instances of the same general task: the modeling of semantic relations between a pair of textual elements. We call them textual relational problems. A popular model for textual relational problems is to embed sentences into fixed size vectors and use composition functions (e.g. difference or concatenation) of those vectors as features for the prediction. Meanwhile, composition of embeddings has been a main focus within the field of Statistical Relational Learning (SRL) whose goal is to predict relations between entities (typically from knowledge base triples). In this work, we prove that textual relational models implicitly use compositions from baseline SRL models. We show that such compositions are not expressive enough for several tasks (e.g. natural language inference).  We build on recent SRL models to solve textual relational problems, showing that they are more expressive, and can alleviate issues from simpler compositions. The resulting models significantly improve the state of the art in both transferable sentence representation learning and relation prediction.", "keywords": ["Statistical Relational Learning", "Sentence Embedding", "Composition functions", "Natural Language Inference", "InferSent", "SentEval", "ComplEx"], "authorids": ["ICLR.cc/2019/Conference/Paper417/Authors"], "authors": ["Anonymous"], "TL;DR": "We apply ideas from Statistical Relational Learning to compose sentence embeddings with more expressivity", "pdf": "/pdf/c83559b637aa58a69e7a92f8d7c66addfea2fbeb.pdf", "paperhash": "anonymous|improving_composition_of_sentence_embeddings_through_the_lens_of_statistical_relational_learning", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Composition of Sentence Embeddings through the Lens of Statistical Relational Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxZFoAqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxbYoC9FQ", "original": "SygZ-BGKtm", "number": 418, "cdate": 1538087800800, "ddate": null, "tcdate": 1538087800800, "tmdate": 1538156173257, "tddate": null, "forum": "BJxbYoC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Classifier-agnostic saliency map extraction", "abstract": "Extracting saliency maps, which indicate parts of the image important to classification, requires many tricks to achieve satisfactory performance when using classifier-dependent methods. Instead, we propose classifier-agnostic saliency map extraction, which finds all parts of the image that any classifier could use, not just one given in advance. We observe that the proposed approach extracts higher quality saliency maps and outperforms existing weakly-supervised localization techniques, setting the new state of the art result on the ImageNet dataset.", "keywords": ["saliency maps", "explainable AI", "convolutional neural networks", "generative adversarial training", "classification"], "authorids": ["ICLR.cc/2019/Conference/Paper418/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new saliency map extraction method which results in extracting higher quality maps.", "pdf": "/pdf/b6a1906a5c7cc172a30b6e20461be3e12a561934.pdf", "paperhash": "anonymous|classifieragnostic_saliency_map_extraction", "_bibtex": "@inproceedings{    \nanonymous2019classifier-agnostic,    \ntitle={Classifier-agnostic saliency map extraction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxbYoC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJfZKiC5FX", "original": "SyeuxYEjuX", "number": 419, "cdate": 1538087800971, "ddate": null, "tcdate": 1538087800971, "tmdate": 1538156173050, "tddate": null, "forum": "SJfZKiC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration", "abstract": "In this paper, we propose a new control framework called the moving endpoint control to restore images corrupted by different degradation levels in one model. The proposed control problem contains a restoration dynamics which is modeled by an RNN. The moving endpoint, which is essentially the terminal time of the associated dynamics, is determined by a policy network. We call the proposed model the dynamically unfolding recurrent restorer (DURR). Numerical experiments show that DURR is able to achieve state-of-the-art performances on blind image denoising and JPEG image deblocking. Furthermore, DURR can well generalize to images with higher degradation levels that are not included in the training stage.", "keywords": ["image restoration"], "authorids": ["ICLR.cc/2019/Conference/Paper419/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/893486cc3b009b9859f0802858722da5a0772886.pdf", "paperhash": "anonymous|dynamically_unfolding_recurrent_restorer_a_moving_endpoint_control_method_for_image_restoration", "_bibtex": "@inproceedings{    \nanonymous2019dynamically,    \ntitle={Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfZKiC5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJfWKsC5K7", "original": "rylEQEbVtm", "number": 420, "cdate": 1538087801141, "ddate": null, "tcdate": 1538087801141, "tmdate": 1538156172845, "tddate": null, "forum": "SJfWKsC5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Explaining Neural Networks Semantically and Quantitatively", "abstract": "This paper presents a method to explain the knowledge encoded in a convolutional neural network (CNN) quantitatively and semantically. How to analyze the specific rationale of each prediction made by the CNN presents one of key issues of understanding neural networks, but it is also of significant practical values in certain applications. In this study, we propose to distill knowledge from the CNN into an explainable additive model, so that we can use the explainable model to provide a quantitative explanation for the CNN prediction. We analyze the typical bias-interpreting problem of the explainable model and develop prior losses to guide the learning of the explainable additive model. Experimental results have demonstrated the effectiveness of our method.", "keywords": ["Network interpretability", "deep learning", "knowledge distillation", "convolutional neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper420/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a method to explain the knowledge encoded in a convolutional neural network (CNN) quantitatively and semantically.", "pdf": "/pdf/bb6a3070e2e0034f27640e96c4ba817f4d4f19a7.pdf", "paperhash": "anonymous|explaining_neural_networks_semantically_and_quantitatively", "_bibtex": "@inproceedings{    \nanonymous2019explaining,    \ntitle={Explaining Neural Networks Semantically and Quantitatively},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfWKsC5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyNbtiR9YX", "original": "Bkltsi55K7", "number": 421, "cdate": 1538087801316, "ddate": null, "tcdate": 1538087801316, "tmdate": 1538156172639, "tddate": null, "forum": "HyNbtiR9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Document Representation using Partition Word-Vectors Averaging", "abstract": "Learning effective document-level representation is essential in many important NLP tasks such as document classification, summarization, etc. Recent research has shown that simple weighted averaging of word vectors is an effective way to represent sentences, often outperforming complicated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One reason for this degradation is due to the fact that a longer document is likely to contain words from many different themes (or topics), and hence creating a single vector while ignoring all the thematic structure is unlikely to yield an effective representation of the document. This problem is less acute in single sentences and other short text fragments where presence of a single theme/topic is most likely. To overcome this problem, in this paper we present PSIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's thematic structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. Through our experiments over multiple real-world datasets and tasks, we demonstrate PSIF's effectiveness compared to simple weighted averaging and many other state-of-the-art baselines. We also show that PSIF is particularly effective in representing long multi-sentence documents. We will release PSIF's embedding source code and data-sets for reproducing results.", "keywords": ["Unsupervised Learning", "Natural Language Processing", "Representation Learning", "Document Embedding"], "authorids": ["ICLR.cc/2019/Conference/Paper421/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple unsupervised method for multi-sentense-document embedding using partition based word vectors averaging that achieve results comparable to sophisticated models.", "pdf": "/pdf/0268b88119cc81ee5b2b4f64e1ede8d574c88029.pdf", "paperhash": "anonymous|unsupervised_document_representation_using_partition_wordvectors_averaging", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Document Representation using Partition Word-Vectors Averaging},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyNbtiR9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1VWtsA5tQ", "original": "SklqUbjwKX", "number": 422, "cdate": 1538087801486, "ddate": null, "tcdate": 1538087801486, "tmdate": 1538156172437, "tddate": null, "forum": "B1VWtsA5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation", "abstract": "Proximal Policy Optimization (PPO) is a highly popular model-free reinforcement learning (RL) approach. However, in continuous state and actions spaces and a Gaussian policy -- common in computer animation and robotics -- PPO is prone to getting stuck in local optima. In this paper, we observe a tendency of PPO to prematurely shrink the exploration variance, which naturally leads to slow progress. Motivated by this, we borrow ideas from CMA-ES, a black-box optimization method designed for intelligent adaptive Gaussian exploration, to derive PPO-CMA, a novel proximal policy optimization approach that expands the exploration variance on objective function slopes and only shrinks the variance when close to the optimum. This is implemented by using separate neural networks for policy mean and variance and training the mean and variance in separate passes. Our experiments demonstrate a clear improvement over vanilla PPO in many difficult OpenAI Gym MuJoCo tasks.", "keywords": ["Continuous Control", "Reinforcement Learning", "Policy Optimization", "Policy Gradient", "Evolution Strategies", "CMA-ES", "PPO"], "authorids": ["ICLR.cc/2019/Conference/Paper422/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new continuous control reinforcement learning method with a variance adaptation strategy inspired by the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) optimization method", "pdf": "/pdf/c76332f20dce1eea8ee42a918b20a45a60f75acd.pdf", "paperhash": "anonymous|ppocma_proximal_policy_optimization_with_covariance_matrix_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019ppo-cma:,    \ntitle={PPO-CMA: Proximal Policy Optimization with Covariance Matrix Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1VWtsA5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklMYjC9FQ", "original": "Hkx7Jk9cYm", "number": 423, "cdate": 1538087801655, "ddate": null, "tcdate": 1538087801655, "tmdate": 1538156172232, "tddate": null, "forum": "BklMYjC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "microGAN: Promoting Variety through Microbatch Discrimination", "abstract": "We propose to tackle the mode collapse problem in generative adversarial networks (GANs) by using multiple discriminators and assigning a different portion of each minibatch, called microbatch, to each discriminator. We gradually change each discriminator's task from distinguishing between real and fake samples to discriminating samples coming from inside or outside its assigned microbatch by using a diversity parameter $\\alpha$. The generator is then forced to promote variety in each minibatch to make the microbatch discrimination harder to achieve by each discriminator. Thus, all models in our framework benefit from having variety in the generated set to reduce their respective losses. We show evidence that our solution promotes sample diversity since early training stages on multiple datasets.", "keywords": ["adversarial training", "gans"], "authorids": ["ICLR.cc/2019/Conference/Paper423/Authors"], "authors": ["Anonymous"], "TL;DR": "We use microbatch discrimination on multi-adversarial GANs to mitigate mode collapse.", "pdf": "/pdf/b89b4030fc4c4892979e8298770b012f26d5889c.pdf", "paperhash": "anonymous|microgan_promoting_variety_through_microbatch_discrimination", "_bibtex": "@inproceedings{    \nanonymous2019microgan:,    \ntitle={microGAN: Promoting Variety through Microbatch Discrimination},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklMYjC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgzYiRqtX", "original": "r1xQtHcqY7", "number": 424, "cdate": 1538087801831, "ddate": null, "tcdate": 1538087801831, "tmdate": 1538156172026, "tddate": null, "forum": "SkgzYiRqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Generate Parameters from Natural Languages for Graph Neural Networks", "abstract": "Recently, progress has been made towards improving relational reasoning in machine learning field. Among existing models, graph neural networks (GNNs) is one of the most effective approaches for multi-hop relational reasoning. In fact, multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction. In this paper, we propose to generate the parameters of graph neural networks (GP-GNNs) according to natural language sentences, which enables GNNs to process relational reasoning on unstructured text inputs. We verify GP-GNNs in relation extraction from text. Experimental results on a human-annotated dataset and two distantly supervised datasets show that our model achieves significant improvements compared to state-of-the-art baselines. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.", "keywords": ["Graph Neural Networks", "Relational Reasoning"], "authorids": ["ICLR.cc/2019/Conference/Paper424/Authors"], "authors": ["Anonymous"], "TL;DR": "A graph neural network model with parameters generated from natural languages, which can perform multi-hop reasoning. ", "pdf": "/pdf/0e449d629400851cbcc295fe78161dbcf15be3e1.pdf", "paperhash": "anonymous|learning_to_generate_parameters_from_natural_languages_for_graph_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Generate Parameters from Natural Languages for Graph Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgzYiRqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyffti0ctQ", "original": "S1eUDhAtKX", "number": 425, "cdate": 1538087802001, "ddate": null, "tcdate": 1538087802001, "tmdate": 1538156171822, "tddate": null, "forum": "Hyffti0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION", "abstract": "In this paper, we propose an efficient framework to accelerate convolutional neural networks. We utilize two types of acceleration methods: pruning and hints. Pruning can reduce model size by removing channels of layers. Hints can improve the performance of student model by transferring knowledge from teacher model. We demonstrate that pruning and hints are complementary to each other. On one hand, hints can benefit pruning by maintaining similar feature representations. On the other hand, the model pruned from teacher networks is a good initialization for student model, which increases the transferability between two networks. Our approach performs pruning stage and hints stage iteratively to further improve the\nperformance. Furthermore, we propose an algorithm to reconstruct the parameters of hints layer and make the pruned model more suitable for hints. Experiments were conducted on various tasks including classification and pose estimation. Results on CIFAR-10, ImageNet and COCO demonstrate the generalization and superiority of our framework.", "keywords": ["model acceleration", "mimic", "knowledge distillation", "channel pruning"], "authorids": ["ICLR.cc/2019/Conference/Paper425/Authors"], "authors": ["Anonymous"], "TL;DR": "This is a work aiming for boosting all the existing pruning and mimic method.", "pdf": "/pdf/0b8f76189d402de4ecf73ec2373a5df2ab4e931c.pdf", "paperhash": "anonymous|pruning_with_hints_an_efficient_framework_for_model_acceleration", "_bibtex": "@inproceedings{    \nanonymous2019pruning,    \ntitle={PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyffti0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1MzKs05F7", "original": "rJglN1r5t7", "number": 426, "cdate": 1538087802179, "ddate": null, "tcdate": 1538087802179, "tmdate": 1538156171609, "tddate": null, "forum": "H1MzKs05F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Vulnerability of Neural Networks Increases with Input Dimension", "abstract": "Over the past four years, neural networks have been proven vulnerable to adversarial images: targeted but imperceptible image perturbations lead to drastically different predictions. We show that adversarial vulnerability increases with the gradients of the training objective when viewed as a function of the inputs. For most current network architectures, we prove that the L1-norm of these gradients grows as the square root of the input size. These nets therefore become increasingly vulnerable with growing image size. Our proofs rely on the network\u2019s weight distribution at initialization, but extensive experiments confirm that our conclusions still hold after training.", "keywords": ["adversarial vulnerability", "neural networks", "gradients", "FGSM", "adversarial data-augmentation", "gradient regularization", "robust optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper426/Authors"], "authors": ["Anonymous"], "TL;DR": "Neural nets have large gradients by design; that makes them adversarially vulnerable.", "pdf": "/pdf/d2c09b1167c533765e5334b65e34623e4475c853.pdf", "paperhash": "anonymous|adversarial_vulnerability_of_neural_networks_increases_with_input_dimension", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Vulnerability of Neural Networks Increases with Input Dimension},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1MzKs05F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkNGYjR9FX", "original": "S1erhnqcKQ", "number": 427, "cdate": 1538087802358, "ddate": null, "tcdate": 1538087802358, "tmdate": 1538156171399, "tddate": null, "forum": "HkNGYjR9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Recurrent Binary/Ternary Weights", "abstract": "Recurrent neural networks (RNNs) have shown excellent performance in processing sequence data. However, they are both complex and memory intensive due to their recursive nature. These limitations make RNNs difficult to embed on mobile devices requiring real-time processes with limited hardware resources. To address the above issues, we introduce a method that can learn binary and ternary weights during the training phase to facilitate hardware implementations of RNNs. As a result, using this approach replaces all multiply-accumulate operations by simple accumulations, bringing significant benefits to custom hardware in terms of silicon area and power consumption. On the software side, we evaluate the performance (in terms of accuracy) of our method using long short-term memories (LSTMs) on various sequential models including sequence classification and language modeling. We demonstrate that our method achieves competitive results on the aforementioned tasks while using binary/ternary weights during the runtime. On the hardware side, we present custom hardware for accelerating the recurrent computations of LSTMs with binary/ternary weights. Ultimately, we show that LSTMs with binary/ternary weights can achieve up to 12x memory saving and 10x inference speedup compared to the full-precision implementation on an ASIC platform.", "keywords": ["Quantized Recurrent Neural Network", "Hardware Implementation", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper427/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose high-performance LSTMs with binary/ternary weights, that can greatly reduce implementation complexity", "pdf": "/pdf/bc4aa2972feaf8edf470ee777639d124afe1c876.pdf", "paperhash": "anonymous|learning_recurrent_binaryternary_weights", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Recurrent Binary/Ternary Weights},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkNGYjR9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJeQYjRqYX", "original": "rye19ryzFX", "number": 428, "cdate": 1538087802532, "ddate": null, "tcdate": 1538087802532, "tmdate": 1538156171188, "tddate": null, "forum": "rJeQYjRqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Effective Path: Know the Unknowns of Neural Network", "abstract": "Despite their enormous success, there is still no solid understanding of deep neural network\u2019s working mechanism. As such, researchers have demonstrated DNNs are vulnerable to small input perturbation, i.e., adversarial attacks. This work proposes the effective path as a new approach to exploring DNNs' internal organization. The effective path is an ensemble of synapses and neurons, which is reconstructed from a trained DNN using our activation-based backward algorithm. The per-image effective path can be aggregated to the class-level effective path, through which we observe that adversarial images activate effective path different from normal images. We propose an effective path similarity-based method to detect adversarial images and demonstrate its high accuracy and broad applicability.\n", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper428/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9bb9c3302a4b7aa271c78443ae3e79172558c35c.pdf", "paperhash": "anonymous|effective_path_know_the_unknowns_of_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019effective,    \ntitle={Effective Path: Know the Unknowns of Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJeQYjRqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyeQFiCcF7", "original": "Hyl1LL5cFX", "number": 429, "cdate": 1538087802697, "ddate": null, "tcdate": 1538087802697, "tmdate": 1538156170980, "tddate": null, "forum": "SyeQFiCcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Siamese Capsule Networks", "abstract": "Capsule Networks have shown encouraging results on defacto benchmark computer vision datasets such as MNIST, CIFAR and smallNORB. Although, they are yet to be tested on tasks where (1) the entities detected inherently have more complex internal representations and (2) there are very few instances per class to learn from and (3) where point-wise classification is not suitable. Hence, this paper carries out experiments on face verification in both controlled and uncontrolled settings that together address these points. In doing so we introduce Siamese Capsule Networks, a new variant that can be used for pairwise learning tasks. The model is trained using contrastive loss with l2-normalized capsule encoded pose features. We find that Siamese Capsule Networks perform well against strong baselines on both pairwise learning datasets, yielding best results in the few-shot learning setting where image pairs in the test set contain unseen subjects.", "keywords": ["capsule networks", "pairwise learning", "few-shot learning", "face verification"], "authorids": ["ICLR.cc/2019/Conference/Paper429/Authors"], "authors": ["Anonymous"], "TL;DR": "A variant of capsule networks that can be used for pairwise learning tasks. Results shows that Siamese Capsule Networks work well in the few shot learning setting.", "pdf": "/pdf/56751b128ffa0216b6353ede94a96d1d8c587d49.pdf", "paperhash": "anonymous|siamese_capsule_networks", "_bibtex": "@inproceedings{    \nanonymous2019siamese,    \ntitle={Siamese Capsule Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyeQFiCcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyfXKoRqFQ", "original": "r1eVUcDcFm", "number": 430, "cdate": 1538087802861, "ddate": null, "tcdate": 1538087802861, "tmdate": 1538156170772, "tddate": null, "forum": "SyfXKoRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Ada-Boundary: Accelerating the DNN Training via Adaptive Boundary Batch Selection", "abstract": "Neural networks can converge faster with help from a smarter batch selection strategy. In this regard, we propose Ada-Boundary, a novel adaptive-batch selection algorithm that constructs an effective mini-batch according to a learner\u2019s level. Our key idea is to automatically derive the learner\u2019s level using the decision boundary which evolves as the learning progresses. Thus, the samples near the current decision boundary are considered as the most effective to expedite convergence. Taking advantage of our design, Ada-Boundary maintains its dominance in various degrees of training difficulty. We demonstrate the advantage of Ada-Boundary by extensive experiments using two convolutional neural networks for three benchmark data sets. The experiment results show that Ada-Boundary improves the training time by up to 31.7% compared with the state-of-the-art strategy and by up to 33.5% compared with the baseline strategy.", "keywords": ["acceleration", "batch selection", "convergence", "decision boundary"], "authorids": ["ICLR.cc/2019/Conference/Paper430/Authors"], "authors": ["Anonymous"], "TL;DR": "We suggest a smart batch selection technique called Ada-Boundary.", "pdf": "/pdf/6716730dbc814f2cfe031e9053270e9ec7740e29.pdf", "paperhash": "anonymous|adaboundary_accelerating_the_dnn_training_via_adaptive_boundary_batch_selection", "_bibtex": "@inproceedings{    \nanonymous2019ada-boundary:,    \ntitle={Ada-Boundary: Accelerating the DNN Training via Adaptive Boundary Batch Selection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyfXKoRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJf7ts0cFm", "original": "B1l3kE55KQ", "number": 431, "cdate": 1538087803027, "ddate": null, "tcdate": 1538087803027, "tmdate": 1538156170567, "tddate": null, "forum": "HJf7ts0cFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "State-Regularized Recurrent Networks", "abstract": "Recurrent networks are a widely used class of neural architectures.  They have, however, two shortcomings. First, it is difficult to understand what exactly they learn. Second, they tend to work poorly on sequences requiring long-term memorization, despite having this capacity in principle. We aim to address both shortcomings with a class of recurrent networks that use a stochastic state transition mechanism between cell applications. This mechanism, which we term state-regularization, makes RNNs transition between a finite set of learnable states. We show that state-regularization (a) simplifies the extraction of finite state automata modeling an RNN's state transition dynamics, and (b) forces RNNs to operate more like automata with external memory and less like finite state machines.", "keywords": ["recurrent network", "finite state machines", "state-regularized", "interpretability and explainability"], "authorids": ["ICLR.cc/2019/Conference/Paper431/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce stochastic state transition mechanism to RNNs, simplifies finite state automata (FDA) extraction, forces RNNs to operate more like automata with external memory, better extrapolation behavior and interpretability.", "pdf": "/pdf/5894684c4f8a818fb6d493918c0e974c55ff74fc.pdf", "paperhash": "anonymous|stateregularized_recurrent_networks", "_bibtex": "@inproceedings{    \nanonymous2019state-regularized,    \ntitle={State-Regularized Recurrent Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJf7ts0cFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1VmtsC5t7", "original": "HJx5gaYZFX", "number": 432, "cdate": 1538087803200, "ddate": null, "tcdate": 1538087803200, "tmdate": 1538156170362, "tddate": null, "forum": "r1VmtsC5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Is PGD-Adversarial Training Necessary? Alternative Training via a Soft-Quantization Network with Noisy-Natural Samples Only", "abstract": "Recent work on adversarial attack and defense suggests that projected gradient descent (PGD) is a universal $l_\\infty$ first-order attack, and PGD adversarial training can significantly improve network robustness against a wide range of first-order $l_\\infty$-bounded attacks, represented as the state-of-the-art defense method. However, an obvious weakness of PGD adversarial training is its highly-computational cost in generating adversarial samples, making it computationally infeasible for large and high-resolution real datasets such as the ImageNet dataset. In addition, recent work also has suggested a simple ``close-form'' solution to a robust model on MNIST. Therefore, a natural question raised is that is PGD adversarial training really necessary for robust defense? In this paper, surprisingly, we give a negative answer by proposing a training paradigm that is comparable to PGD adversarial training on several standard datasets, while only using noisy-natural samples. Specifically, we reformulate the min-max objective in PGD adversarial training by a minimization problem to minimize the original network loss plus $l_1$ norms of its gradients evaluated on the inputs (including adversarial samples). The original loss can be solved by natural training; for the $l_1$-norm loss, we propose a computationally-feasible solution by embedding a differentiable soft-quantization layer after the input layer of a network. We show formally that the soft-quantization layer trained with noisy-natural samples is an alternative approach to minimizing the $l_1$-gradient norms as in PGD adversarial training. Extensive empirical evaluations on three standard datasets including MNIST, CIFAR-10 and ImageNet show that our proposed models are comparable to PGD-adversarially-trained models under PGD and BPDA attacks using both cross-entropy and $CW_\\infty$ losses. Remarkably, our method achieves a 24X speed-up on MNIST while maintaining a comparable defensive ability, and for the first time fine-tunes a robust Imagenet model within only two days. Code for the experiments will be released on Github.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper432/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b318b89968b32accae2883fc733fa51c16ff0995.pdf", "paperhash": "anonymous|is_pgdadversarial_training_necessary_alternative_training_via_a_softquantization_network_with_noisynatural_samples_only", "_bibtex": "@inproceedings{    \nanonymous2019is,    \ntitle={Is PGD-Adversarial Training Necessary? Alternative Training via a Soft-Quantization Network with Noisy-Natural Samples Only},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1VmtsC5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByN7Yo05YX", "original": "S1eEwmOtY7", "number": 433, "cdate": 1538087803436, "ddate": null, "tcdate": 1538087803436, "tmdate": 1538156170149, "tddate": null, "forum": "ByN7Yo05YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Neural Trees", "abstract": "Deep neural networks and decision trees operate on largely separate paradigms; typically, the former performs representation learning with pre-specified architectures, while the latter is characterised by learning hierarchies over pre-specified features with data-driven architectures. We unite the two via adaptive neural trees (ANTs), a model that incorporates representation learning into edges, routing functions and leaf nodes of a decision tree, along with a backpropagation-based training algorithm that adaptively grows the architecture from primitive modules (e.g., convolutional layers). ANTs allow increased interpretability via hierarchical clustering, e.g., learning meaningful class associations, such as separating natural vs. man-made objects. We demonstrate this whilst achieving over 99% and 90% accuracy on the MNIST and CIFAR-10 datasets. Furthermore, ANT optimisation naturally adapts the architecture to the size and complexity of the training data.", "keywords": ["neural networks", "decision trees", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper433/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a framework to combine decision trees and neural networks, and show on image classification tasks that it enjoys the complementary benefits of the two approaches, while addressing the limitations of prior work.", "pdf": "/pdf/904984c5a8473eaa0b4cbd2461cb361e85b320a0.pdf", "paperhash": "anonymous|adaptive_neural_trees", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Neural Trees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByN7Yo05YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eEKi0qYQ", "original": "SJg_s659KX", "number": 434, "cdate": 1538087803608, "ddate": null, "tcdate": 1538087803608, "tmdate": 1538156169944, "tddate": null, "forum": "B1eEKi0qYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Interactive Parallel Exploration for Reinforcement Learning in Continuous Action Spaces", "abstract": "In this paper, a new interactive parallel learning scheme is proposed to enhance the performance of off-policy continuous-action reinforcement learning.  In the proposed interactive parallel learning scheme, multiple identical learners with their own value-functions and policies sharing a common experience replay buffer search a good policy in collaboration with the guidance of the best policy information in the previous search interval. The information of the best policy parameter of the previous search interval is fused in a soft manner by constructing an augmented loss function for policy update to enlarge the overall search space by the multiple learners. The guidance by the previous best policy and the enlarged search space by the proposed interactive parallel learning scheme enables faster and better policy search in the policy parameter space. A working algorithm is constructed by  applying the proposed interactive parallel learning scheme to the  TD3 algorithm, and numerical results show that the constructed new algorithm outperforms most of the current state-of-the-art reinforcement learning algorithms for continuous action control.", "keywords": ["reinforcement learning", "continuous action space RL"], "authorids": ["ICLR.cc/2019/Conference/Paper434/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ff26cdc79751845f6b21904c33c1493468f73501.pdf", "paperhash": "anonymous|interactive_parallel_exploration_for_reinforcement_learning_in_continuous_action_spaces", "_bibtex": "@inproceedings{    \nanonymous2019interactive,    \ntitle={Interactive Parallel Exploration for Reinforcement Learning in Continuous Action Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eEKi0qYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeNFoRcK7", "original": "H1lARld5Km", "number": 435, "cdate": 1538087803783, "ddate": null, "tcdate": 1538087803783, "tmdate": 1538156169738, "tddate": null, "forum": "ByeNFoRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PA-GAN: Improving GAN Training by Progressive Augmentation", "abstract": "Despite recent progress, Generative Adversarial Networks (GANs) still suffer from training instability, requiring careful consideration of architecture design choices and hyper-parameter tuning. The reason for this fragile training behaviour is partially due to the discriminator performing well very quickly; its loss converges to zero, providing no reliable backpropagation signal to the generator. In this work we introduce a new technique - progressive augmentation of GANs (PA-GAN) - that helps to overcome this fundamental limitation and improve the overall stability of GAN training. The key idea is to gradually increase the task difficulty of the discriminator by progressively augmenting its input space, thus enabling continuous learning of the generator. We show that the proposed progressive augmentation preserves the original GAN objective, does not bias the optimality of the discriminator and encourages the healthy competition between the generator and discriminator, leading to a better-performing generator. We experimentally demonstrate the effectiveness of the proposed approach on multiple benchmarks (MNIST, Fashion-MNIST, CIFAR10, CELEBA) for the image generation task.", "keywords": ["Deep Learning", "GANs", "Augmentation", "Generative Modelling"], "authorids": ["ICLR.cc/2019/Conference/Paper435/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a new technique - progressive augmentation of GANs (PA-GAN) - that helps to improve the overall stability of GAN training.", "pdf": "/pdf/8dbbcd305b508334d145a2bd4e49c2b9412e78ae.pdf", "paperhash": "anonymous|pagan_improving_gan_training_by_progressive_augmentation", "_bibtex": "@inproceedings{    \nanonymous2019pa-gan:,    \ntitle={PA-GAN: Improving GAN Training by Progressive Augmentation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeNFoRcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xEtoRqtQ", "original": "rygwAbH9Km", "number": 436, "cdate": 1538087803959, "ddate": null, "tcdate": 1538087803959, "tmdate": 1538156169534, "tddate": null, "forum": "H1xEtoRqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Problem of Model Completion", "abstract": "We introduce the problem of model completion: Given the entire training data set oran environment simulator, and a subset of the parameters of a trained deep learning model, how much training is required to recover the model's original performance? We define a metric for evaluating the hardness of the model completion problem and study it empirically in both supervised learning on ImageNet and reinforcement learning on Atari and DeepMind Lab. Our experiments show that (1) the model completion problem is harder in reinforcement learning than in supervised learning because of the unavailability of the trained agent\u2019s trajectories, and (2) its hardness depends not primarily on the number of parameters of the missing part, but more so on their type and location.", "keywords": ["deep learning", "reinforcement learning", "multi-party computation"], "authorids": ["ICLR.cc/2019/Conference/Paper436/Authors"], "authors": ["Anonymous"], "TL;DR": "We study empirically how hard it is to recover missing parts of trained models", "pdf": "/pdf/dd34bd6d8c8e2e1622411644c49a2a236f17832a.pdf", "paperhash": "anonymous|the_problem_of_model_completion", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Problem of Model Completion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xEtoRqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bke4KsA5FX", "original": "Byxo9EP5YQ", "number": 437, "cdate": 1538087804139, "ddate": null, "tcdate": 1538087804139, "tmdate": 1538156169329, "tddate": null, "forum": "Bke4KsA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Code Modeling with Graphs", "abstract": "Generative models forsource code are an interesting structured prediction problem, requiring to reason about both hard syntactic and semantic constraints as well as about natural, likely programs. We present a novel model for this problem that uses a graph to represent the intermediate state of the generated output. Our model generates code by interleaving grammar-driven expansion steps with graph augmentation and neural message passing steps. An experimental evaluation shows that our new model can generate semantically meaningful expressions, outperforming a range of strong baselines.", "keywords": ["Generative Model", "Source Code", "Graph Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper437/Authors"], "authors": ["Anonymous"], "TL;DR": "Representing programs as graphs including semantics helps when generating programs", "pdf": "/pdf/8867ed1bd8d88378580c46d70d48bae2e896237c.pdf", "paperhash": "anonymous|generative_code_modeling_with_graphs", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Code Modeling with Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bke4KsA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyeVtoRqtQ", "original": "H1eM5kqctm", "number": 438, "cdate": 1538087804314, "ddate": null, "tcdate": 1538087804314, "tmdate": 1538156169117, "tddate": null, "forum": "HyeVtoRqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Trellis Networks for Sequence Modeling", "abstract": "We present trellis networks, a new architecture for sequence modeling. On the one hand, a trellis network is a temporal convolutional network with special structure, characterized by weight tying across depth and direct injection of the input into deep layers. On the other hand, we show that truncated recurrent networks are equivalent to trellis networks with special sparsity structure in their weight matrices. Thus trellis networks with general weight matrices generalize truncated recurrent networks. We leverage these connections to design high-performing trellis networks that absorb structural and algorithmic elements from both recurrent and convolutional models. Experiments demonstrate that trellis networks outperform the current state of the art on a variety of challenging benchmarks, including word-level language modeling on Penn Treebank and WikiText-103, character-level language modeling on Penn Treebank, and stress tests designed to evaluate long-term memory retention.\n", "keywords": ["sequence modeling", "language modeling", "recurrent networks", "convolutional networks", "trellis networks"], "authorids": ["ICLR.cc/2019/Conference/Paper438/Authors"], "authors": ["Anonymous"], "TL;DR": "Trellis networks are a new sequence modeling architecture that bridges recurrent and convolutional models and sets a new state of the art on word- and character-level language modeling.", "pdf": "/pdf/3ec46f4dff5abbf87bc9ef7413d6059f32d65374.pdf", "paperhash": "anonymous|trellis_networks_for_sequence_modeling", "_bibtex": "@inproceedings{    \nanonymous2019trellis,    \ntitle={Trellis Networks for Sequence Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeVtoRqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJx4KjRqYQ", "original": "SkxVjFgIFQ", "number": 439, "cdate": 1538087804487, "ddate": null, "tcdate": 1538087804487, "tmdate": 1538156168916, "tddate": null, "forum": "HJx4KjRqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Ergodic Measure Preserving Flows", "abstract": "Training probabilistic models with neural network components is intractable in most cases and requires to use approximations such as Markov chain Monte Carlo (MCMC), which is not scalable and requires significant hyper-parameter tuning, or mean-field variational inference (VI), which is biased. While there has been attempts at combining both approaches, the resulting methods have some important limitations in theory and in practice. As an alternative, we propose a novel method which is scalable, like mean-field VI, and, due to its theoretical foundation in ergodic theory, is also asymptotically accurate, like MCMC. We test our method on popular benchmark problems with deep generative models and Bayesian neural networks. Our results show that we can outperform existing approximate inference methods.", "keywords": ["Markov chain Monte Carlo", "variational inference", "deep generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper439/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel computational scalable inference framework for training deep generative models and general statistical inference.", "pdf": "/pdf/2cea76e107cfd98007b763aa8caa490d488f3379.pdf", "paperhash": "anonymous|ergodic_measure_preserving_flows", "_bibtex": "@inproceedings{    \nanonymous2019ergodic,    \ntitle={Ergodic Measure Preserving Flows},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJx4KjRqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxHKjAcYX", "original": "HkgGodd9KX", "number": 440, "cdate": 1538087804660, "ddate": null, "tcdate": 1538087804660, "tmdate": 1538156168710, "tddate": null, "forum": "SyxHKjAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Zero-Resource Multilingual Model Transfer: Learning What to Share", "abstract": "Modern natural language processing and understanding applications have enjoyed a great boost utilizing neural networks models. However,  this is not the case for most languages especially low-resource ones with insufficient annotated training data. Cross-lingual transfer learning methods improve the performance on a low-resource target language by leveraging labeled data from other (source) languages, typically with the help of cross-lingual resources such as parallel corpora. In this work, we propose the first zero-resource multilingual transfer learning model that can utilize training data in multiple source languages, while not requiring target language training data nor cross-lingual supervision. Unlike existing methods that only rely on language-invariant features for cross-lingual transfer, our approach utilizes both language-invariant and language-specific features in a coherent way. Our model leverages adversarial networks to learn language-invariant features and mixture-of-experts models to dynamically exploit the relation between the target language and each individual source language. This enables our model to learn effectively what to share between various languages in the multilingual setup. It results in significant performance gains over prior art, as shown in an extensive set of experiments over multiple text classification and sequence tagging tasks including a large-scale real-world industry dataset.", "keywords": ["cross-lingual transfer learning", "multilingual transfer learning", "zero-resource model transfer", "adversarial training", "mixture of experts", "multilingual natural language understanding"], "authorids": ["ICLR.cc/2019/Conference/Paper440/Authors"], "authors": ["Anonymous"], "TL;DR": "The first zero-resource multilingual transfer learning model that requires neither target language training data nor cross-lingual resources.", "pdf": "/pdf/0ecfd307eaf2c53c65c2a2d9196cd53c92eb54fd.pdf", "paperhash": "anonymous|zeroresource_multilingual_model_transfer_learning_what_to_share", "_bibtex": "@inproceedings{    \nanonymous2019zero-resource,    \ntitle={Zero-Resource Multilingual Model Transfer: Learning What to Share},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxHKjAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxStoC5F7", "original": "B1xUcC9qYQ", "number": 441, "cdate": 1538087804846, "ddate": null, "tcdate": 1538087804846, "tmdate": 1538156168503, "tddate": null, "forum": "HkxStoC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper441/Authors"], "authors": ["Anonymous"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/dc7101c2f7fc79f2a73223c0e9e37132b201804e.pdf", "paperhash": "anonymous|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning Probabilistic Inference for Prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxStoC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygrtoC9Km", "original": "Hkl5NRL9Y7", "number": 442, "cdate": 1538087805018, "ddate": null, "tcdate": 1538087805018, "tmdate": 1538156168301, "tddate": null, "forum": "BygrtoC9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning with Individualized Feature Space for Few-Shot Classification", "abstract": "Meta-learning provides a promising learning framework to address few-shot classification tasks. In existing meta-learning methods, the meta-learner is designed to learn about model optimization, parameter initialization, or similarity metric. Differently, in this paper, we propose to learn how to create an individualized feature embedding specific to a given query image for better classifying, i.e., given a query image, a specific feature embedding tailored for its characteristics is created accordingly, leading to an individualized feature space in which the query image can be more accurately classified.\u00a0 Specifically, we introduce a kernel generator as meta-learner to learn to construct feature embedding for query images. The kernel generator acquires meta-knowledge of generating adequate convolutional kernels for different query images during training, which can generalize to unseen categories without fine-tuning. In two standard few-shot classification data sets, i.e. Omniglot, and \\emph{mini}ImageNet, our method shows highly competitive performance. ", "keywords": ["few-shot classification", "meta-learning", "individualized feature space"], "authorids": ["ICLR.cc/2019/Conference/Paper442/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e40c7c2a4a67dc58a7b19e7b1c848d6ddabedbe1.pdf", "paperhash": "anonymous|metalearning_with_individualized_feature_space_for_fewshot_classification", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning with Individualized Feature Space for Few-Shot Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygrtoC9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkeStsCcKQ", "original": "HJxL_7DKK7", "number": 443, "cdate": 1538087805181, "ddate": null, "tcdate": 1538087805181, "tmdate": 1538156168090, "tddate": null, "forum": "BkeStsCcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Critical Learning Periods in Deep Networks", "abstract": "Similar to humans and animals, deep artificial neural networks exhibit critical periods during which a temporary stimulus deficit can impair the development of a skill. The extent of the impairment depends on the onset and length of the deficit window, as in animal models, and on the size of the neural network. Deficits that do not affect low-level statistics, such as vertical flipping of the images, have no lasting effect on performance and can be overcome with further training.  To better understand this phenomenon, we use the Fisher Information of the weights to measure the effective connectivity between layers of a network during training.  Counterintuitively, information raises rapidly in the early phases of training, and then decreases, preventing redistribution of information resources in a phenomenon we refer to as a loss of \"Information Plasticity\".  Our analysis suggests that the first few epochs are critical for the creation of strong connections that are optimal relative to the input data distribution. Once such strong connections are created, they do not appear to change during additional training. These findings suggest that the initial learning transient, under-scrutinized compared to asymptotic behavior, plays a key role in determining the outcome of the training process. Our findings, combined with recent theoretical results in the literature, also suggest that forgetting (decrease of information in the weights) is critical to achieving invariance and disentanglement in representation learning. Finally, critical periods are not restricted to biological systems, but can emerge naturally in learning systems, whether biological or artificial, due to fundamental constrains arising from learning dynamics and information processing.", "keywords": ["Critical Period", "Deep Learning", "Information Theory", "Artificial Neuroscience", "Information Plasticity"], "authorids": ["ICLR.cc/2019/Conference/Paper443/Authors"], "authors": ["Anonymous"], "TL;DR": "Sensory deficits in early training phases can lead to irreversible performance loss in both artificial and neuronal networks, suggesting information phenomena as the common cause, and point to the importance of the initial transient and forgetting.", "pdf": "/pdf/a597559605c420cee99dfb7eee7bf93d7da523b4.pdf", "paperhash": "anonymous|critical_learning_periods_in_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019critical,    \ntitle={Critical Learning Periods in Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeStsCcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxBFsRqYm", "original": "H1xyGysqFX", "number": 444, "cdate": 1538087805360, "ddate": null, "tcdate": 1538087805360, "tmdate": 1538156167881, "tddate": null, "forum": "ByxBFsRqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Attention, Learn to Solve Routing Problems!", "abstract": "The recently presented idea to learn heuristics for combinatorial optimization problems is promising as it can save costly development. However, in order to push this idea towards practical implementation, we need better models and better ways of training. We contribute in both directions: we propose a model based entirely on attention layers with benefits over the Pointer Network and we show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which we find is much more efficient than using a value function. We significantly improve over recent learned heuristics for the Travelling Salesman Problem (TSP), getting close to optimal results for problems up to 100 nodes. With the same hyperparameters, we learn strong heuristics for two variants of the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochastic variant of) the Prize Collecting TSP (PCTSP), outperforming a wide range of baselines and getting results close to highly optimized and specialized algorithms. The ability to construct a tour in order is beneficial in the online (stochastic) setting. We make code publicly available.", "keywords": ["learning", "routing problems", "heuristics", "attention", "reinforce", "travelling salesman problem", "vehicle routing problem", "orienteering problem", "prize collecting travelling salesman problem"], "authorids": ["ICLR.cc/2019/Conference/Paper444/Authors"], "authors": ["Anonymous"], "TL;DR": "Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems", "pdf": "/pdf/41e86675482bf6394f6f80800db98ab5bdf8c437.pdf", "paperhash": "anonymous|attention_learn_to_solve_routing_problems", "_bibtex": "@inproceedings{    \nanonymous2019attention,,    \ntitle={Attention, Learn to Solve Routing Problems!},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxBFsRqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl8FoRcY7", "original": "Hkecjp55Ym", "number": 445, "cdate": 1538087805542, "ddate": null, "tcdate": 1538087805542, "tmdate": 1538156167672, "tddate": null, "forum": "rJl8FoRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Generative Models for learning Coherent Latent Representations from Multi-Modal Data", "abstract": "The application of multi-modal generative models by means of a Variational Auto Encoder (VAE) is an upcoming research topic for sensor fusion and bi-directional modality exchange.\nThis contribution gives insights into the learned joint latent representation and shows that expressiveness and coherence are decisive properties for multi-modal data sets.\nFurthermore, we propose a multi-modal VAE derived from the full joint marginal log-likelihood that is able to learn the most meaningful representation for ambiguous observations.\nSince the properties of multi-modal sensor setups are essential for our approach but hardly available, we also propose a technique to generate correlated data sets from uni-modal ones.\n", "keywords": ["Multi-Modal Deep Generative Models", "Sensor Fusion", "Data Generation"], "authorids": ["ICLR.cc/2019/Conference/Paper445/Authors"], "authors": ["Anonymous"], "TL;DR": "Deriving a general formulation of a multi-modal VAE from the joint marginal log-likelihood.", "pdf": "/pdf/1fe6bbf4ccc1d086d38cea9df51cfcbe1d95b195.pdf", "paperhash": "anonymous|deep_generative_models_for_learning_coherent_latent_representations_from_multimodal_data", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Generative Models for learning Coherent Latent Representations from Multi-Modal Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl8FoRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SylLYsCcFm", "original": "H1lDNkjqKX", "number": 446, "cdate": 1538087805717, "ddate": null, "tcdate": 1538087805717, "tmdate": 1538156167461, "tddate": null, "forum": "SylLYsCcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Make Analogies by Contrasting Abstract Relational Structure", "abstract": "Analogical reasoning has been a principal focus of various waves of AI research. Analogy is particularly challenging for machines because it requires relational structures to be represented such that they can be flexibly applied across diverse domains of experience. Here, we study how analogical reasoning can be induced in neural networks that learn to perceive and reason about raw visual data. We find that the critical factor for inducing such a capacity is not an elaborate architecture, but rather, careful attention to the choice of data and the manner in which it is presented to the model. The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains, a training method that uses only the input data to force models to learn about important abstract features. Using this technique we demonstrate capacities for complex, visual and symbolic analogy making and generalisation in even the simplest neural network architectures.", "keywords": ["cognitive science", "analogy", "psychology", "cognitive theory", "cognition", "abstraction", "generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper446/Authors"], "authors": ["Anonymous"], "TL;DR": "The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains.", "pdf": "/pdf/f45112e8f2ab2b89b8008c1742d34702f0ec91a6.pdf", "paperhash": "anonymous|learning_to_make_analogies_by_contrasting_abstract_relational_structure", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Make Analogies by Contrasting Abstract Relational Structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SylLYsCcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlLKjR9FQ", "original": "HJgm47q5F7", "number": 447, "cdate": 1538087805882, "ddate": null, "tcdate": 1538087805882, "tmdate": 1538156167250, "tddate": null, "forum": "HJlLKjR9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards Understanding Regularization in Batch Normalization", "abstract": "Batch Normalization (BN) improves both convergence and generalization in training neural networks. This work understands these phenomena theoretically. We analyze BN by using a basic block of neural networks, consisting of a kernel layer, a BN layer, and a nonlinear activation function. This basic network helps us understand the impacts of BN in three aspects. First, by viewing BN as an implicit regularizer, BN can be decomposed into population normalization (PN) and gamma decay as an explicit regularization. Second, learning dynamics of BN and the regularization show that training converged with large maximum and effective learning rate. Third, generalization of BN is explored by using statistical mechanics. Experiments demonstrate that BN in convolutional neural networks share the same traits of regularization as the above analyses.", "keywords": ["batch normalization", "regularization", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper447/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9f571d274202861de1ffed9285b8f74f5ed844f2.pdf", "paperhash": "anonymous|towards_understanding_regularization_in_batch_normalization", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Understanding Regularization in Batch Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlLKjR9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByGUFsAqYm", "original": "rJx2ZEd5KX", "number": 448, "cdate": 1538087806049, "ddate": null, "tcdate": 1538087806049, "tmdate": 1538156167038, "tddate": null, "forum": "ByGUFsAqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Downsampling leads to Image Memorization in Convolutional Autoencoders", "abstract": "Memorization of data in deep neural networks has become a subject of significant research interest. \nIn this paper, we link memorization of  images in deep convolutional autoencoders to downsampling through strided convolution.  To analyze this mechanism in a simpler setting, we train linear convolutional autoencoders and show that linear combinations of training data are stored as eigenvectors in the linear operator corresponding to the network when downsampling is used.  On the other hand, networks without downsampling do not memorize training data.  We provide further evidence that the same effect happens in nonlinear networks.  Moreover, downsampling in nonlinear networks causes the model to not only memorize just linear combinations of images, but individual training images.  Since convolutional autoencoder components are building blocks of deep convolutional networks, we envision that our findings will shed light on the important phenomenon of memorization in over-parameterized deep networks.  \n", "keywords": ["Memorization in Deep Learning", "Convolutional Autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper448/Authors"], "authors": ["Anonymous"], "TL;DR": "We identify downsampling as a mechansim for memorization in convolutional autoencoders.", "pdf": "/pdf/fe386b94f5c2f7722843c94e559a5dbd62788b9f.pdf", "paperhash": "anonymous|downsampling_leads_to_image_memorization_in_convolutional_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019downsampling,    \ntitle={Downsampling leads to Image Memorization in Convolutional Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByGUFsAqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkzUYjCcFm", "original": "BJlFMkjcFQ", "number": 449, "cdate": 1538087806271, "ddate": null, "tcdate": 1538087806271, "tmdate": 1538156166829, "tddate": null, "forum": "rkzUYjCcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "INTERPRETING DEEP NEURAL NETWORK: FAST OBJECT LOCALIZATION VIA SENSITIVITY ANALYSIS", "abstract": "Deep Convolutional Neural Networks (CNNs) have been repeatedly shown to perform well on image classification tasks, successfully recognizing a broad array of objects when given sufficient training data. Methods for object localization, however, are still in need of substantial improvement. Common approaches to this problem involve the use of a sliding window, sometimes at multiple scales, providing input to a deep CNN trained to classify the contents of the window. In general, these approaches are time consuming, requiring many classification calculations. In this paper, we offer a fundamentally different approach to the localization of recognized objects in images. Our method is predicated on the idea that a deep CNN capable of recognizing an object must implicitly contain knowledge about object location in its connection weights. We provide a simple method to interpret classifier weights in the context of individual classified images. This method involves the calculation of the derivative of network generated activation patterns, such as the activation of output class label units, with regard to each in- put pixel, performing a sensitivity analysis that identifies the pixels that, in a local sense, have the greatest influence on internal representations and object recognition. These derivatives can be efficiently computed using a single backward pass through the deep CNN classifier, producing a sensitivity map of the image. We demonstrate that a simple linear mapping can be learned from sensitivity maps to bounding box coordinates, localizing the recognized object. Our experimental results, using real-world data sets for which ground truth localization information is known, reveal competitive accuracy from our fast technique.", "keywords": ["Internal Representations", "Sensitivity Analysis", "Object Detection"], "authorids": ["ICLR.cc/2019/Conference/Paper449/Authors"], "authors": ["Anonymous"], "TL;DR": "Proposing a novel object localization(detection) approach based on interpreting the deep CNN using internal representation and network's thoughts", "pdf": "/pdf/8c696d7cd0c7900f080ff5ced008e76f8315f3d5.pdf", "paperhash": "anonymous|interpreting_deep_neural_network_fast_object_localization_via_sensitivity_analysis", "_bibtex": "@inproceedings{    \nanonymous2019interpreting,    \ntitle={INTERPRETING DEEP NEURAL NETWORK: FAST OBJECT LOCALIZATION VIA SENSITIVITY ANALYSIS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkzUYjCcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkNUFjR5KQ", "original": "SJexq5b5Ym", "number": 450, "cdate": 1538087806441, "ddate": null, "tcdate": 1538087806441, "tmdate": 1538156166620, "tddate": null, "forum": "BkNUFjR5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Internal Dense But External Sparse Structures of Deep Neural Network", "abstract": "Recent years have witnessed two seemingly opposite developments of deep convolutional neural networks (CNNs). On one hand, increasing the density of CNNs by adding cross-layer connections achieve higher accuracy. On the other hand, creating sparsity structures through regularization and pruning methods enjoys lower computational costs. In this paper, we bridge these two by proposing a new network structure with locally dense yet externally sparse connections. This new structure uses dense modules, as basic building blocks and then sparsely connects these modules via a novel algorithm during the training process. Experimental results demonstrate that the locally dense yet externally sparse structure could acquire competitive performance on benchmark tasks (CIFAR10, CIFAR100, and ImageNet) while keeping the network structure slim.", "keywords": ["Convolutional Neural Network", "Hierarchical Neural Architecture", "Structural Sparsity", "Evolving Algorithm"], "authorids": ["ICLR.cc/2019/Conference/Paper450/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper, we explore an internal dense yet external sparse network structure of deep neural networks and analyze its key properties.", "pdf": "/pdf/43166ec0d9f4d654bc398cc4421d96d409864b7c.pdf", "paperhash": "anonymous|learning_internal_dense_but_external_sparse_structures_of_deep_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Internal Dense But External Sparse Structures of Deep Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkNUFjR5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xwKoR9Y7", "original": "HJeTzp9qKQ", "number": 451, "cdate": 1538087806620, "ddate": null, "tcdate": 1538087806620, "tmdate": 1538156166415, "tddate": null, "forum": "r1xwKoR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GamePad: A Learning Environment for Theorem Proving", "abstract": "In this paper, we introduce a system called GamePad that can be used to explore the application of machine learning methods to theorem proving in the Coq proof assistant. Interactive theorem provers such as Coq enable users to construct machine-checkable proofs in a step-by-step manner. Hence, they provide an opportunity to explore theorem proving with human supervision. We use GamePad to synthesize proofs for a simple algebraic rewrite problem and train baseline models for a formalization of the Feit-Thompson theorem. We address position evaluation (i.e., predict the number of proof steps left) and tactic prediction (i.e., predict the next proof step) tasks, which arise naturally in tactic-based theorem proving.", "keywords": ["Theorem proving", "ITP", "systems", "neural embeddings"], "authorids": ["ICLR.cc/2019/Conference/Paper451/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a system called GamePad to explore the application of machine learning methods to theorem proving in the Coq proof assistant.", "pdf": "/pdf/d8e6768569b6dc2d114df00ede8c64399cc3ddf5.pdf", "paperhash": "anonymous|gamepad_a_learning_environment_for_theorem_proving", "_bibtex": "@inproceedings{    \nanonymous2019gamepad:,    \ntitle={GamePad: A Learning Environment for Theorem Proving},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xwKoR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxPYjC5KQ", "original": "rJeJwltqY7", "number": 452, "cdate": 1538087806789, "ddate": null, "tcdate": 1538087806789, "tmdate": 1538156166210, "tddate": null, "forum": "ByxPYjC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving Generalization and Stability of Generative Adversarial Networks", "abstract": "Generative Adversarial Networks (GANs) are one of the most popular tools for learning complex high dimensional distributions. However, generalization properties of GANs have not been well understood. In this paper, we analyze the generalization of GANs in practical settings. We show that discriminators trained on discrete datasets with the original GAN loss have poor generalization capability and do not approximate the theoretically optimal discriminator. We propose a zero-centered gradient penalty for improving the generalization of the discriminator by pushing it toward the optimal discriminator. The penalty guarantees the generalization and convergence of GANs. Experiments on synthetic and large scale datasets verify our theoretical analysis.\n", "keywords": ["GAN", "generalization", "gradient penalty", "zero centered", "convergence"], "authorids": ["ICLR.cc/2019/Conference/Paper452/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a zero-centered gradient penalty for improving generalization and stability of GANs", "pdf": "/pdf/608d7d485dfb9357865beed134301a9eed7cdcaa.pdf", "paperhash": "anonymous|improving_generalization_and_stability_of_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Generalization and Stability of Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxPYjC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJevYoA9Fm", "original": "HklllZicF7", "number": 453, "cdate": 1538087806963, "ddate": null, "tcdate": 1538087806963, "tmdate": 1538156166004, "tddate": null, "forum": "rJevYoA9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Singular Values of Convolutional Layers", "abstract": "We characterize the singular values of the linear transformation associated with a standard 2D multi-channel convolutional layer, enabling their efficient computation.  This characterization also leads to an algorithm for projecting a convolutional layer onto an operator-norm ball. We show that this is an effective regularizer;  for example, it improves the test error of a deep residual network using batch normalization on CIFAR-10 from 6.2\\% to 5.3\\%. ", "keywords": ["singular values", "operator norm", "convolutional layers", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper453/Authors"], "authors": ["Anonymous"], "TL;DR": "We characterize the singular values of the linear transformation associated with a standard 2D multi-channel convolutional layer, enabling their efficient computation. ", "pdf": "/pdf/8e8cc1e289be9bc44acd5e5ded7fe4892a6d4124.pdf", "paperhash": "anonymous|the_singular_values_of_convolutional_layers", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Singular Values of Convolutional Layers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJevYoA9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1fPYj0qt7", "original": "BJlZ5SdcY7", "number": 454, "cdate": 1538087807139, "ddate": null, "tcdate": 1538087807139, "tmdate": 1538156165805, "tddate": null, "forum": "B1fPYj0qt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Riemannian Stochastic Gradient Descent for Tensor-Train Recurrent Neural Networks", "abstract": "The Tensor-Train factorization (TTF) is an efficient way to compress large weight matrices of fully-connected layers and recurrent layers in recurrent neural networks (RNNs). However, high Tensor-Train ranks for all the core tensors of parameters need to be element-wise fixed, which results in an unnecessary redundancy of model parameters. This work applies Riemannian stochastic gradient descent (RSGD) to train core tensors of parameters in the Riemannian Manifold before finding vectors of lower Tensor-Train ranks for parameters. The paper first presents the RSGD algorithm with a convergence analysis and then tests it on more advanced Tensor-Train RNNs such as bi-directional GRU/LSTM and Encoder-Decoder RNNs with a Tensor-Train attention model. The experiments on digit recognition and machine translation tasks suggest the effectiveness of the RSGD algorithm for Tensor-Train RNNs. ", "keywords": ["Riemannian Stochastic Gradient Descent", "Tensor-Train", "Recurrent Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper454/Authors"], "authors": ["Anonymous"], "TL;DR": "Applying the Riemannian SGD (RSGD) algorithm for training Tensor-Train RNNs to further reduce model parameters.", "pdf": "/pdf/adcd9143448fd902ce58ddabf1283443b08ff865.pdf", "paperhash": "anonymous|riemannian_stochastic_gradient_descent_for_tensortrain_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019riemannian,    \ntitle={Riemannian Stochastic Gradient Descent for Tensor-Train Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1fPYj0qt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJfPFjA9Fm", "original": "H1gizWicFX", "number": 455, "cdate": 1538087807316, "ddate": null, "tcdate": 1538087807316, "tmdate": 1538156165588, "tddate": null, "forum": "SJfPFjA9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ACCELERATING NONCONVEX LEARNING VIA REPLICA EXCHANGE LANGEVIN DIFFUSION", "abstract": "Langevin diffusion is a powerful method for nonconvex optimization, which enables the escape from local minima by injecting noise into the gradient. In particular, the temperature parameter controlling the noise level gives rise to a tradeoff between ``global exploration'' and ``local exploitation'', which correspond to high and low temperatures. To attain the advantages of both regimes, we propose to use replica exchange, which swaps between two Langevin diffusions with different temperatures. We theoretically analyze the acceleration effect of replica exchange from two perspectives: (i) the convergence in $\\chi^2$-divergence, and (ii) the large deviation principle. Such an acceleration effect allows us to faster approach the global minima. Furthermore, by discretizing the replica exchange Langevin diffusion, we obtain a discrete-time algorithm. For such an algorithm, we quantify its discretization error in theory and demonstrate its acceleration effect in practice. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper455/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/61ccddafa974ca7a2a69f8839cdf66bd33f7fb87.pdf", "paperhash": "anonymous|accelerating_nonconvex_learning_via_replica_exchange_langevin_diffusion", "_bibtex": "@inproceedings{    \nanonymous2019accelerating,    \ntitle={ACCELERATING NONCONVEX LEARNING VIA REPLICA EXCHANGE LANGEVIN DIFFUSION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfPFjA9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyNvti09KQ", "original": "B1lE1XZ9tQ", "number": 456, "cdate": 1538087807488, "ddate": null, "tcdate": 1538087807488, "tmdate": 1538156165385, "tddate": null, "forum": "SyNvti09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards", "abstract": "The human autonomic nervous system has evolved over millions of years and is essential for survival and responding to threats.\n As people learn to navigate the world, ``fight or flight'' responses provide intrinsic feedback about the potential consequence of action choices (e.g., becoming nervous when close to a cliff edge or driving fast around a bend.) Physiological changes are correlated with these biological preparations to protect one-self from danger. We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. Our hypothesis is that such reward functions can circumvent the challenges associated with sparse and skewed rewards in reinforcement learning settings and can help improve sample efficiency. We test this in a simulated driving environment and show that it can increase the speed of learning and reduce the number of collisions during the learning stage.", "keywords": ["Reinforcement Learning", "Simulation", "Affective Computing"], "authorids": ["ICLR.cc/2019/Conference/Paper456/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. ", "pdf": "/pdf/3f98984a9dc2badbe188601ba6839f35d9afb36d.pdf", "paperhash": "anonymous|visceral_machines_reinforcement_learning_with_intrinsic_physiological_rewards", "_bibtex": "@inproceedings{    \nanonymous2019visceral,    \ntitle={Visceral Machines: Reinforcement Learning with Intrinsic Physiological Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyNvti09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xOYoA5tQ", "original": "r1gGUbo9FQ", "number": 457, "cdate": 1538087807661, "ddate": null, "tcdate": 1538087807661, "tmdate": 1538156165175, "tddate": null, "forum": "B1xOYoA5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-way Encoding for Robustness to Adversarial Attacks", "abstract": "Deep models are state-of-the-art for many computer vision tasks including image classification and object detection. However, it has been shown that deep models are vulnerable to adversarial examples. We highlight how one-hot encoding directly contributes to this vulnerability and propose breaking away from this widely-used, but highly-vulnerable mapping. We demonstrate that by leveraging a different output encoding, multi-way encoding, we can make models more robust. Our approach makes it more difficult for adversaries to find useful gradients for generating adversarial attacks. We present state-of-the-art robustness results for black-box, white-box attacks, and achieve higher clean accuracy on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN when combined with adversarial training. The strength of our approach is also presented in the form of an attack for model watermarking, raising challenges in detecting stolen models.", "keywords": ["Adversarial Defense", "Robustness of Deep Convolutional Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper457/Authors"], "authors": ["Anonymous"], "TL;DR": "We demonstrate that by leveraging a multi-way output encoding, rather than the widely used one-hot encoding, we can make deep models more robust to adversarial attacks.", "pdf": "/pdf/3eb29c9006fdf826cdffc406f858d40529a9b5b5.pdf", "paperhash": "anonymous|multiway_encoding_for_robustness_to_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019multi-way,    \ntitle={Multi-way Encoding for Robustness to Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xOYoA5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rke_YiRct7", "original": "r1gDn5xvYX", "number": 458, "cdate": 1538087807835, "ddate": null, "tcdate": 1538087807835, "tmdate": 1538156164963, "tddate": null, "forum": "rke_YiRct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Small nonlinearities in activation functions create bad local minima in neural networks", "abstract": "We investigate the loss surface of neural networks. We prove that even for one-hidden-layer networks with \"slightest\" nonlinearity, the empirical risks have spurious local minima in most cases. Our results thus indicate that in general \"no spurious local minima\" is a property limited to deep linear networks, and insights obtained from linear networks are not robust. Specifically, for ReLU(-like) networks we constructively prove that for almost all (in contrast to previous results) practical datasets there exist infinitely many local minima. We also present a counterexample for more general activations (sigmoid, tanh, arctan, ReLU, etc.), for which there exists a bad local minimum. Our results make the least restrictive assumptions relative to existing results on local optimality in neural networks. We complete our discussion by presenting a comprehensive characterization of global optimality for deep linear networks, which unifies other results on this topic.", "keywords": ["spurious local minima", "loss surface", "optimization landscape", "neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper458/Authors"], "authors": ["Anonymous"], "TL;DR": "We constructively prove that even the slightest nonlinear activation functions introduce spurious local minima, for general datasets and activation functions.", "pdf": "/pdf/bfdc5480b88965bb591f62dcd8f6c5e1ef8be69a.pdf", "paperhash": "anonymous|small_nonlinearities_in_activation_functions_create_bad_local_minima_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019small,    \ntitle={Small nonlinearities in activation functions create bad local minima in neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rke_YiRct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJzuKiC9KX", "original": "H1xVFWjqFQ", "number": 459, "cdate": 1538087808013, "ddate": null, "tcdate": 1538087808013, "tmdate": 1538156164757, "tddate": null, "forum": "BJzuKiC9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Revisiting Reweighted Wake-Sleep", "abstract": " Discrete latent-variable models, while applicable in a variety of settings, can often be difficult to learn. Sampling discrete latent variables can result in high-variance gradient estimators for two primary reasons: 1) branching on the samples within the model, and 2) the lack of a pathwise derivative for the samples. While current state-of-the-art methods employ control-variate schemes for the former and continuous-relaxation methods for the latter, their utility is limited by the complexities of implementing and training effective control-variate schemes and the necessity of evaluating (potentially exponentially) many branch paths in the model. Here, we revisit the Reweighted Wake Sleep (RWS; Bornschein and Bengio, 2015) algorithm, and through extensive evaluations, show that it circumvents both these issues, outperforming current state-of-the-art methods in learning discrete latent-variable models. Moreover, we observe that, unlike the Importance-weighted Autoencoder, RWS learns better models and inference networks with increasing numbers of particles, and that its benefits extend to continuous latent-variable models as well. Our results suggest that RWS is a competitive, often preferable, alternative for learning deep generative models.", "keywords": ["variational inference", "approximate inference", "generative models", "gradient estimators"], "authorids": ["ICLR.cc/2019/Conference/Paper459/Authors"], "authors": ["Anonymous"], "TL;DR": "Empirical analysis and explanation of particle-based gradient estimators for approximate inference with deep generative models.", "pdf": "/pdf/c653bb9ffd52e2374b3b1568ae2b870a653004f6.pdf", "paperhash": "anonymous|revisiting_reweighted_wakesleep", "_bibtex": "@inproceedings{    \nanonymous2019revisiting,    \ntitle={Revisiting Reweighted Wake-Sleep},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJzuKiC9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJf_YjCqYX", "original": "Sye52ZWcKm", "number": 460, "cdate": 1538087808187, "ddate": null, "tcdate": 1538087808187, "tmdate": 1538156164547, "tddate": null, "forum": "BJf_YjCqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Identifying Bias in AI using Simulation", "abstract": "Machine learned models exhibit bias, often because the datasets used to train them are biased. This presents a serious problem for the deployment of such technology, as the resulting models might perform poorly on populations that are minorities within the training set and ultimately present higher risks to them. We propose to use high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. We present a framework that leverages Bayesian parameter search to efficiently characterize the high dimensional feature space and more quickly identify weakness in performance. We apply our approach to an example domain, face detection, and show that it can be used to help identify demographic biases in commercial face application programming interfaces (APIs).", "keywords": ["Bias", "Simulation", "Optimization", "Face Detection"], "authorids": ["ICLR.cc/2019/Conference/Paper460/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a framework that leverages high-fidelity computer simulations to interrogate and diagnose biases within ML classifiers. ", "pdf": "/pdf/c07a6c89761982a2f13ce4c5ec9adc880bc2ac40.pdf", "paperhash": "anonymous|identifying_bias_in_ai_using_simulation", "_bibtex": "@inproceedings{    \nanonymous2019identifying,    \ntitle={Identifying Bias in AI using Simulation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJf_YjCqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hk4dFjR5K7", "original": "r1lXLv4FKm", "number": 461, "cdate": 1538087808359, "ddate": null, "tcdate": 1538087808359, "tmdate": 1538156164340, "tddate": null, "forum": "Hk4dFjR5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ADef: an Iterative Algorithm to Construct Adversarial Deformations", "abstract": "While deep neural networks have proven to be a powerful tool for many recognition and classification tasks, their stability properties are still not well understood. In the past, image classifiers have been shown to be vulnerable to so-called adversarial attacks, which are created by additively perturbing the correctly classified image. In this paper, we propose the ADef algorithm to construct a different kind of adversarial attack created by iteratively applying small deformations to the image, found through a gradient descent step. We demonstrate our results on MNIST with convolutional neural networks and on ImageNet with Inception-v3 and ResNet-101.", "keywords": ["Adversarial examples", "deformations", "deep neural networks", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper461/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new, efficient algorithm to construct adversarial examples by means of deformations, rather than additive perturbations.", "pdf": "/pdf/10b53ff18dd97395f44365c33889198303cc254d.pdf", "paperhash": "anonymous|adef_an_iterative_algorithm_to_construct_adversarial_deformations", "_bibtex": "@inproceedings{    \nanonymous2019adef:,    \ntitle={ADef: an Iterative Algorithm to Construct Adversarial Deformations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hk4dFjR5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lFYoRcFm", "original": "Hkg-ERBqFm", "number": 462, "cdate": 1538087808537, "ddate": null, "tcdate": 1538087808537, "tmdate": 1538156164130, "tddate": null, "forum": "r1lFYoRcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Quantile Regression Reinforcement Learning with State Aligned Vector Rewards", "abstract": "Learning from a scalar reward in continuous action space environments is difficult and often requires millions if not billions of interactions.  We introduce state aligned vector rewards, which are easily defined in metric state spaces and allow our deep reinforcement learning agent to tackle the curse of dimensionality.  Our agent learns to map from action distributions to state change distributions implicitly defined in a quantile function neural network.   We further introduce a new reinforcement learning technique inspired by quantile regression which does not limit agents to explicitly parameterized action distributions.  Our results in high dimensional state spaces show that training with vector rewards allows our agent to learn multiple times faster than an agent training with scalar rewards.", "keywords": ["deep reinforcement learning", "quantile regression", "vector reward"], "authorids": ["ICLR.cc/2019/Conference/Paper462/Authors"], "authors": ["Anonymous"], "TL;DR": "We train with state aligned vector rewards an agent predicting state changes from action distributions, using a new reinforcement learning technique inspired by quantile regression.", "pdf": "/pdf/341834dbcdff49cfe061cb8cf82ec24315415c00.pdf", "paperhash": "anonymous|quantile_regression_reinforcement_learning_with_state_aligned_vector_rewards", "_bibtex": "@inproceedings{    \nanonymous2019quantile,    \ntitle={Quantile Regression Reinforcement Learning with State Aligned Vector Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lFYoRcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eFtj0cKQ", "original": "SJeqiKXcK7", "number": 463, "cdate": 1538087808716, "ddate": null, "tcdate": 1538087808716, "tmdate": 1538156163911, "tddate": null, "forum": "S1eFtj0cKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Models from the perspective of Continual Learning", "abstract": "Which generative model is the most suitable for Continual Learning? This paper aims at evaluating and comparing generative models on disjoint sequential image generation tasks. We investigate how several models learn and forget, considering various strategies: rehearsal, regularization, generative replay and fine-tuning. We used two quantitative metrics to estimate the generation quality and memory ability. We experiment with sequential tasks on three commonly used benchmarks for Continual Learning (MNIST, Fashion MNIST and CIFAR10). We found that among all models, the original GAN performs best and among Continual Learning strategies, generative replay outperforms all other methods. Even if we found satisfactory combinations on MNIST and Fashion MNIST, training generative models sequentially on CIFAR10 is particularly instable, and remains a challenge.", "keywords": ["Generative Models", "Continual Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper463/Authors"], "authors": ["Anonymous"], "TL;DR": "A comparative study of generative models on Continual Learning scenarios.", "pdf": "/pdf/bd5db30837947abdb2e94e58c129e7eaec500d79.pdf", "paperhash": "anonymous|generative_models_from_the_perspective_of_continual_learning", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Models from the perspective of Continual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eFtj0cKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lKtjA9FQ", "original": "r1l1vGj9FQ", "number": 464, "cdate": 1538087808888, "ddate": null, "tcdate": 1538087808888, "tmdate": 1538156163701, "tddate": null, "forum": "B1lKtjA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Overfitting Detection of Deep Neural Networks without a Hold Out Set", "abstract": "Overfitting is an ubiquitous problem in neural network training and usually mitigated using a holdout data set.\nHere we challenge this rationale and investigate criteria for overfitting without using a holdout data set.\nSpecifically, we train a model for a fixed number of epochs multiple times with varying fractions of randomized labels and for a range of regularization strengths. \nA properly trained model should not be able to attain an accuracy greater than the fraction of properly labeled data points. Otherwise the model overfits. \nWe introduce two criteria for detecting overfitting and one to detect underfitting. We analyze early stopping, the regularization factor, and network depth.\nIn safety critical applications we are interested in models and parameter settings which perform well and are not likely to overfit. The methods of this paper allow characterizing and identifying such models.", "keywords": ["deep learning", "overfitting", "generalization", "memorization"], "authorids": ["ICLR.cc/2019/Conference/Paper464/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce and analyze several criteria for detecting overfitting.", "pdf": "/pdf/dff979517dcedcfc63afcd2e48f4285e341984c1.pdf", "paperhash": "anonymous|overfitting_detection_of_deep_neural_networks_without_a_hold_out_set", "_bibtex": "@inproceedings{    \nanonymous2019overfitting,    \ntitle={Overfitting Detection of Deep Neural Networks without a Hold Out Set},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lKtjA9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gKYo09tX", "original": "SkldYKNrK7", "number": 465, "cdate": 1538087809063, "ddate": null, "tcdate": 1538087809063, "tmdate": 1538156163488, "tddate": null, "forum": "H1gKYo09tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "code2seq: Generating Sequences from Structured Representations of Code", "abstract": "The ability to generate natural language sequences from source code snippets has a variety of applications such as code summarization, documentation, and retrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine translation (NMT), have achieved state-of-the-art performance on these tasks by treating source code as a sequence of tokens. We present code2seq: an alternative approach that leverages the syntactic structure of programming languages to better encode source code. Our model represents a code snippet as the set of compositional paths in its abstract syntax tree (AST) and uses attention to select the relevant paths while decoding.\nWe demonstrate the effectiveness of our approach for two tasks, two programming languages, and four datasets of up to 16M examples. Our model significantly outperforms previous models that were specifically designed for programming languages, as well as general state-of-the-art NMT models. ", "keywords": ["source code", "programs", "code2seq"], "authorids": ["ICLR.cc/2019/Conference/Paper465/Authors"], "authors": ["Anonymous"], "TL;DR": "We leverage the syntactic structure of source code to generate natural language sequences.", "pdf": "/pdf/60b557dbcee4cbc5f2d9dd5b2eb8c4a85acc90e7.pdf", "paperhash": "anonymous|code2seq_generating_sequences_from_structured_representations_of_code", "_bibtex": "@inproceedings{    \nanonymous2019code2seq:,    \ntitle={code2seq: Generating Sequences from Structured Representations of Code},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gKYo09tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklKFo09YX", "original": "Hyg12foctQ", "number": 466, "cdate": 1538087809233, "ddate": null, "tcdate": 1538087809233, "tmdate": 1538156163283, "tddate": null, "forum": "BklKFo09YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mol-CycleGAN - a generative model for molecular optimization", "abstract": "Designing a molecule with desired properties is one of the biggest challenges in drug development, as it requires optimization of chemical compound structures with respect to many complex properties. To augment the compound design process we introduce Mol-CycleGAN -- a CycleGAN-based model that generates optimized compounds with a chemical scaffold of interest. Namely, given a molecule our model generates a structurally similar one with an optimized value of the considered property. We evaluate the performance of the model on selected optimization objectives related to structural properties (presence of halogen groups, number of aromatic rings) and to a physicochemical property (penalized logP). In the task of optimization of penalized logP of drug-like molecules our model significantly outperforms previous results. ", "keywords": ["generative adversarial networks", "drug design", "deep learning", "molecule optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper466/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce Mol-CycleGAN - a new generative model for optimization of molecules to augment drug design.", "pdf": "/pdf/7203e57ca5c9da0c706368097c2cafa5d27ab1bf.pdf", "paperhash": "anonymous|molcyclegan_a_generative_model_for_molecular_optimization", "_bibtex": "@inproceedings{    \nanonymous2019mol-cyclegan,    \ntitle={Mol-CycleGAN - a generative model for molecular optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklKFo09YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJGtFoC5Fm", "original": "Hkl8NLfcFm", "number": 467, "cdate": 1538087809410, "ddate": null, "tcdate": 1538087809410, "tmdate": 1538156163076, "tddate": null, "forum": "HJGtFoC5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Margin Theory of Feedforward Neural Networks", "abstract": "Past works have shown that, somewhat surprisingly, over-parametrization can help generalization in neural networks. Towards explaining this phenomenon, we adopt a margin-based perspective. We establish: 1) for multi-layer feedforward relu networks, the global minimizer of a weakly-regularized cross-entropy loss has the maximum normalized margin among all networks, 2) as a result, increasing the over-parametrization improves the normalized margin and generalization error bounds for two-layer networks. In particular, an infinite-size neural network enjoys the best generalization guarantees. The typical infinite feature methods are kernel methods; we compare the neural net margin with that of kernel methods and construct natural instances where kernel methods have much weaker generalization guarantees. We validate this gap between the two approaches empirically. Finally, this infinite-neuron viewpoint is also fruitful for analyzing optimization. We show that a perturbed gradient flow on infinite-size networks finds a global optimizer in polynomial time.", "keywords": ["generalization theory", "implicit regularization", "generalization", "over-parametrization", "theory", "deep learning theory", "margin"], "authorids": ["ICLR.cc/2019/Conference/Paper467/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result.", "pdf": "/pdf/06dd1e3291cc20d36f0f971dcb73365c7630ad3b.pdf", "paperhash": "anonymous|on_the_margin_theory_of_feedforward_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Margin Theory of Feedforward Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJGtFoC5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgqFiAcFm", "original": "HylKTELFYm", "number": 468, "cdate": 1538087809580, "ddate": null, "tcdate": 1538087809580, "tmdate": 1538156162866, "tddate": null, "forum": "HkgqFiAcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Marginal Policy Gradients: A Unified Family of Estimators for Bounded Action Spaces with Applications", "abstract": "Many complex domains, such as robotics control and real-time strategy (RTS) games, require an agent to learn a continuous control. In the former, an agent learns a policy over R^d and in the latter, over a discrete set of actions each of which is parametrized by a continuous parameter. Such problems are naturally solved using policy based reinforcement learning (RL) methods, but unfortunately these often suffer from high variance leading to instability and slow convergence. Unnecessary variance is introduced whenever policies over bounded action spaces are modeled using distributions with unbounded support by applying a transformation T to the sampled action before execution in the environment. Recently, the variance reduced clipped action policy gradient (CAPG) was introduced for actions in bounded intervals, but to date no variance reduced methods exist when the action is a direction, something often seen in RTS games. To this end we introduce the angular policy gradient (APG), a stochastic policy gradient method for directional control. With the marginal policy gradients family of estimators we present a unified analysis of the variance reduction properties of APG and CAPG; our results provide a stronger guarantee than existing analyses for CAPG. Experimental results on a popular RTS game and a navigation task  show that the APG estimator offers a substantial improvement over the standard policy gradient.", "keywords": ["reinforcement learning", "policy gradient", "MOBA games"], "authorids": ["ICLR.cc/2019/Conference/Paper468/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/6f73e6967786c82b68c75dda9c351376849d8c0d.pdf", "paperhash": "anonymous|marginal_policy_gradients_a_unified_family_of_estimators_for_bounded_action_spaces_with_applications", "_bibtex": "@inproceedings{    \nanonymous2019marginal,    \ntitle={Marginal Policy Gradients: A Unified Family of Estimators for Bounded Action Spaces with Applications},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgqFiAcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1x5KiCcFX", "original": "HylzxXi5tX", "number": 469, "cdate": 1538087809762, "ddate": null, "tcdate": 1538087809762, "tmdate": 1538156162658, "tddate": null, "forum": "B1x5KiCcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding GANs via Generalization Analysis for Disconnected Support", "abstract": "This paper provides theoretical analysis of generative adversarial networks (GANs) to explain its advantages over other standard methods of learning probability measures. GANs learn a probability through observations, using the objective function with a generator and a discriminator. While many empirical results indicate that GANs can generate realistic samples, the reason for such successful performance remains unelucidated. This paper focuses the situation where the target probability measure satisfies the disconnected support property, which means a separate support of a probability, and relates it with the advantage of GANs.  It is theoretically shown that, unlike other popular models, GANs do not suffer from the decrease of generalization performance caused by the disconnected support property.  We rigorously quantify the generalization performance of GANs of a given architecture, and compare it with the performance of the other models. Based on the theory, we also provide a guideline for selecting deep network architecture for GANs.  We demonstrate some numerical examples which support our results.", "keywords": ["Generalization analysis", "Statistical estimation", "Understanding GANs", "Disconnected support"], "authorids": ["ICLR.cc/2019/Conference/Paper469/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate the generalization performance of GANs and show how GANs outperform others with a specific property of data.", "pdf": "/pdf/03f3e17035860c368083393e5e05b82452afe560.pdf", "paperhash": "anonymous|understanding_gans_via_generalization_analysis_for_disconnected_support", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding GANs via Generalization Analysis for Disconnected Support},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1x5KiCcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkGcYi09Km", "original": "Hkg6S5bOYX", "number": 470, "cdate": 1538087809935, "ddate": null, "tcdate": 1538087809935, "tmdate": 1538156162450, "tddate": null, "forum": "rkGcYi09Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NUTS: Network for Unsupervised Telegraphic Summarization", "abstract": "Extractive summarization methods operate by ranking and selecting the sentences which best encapsulate the theme of a given document. They do not fare well in domains like fictional narratives where there is no central theme and core information is not encapsulated by a small set of sentences. For the purpose of reducing the size of the document while conveying the idea expressed by each sentence, we need more sentence specific methods. Telegraphic summarization, which selects short segments across several sentences, is better suited for such domains. Telegraphic summarization captures the plot better by retaining shorter versions of each sentence while not really concerning itself with grammatically linking these segments. In this paper, we propose an unsupervised deep learning network (NUTS) to generate telegraphic summaries.\nWe use multiple encoder-decoder networks and learn to drop portions of the text that are inferable from the chosen segments. The model is agnostic to both sentence length and style. We demonstrate that the summaries produced by our model show significant quantitative and qualitative improvement over those produced by existing methods and baselines.", "keywords": ["nlp", "summarization", "unsupervised learning", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper470/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper, we propose an unsupervised deep learning network (NUTS) to generate telegraphic summaries.", "pdf": "/pdf/e74210ec375af7a1db0f94484d378a5603321bb6.pdf", "paperhash": "anonymous|nuts_network_for_unsupervised_telegraphic_summarization", "_bibtex": "@inproceedings{    \nanonymous2019nuts:,    \ntitle={NUTS: Network for Unsupervised Telegraphic Summarization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkGcYi09Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1M9FjC5FQ", "original": "rkxAfQs9tQ", "number": 471, "cdate": 1538087810111, "ddate": null, "tcdate": 1538087810111, "tmdate": 1538156162240, "tddate": null, "forum": "B1M9FjC5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gradient Acceleration in Activation Functions", "abstract": "Dropout has been one of standard approaches to train deep neural networks, and it is known to regularize large models to avoid overfitting. The effect of dropout has been explained by avoiding co-adaptation.\nIn this paper, however, we propose a new explanation of why dropout works and propose a new technique to design better activation functions. First, we show that dropout can be explained as an optimization technique to push the input towards the saturation area of nonlinear activation function by accelerating gradient information flowing even in the saturation area in backpropagation. Based on this explanation, we propose a new technique for activation functions, {\\em gradient acceleration in activation function (GAAF)}, that accelerates gradients to flow even in the saturation area. Then, input to the activation function can climb onto the saturation area which makes the network more robust because the model converges on a flat region.  \nExperiment results support our explanation of dropout and confirm that the proposed GAAF technique improves performances with expected properties.", "keywords": ["Gradient Acceleration", "Saturation Areas", "Dropout", "Coadaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper471/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4cad9da8928bcf932b867fdf25ced5b110de0fc7.pdf", "paperhash": "anonymous|gradient_acceleration_in_activation_functions", "_bibtex": "@inproceedings{    \nanonymous2019gradient,    \ntitle={Gradient Acceleration in Activation Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1M9FjC5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklcFsAcKX", "original": "B1lMvfjqY7", "number": 472, "cdate": 1538087810287, "ddate": null, "tcdate": 1538087810287, "tmdate": 1538156162024, "tddate": null, "forum": "SklcFsAcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior", "abstract": "Deep neural networks provide state-of-the-art performance for image denoising, where the goal is to recover a near noise-free image from a noisy image.\nThe underlying principle is that neural networks trained on large datasets have empirically been shown to be able to generate natural images well from a low-dimensional latent representation of the image.\nGiven such a generator network, or prior, a noisy image can be denoised by finding the closest image in the range of the prior.\nHowever, there is little theory to justify this success, let alone to predict the denoising performance as a function of the networks parameters.\nIn this paper we consider the problem of denoising an image from additive Gaussian noise, assuming the image is well described by a deep neural network with ReLu activations functions, mapping a k-dimensional latent space to an n-dimensional image.\nWe state and analyze a simple gradient-descent-like iterative algorithm that minimizes a non-convex loss function, and provably removes a fraction of (1 - O(k/n)) of the noise energy.\nWe also demonstrate in numerical experiments that this denoising performance is, indeed, achieved by generative priors learned from data.", "keywords": ["non-convex optimization", "denoising", "generative neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper472/Authors"], "authors": ["Anonymous"], "TL;DR": "By analyzing an algorithms minimizing a non-convex loss, we show that all but a small fraction of noise can be removed from an image using a deep neural network based generative prior.", "pdf": "/pdf/1d6118fef5757ca4fb6b725551e9464dfa8bbbfa.pdf", "paperhash": "anonymous|deep_denoising_rateoptimal_recovery_of_structured_signals_with_a_deep_prior", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Denoising: Rate-Optimal Recovery of Structured Signals with a Deep Prior},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklcFsAcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylctiCctX", "original": "SJxlEA4KYQ", "number": 473, "cdate": 1538087810457, "ddate": null, "tcdate": 1538087810457, "tmdate": 1538156161814, "tddate": null, "forum": "BylctiCctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Guiding Physical Intuition with Neural Stethoscopes", "abstract": "Model interpretability and systematic, targeted model adaptation present central challenges in deep learning. In the domain of intuitive physics, we study the task of visually predicting stability of block towers with the goal of understanding and influencing the model's reasoning. Our contributions are two-fold. Firstly, we introduce neural stethoscopes as a framework for quantifying the degree of importance of specific factors of influence in deep networks as well as for actively promoting and suppressing information as appropriate. In doing so, we unify concepts from multitask learning as well as training with auxiliary and adversarial losses. Secondly, we deploy the stethoscope framework to provide an in-depth analysis of a state-of-the-art deep neural network for stability prediction, specifically examining its physical reasoning. We show that the baseline model is susceptible to being misled by incorrect visual cues. This leads to a performance breakdown to the level of random guessing when training on scenarios where visual cues are inversely correlated with stability. Using stethoscopes to promote meaningful feature extraction increases performance from 51% to 90% prediction accuracy. Conversely, training on an easy dataset where visual cues are positively correlated with stability, the baseline model learns a bias leading to poor performance on a harder dataset. Using an adversarial stethoscope, the network is successfully de-biased, leading to a performance increase from 66% to 88%.", "keywords": ["Deep Learning", "Intuitive Physics", "Stability Prediction", "Adversarial Training", "Auxiliary Training", "Multi-Task Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper473/Authors"], "authors": ["Anonymous"], "TL;DR": "Combining auxiliary and adversarial training to interrogate and help physical understanding.", "pdf": "/pdf/7e7599482a8c679065e023e5893b7e06e9e659d8.pdf", "paperhash": "anonymous|guiding_physical_intuition_with_neural_stethoscopes", "_bibtex": "@inproceedings{    \nanonymous2019guiding,    \ntitle={Guiding Physical Intuition with Neural Stethoscopes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylctiCctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxjYoCqKX", "original": "H1lIt7j5FQ", "number": 474, "cdate": 1538087810629, "ddate": null, "tcdate": 1538087810629, "tmdate": 1538156161608, "tddate": null, "forum": "HkxjYoCqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Relaxed Quantization for Discretized Neural Networks", "abstract": "Neural network quantization has become an important research area due to its great impact on deployment of large models on resource constrained devices. In order to train networks that can be effectively discretized without loss of performance, we introduce a differentiable quantization procedure. Differentiability can be achieved by transforming continuous distributions over the weights and activations of the network to categorical distributions over the quantization grid. These are subsequently relaxed to continuous surrogates that can allow for efficient gradient-based optimization. We further show that stochastic rounding can be seen as a special case of the proposed approach and that under this formulation the quantization grid itself can also be optimized with gradient descent. We experimentally validate the performance of our method on MNIST, CIFAR 10 and Imagenet classification.", "keywords": ["Quantization", "Compression", "Neural Networks", "Efficiency"], "authorids": ["ICLR.cc/2019/Conference/Paper474/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a technique that allows for gradient based training of quantized neural networks.", "pdf": "/pdf/cecab380f645cd6a484fa97b18424f73f442981f.pdf", "paperhash": "anonymous|relaxed_quantization_for_discretized_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019relaxed,    \ntitle={Relaxed Quantization for Discretized Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxjYoCqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gstsCqt7", "original": "rJxWB4JDtQ", "number": 475, "cdate": 1538087810805, "ddate": null, "tcdate": 1538087810805, "tmdate": 1538156161391, "tddate": null, "forum": "B1gstsCqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sparse Dictionary Learning by Dynamical Neural Networks", "abstract": "A dynamical neural network consists of a set of interconnected neurons that interact over time continuously. It can exhibit computational properties in the sense that the dynamical system\u2019s evolution and/or limit points in the associated state space can correspond to numerical solutions to certain mathematical optimization or learning problems. Such a computational system is particularly attractive in that it can be mapped to a massively parallel computer architecture for power and throughput efficiency, especially if each neuron can rely solely on local information (i.e., local memory). Deriving gradients from the dynamical network\u2019s various states while conforming to this last constraint, however, is challenging. We show that by combining ideas of top-down feedback and contrastive learning, a dynamical network for solving the l1-minimizing dictionary learning problem can be constructed, and the true gradients for learning are provably computable by individual neurons. Using spiking neurons to construct our dynamical network, we present a learning process, its rigorous mathematical analysis, and numerical results on several dictionary learning problems.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper475/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1ede27520ca7636499f01f6c077dbbd1ebc0883f.pdf", "paperhash": "anonymous|sparse_dictionary_learning_by_dynamical_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019sparse,    \ntitle={Sparse Dictionary Learning by Dynamical Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gstsCqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGiYoAqt7", "original": "B1g1R4c5tm", "number": 476, "cdate": 1538087810980, "ddate": null, "tcdate": 1538087810980, "tmdate": 1538156161185, "tddate": null, "forum": "ryGiYoAqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning  agents with prioritization and parameter noise in continuous state and action space", "abstract": "Reinforcement  Learning  (RL) problem can be solved in two different ways - the Value function-based approach and the policy optimization-based approach - to eventually arrive at an optimal policy for the given environment. One of the recent breakthroughs in reinforcement learning is the use of deep neural networks as function approximators to approximate the value function or q-function in a reinforcement learning scheme. This has led to results with agents automatically learning how to play games like alpha-go showing better-than-human performance. Deep Q-learning networks (DQN) and  Deep Deterministic Policy Gradient (DDPG) are two such methods that have shown state-of-the-art results in recent times. Among the many variants of RL, an important class of problems is where the state and action spaces are continuous --- autonomous robots, autonomous vehicles, optimal control are all examples of such problems that can lend themselves naturally to reinforcement based algorithms, and have continuous state and action spaces. In this paper, we adapt and combine approaches such as DQN and DDPG in novel ways to outperform the earlier results for continuous state and action space problems.  We believe these results are a valuable addition to the fast-growing body of results on Reinforcement Learning, more so for continuous state and action space problems.", "keywords": ["reinforcement learning", "continuous action space", "prioritization", "parameter", "noise", "policy gradients"], "authorids": ["ICLR.cc/2019/Conference/Paper476/Authors"], "authors": ["Anonymous"], "TL;DR": "Improving the performance of an RL agent in the continuous action and state space domain by using prioritised experience replay and parameter noise.", "pdf": "/pdf/a36561edcadcf5a168252742d99bcc132e87f5c5.pdf", "paperhash": "anonymous|learning_agents_with_prioritization_and_parameter_noise_in_continuous_state_and_action_space", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning  agents with prioritization and parameter noise in continuous state and action space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGiYoAqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1fiFs09YX", "original": "S1x8UAuqKX", "number": 477, "cdate": 1538087811160, "ddate": null, "tcdate": 1538087811160, "tmdate": 1538156160958, "tddate": null, "forum": "r1fiFs09YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sample-efficient policy learning in multi-agent Reinforcement Learning via meta-learning", "abstract": "To gain high rewards in muti-agent scenes, it is sometimes necessary to understand other agents and make corresponding optimal decisions. We can solve these tasks by first building models for other agents and then finding the optimal policy with these models. To get an accurate model, many observations are needed and this can be sample-inefficient. What's more, the learned model and policy can overfit to current agents and cannot generalize if the other agents are replaced by new agents. In many practical situations, each agent we face can be considered as a sample from a population with a fixed but unknown distribution. Thus we can treat the task against some specific agents as a task sampled from a task distribution. We apply meta-learning method to build models and learn policies. Therefore when new agents come, we can adapt to them efficiently. Experiments on grid games show that our method can quickly get high rewards.", "keywords": ["Multi-agent", "Reinforcement Learning", "Meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper477/Authors"], "authors": ["Anonymous"], "TL;DR": "Our work applies meta-learning to multi-agent Reinforcement Learning to help our agent efficiently adapted to new coming opponents.", "pdf": "/pdf/0d46a0f76a0400fede890eee0fe90d17aa54dbc5.pdf", "paperhash": "anonymous|sampleefficient_policy_learning_in_multiagent_reinforcement_learning_via_metalearning", "_bibtex": "@inproceedings{    \nanonymous2019sample-efficient,    \ntitle={Sample-efficient policy learning in multi-agent Reinforcement Learning via meta-learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1fiFs09YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1EjKsRqtQ", "original": "SJgmSSocK7", "number": 478, "cdate": 1538087811336, "ddate": null, "tcdate": 1538087811336, "tmdate": 1538156160750, "tddate": null, "forum": "B1EjKsRqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Attention: What Really Counts in Various NLP Tasks", "abstract": "Attention mechanisms in sequence to sequence models have shown great ability and wonderful performance in various natural language processing  (NLP)  tasks, such as sentence embedding, text generation, machine translation, machine reading comprehension, etc. Unfortunately, existing attention mechanisms only learn either high-level or low-level features. In this paper, we think that the lack of hierarchical mechanisms is a bottleneck in improving the performance of the attention mechanisms, and propose a novel Hierarchical Attention Mechanism (Ham) based on the weighted sum of different layers of a multi-level attention. \nHam achieves a state-of-the-art BLEU score of 0.26 on Chinese poem generation task and a nearly 6.5% averaged improvement compared with the existing machine reading comprehension models such as BIDAF and Match-LSTM. Furthermore, our experiments and theorems reveal that Ham has greater generalization and representation ability than existing attention mechanisms. ", "keywords": ["attention", "hierarchical", "machine reading comprehension", "poem generation"], "authorids": ["ICLR.cc/2019/Conference/Paper478/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper proposed a novel hierarchical model to replace the original attention model in various NLP tasks.", "pdf": "/pdf/2de1a2d23536899248aea15fe0c19a5a9ea7cd65.pdf", "paperhash": "anonymous|hierarchical_attention_what_really_counts_in_various_nlp_tasks", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Attention: What Really Counts in Various NLP Tasks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1EjKsRqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sk4jFoA9K7", "original": "Bkgq6OP9t7", "number": 479, "cdate": 1538087811508, "ddate": null, "tcdate": 1538087811508, "tmdate": 1538156160543, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper479/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4df4c70fe26b5d994681ec87e8752d14669abe34.pdf", "paperhash": "anonymous|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019peernets:,    \ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sk4jFoA9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1x2Fj0qKQ", "original": "HkeTG2BtKm", "number": 480, "cdate": 1538087811683, "ddate": null, "tcdate": 1538087811683, "tmdate": 1538156160327, "tddate": null, "forum": "S1x2Fj0qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Whitening and Coloring transform for GANs", "abstract": "Batch Normalization (BN) is a common technique used \nto speed-up and stabilize training. On the other hand, the learnable parameters of BN are commonly used in conditional Generative Adversarial Networks (cGANs)\nfor representing class-specific information using conditional Batch Normalization (cBN). In this paper we propose to generalize both BN and cBN using a Whitening and Coloring based batch normalization. \nWe show that our conditional Coloring can represent categorical conditioning information which largely helps the cGAN qualitative results. Moreover, we show that full-feature whitening is important in a general GAN scenario in which the training process is known to be highly unstable.\nWe test our approach on different datasets and \nusing different GAN networks and training protocols,\nshowing a consistent improvement in all the tested frameworks. Our CIFAR-10 supervised results are higher than all previous works on this dataset.", "keywords": ["Generative Adversarial Networks", "conditional GANs", "Batch Normalization"], "authorids": ["ICLR.cc/2019/Conference/Paper480/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4496e9a4312d1048c7565ec63896110b6b6f7834.pdf", "paperhash": "anonymous|whitening_and_coloring_transform_for_gans", "_bibtex": "@inproceedings{    \nanonymous2019whitening,    \ntitle={Whitening and Coloring transform for GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1x2Fj0qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByghKiC5YX", "original": "HJewSzbPK7", "number": 481, "cdate": 1538087811858, "ddate": null, "tcdate": 1538087811858, "tmdate": 1538156160070, "tddate": null, "forum": "ByghKiC5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data", "abstract": "We present a probabilistic framework for studying adversarial attacks on discrete data. Based on this framework, we derive a perturbation-based method, Greedy Attack, and a scalable learning-based method, Gumbel Attack, that illustrate various tradeoffs in the design of attacks. We demonstrate the effectiveness of these methods using both quantitative metrics and human evaluation on various state-of-the-art models for text classification, including a word-based CNN, a character-based CNN and an LSTM. As an example of our results, we show that the accuracy of character-based convolutional networks drops to the level of random selection by modifying only five characters through Greedy Attack.", "keywords": ["Adversarial Examples"], "authorids": ["ICLR.cc/2019/Conference/Paper481/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop two methods for generating adversarial examples on discrete data under a probabilistic framework.", "pdf": "/pdf/e82382c2a950ca35821c18918260b79093f5e9d8.pdf", "paperhash": "anonymous|greedy_attack_and_gumbel_attack_generating_adversarial_examples_for_discrete_data", "_bibtex": "@inproceedings{    \nanonymous2019greedy,    \ntitle={Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByghKiC5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1znKiAcY7", "original": "H1ebSc5qYX", "number": 482, "cdate": 1538087812035, "ddate": null, "tcdate": 1538087812035, "tmdate": 1538156159859, "tddate": null, "forum": "r1znKiAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Few-shot Classification on Graphs with Structural Regularized GCNs", "abstract": "We consider the fundamental problem of semi-supervised node classification in attributed graphs with a focus on \\emph{few-shot} learning. Here, we propose Structural Regularized Graph Convolutional Networks (SRGCN), novel neural network architectures extending the well-known GCN structures by stacking transposed convolutional layers for reconstruction of input features. We add a reconstruction error term in the loss function as a regularizer. Unlike standard regularization such as $L_1$ or $L_2$, which controls the model complexity by including a penalty term depends solely on parameters, our regularization function is parameterized by a trainable neural network whose structure depends on the topology of the underlying graph. The new approach effectively addresses the shortcomings of previous graph convolution-based techniques for learning classifiers in the few-shot regime and significantly improves generalization performance over original GCNs when the number of labeled samples is insufficient. Experimental studies on three challenging benchmarks demonstrate that the proposed approach has matched state-of-the-art results and can improve classification accuracies by a notable margin when there are very few examples from each class.", "keywords": ["Graph Convolutional Networks", "Few-shot", "Classification"], "authorids": ["ICLR.cc/2019/Conference/Paper482/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/23212d65f75a0d222b7868f15f06baaf0b070a61.pdf", "paperhash": "anonymous|fewshot_classification_on_graphs_with_structural_regularized_gcns", "_bibtex": "@inproceedings{    \nanonymous2019few-shot,    \ntitle={Few-shot Classification on Graphs with Structural Regularized GCNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1znKiAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyMnYiR9Y7", "original": "SyxJnqlYYX", "number": 483, "cdate": 1538087812206, "ddate": null, "tcdate": 1538087812206, "tmdate": 1538156159652, "tddate": null, "forum": "HyMnYiR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING", "abstract": "Supervised models suffer from domain shifting where distribution mismatch across domains greatly affect model performance. Particularly, noise scattered in each domain has played a crucial role in representing such distribution, especially in various natural language processing (NLP) tasks. In addressing this issue, training data selection (TDS) has been proven to be a prospective way to train supervised models with higher performance and efficiency. Following the TDS methodology, in this paper, we propose a general data selection framework with representation learning and distribution matching simultaneously for domain adaptation on neural models. In doing so, we formulate TDS as a novel selection process based on a learned distribution from the input data, which is produced by a trainable selection distribution generator (SDG) that is optimized by reinforcement learning (RL). Then, the model trained by the selected data not only predicts the target domain data in a specific task, but also provides input for the value function of the RL. Experiments are conducted on three typical NLP tasks, namely, part-of-speech tagging, dependency parsing, and sentiment analysis. Results demonstrate the validity and effectiveness of our approach.", "keywords": ["domain adaptation", "training data selection", "reinforcement learning", "natural language processing"], "authorids": ["ICLR.cc/2019/Conference/Paper483/Authors"], "authors": ["Anonymous"], "TL;DR": "Training data selection via reinforcement learning", "pdf": "/pdf/865a25138acdc4f0f875286ae06430edea7a97fb.pdf", "paperhash": "anonymous|domain_adaptation_via_distribution_and_representation_matching_a_case_study_on_training_data_selection_via_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019domain,    \ntitle={DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMnYiR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1E3Ko09F7", "original": "HJeBv1guY7", "number": 484, "cdate": 1538087812375, "ddate": null, "tcdate": 1538087812375, "tmdate": 1538156159442, "tddate": null, "forum": "S1E3Ko09F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data", "abstract": "Instancewise feature scoring is a method for model interpretation, which yields, for each test instance, a vector of importance scores associated with the feature vector. Methods based on the Shapley score have been proposed as a fair way of computing feature attributions of this kind, but incur an exponential complexity in the number of features for black-box models.  This combinatorial explosion arises from the definition of the Shapley value and prevents these methods from being scalable to large data sets and complex models. We focus on settings in which the data have a graph structure, and the contribution of features to the target variable is well-approximated by a graph-structured factorization.  In such settings, we develop two algorithms with linear complexity for instancewise feature importance scoring on black-box models.  We establish the relationship of our methods to the Shapley value and a closely related concept known as the Myerson value from cooperative game theory. We demonstrate on both language and image data that our algorithms compare favorably with other methods for model interpretation.", "keywords": ["Model Interpretation", "Feature Selection"], "authorids": ["ICLR.cc/2019/Conference/Paper484/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop two linear-complexity algorithms for model-agnostic model interpretation based on the Shapley value, in the settings where the contribution of features to the target is well-approximated by a graph-structured factorization.", "pdf": "/pdf/57faccefea15a3cbc31d9ad417585b41ebfdd37b.pdf", "paperhash": "anonymous|lshapley_and_cshapley_efficient_model_interpretation_for_structured_data", "_bibtex": "@inproceedings{    \nanonymous2019l-shapley,    \ntitle={L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1E3Ko09F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlaYi05tm", "original": "H1lrYYSqY7", "number": 485, "cdate": 1538087812557, "ddate": null, "tcdate": 1538087812557, "tmdate": 1538156159231, "tddate": null, "forum": "BJlaYi05tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Geometry of Deep Convolutional Networks", "abstract": " We give a formal procedure for computing preimages of convolutional\n  network outputs using the dual basis defined from the set of\n  hyperplanes associated with the layers of the network. We point out\n  the special symmetry associated with arrangements of hyperplanes of\n  convolutional networks that take the form of regular\n  multidimensional polyhedral cones. We discuss  the efficiency of of\n  large number of layers of nested cones that result from incremental\n  small size convolutions in order to give a good compromise between\n  efficient contraction of data to low dimensions and shaping of\n  preimage manifolds. We demonstrate how a specific network flattens a\n  non linear input manifold to an affine output manifold and discuss\n  it's relevance to understanding classification properties of deep\n  networks.", "keywords": ["convolutional networks", "geometry"], "authorids": ["ICLR.cc/2019/Conference/Paper485/Authors"], "authors": ["Anonymous"], "TL;DR": "Analysis of deep convolutional networks in terms of associated arrangement of hyperplanes", "pdf": "/pdf/56f9f4a1fd0f28b18a1677dc703603a3ad5b3f4b.pdf", "paperhash": "anonymous|geometry_of_deep_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019geometry,    \ntitle={Geometry of Deep Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlaYi05tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxaFoC9KQ", "original": "Bke2bwo5FX", "number": 486, "cdate": 1538087812734, "ddate": null, "tcdate": 1538087812734, "tmdate": 1538156159029, "tddate": null, "forum": "HkxaFoC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep reinforcement learning with relational inductive biases", "abstract": "We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretability. Our architecture encodes an image as a set of vectors, and applies an iterative message-passing procedure to discover and reason about relevant entities and relations in a scene. In six of seven StarCraft II Learning Environment mini-games, our agent achieved state-of-the-art performance, and surpassed human grandmaster-level on four. In a novel navigation and planning task, our agent's performance and learning efficiency far exceeded non-relational baselines, it was able to generalize to more complex scenes than it had experienced during training. Moreover, when we examined its learned internal representations, they reflected important structure about the problem and the agent's intentions. Our main contribution is a new approach for representing and reasoning about states in model-free deep reinforcement learning agents via relational inductive biases, which can offer advantages more often associated with model-based methods, such as efficiency, generalization, and interpretability, and which can scale up to meet some of the most challenging reinforcement learning environments.", "keywords": ["relational reasoning", "reinforcement learning", "graph neural networks", "starcraft", "generalization", "inductive bias"], "authorids": ["ICLR.cc/2019/Conference/Paper486/Authors"], "authors": ["Anonymous"], "TL;DR": "Relational inductive biases improve out-of-distribution generalization capacities in model-free reinforcement learning agents", "pdf": "/pdf/868f30b7efc91d533033058c6bac91f6ea2475dd.pdf", "paperhash": "anonymous|deep_reinforcement_learning_with_relational_inductive_biases", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep reinforcement learning with relational inductive biases},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxaFoC9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syl6tjAqKX", "original": "rJl7mPQ9FX", "number": 487, "cdate": 1538087812918, "ddate": null, "tcdate": 1538087812918, "tmdate": 1538156158821, "tddate": null, "forum": "Syl6tjAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BEHAVIOR MODULE IN NEURAL NETWORKS", "abstract": "Prefrontal cortex (PFC) is a part of the brain which is responsible for behavior repertoire. Inspired by PFC functionality and connectivity,  as well as human behavior formation process, we propose a novel modular architecture of neural networks with a Behavioral Module (BM) and corresponding end-to-end training strategy.  This approach allows the efficient learning of behaviors and preferences representation. This property is particularly useful for user modeling (as for dialog agents) and recommendation tasks, as allows learning personalized representations of different user states.  In the experiment with video games playing, the resultsshow that the proposed method allows separation of main task\u2019s objectives andbehaviors between different BMs. The experiments also show network extendability through independent learning of new behavior patterns. Moreover, we demonstrate a strategy for an efficient transfer of newly learned BMs to unseen tasks.", "keywords": ["Modular Networks", "Reinforcement Learning", "Task Separation", "Representation Learning", "Transfer Learning", "Adversarial Transfer"], "authorids": ["ICLR.cc/2019/Conference/Paper487/Authors"], "authors": ["Anonymous"], "TL;DR": "Extendable Modular Architecture is proposed for developing of variety of Agent Behaviors in DQN.", "pdf": "/pdf/d91365d674d7c71e62f89e9dfa7cc48366e48640.pdf", "paperhash": "anonymous|behavior_module_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019behavior,    \ntitle={BEHAVIOR MODULE IN NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syl6tjAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxaYsAqY7", "original": "HylrE7vtKm", "number": 488, "cdate": 1538087813107, "ddate": null, "tcdate": 1538087813107, "tmdate": 1538156158614, "tddate": null, "forum": "SyxaYsAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Second-Order Adversarial Attack and Certifiable Robustness", "abstract": "Adversarial training has been recognized as a strong defense against adversarial attacks. In this paper, we propose a powerful second-order attack method that reduces the accuracy of the defense model by Madry et al. (2017). We demonstrate that adversarial training overfits to the choice of the norm in the sense that it is only robust to the attack used for adversarial training, thus suggesting it has not achieved universal robustness. The effectiveness of our attack method motivates an investigation of provable robustness of a defense model. To this end, we introduce a framework that allows one to obtain a certifiable lower bound on the prediction accuracy against adversarial examples. We conduct experiments to show the effectiveness of our attack method. At the same time, our defense model achieves significant improvements compared to previous works under our proposed attack.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper488/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/bc69fa83c2566570e88bd022d556c5e28db87f96.pdf", "paperhash": "anonymous|secondorder_adversarial_attack_and_certifiable_robustness", "_bibtex": "@inproceedings{    \nanonymous2019second-order,    \ntitle={Second-Order Adversarial Attack and Certifiable Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxaYsAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJz6tiCqYm", "original": "S1xnna59tm", "number": 489, "cdate": 1538087813282, "ddate": null, "tcdate": 1538087813282, "tmdate": 1538156158404, "tddate": null, "forum": "HJz6tiCqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["ICLR.cc/2019/Conference/Paper489/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/06f808d17e2d3d3d9c8d2d054cfcd1c1866e705f.pdf", "paperhash": "anonymous|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{    \nanonymous2019benchmarking,    \ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJz6tiCqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryf6Fs09YX", "original": "BkloSJS-Km", "number": 490, "cdate": 1538087813459, "ddate": null, "tcdate": 1538087813459, "tmdate": 1538156158198, "tddate": null, "forum": "ryf6Fs09YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GO Gradient for Expectation-Based Objectives", "abstract": "Within many machine learning algorithms, a fundamental problem concerns efficient calculation of an unbiased gradient wrt parameters $\\boldsymbol{\\gamma}$ for expectation-based objectives $\\mathbb{E}_{q_{\\boldsymbol{\\gamma}} (\\boldsymbol{y})} [f (\\boldsymbol{y}) ]$. Most existing methods either ($i$) suffer from high variance, seeking help from (often) complicated variance-reduction techniques; or ($ii$) they only apply to distributions of continuous random variables and employ a reparameterization trick. To address these limitations, we propose a General and One-sample (GO) gradient that ($i$) applies to distributions associated with continuous {\\em or} discrete random variables, and ($ii$) has the same low-variance as the reparameterization trick. We find that the GO gradient often works well in practice based on only one Monte Carlo sample (although one can of course use more samples if desired). Alongside the GO gradient, we develop a means of propagating the chain rule through distributions, yielding {statistical back-propagation}, coupling neural networks to random variables.", "keywords": ["generalized reparameterization gradient", "variance reduction", "non-reparameterizable", "discrete random variable", "GO gradient", "general and one-sample gradient", "expectation-based objective", "variable nabla", "statistical back-propagation", "hierarchical", "graphical model"], "authorids": ["ICLR.cc/2019/Conference/Paper490/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fb0f6928c8565438eb3b75fcc38e3ade0fe1abf3.pdf", "paperhash": "anonymous|go_gradient_for_expectationbased_objectives", "_bibtex": "@inproceedings{    \nanonymous2019go,    \ntitle={GO Gradient for Expectation-Based Objectives},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryf6Fs09YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlRKjActQ", "original": "rkx9zS9ttm", "number": 491, "cdate": 1538087813638, "ddate": null, "tcdate": 1538087813638, "tmdate": 1538156157992, "tddate": null, "forum": "rJlRKjActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Manifold Mixup: Learning Better Representations by Interpolating Hidden States", "abstract": "Deep networks often perform well on the data distribution on which they are trained, yet give incorrect (and often very confident) answers when evaluated on points from off of the training distribution. This is exemplified by the adversarial examples phenomenon but can also be seen in terms of model generalization and domain shift.  Ideally, a model would assign lower confidence to points unlike those from the training distribution.  We propose a regularizer which addresses this issue by training with interpolated hidden states and encouraging the classifier to be less confident at these points.  Because the hidden states are learned, this has an important effect of encouraging the hidden states for a class to be concentrated in such a way so that interpolations within the same class or between two different classes do not intersect with the real data points from other classes.  This has a major advantage in that it avoids the underfitting which can result from interpolating in the input space.  We prove that the exact condition for this problem of underfitting to be avoided by Manifold Mixup is that the dimensionality of the hidden states exceeds the number of classes, which is often the case in practice.  Additionally, this concentration can be seen as making the features in earlier layers more discriminative.  We show that despite requiring no significant additional computation, Manifold Mixup achieves large improvements over strong baselines in supervised learning, robustness to single-step adversarial attacks, semi-supervised learning, and Negative Log-Likelihood on held out samples.", "keywords": ["Regularizer", "Supervised Learning", "Semi-supervised Learning", "Better representation learning", "Deep Neural Networks."], "authorids": ["ICLR.cc/2019/Conference/Paper491/Authors"], "authors": ["Anonymous"], "TL;DR": "A method for learning better representations, that acts as a regularizer and despite its no significant additional computation cost , achieves improvements over strong baselines on Supervised and Semi-supervised Learning tasks.", "pdf": "/pdf/1d359c956a24a95b60f90b7abaaeaf39f0ad4793.pdf", "paperhash": "anonymous|manifold_mixup_learning_better_representations_by_interpolating_hidden_states", "_bibtex": "@inproceedings{    \nanonymous2019manifold,    \ntitle={Manifold Mixup: Learning Better Representations by Interpolating Hidden States},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlRKjActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1e0KsRcYQ", "original": "Skx4wSo9t7", "number": 492, "cdate": 1538087813817, "ddate": null, "tcdate": 1538087813817, "tmdate": 1538156157782, "tddate": null, "forum": "B1e0KsRcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Codebook and Factorization for Second Order Representation Learning", "abstract": "Learning rich and compact representations is an open topic in many fields such as word embedding, visual question-answering, object recognition or image retrieval. Although deep neural networks (convolutional or not) have made a major breakthrough during the last few years by providing hierarchical, semantic and abstract representations for all of these tasks, these representations are not necessary as rich as needed nor as compact as expected. Models using higher order statistics, such as bilinear pooling, provide richer representations at the cost of higher dimensional features. Factorization schemes have been proposed but without being able to reach the original compactness of first order models, or at a heavy loss in performances. This paper addresses these two points by extending factorization schemes to codebook strategies, allowing compact representations with the same dimensionality as first order representations, but with second order performances. Moreover, we extend this framework with a joint codebook and factorization scheme, granting a reduction both in terms of parameters and computation cost. This formulation leads to state-of-the-art results and compact second-order models with few additional parameters and intermediate representations with a dimension similar to that of first-order statistics.", "keywords": ["Second order pooling"], "authorids": ["ICLR.cc/2019/Conference/Paper492/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a joint codebook and factorization scheme to improve second order pooling.", "pdf": "/pdf/367de78ffa1e0db3580d48f264b841c53eb45e7e.pdf", "paperhash": "anonymous|efficient_codebook_and_factorization_for_second_order_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Codebook and Factorization for Second Order Representation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e0KsRcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1f0YiCctm", "original": "BklJug59K7", "number": 493, "cdate": 1538087814052, "ddate": null, "tcdate": 1538087814052, "tmdate": 1538156157578, "tddate": null, "forum": "r1f0YiCctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters", "abstract": "While deep neural networks are a highly successful model class, their large memory footprint puts considerable strain on energy consumption, communication bandwidth, and storage requirements. Consequently, model size reduction has become an utmost goal in deep learning. A typical approach is to train a set of deterministic weights, while applying certain techniques such as pruning and quantization, in order that the empirical weight distribution becomes amenable to Shannon-style coding schemes. However, as shown in this paper, relaxing weight determinism and using a full variational distribution over weights allows for more efficient coding schemes and consequently higher compression rates. In particular, following the classical bits-back argument, we encode the network weights using a random sample, requiring only a number of bits corresponding to the Kullback-Leibler divergence between the sampled variational distribution and the encoding distribution. By imposing a constraint on the Kullback-Leibler divergence, we are able to explicitly control the compression rate, while optimizing the expected loss on the training set. The employed encoding scheme can be shown to be close to the optimal information-theoretical lower bound, with respect to the employed variational family. Our method sets new state-of-the-art in neural network compression, as it strictly dominates previous approaches in a Pareto sense: On the benchmarks LeNet-5/MNIST and VGG-16/CIFAR-10, our approach yields the best test performance for a fixed memory budget, and vice versa, it achieves the highest compression rates for a fixed test performance.", "keywords": ["compression", "neural networks", "bits-back argument", "Bayesian", "Shannon", "information theory"], "authorids": ["ICLR.cc/2019/Conference/Paper493/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes an effective method to compress neural networks based on recent results in information theory.", "pdf": "/pdf/e1a2516e4f05c216edf000101b2d57220eca6c88.pdf", "paperhash": "anonymous|minimal_random_code_learning_getting_bits_back_from_compressed_model_parameters", "_bibtex": "@inproceedings{    \nanonymous2019minimal,    \ntitle={Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1f0YiCctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GRtj05t7", "original": "HJe22G3YFQ", "number": 494, "cdate": 1538087814246, "ddate": null, "tcdate": 1538087814246, "tmdate": 1538156157374, "tddate": null, "forum": "B1GRtj05t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reinforcement Learning: From temporal to spatial value decomposition", "abstract": "Value function lies in the heart of reinforcement learning, as it can capture the long-term dependency between current state/action and delayed reward. Value function is defined as expected total reward. Following this definition, it's natural to derive a temporal decomposition for value function, as a sum of discounted reward on different time steps. Most existing RL algorithms estimate value function based on this temporal decomposition.\n\nIn our formulation, value function $Q(s,a)$ is a weight sum of reward $R(s')$, and the weight is the discounted visiting frequency $d(s, a, s')$. Here $d(s, a, s')$ is the key part that captures long-term dependency between current state/action with future state. This formulation inspires us to study $d(s, a, s')$ in depth, with function approximation as usual.\nUnder the function approximation setting, $d(s, a, s')$ enjoys the benefit of generalization between similar state $s'$. Due to this generalization property, we can get better estimation for $d(s, a, s')$, thus resulting in a better estimation for $Q(s,a)$. We propose spatial monte-carlo (SMC) method, and apply the idea of SMC to actor-critic algorithms with $m$-step advantage estimation and GAE. Experiments demonstrate that our algorithms work empirically well.", "keywords": ["reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper494/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cfcddf56ed3358b5051da572a5249e2e2cb47367.pdf", "paperhash": "anonymous|reinforcement_learning_from_temporal_to_spatial_value_decomposition", "_bibtex": "@inproceedings{    \nanonymous2019reinforcement,    \ntitle={Reinforcement Learning: From temporal to spatial value decomposition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GRtj05t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJ4AFsRcFQ", "original": "BJefIdoqY7", "number": 495, "cdate": 1538087814427, "ddate": null, "tcdate": 1538087814427, "tmdate": 1538156157168, "tddate": null, "forum": "BJ4AFsRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Total Style Transfer with a Single Feed-Forward Network", "abstract": "Recent image style transferring methods achieved arbitrary stylization with input content and style images. To transfer the style of an arbitrary image to a content image, these methods used a feed-forward network with a lowest-scaled feature transformer or a cascade of the networks with a feature transformer of a corresponding scale. However, their approaches did not consider either multi-scaled style in their single-scale feature transformer or dependency between the transformed feature statistics across the cascade networks. This shortcoming resulted in generating partially and inexactly transferred style in the generated images.\nTo overcome this limitation of partial style transfer, we propose a total style transferring method which transfers multi-scaled feature statistics through a single feed-forward process. First, our method transforms multi-scaled feature maps of a content image into those of a target style image by considering both inter-channel correlations in each single scaled feature map and inter-scale correlations between multi-scaled feature maps. Second, each transformed feature map is inserted into the decoder layer of the corresponding scale using skip-connection. Finally, the skip-connected multi-scaled feature maps are decoded into a stylized image through our trained decoder network.", "keywords": ["Image Style Transfer", "Deep Learning", "Neural Network"], "authorids": ["ICLR.cc/2019/Conference/Paper495/Authors"], "authors": ["Anonymous"], "TL;DR": "A paper suggesting a method to transform the style of images using deep neural networks.", "pdf": "/pdf/ea3856820e1ebb8047b7f356c98c5bb5ffe34c98.pdf", "paperhash": "anonymous|total_style_transfer_with_a_single_feedforward_network", "_bibtex": "@inproceedings{    \nanonymous2019total,    \ntitle={Total Style Transfer with a Single Feed-Forward Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJ4AFsRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkg1csA5Y7", "original": "SygP3lwFFX", "number": 496, "cdate": 1538087814602, "ddate": null, "tcdate": 1538087814602, "tmdate": 1538156156947, "tddate": null, "forum": "Hkg1csA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A fast quasi-Newton-type method for large-scale stochastic optimisation", "abstract": "During recent years there has been an increased interest in stochastic adaptations of limited memory quasi-Newton methods, which compared to pure gradient-based routines can improve the convergence by incorporating second order information. In this work we propose a direct least-squares approach conceptually similar to the limited memory quasi-Newton methods, but that computes the search direction in a slightly different way. This is achieved in a fast and numerically robust manner by maintaining a Cholesky factor of low dimension. This is combined with a stochastic line search relying upon fulfilment of the Wolfe condition in a backtracking manner, where the step length is adaptively modified with respect to the optimisation progress. We support our new algorithm by providing several theoretical results guaranteeing its performance. The performance is demonstrated on real-world benchmark problems which shows improved results in comparison with already established methods.", "keywords": ["optimisation", "large-scale", "stochastic"], "authorids": ["ICLR.cc/2019/Conference/Paper496/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7d1445801d8532955f393e2d065de27633f40da7.pdf", "paperhash": "anonymous|a_fast_quasinewtontype_method_for_largescale_stochastic_optimisation", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A fast quasi-Newton-type method for large-scale stochastic optimisation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkg1csA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygk9oA9Ym", "original": "BkxRDHo5tm", "number": 497, "cdate": 1538087814774, "ddate": null, "tcdate": 1538087814774, "tmdate": 1538156156737, "tddate": null, "forum": "rygk9oA9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "3D-RelNet: Joint Object and Relational Network for 3D Prediction", "abstract": "We propose an approach to predict the 3D shape and pose for the objects present in a scene. Existing learning based methods that pursue this goal make independent predictions per object, and do not leverage the relationships amongst them. We argue that reasoning about these relationships is crucial, and present an approach to incorporate these in a 3D prediction framework. In addition to independent per-object predictions, we predict pairwise relations in the form of relative 3D pose, and demonstrate that these can be easily incorporated to improve object level estimates. We report performance across different datasets (SUNCG, NYUv2), and show that our approach significantly improves over independent prediction approaches while also outperforming alternate implicit reasoning methods.", "keywords": ["3D Reconstruction", "3D Scene Understanding", "Relative Prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper497/Authors"], "authors": ["Anonymous"], "TL;DR": "We reason about relative spatial relationships between the objects in a scene to produce better 3D predictions", "pdf": "/pdf/70866ce8dbc0f28f596c70d7b0ea9c3c556f3683.pdf", "paperhash": "anonymous|3drelnet_joint_object_and_relational_network_for_3d_prediction", "_bibtex": "@inproceedings{    \nanonymous20193d-relnet:,    \ntitle={3D-RelNet: Joint Object and Relational Network for 3D Prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygk9oA9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1zk9iRqF7", "original": "BJeVxRbKFm", "number": 498, "cdate": 1538087814955, "ddate": null, "tcdate": 1538087814955, "tmdate": 1538156156533, "tddate": null, "forum": "S1zk9iRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["ICLR.cc/2019/Conference/Paper498/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e7b0c524efd14960bf4563219e564080769dddab.pdf", "paperhash": "anonymous|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{    \nanonymous2019pate-gan:,    \ntitle={PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1zk9iRqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkMk9j0qYm", "original": "rJx9p4qqKm", "number": 499, "cdate": 1538087815137, "ddate": null, "tcdate": 1538087815137, "tmdate": 1538156156333, "tddate": null, "forum": "rkMk9j0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Explainable Adversarial Learning: Implicit Generative Modeling of Random Noise during Training for Adversarial Robustness", "abstract": "We introduce Explainable Adversarial Learning, ExL, an approach for training neural networks that are intrinsically robust to adversarial attacks. We find that the implicit generative modeling of random noise with the same loss function used during posterior maximization, improves a model's understanding of the data manifold furthering adversarial robustness. We prove our approach's efficacy and provide a simplistic visualization tool for understanding adversarial data, using Principal Component Analysis. Our analysis reveals that adversarial robustness, in general, manifests in models with higher variance along the high-ranked principal components. We show that models learnt with our approach perform remarkably well against a wide-range of attacks. Furthermore, combining ExL with state-of-the-art adversarial training extends the robustness of a model, even beyond what it is adversarially trained for, in both white-box and black-box attack scenarios.", "keywords": ["Adversarial Robustness", "PCA variance", "PCA subspace", "Generative Noise Modeling", "Adversarial attack", "Adversarial Robustness Metric"], "authorids": ["ICLR.cc/2019/Conference/Paper499/Authors"], "authors": ["Anonymous"], "TL;DR": "Noise modeling at the input during discriminative training improves adversarial robustness. Propose PCA based evaluation metric for adversarial robustness", "pdf": "/pdf/592abe1818d0fbbb1252656299db843fae4b723d.pdf", "paperhash": "anonymous|explainable_adversarial_learning_implicit_generative_modeling_of_random_noise_during_training_for_adversarial_robustness", "_bibtex": "@inproceedings{    \nanonymous2019explainable,    \ntitle={Explainable Adversarial Learning: Implicit Generative Modeling of Random Noise during Training for Adversarial Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMk9j0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryEkcsActX", "original": "rJgcFEc5Ym", "number": 500, "cdate": 1538087815310, "ddate": null, "tcdate": 1538087815310, "tmdate": 1538156156131, "tddate": null, "forum": "ryEkcsActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Teacher Guided Architecture Search", "abstract": "Strong improvements in neural network performance in vision tasks have resulted from the search of alternative network architectures, and prior work has shown that this search process can be automated and guided by evaluating candidate network performance following limited training (\u201cPerformance Guided Architecture Search\u201d or PGAS).  However, because of the large architecture search spaces and the high computational cost associated with evaluating each candidate model, further gains in computational efficiency are needed.  Here we present a method termed Teacher Guided Search for Architectures by Generation and Evaluation (TG-SAGE) that produces up to an order of magnitude in search efficiency over PGAS methods. Specifically, TG-SAGE guides each step of the architecture search by evaluating the similarity of internal representations of the candidate networks with those of the (fixed) teacher network. We show that this procedure leads to significant reduction in required per-sample training and that, this advantage holds for two different search spaces of architectures, and two different search algorithms. We further show that in the space of convolutional cells for visual categorization, TG-SAGE finds a cell structure with similar performance as was previously found using other methods but at a total computational cost that is two orders of magnitude lower than Neural Architecture Search (NAS) and more than four times lower than progressive neural architecture search (PNAS). These results suggest that TG-SAGE can be used to accelerate network architecture search in cases where one has access to some or all of the internal representations of a teacher network of interest, such as the brain. ", "keywords": ["hyperparameter search", "architecture search", "convolutional neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper500/Authors"], "authors": ["Anonymous"], "TL;DR": "Faster architecture search by maximizing representational similarity with a teacher network", "pdf": "/pdf/29b26aa22e8d5749c7031b50ac222d53ded62128.pdf", "paperhash": "anonymous|teacher_guided_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019teacher,    \ntitle={Teacher Guided Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryEkcsActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1NJqsRctX", "original": "r1xr5ucqY7", "number": 501, "cdate": 1538087815485, "ddate": null, "tcdate": 1538087815485, "tmdate": 1538156155913, "tddate": null, "forum": "r1NJqsRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Auxiliary Variational MCMC", "abstract": "We introduce Auxiliary Variational MCMC, a novel framework for learning MCMC kernels that combines recent advances in variational inference with insights drawn from traditional auxiliary variable MCMC methods such as Hamiltonian Monte Carlo. Our framework exploits low dimensional structure in the target distribution in order to learn a more efficient MCMC sampler. The resulting sampler is able to suppress random walk behaviour and mix between modes efficiently, without the need to compute gradients of the target distribution. We test our sampler on a number of challenging distributions, where the underlying structure is known, and on the task of posterior sampling in Bayesian logistic regression. Code to reproduce all experiments is available at https://github.com/AVMCMC/AuxiliaryVariationalMCMC.\n", "keywords": ["MCMC", "Variational Inference"], "authorids": ["ICLR.cc/2019/Conference/Paper501/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a0964bc98c52ba6e1380724852330f7ff3bde2ee.pdf", "paperhash": "anonymous|auxiliary_variational_mcmc", "_bibtex": "@inproceedings{    \nanonymous2019auxiliary,    \ntitle={Auxiliary Variational MCMC},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1NJqsRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1excoAqKQ", "original": "BklvH219Y7", "number": 502, "cdate": 1538087815661, "ddate": null, "tcdate": 1538087815661, "tmdate": 1538156155707, "tddate": null, "forum": "B1excoAqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning", "abstract": "Learning to imitate expert actions given demonstrations containing image observations is a difficult problem in robotic control. The key challenge is generalizing behavior to out-of-distribution states that differ from those in the demonstrations. State-of-the-art imitation learning algorithms perform well in environments with low-dimensional observations, but typically involve adversarial optimization procedures, which can be difficult to use with high-dimensional image observations. We propose a remarkably simple alternative based on off-policy reinforcement learning, which rewards the agent for matching demonstrated actions in demonstrated states \u2014 the key idea is initially filling the agent's experience replay buffer with demonstrations where rewards are set to a positive constant, and setting rewards to zero in all additional experiences. We derive this RL algorithm from first principles as a method for performing approximate inference under the MaxCausalEnt model of expert behavior \u2014 the approximate inference objective trades off between a pure behavioral cloning loss and a regularization term that incorporates information about state transitions via the soft Bellman error. Our experiments show that this algorithm matches the state of the art in low-dimensional environments, and significantly outperforms prior work in playing video games from high-dimensional images.\n\n", "keywords": ["imitation learning", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper502/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a simple and effective imitation learning algorithm based on off-policy RL, which works well on image-based tasks and implicitly performs approximate inference of the expert policy.", "pdf": "/pdf/e7033535b35b3b4a51e1a6bf4544ef0da3626de0.pdf", "paperhash": "anonymous|what_would_pi_do_imitation_learning_via_offpolicy_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019what,    \ntitle={What Would pi* Do?: Imitation Learning via Off-Policy Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1excoAqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJleciCcKQ", "original": "rJeV5sO5tX", "number": 503, "cdate": 1538087815839, "ddate": null, "tcdate": 1538087815839, "tmdate": 1538156155502, "tddate": null, "forum": "BJleciCcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "EXPLORATION OF EFFICIENT ON-DEVICE ACOUSTIC MODELING WITH NEURAL NETWORKS", "abstract": "Real-time speech recognition on mobile and embedded devices is an important application of neural networks. Acoustic modeling is the fundamental part of speech recognition and is usually implemented with long short-term memory (LSTM)-based recurrent neural networks (RNNs). However, the single thread execution of an LSTM RNN is extremely slow in most embedded devices because the algorithm needs to fetch a large number of parameters from the DRAM for computing each output sample. We explore a few acoustic modeling algorithms that can be executed very efficiently on embedded devices. These algorithms reduce the overhead of memory accesses using multi-timestep parallelization that computes multiple output samples at a time by reading the parameters only once from the DRAM. The algorithms considered are the quasi RNNs (QRNNs), Gated ConvNets, and diagonalized LSTMs. In addition, we explore neural networks that equip one-dimensional (1-D) convolution at each layer of these algorithms, and by which can obtain a very large performance increase in the QRNNs and Gated ConvNets. The experiments were conducted using two tasks, one is the connectionist temporal classification (CTC)-based end-to-end speech recognition on WSJ corpus and the other is the phoneme classification on TIMIT dataset. We not only significantly increase the execution speed but also obtain a much higher accuracy, compared to LSTM RNN-based modeling. Thus, this work can be applicable not only to embedded system-based implementations but also to server-based ones.", "keywords": ["Parallelization", "Speech Recognition", "Sequence Modeling", "Recurrent Neural Network", "Embedded Systems"], "authorids": ["ICLR.cc/2019/Conference/Paper503/Authors"], "authors": ["Anonymous"], "TL;DR": "Multi-timestep parallelizable acoustic modeling with diagonal LSTM, QRNN and Gated ConvNet", "pdf": "/pdf/79318611dfb37810a1901ee539ac363e4e0907b1.pdf", "paperhash": "anonymous|exploration_of_efficient_ondevice_acoustic_modeling_with_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019exploration,    \ntitle={EXPLORATION OF EFFICIENT ON-DEVICE ACOUSTIC MODELING WITH NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJleciCcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyfg5o0qtm", "original": "SylvyZEwYQ", "number": 504, "cdate": 1538087816033, "ddate": null, "tcdate": 1538087816033, "tmdate": 1538156155300, "tddate": null, "forum": "Hyfg5o0qtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Temporal Gaussian Mixture Layer for Videos", "abstract": "We introduce a new convolutional layer named the Temporal Gaussian Mixture (TGM) layer and present how it can be used to efficiently capture longer-term temporal information in continuous activity videos. The TGM layer is a temporal convolutional layer governed by a much smaller set of parameters (e.g., location/variance of Gaussians) that are fully differentiable. We present our fully convolutional video models with multiple TGM layers for activity detection. The experiments on multiple datasets including Charades and MultiTHUMOS confirm the effectiveness of TGM layers, outperforming the state-of-the-arts.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper504/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1d2f20e33fe87fc3696a6cda7643b64ce022bae8.pdf", "paperhash": "anonymous|temporal_gaussian_mixture_layer_for_videos", "_bibtex": "@inproceedings{    \nanonymous2019temporal,    \ntitle={Temporal Gaussian Mixture Layer for Videos},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyfg5o0qtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1MxciCcKm", "original": "SygfH-Q5YQ", "number": 505, "cdate": 1538087816215, "ddate": null, "tcdate": 1538087816215, "tmdate": 1538156155086, "tddate": null, "forum": "r1MxciCcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Connecting the Dots Between MLE and RL for Sequence Generation", "abstract": "Sequence generation models such as recurrent networks can be trained with a diverse set of learning algorithms. For example, maximum likelihood learning is simple and efficient, yet suffers from the exposure bias problem. Reinforcement learning like policy gradient addresses the problem but can have prohibitively poor exploration efficiency. A variety of other algorithms such as RAML, SPG, and data noising, have also been developed in different perspectives. This paper establishes a formal connection between these algorithms. We present a generalized entropy regularized policy optimization formulation, and show that the apparently divergent algorithms can all be reformulated as special instances of the framework, with the only difference being the configurations of reward function and a couple of hyperparameters. The unified interpretation offers a systematic view of the varying properties of exploration and learning efficiency. Besides, based on the framework, we present a new algorithm that dynamically interpolates among the existing algorithms for improved learning. Experiments on machine translation and text summarization demonstrate the superiority of the proposed algorithm.", "keywords": ["sequence generation", "maximum likelihood learning", "reinforcement learning", "policy optimization", "text generation", "reward augmented maximum likelihood", "exposure bias"], "authorids": ["ICLR.cc/2019/Conference/Paper505/Authors"], "authors": ["Anonymous"], "TL;DR": "A unified perspective of various learning algorithms for sequence generation, such as MLE, RL, RAML, data noising, etc.", "pdf": "/pdf/928d871b2bd7fb68499895b3f53b11bbbe14a710.pdf", "paperhash": "anonymous|connecting_the_dots_between_mle_and_rl_for_sequence_generation", "_bibtex": "@inproceedings{    \nanonymous2019connecting,    \ntitle={Connecting the Dots Between MLE and RL for Sequence Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1MxciCcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S14g5s09tm", "original": "rJx21z4PYm", "number": 506, "cdate": 1538087816394, "ddate": null, "tcdate": 1538087816394, "tmdate": 1538156154883, "tddate": null, "forum": "S14g5s09tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unseen Action Recognition with Multimodal Learning", "abstract": " In this paper, we present a method to learn a joint multimodal representation space that allows for the recognition of unseen activities in videos. We compare the effect of placing various constraints on the embedding space using paired text and video data. Additionally, we propose a method to improve the joint embedding space using an adversarial formulation with unpaired text and video data. In addition to testing on publicly available datasets, we introduce a new, large-scale text/video dataset. We experimentally confirm that learning such shared embedding space benefits three difficult tasks (i) zero-shot activity classification, (ii) unsupervised activity discovery, and (iii) unseen activity captioning.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper506/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/302e6a27ceef395a72afd3271e0e9220cfbb3efe.pdf", "paperhash": "anonymous|unseen_action_recognition_with_multimodal_learning", "_bibtex": "@inproceedings{    \nanonymous2019unseen,    \ntitle={Unseen Action Recognition with Multimodal Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S14g5s09tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeZ5jC5YQ", "original": "Bye7vnZKYm", "number": 507, "cdate": 1538087816574, "ddate": null, "tcdate": 1538087816574, "tmdate": 1538156154673, "tddate": null, "forum": "ByeZ5jC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks", "abstract": "Feature selection is a pervasive problem. The discovery of relevant features can be as important for performing a particular task (such as to avoid overfitting in prediction) as it can be for understanding the underlying processes governing the true label (such as discovering relevant genetic factors for a disease). Machine learning driven feature selection can enable discovery from large, high-dimensional, non-linear observational datasets by creating a subset of features for experts to focus on. In order to use expert time most efficiently, we need a principled methodology capable of controlling the False Discovery Rate. In this work, we build on the promising Knockoff framework by developing a flexible knockoff generation model. We adapt the Generative Adversarial Networks framework to allow us to generate knockoffs with no assumptions on the feature distribution. Our model consists of 4 networks, a generator, a discriminator, a stability network and a power network. We demonstrate the capability of our model to perform feature selection, showing that it performs as well as the originally proposed knockoff generation model in the Gaussian setting and that it outperforms the original model in non-Gaussian settings, including on a real-world dataset.", "keywords": ["Knockoff model", "Feature selection", "False discovery rate control", "Generative Adversarial networks"], "authorids": ["ICLR.cc/2019/Conference/Paper507/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a970d4348a7fdc302fc2ad3041c38ee0b477ce60.pdf", "paperhash": "anonymous|knockoffgan_generating_knockoffs_for_feature_selection_using_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019knockoffgan:,    \ntitle={KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeZ5jC5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xWcj0qYm", "original": "Ske4LuTPFX", "number": 508, "cdate": 1538087816752, "ddate": null, "tcdate": 1538087816752, "tmdate": 1538156154469, "tddate": null, "forum": "B1xWcj0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data", "abstract": "Empirical risk minimization (ERM), with proper loss function and regularization, is the common practice of supervised classification. In this paper, we study training arbitrary (from linear to deep) binary classifier from only unlabeled (U) data by ERM. We prove that it is impossible to estimate the risk of an arbitrary binary classifier in an unbiased manner given a single set of U data, but it becomes possible given two sets of U data with different class priors. These two facts answer a fundamental question---what the minimal supervision is for training any binary classifier from only U data. Following these findings, we propose an ERM-based learning method from two sets of U data, and then prove it is consistent. Experiments demonstrate the proposed method could train deep models and outperform state-of-the-art methods for learning from two sets of U data.", "keywords": ["learning from only unlabeled data", "empirical risk minimization", "unbiased risk estimator"], "authorids": ["ICLR.cc/2019/Conference/Paper508/Authors"], "authors": ["Anonymous"], "TL;DR": "Three class priors are all you need to train deep models from only U data, while any two should not be enough.", "pdf": "/pdf/a6741aa791a42bbe7b8036b9f4b61a33c0a52083.pdf", "paperhash": "anonymous|on_the_minimal_supervision_for_training_any_binary_classifier_from_only_unlabeled_data", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Minimal Supervision for Training Any Binary Classifier from Only Unlabeled Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xWcj0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJfW5oA5KQ", "original": "H1xvmhCFtm", "number": 509, "cdate": 1538087816936, "ddate": null, "tcdate": 1538087816936, "tmdate": 1538156154265, "tddate": null, "forum": "rJfW5oA5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Approximability of Discriminators Implies Diversity in GANs", "abstract": "While Generative Adversarial Networks (GANs) have empirically produced impressive results on learning complex real-world distributions, recent works have shown that they suffer from lack of diversity or mode collapse. The theoretical work of Arora et al. (2017a) suggests a dilemma about GANs\u2019 statistical properties: powerful discriminators cause overfitting, whereas weak discriminators cannot detect mode collapse.\nBy contrast, we show in this paper that GANs can in principle learn distributions in Wasserstein distance (or KL-divergence in many cases) with polynomial sample complexity, if the discriminator class has strong distinguishing power against the particular generator class (instead of against all possible generators). For various generator classes such as mixture of Gaussians, exponential families, and invertible and injective neural networks generators, we design corresponding discriminators (which are often neural nets of specific architectures) such that the Integral Probability Metric (IPM) induced by the discriminators can provably approximate the Wasserstein distance and/or KL-divergence. This implies that if the training is successful, then the learned distribution is close to the true distribution in Wasserstein distance or KL divergence, and thus cannot drop modes. Our preliminary experiments show that on synthetic datasets the test IPM is well correlated with KL divergence or the Wasserstein distance, indicating that the lack of diversity in GANs may be caused by the sub-optimality in optimization instead of statistical inefficiency.", "keywords": ["Theory", "Generative adversarial networks", "Mode collapse", "Generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper509/Authors"], "authors": ["Anonymous"], "TL;DR": "GANs can in principle learn distributions sample-efficiently, if the discriminator class is compact and has strong distinguishing power against the particular generator class.", "pdf": "/pdf/1ab9adfd2d8cba77c273ffc168997cdceedb0f85.pdf", "paperhash": "anonymous|approximability_of_discriminators_implies_diversity_in_gans", "_bibtex": "@inproceedings{    \nanonymous2019approximability,    \ntitle={Approximability of Discriminators Implies Diversity in GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJfW5oA5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJfb5jCqKm", "original": "rkxtGsqqFX", "number": 510, "cdate": 1538087817118, "ddate": null, "tcdate": 1538087817118, "tmdate": 1538156154060, "tddate": null, "forum": "SJfb5jCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers", "abstract": "We consider the problem of uncertainty estimation in the context of (non-Bayesian) deep neural classification. In this context, all known methods are based on extracting uncertainty signals from a trained network optimized to solve the classification problem at hand. We demonstrate that such techniques tend to introduce biased estimates for instances whose predictions are supposed to be highly confident. We argue that this deficiency is an artifact of the dynamics of training with SGD-like optimizers, and it has some properties similar to overfitting. Based on this observation, we develop an uncertainty estimation algorithm that selectively estimates the uncertainty of highly confident points, using earlier snapshots of the trained model, before their estimates are jittered (and way before they are ready for actual classification). We present extensive experiments indicating that the proposed algorithm provides uncertainty estimates that are consistently better than all known methods.", "keywords": ["Uncertainty estimation", "Deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper510/Authors"], "authors": ["Anonymous"], "TL;DR": "We use snapshots from the training process to improve any uncertainty estimation method of a DNN classifier.", "pdf": "/pdf/8e1a5e2df732338df123f5de432ff4dfc9e4ccd9.pdf", "paperhash": "anonymous|biasreduced_uncertainty_estimation_for_deep_neural_classifiers", "_bibtex": "@inproceedings{    \nanonymous2019bias-reduced,    \ntitle={Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfb5jCqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1Nb5i05tX", "original": "BygSCBEqF7", "number": 511, "cdate": 1538087817295, "ddate": null, "tcdate": 1538087817295, "tmdate": 1538156153843, "tddate": null, "forum": "r1Nb5i05tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The effectiveness of layer-by-layer training using the information bottleneck principle", "abstract": "The recently proposed information bottleneck (IB) theory of deep nets suggests that during training, each layer attempts to maximize its mutual information (MI) with the target labels (so as to allow good prediction accuracy), while minimizing its MI with the input (leading to effective compression and thus good generalization). To date, evidence of this phenomenon has been indirect and aroused controversy due to theoretical and practical complications. In particular, it has been pointed out that the MI with the input is theoretically in\ufb01nite in many cases of interest, and that the MI with the target is fundamentally dif\ufb01cult to estimate in high dimensions. As a consequence, the validity of this theory has been questioned. In this paper, we overcome these obstacles by two means. First, as previously suggested, we replace the MI with the input by a noise-regularized version, which ensures it is \ufb01nite. As we show, this modi\ufb01ed penalty in fact acts as a form of weight decay regularization. Second, to obtain accurate (noise regularized) MI estimates between an intermediate representation and the input, we incorporate the strong prior-knowledge we have about their relation, into the recently proposed MI estimator of Belghazi et al. (2018). With this scheme, we are able to stably train each layer independently to explicitly optimize the IB functional. Surprisingly, this leads to enhanced prediction accuracy, thus directly validating the IB theory of deep nets for the \ufb01rst time.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper511/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cd16d24a97cdf99a42891e90fef94d552f63c38e.pdf", "paperhash": "anonymous|the_effectiveness_of_layerbylayer_training_using_the_information_bottleneck_principle", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The effectiveness of layer-by-layer training using the information bottleneck principle},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1Nb5i05tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1VZqjAcYX", "original": "S1lk-PFqKm", "number": 512, "cdate": 1538087817475, "ddate": null, "tcdate": 1538087817475, "tmdate": 1538156153637, "tddate": null, "forum": "B1VZqjAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY", "abstract": "Pruning large neural networks while maintaining the performance is often highly desirable due to the reduced space and time complexity. In existing methods, pruning is incorporated within an iterative optimization procedure with either heuristically designed pruning schedules or additional hyperparameters, undermining their utility. In this work, we present a new approach that prunes a given network once at initialization. Specifically, we introduce a saliency criterion based on connection sensitivity that identifies structurally important connections in the network for the given task even before training. This eliminates the need for both pretraining as well as the complex pruning schedule while making it robust to architecture variations. After pruning, the sparse network is trained in the standard way. Our method obtains extremely sparse networks with virtually the same accuracy as the reference network on image classification tasks and is broadly applicable to various architectures including convolutional, residual and recurrent networks. Unlike existing methods, our approach enables us to demonstrate that the retained connections are indeed relevant to the given task.", "keywords": ["neural network pruning", "connection sensitivity"], "authorids": ["ICLR.cc/2019/Conference/Paper512/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a new approach, SNIP, that is simple, versatile and interpretable; it prunes irrelevant connections for a given task at single-shot prior to training and is applicable to a variety of neural network models without modifications.", "pdf": "/pdf/3b4408062d47079caf01147df0e4321eb792f507.pdf", "paperhash": "anonymous|snip_singleshot_network_pruning_based_on_connection_sensitivity", "_bibtex": "@inproceedings{    \nanonymous2019snip:,    \ntitle={SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1VZqjAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklz9iAcKQ", "original": "SkgHFy_FFX", "number": 513, "cdate": 1538087817649, "ddate": null, "tcdate": 1538087817649, "tmdate": 1538156153432, "tddate": null, "forum": "rklz9iAcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Graph Infomax", "abstract": "We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs---both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to graph representation learning, DGI does not rely on random walks, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.", "keywords": ["Unsupervised Learning", "Graph Neural Networks", "Graph Convolutions", "Mutual Information", "Infomax", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper513/Authors"], "authors": ["Anonymous"], "TL;DR": "A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.", "pdf": "/pdf/c9952877baacc760327db2c015916351e0349f03.pdf", "paperhash": "anonymous|deep_graph_infomax", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Graph Infomax},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklz9iAcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xf9jAqFQ", "original": "r1l2o9i9tm", "number": 514, "cdate": 1538087817825, "ddate": null, "tcdate": 1538087817825, "tmdate": 1538156153219, "tddate": null, "forum": "B1xf9jAqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Speed Reading with Structural-Jump-LSTM", "abstract": "Recurrent neural networks (RNNs) can model natural language by sequentially ''reading'' input tokens and outputting a distributed representation of each token. Due to the sequential nature of RNNs, inference time is linearly dependent on the input length, and all inputs are read regardless of their importance. Efforts to speed up this inference, known as ''neural speed reading'', either ignore or skim over part of the input. We present Structural-Jump-LSTM: the first neural speed reading model to both skip and jump text during inference. The model consists of a standard LSTM and two agents: one capable of skipping single words when reading, and one capable of exploiting punctuation structure (sub-sentence separators (,:), sentence end symbols (.!?), or end of text markers) to jump ahead after reading a word.\nA comprehensive experimental evaluation of our model against all five state-of-the-art neural reading models shows that \nStructural-Jump-LSTM achieves the best overall floating point operations (FLOP) reduction (hence is faster), while keeping the same accuracy or even improving it compared to a vanilla LSTM that reads the whole text.", "keywords": ["natural language processing", "speed reading", "recurrent neural network", "classification"], "authorids": ["ICLR.cc/2019/Conference/Paper514/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new model for neural speed reading that utilizes the inherent punctuation structure of a text to define effective jumping and skipping behavior.", "pdf": "/pdf/f11a08a6a89bb0a73bd3b3f57ce23e9c2854ce77.pdf", "paperhash": "anonymous|neural_speed_reading_with_structuraljumplstm", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Speed Reading with Structural-Jump-LSTM},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xf9jAqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlMcjC5K7", "original": "SJlwr955Fm", "number": 515, "cdate": 1538087818012, "ddate": null, "tcdate": 1538087818012, "tmdate": 1538156152997, "tddate": null, "forum": "BJlMcjC5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Random Projections for Language Modelling", "abstract": "Neural network-based language models deal with data sparsity problems by mapping the large discrete space of words into a smaller continuous space of real-valued vectors. By learning distributed vector representations for words, each training sample informs the neural network model about a combinatorial number of other patterns. In this paper, we exploit the sparsity in natural language even further by encoding each unique input word using a fixed sparse random representation. \nThese sparse codes are then projected onto a smaller embedding space which allows for the encoding of word occurrences from a possibly unknown vocabulary, along with the creation of more compact language models using a reduced number of parameters. We investigate the properties of our encoding mechanism empirically, by evaluating its performance on the widely used Penn Treebank corpus. We show that guaranteeing approximately equidistant vector representations for unique discrete inputs is enough to provide the neural network model with enough information to learn --and make use-- of \ndistributed representations for these inputs.", "keywords": ["neural networks", "language modelling", "natural language processing", "uncertainty", "random projections"], "authorids": ["ICLR.cc/2019/Conference/Paper515/Authors"], "authors": ["Anonymous"], "TL;DR": "Neural language models can be trained with a compressed embedding space, by using sparse random projections, created incrementally for each unique discrete input.", "pdf": "/pdf/bb4315904dacbc8b01b2978d9bf8b11b8501bb4e.pdf", "paperhash": "anonymous|neural_random_projections_for_language_modelling", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Random Projections for Language Modelling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlMcjC5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxz5jRcFm", "original": "H1gsblK9Fm", "number": 516, "cdate": 1538087818192, "ddate": null, "tcdate": 1538087818192, "tmdate": 1538156152802, "tddate": null, "forum": "BJxz5jRcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Tangent-Normal Adversarial Regularization for Semi-supervised Learning", "abstract": "The ever-increasing size of modern datasets combined with the difficulty of obtaining label information has made semi-supervised learning of significant practical importance in modern machine learning applications. In comparison to supervised learning, the key difficulty in semi-supervised learning is how to make full use of the unlabeled data. In order to utilize manifold information provided by unlabeled data, we propose a novel regularization called the tangent-normal adversarial regularization, which is composed by two parts. The two parts complement with each other and jointly enforce the smoothness along two different directions that are crucial for semi-supervised learning. One is applied along the tangent space of the data manifold, aiming to enforce local invariance of the classifier on the manifold, while the other is performed on the normal space orthogonal to the tangent space, intending to impose robustness on the classifier against the noise causing the observed data deviating from the underlying data manifold.  Both of the two regularizers are achieved by the strategy of virtual adversarial training. Our method has achieved state-of-the-art performance on semi-supervised learning tasks on both artificial dataset and practical datasets.", "keywords": ["semi-supervised learning", "manifold regularization", "adversarial training"], "authorids": ["ICLR.cc/2019/Conference/Paper516/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel manifold regularization strategy based on adversarial training, which can significantly improve the performance of semi-supervised learning.", "pdf": "/pdf/5bec4b35de99569885d09aaa34b96dbdb03f85f7.pdf", "paperhash": "anonymous|tangentnormal_adversarial_regularization_for_semisupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019tangent-normal,    \ntitle={Tangent-Normal Adversarial Regularization for Semi-supervised Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxz5jRcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryzfcoR5YQ", "original": "SkxO5iocYX", "number": 517, "cdate": 1538087818374, "ddate": null, "tcdate": 1538087818374, "tmdate": 1538156152591, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["ICLR.cc/2019/Conference/Paper517/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "anonymous|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@inproceedings{    \nanonymous2019layerwise,    \ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryzfcoR5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gQ5sRcFm", "original": "BJgvymrYYX", "number": 518, "cdate": 1538087818556, "ddate": null, "tcdate": 1538087818556, "tmdate": 1538156152381, "tddate": null, "forum": "S1gQ5sRcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Consistent Jumpy Predictions for Videos and Scenes", "abstract": "Stochastic video prediction models take in a sequence of image frames, and generate a sequence of consecutive future image frames. These models typically generate future frames in an autoregressive fashion, which is slow and requires the input and output frames to be consecutive. We introduce a model that overcomes these drawbacks by generating a latent representation from an arbitrary set of frames that can then be used to simultaneously and efficiently sample temporally consistent frames at arbitrary time-points. For example, our model can \"jump\" and directly sample frames at the end of the video, without sampling intermediate frames. Synthetic video evaluations confirm substantial gains in speed and functionality without loss in fidelity. We also apply our framework to a 3D scene reconstruction dataset. Here, our model is conditioned on camera location and can sample consistent sets of images for what an occluded region of a 3D scene might look like, even if there are multiple possibilities for what that region might contain. Reconstructions and videos are available at https://bit.ly/2O4Pc4R.\n", "keywords": ["jumpy predictions", "generative models", "scene reconstruction", "video prediction", "variational auto-encoders", "DRAW"], "authorids": ["ICLR.cc/2019/Conference/Paper518/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a model for consistent 3D reconstruction and jumpy video prediction e.g. producing image frames multiple time-steps in the future without generating intermediate frames.", "pdf": "/pdf/8b65a975d2b070cf9d36a985b581d667e40d2b52.pdf", "paperhash": "anonymous|consistent_jumpy_predictions_for_videos_and_scenes", "_bibtex": "@inproceedings{    \nanonymous2019consistent,    \ntitle={Consistent Jumpy Predictions for Videos and Scenes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gQ5sRcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sye7qoC5FQ", "original": "Ske4c2m5KX", "number": 519, "cdate": 1538087818749, "ddate": null, "tcdate": 1538087818749, "tmdate": 1538156152172, "tddate": null, "forum": "Sye7qoC5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Attacks on Node Embeddings", "abstract": "The goal of network representation learning is to learn low-dimensional node embeddings that capture the graph structure and are useful for solving downstream tasks. However, despite the proliferation of such methods there is currently no study of their robustness to adversarial attacks. We provide the first adversarial vulnerability analysis on the widely used family of methods based on random walks. We derive efficient adversarial perturbations that poison the network structure and have a negative effect on both the quality of the embeddings and the downstream tasks. We further show that our attacks are transferable since they generalize to many models, and are successful even when the attacker is restricted.", "keywords": ["node embeddings", "adversarial attacks"], "authorids": ["ICLR.cc/2019/Conference/Paper519/Authors"], "authors": ["Anonymous"], "TL;DR": "Adversarial attacks on unsupervised node embeddings based on eigenvalue perturbation theory.", "pdf": "/pdf/40190549f34975ee8fb538e76ef879390c40bbf3.pdf", "paperhash": "anonymous|adversarial_attacks_on_node_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Attacks on Node Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sye7qoC5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MX5j0cFX", "original": "S1xjnsocYQ", "number": 520, "cdate": 1538087818942, "ddate": null, "tcdate": 1538087818942, "tmdate": 1538156151972, "tddate": null, "forum": "B1MX5j0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["ICLR.cc/2019/Conference/Paper520/Authors"], "authors": ["Anonymous"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/f1472170b6782e95df80efd70a4d77004303fe03.pdf", "paperhash": "anonymous|universal_attacks_on_equivariant_networks", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Attacks on Equivariant Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MX5j0cFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryMQ5sRqYX", "original": "Bkxie5uYKX", "number": 521, "cdate": 1538087819131, "ddate": null, "tcdate": 1538087819131, "tmdate": 1538156151765, "tddate": null, "forum": "ryMQ5sRqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Finding Mixed Nash Equilibria of Generative Adversarial Networks", "abstract": "We reconsider the training objective of Generative Adversarial Networks (GANs) from the mixed Nash Equilibria (NE) perspective. Inspired by the classical prox methods, we develop a novel algorithmic framework for GANs via an infinite-dimensional two-player game and prove rigorous convergence rates to the mixed NE, resolving the longstanding problem that no provably convergent algorithm exists for general GANs. We then propose a principled procedure to reduce our novel prox methods to simple sampling routines, leading to practically efficient algorithms. Finally, we provide experimental evidence that our approach outperforms methods that seek pure strategy equilibria, such as SGD, Adam, and RMSProp, both in speed and quality.", "keywords": ["GANs", "mixed Nash equilibrium", "mirror descent", "sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper521/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8976a9628cd63d4f3ece0447e8e882b9f0ff2638.pdf", "paperhash": "anonymous|finding_mixed_nash_equilibria_of_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019finding,    \ntitle={Finding Mixed Nash Equilibria of Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryMQ5sRqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkemqsC9Fm", "original": "B1lMqa0YK7", "number": 522, "cdate": 1538087819308, "ddate": null, "tcdate": 1538087819308, "tmdate": 1538156151556, "tddate": null, "forum": "rkemqsC9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Information Theoretic lower bounds on negative log likelihood", "abstract": "In this article we use rate-distortion theory, a branch of information theory devoted to the problem of lossy compression, to shed light on an important problem in latent variable modeling of data: is there room to improve the model? One way to address this question is to find an upper bound on the probability (equivalently a lower bound on the negative log likelihood) that the model can assign to some data as one varies the prior and/or the likelihood function in a latent variable model. The core of our contribution is to formally show that the problem of optimizing priors in latent variable models is exactly an instance of the variational optimization problem that information theorists solve when computing rate-distortion functions, and then to use this to derive a lower bound on negative log likelihood. Moreover, we will show that if changing the prior can improve the log likelihood, then there is a way to change the likelihood function instead and attain the same log likelihood, and thus rate-distortion theory is of relevance to both optimizing priors as well as optimizing likelihood functions. We will experimentally argue for the usefulness of quantities derived from rate-distortion theory in latent variable modeling by applying them to a problem in image modeling.", "keywords": ["latent variable modeling", "rate-distortion theory", "log likelihood bounds"], "authorids": ["ICLR.cc/2019/Conference/Paper522/Authors"], "authors": ["Anonymous"], "TL;DR": "Use rate-distortion theory to bound how much a latent variable model can be improved", "pdf": "/pdf/c967ba5a1f2293b66ddee7de3daad8d94a5ec056.pdf", "paperhash": "anonymous|information_theoretic_lower_bounds_on_negative_log_likelihood", "_bibtex": "@inproceedings{    \nanonymous2019information,    \ntitle={Information Theoretic lower bounds on negative log likelihood},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkemqsC9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xmqiAqFm", "original": "rklknVc5KX", "number": 523, "cdate": 1538087819488, "ddate": null, "tcdate": 1538087819488, "tmdate": 1538156151349, "tddate": null, "forum": "H1xmqiAqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Investigating CNNs' Learning Representation under label noise", "abstract": "Deep convolutional neural networks (CNNs) are known to be robust against label noise on extensive datasets. However, at the same time, CNNs are capable of memorizing all labels even if they are random, which means they can memorize corrupted labels. Are CNNs robust or fragile to label noise? Much of researches focusing on such memorization uses class-irrelevant label noise to simulate label corruption, but this setting is simple and unrealistic. In this paper, we investigate the behavior of CNNs under realistically simulated label noise, which is generated based on the conceptual distance between classes of a large dataset (i.e., ImageNet-1k). Contrary to previous knowledge, we reveal CNNs are more robust to such realistic label noise than class-irrelevant label noise. We also demonstrate the networks under realistic noise situations learn similar representation to the no noise situation, compared to class-independent noise situations.", "keywords": ["learning with noisy labels", "deep learning", "convolutional neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper523/Authors"], "authors": ["Anonymous"], "TL;DR": "Are CNNs robust or fragile to label noise? Practically, robust.", "pdf": "/pdf/05e834630ada759fc109d33e36c7de22271aa8db.pdf", "paperhash": "anonymous|investigating_cnns_learning_representation_under_label_noise", "_bibtex": "@inproceedings{    \nanonymous2019investigating,    \ntitle={Investigating CNNs' Learning Representation under label noise},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xmqiAqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gEqiC9FX", "original": "SJxL_CYqKm", "number": 524, "cdate": 1538087819730, "ddate": null, "tcdate": 1538087819730, "tmdate": 1538156151135, "tddate": null, "forum": "r1gEqiC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Equi-normalization of Neural Networks", "abstract": "Modern neural networks are over-parametrized. In particular, each rectified linear hidden unit can be modified by a multiplicative factor by adjusting input and out- put weights, without changing the rest of the network. Inspired by the Sinkhorn-Knopp algorithm, we introduce a fast iterative method for minimizing the l2 norm of the weights, equivalently the weight decay regularizer. It provably converges to a unique solution. Interleaving our algorithm with SGD during training improves the test accuracy. For small batches, our approach offers an alternative to batch- and group- normalization on CIFAR-10 and ImageNet with a ResNet-18.", "keywords": ["convolutional neural networks", "Normalization", "Sinkhorn", "Regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper524/Authors"], "authors": ["Anonymous"], "TL;DR": "Fast iterative algorithm to balance the energy of a network while staying in the same functional equivalence class", "pdf": "/pdf/02ad65adbfe9d575f98662afd93fcaf54a4e9afb.pdf", "paperhash": "anonymous|equinormalization_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019equi-normalization,    \ntitle={Equi-normalization of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gEqiC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygNqoR9tm", "original": "H1gjFHlqt7", "number": 525, "cdate": 1538087819901, "ddate": null, "tcdate": 1538087819901, "tmdate": 1538156150908, "tddate": null, "forum": "BygNqoR9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sinkhorn AutoEncoders", "abstract": "Optimal Transport offers an alternative to maximum likelihood for learning generative autoencoding models. We show how this principle dictates the minimization of the Wasserstein distance between the encoder aggregated posterior and the prior, plus a reconstruction error. We prove that in the non-parametric limit the autoencoder generates the data distribution if and only if the two distributions match exactly, and that the optimum can be obtained by deterministic autoencoders.\nWe then introduce the Sinkhorn AutoEncoder (SAE), which casts the problem into Optimal Transport on the latent space. The resulting Wasserstein distance is minimized by backpropagating through the Sinkhorn algorithm. \nSAE models the aggregated posterior as an implicit distribution and therefore does not need a reparameterization trick for gradients estimation. Moreover, it requires virtually no adaptation to different prior distributions. We demonstrate its flexibility by considering models with hyperspherical and Dirichlet priors, as well as a simple case of probabilistic programming. SAE matches or outperforms other autoencoding models in visual quality and FID scores. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper525/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0f6bc30f7294a83bb92e87c2cc917d9424b19ccf.pdf", "paperhash": "anonymous|sinkhorn_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019sinkhorn,    \ntitle={Sinkhorn AutoEncoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygNqoR9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJeEqiC5KQ", "original": "S1ermRS9FX", "number": 526, "cdate": 1538087820096, "ddate": null, "tcdate": 1538087820096, "tmdate": 1538156150699, "tddate": null, "forum": "rJeEqiC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT", "abstract": "Context Aware Advertisement (CAA) is a type of advertisement\nappearing on websites or mobile apps. The advertisement is targeted\non specific group of users and/or the content displayed on the\nwebsites or apps. This paper focuses on classifying images displayed\non the websites by incremental learning classifier with Deep\nConvolutional Neural Network (DCNN) especially for Context Aware\nAdvertisement (CAA) framework. Incrementally learning new knowledge\nwith DCNN leads to catastrophic forgetting as previously stored\ninformation is replaced with new information. To prevent\ncatastrophic forgetting, part of previously learned knowledge should\nbe stored for the life time of incremental classifier. Storing\ninformation for life time involves privacy and legal concerns\nespecially in context aware advertising framework. Here, we propose\nan incremental classifier learning method which addresses privacy\nand legal concerns while taking care of catastrophic forgetting\nproblem. We conduct experiments on different datasets including\nCIFAR-100. Experimental results show that proposed system achieves\nrelatively high performance compared to the state-of-the-art\nincremental learning methods.", "keywords": ["Incremental learning", "deep learning", "autoencoder", "privacy", "convolutional neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper526/Authors"], "authors": ["Anonymous"], "TL;DR": "Human brain inspired incremental learning system", "pdf": "/pdf/de32809720997cc7dbd94749cc66085c1f425415.pdf", "paperhash": "anonymous|on_the_use_of_convolutional_autoencoder_for_incremental_classifier_learning_in_context_aware_advertisement", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJeEqiC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xN5oA5tm", "original": "rJgcj98tFX", "number": 527, "cdate": 1538087820280, "ddate": null, "tcdate": 1538087820280, "tmdate": 1538156150489, "tddate": null, "forum": "r1xN5oA5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Phrase-Based Attentions", "abstract": "Most state-of-the-art neural machine translation systems, despite being different\nin architectural skeletons (e.g., recurrence, convolutional), share an indispensable\nfeature: the Attention. However, most existing attention methods are token-based\nand ignore the importance of phrasal alignments, the key ingredient for the success\nof phrase-based statistical machine translation. In this paper, we propose\nnovel phrase-based attention methods to model n-grams of tokens as attention\nentities. We incorporate our phrase-based attentions into the recently proposed\nTransformer network, and demonstrate that our approach yields improvements of\n1.3 BLEU for English-to-German and 0.5 BLEU for German-to-English translation\ntasks on WMT newstest2014 using WMT\u201916 training data.", "keywords": ["neural machine translation", "natural language processing", "attention", "transformer", "seq2seq", "phrase-based", "phrase", "n-gram"], "authorids": ["ICLR.cc/2019/Conference/Paper527/Authors"], "authors": ["Anonymous"], "TL;DR": "Phrase-based attention mechanisms to assign attention on phrases, achieving token-to-phrase, phrase-to-token, phrase-to-phrase attention alignments, in addition to existing token-to-token attentions.", "pdf": "/pdf/fe5a54625a68bea60bfd11136ef36668fb240546.pdf", "paperhash": "anonymous|phrasebased_attentions", "_bibtex": "@inproceedings{    \nanonymous2019phrase-based,    \ntitle={Phrase-Based Attentions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xN5oA5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gVqsA9tQ", "original": "B1lyHutqt7", "number": 528, "cdate": 1538087820455, "ddate": null, "tcdate": 1538087820455, "tmdate": 1538156150197, "tddate": null, "forum": "r1gVqsA9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ChainGAN: A sequential approach to GANs", "abstract": "We propose a new architecture and training methodology for generative adversarial networks. Current approaches attempt to learn the transformation from a noise sample to a generated data sample in one shot. Our proposed generator architecture, called ChainGAN, uses a two-step process. It first attempts to transform a noise vector into a crude sample, similar to a traditional generator. Next, a chain of networks, called editors, attempt to sequentially enhance this sample. We train each of these units independently, instead of with end-to-end backpropagation on the entire chain. Our model is robust, efficient, and flexible as we can apply it to various network architectures. We provide rationale for our choices and experimentally evaluate our model, achieving competitive results on several datasets.", "keywords": ["Machine Learning", "Sequential Models", "GANs"], "authorids": ["ICLR.cc/2019/Conference/Paper528/Authors"], "authors": ["Anonymous"], "TL;DR": "Multistep generation process for GANs", "pdf": "/pdf/4e3ae95216a1bf315e3be4c48796e5cd69abc7f2.pdf", "paperhash": "anonymous|chaingan_a_sequential_approach_to_gans", "_bibtex": "@inproceedings{    \nanonymous2019chaingan:,    \ntitle={ChainGAN: A sequential approach to GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gVqsA9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sklr9i09KQ", "original": "HylrJps5YQ", "number": 529, "cdate": 1538087820632, "ddate": null, "tcdate": 1538087820632, "tmdate": 1538156149986, "tddate": null, "forum": "Sklr9i09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Networks for Modeling Source Code Edits", "abstract": "Programming languages are emerging as a challenging and interesting domain for machine learning. A core task, which has received significant attention in recent years, is building generative models of source code. However, to our knowledge, previous generative models have always been framed in terms of generating static snapshots of code. In this work, we instead treat source code as a dynamic object and tackle the problem of modeling the edits that software developers make to source code files. This requires extracting intent from previous edits and leveraging it to generate subsequent edits. We develop several neural networks and use synthetic data to test their ability to learn challenging edit patterns that require strong generalization. We then collect and train our models on a large-scale dataset consisting of millions of fine-grained edits from thousands of Python developers.", "keywords": ["Neural Networks", "Program Synthesis", "Source Code Modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper529/Authors"], "authors": ["Anonymous"], "TL;DR": "Neural networks for source code that model changes being made to the code-base rather than static snapshots of code.", "pdf": "/pdf/bb53d0af3107475fe2e9e83b58f9c39b59d6f344.pdf", "paperhash": "anonymous|neural_networks_for_modeling_source_code_edits", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Networks for Modeling Source Code Edits},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sklr9i09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyeBqsRctm", "original": "BJgsETi9t7", "number": 530, "cdate": 1538087820814, "ddate": null, "tcdate": 1538087820814, "tmdate": 1538156149775, "tddate": null, "forum": "SyeBqsRctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Step-wise Sensitivity Analysis: Identifying Partially Distributed Representations for Interpretable Deep Learning", "abstract": " In this paper, we introduce a novel method, called step-wise sensitivity analysis, which makes three contributions towards increasing the interpretability of Deep Neural Networks (DNNs). First, we are the first to suggest a methodology that aggregates results across input stimuli to gain model-centric results. Second, we linearly approximate the neuron activation and propose to use the outlier weights to identify distributed code. Third, our method constructs a dependency graph of the relevant neurons across the network to gain fine-grained understanding of the nature and interactions of DNN's internal features. The dependency graph illustrates shared subgraphs that generalise across 10 classes and can be clustered into semantically related groups. This is the first step towards building decision trees as an interpretation of learned representations.", "keywords": ["Interpretability", "Interpretable Deep Learning", "XAI", "dependency graph", "sensitivity analysis", "outlier detection", "instance-specific", "model-centric"], "authorids": ["ICLR.cc/2019/Conference/Paper530/Authors"], "authors": ["Anonymous"], "TL;DR": "We find dependency graphs between learned representations as a first step towards building decision trees to interpret the representation manifold.", "pdf": "/pdf/ba387065b9e05da99fe9e68338a91c0bdea44438.pdf", "paperhash": "anonymous|stepwise_sensitivity_analysis_identifying_partially_distributed_representations_for_interpretable_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019step-wise,    \ntitle={Step-wise Sensitivity Analysis: Identifying Partially Distributed Representations for Interpretable Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyeBqsRctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MB5oRqtQ", "original": "ByxzojoqKm", "number": 531, "cdate": 1538087820993, "ddate": null, "tcdate": 1538087820993, "tmdate": 1538156149565, "tddate": null, "forum": "B1MB5oRqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On-Policy Trust Region Policy Optimisation with Replay Buffers", "abstract": "Building upon the recent success of deep reinforcement learning methods, we investigate the possibility of on-policy reinforcement learning improvement by reusing the data from several consecutive policies. On-policy methods bring many benefits, such as ability to evaluate each resulting policy. However, they usually discard all the information about the policies which existed before. In this work, we propose adaptation of the replay buffer concept, borrowed from the off-policy learning setting, to the on-policy algorithms. To achieve this, the proposed algorithm generalises the Q-, value and advantage functions for data from multiple policies. The method uses trust region optimisation, while avoiding some of the common problems of the algorithms such as TRPO or ACKTR: it uses hyperparameters to replace the trust region selection heuristics, as well as  the trainable covariance matrix instead of the fixed one. In many cases, the method not only improves the results comparing to the state-of-the-art trust region on-policy learning algorithms such as ACKTR and TRPO, but also with respect to their off-policy counterpart DDPG.  ", "keywords": ["reinforcement learning", "on-policy learning", "trust region policy optimisation", "replay buffer"], "authorids": ["ICLR.cc/2019/Conference/Paper531/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate the theoretical and practical evidence of on-policy reinforcement learning improvement by reusing the data from several consecutive policies.", "pdf": "/pdf/3ebaa0ea32ee3bfb998b9af988db0bd25575b376.pdf", "paperhash": "anonymous|onpolicy_trust_region_policy_optimisation_with_replay_buffers", "_bibtex": "@inproceedings{    \nanonymous2019on-policy,    \ntitle={On-Policy Trust Region Policy Optimisation with Replay Buffers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MB5oRqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1GB5jA5tm", "original": "Hygzzyo5Y7", "number": 532, "cdate": 1538087821184, "ddate": null, "tcdate": 1538087821184, "tmdate": 1538156149360, "tddate": null, "forum": "r1GB5jA5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Sampling for Active Learning", "abstract": "This paper proposes ASAL, a new pool based active learning method that generates high entropy samples. Instead of directly annotating the synthetic samples, ASAL searches similar samples from the pool and includes them for training. Hence, the quality of new samples is high and annotations are reliable.  ASAL is particularly suitable for large data sets because it achieves a better run-time complexity (sub-linear) for sample selection than traditional uncertainty sampling (linear). We present a comprehensive set of experiments on two data sets and show that ASAL outperforms similar methods and clearly exceeds the established baseline (random sampling).  In the discussion section we analyze in which situations ASAL performs best and why it is sometimes hard to outperform random sample selection. To the best of our knowledge this is the first adversarial active learning technique that is applied for multiple class problems using deep convolutional classifiers and demonstrates superior performance than random sample selection.", "keywords": ["active learning", "adversarial training", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper532/Authors"], "authors": ["Anonymous"], "TL;DR": "ASAL is a pool based active learning method that generates high entropy samples and retrieves matching samples from the pool in sub-linear time.", "pdf": "/pdf/756135c11785a835cc807ba69bf6cdc301a9a196.pdf", "paperhash": "anonymous|adversarial_sampling_for_active_learning", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Sampling for Active Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GB5jA5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxB5sRcFQ", "original": "H1xdAnEXKX", "number": 533, "cdate": 1538087821370, "ddate": null, "tcdate": 1538087821370, "tmdate": 1538156149153, "tddate": null, "forum": "HJxB5sRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LayoutGAN: Generating Graphic Layouts with Wireframe Discriminator", "abstract": "Layouts are important for graphic design and scene generation. We propose a novel generative adversarial network, named as LayoutGAN, that synthesizes graphic layouts by modeling semantic and geometric relations of 2D elements. The generator of LayoutGAN takes as input a set of randomly placed 2D graphic elements and uses self-attention modules to refine their semantic and geometric parameters jointly to produce a meaningful layout. Accurate alignment is critical for good layouts. We thus propose a novel differentiable wireframe rendering layer that maps the generated layout to a wireframe image, upon which a CNN-based discriminator is used to optimize the layouts in visual domain. We validate the effectiveness of LayoutGAN in various experiments including MNIST digit generation, document layout generation, clipart abstract scene generation and tangram graphic design.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper533/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e9e3fd96ed745493c87446c9a5f87dccd41757a6.pdf", "paperhash": "anonymous|layoutgan_generating_graphic_layouts_with_wireframe_discriminator", "_bibtex": "@inproceedings{    \nanonymous2019layoutgan:,    \ntitle={LayoutGAN: Generating Graphic Layouts with Wireframe Discriminator},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxB5sRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylIcj0qFQ", "original": "S1xdjgqqK7", "number": 534, "cdate": 1538087821558, "ddate": null, "tcdate": 1538087821558, "tmdate": 1538156148947, "tddate": null, "forum": "HylIcj0qFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Capacity of Deep Neural Networks under Parameter Quantization", "abstract": "Most deep neural networks (DNNs) require complex models to achieve high performance. Parameter quantization is widely used for reducing the implementation complexities. Previous studies on quantization were mostly based on extensive simulation using training data. We choose a different approach and attempt to measure the per-parameter capacity of DNN models and interpret the results to obtain insights on optimum quantization of parameters. This research uses artificially generated data and generic forms of fully connected DNNs, convolutional neural networks, and recurrent neural networks. We conduct memorization and classification tests to study the effects of the number and precision of the parameters on the performance. The model and the per-parameter capacities are assessed by measuring the mutual information between the input and the classified output. We also extend the memorization capacity measurement results to image classification and language modeling tasks. To get insight for parameter quantization when performing real tasks, the training and test performances are compared.", "keywords": ["quantization", "network capacity", "hardware implementation", "network compression"], "authorids": ["ICLR.cc/2019/Conference/Paper534/Authors"], "authors": ["Anonymous"], "TL;DR": "We suggest the sufficient number of bits for representing weights of DNNs and the optimum bits are conservative when solving real problems.", "pdf": "/pdf/fc2db9ff2711eadf8800592969fa458c825749c6.pdf", "paperhash": "anonymous|capacity_of_deep_neural_networks_under_parameter_quantization", "_bibtex": "@inproceedings{    \nanonymous2019capacity,    \ntitle={Capacity of Deep Neural Networks under Parameter Quantization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylIcj0qFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylIciRcYQ", "original": "SJxOkROqF7", "number": 535, "cdate": 1538087821746, "ddate": null, "tcdate": 1538087821746, "tmdate": 1538156148737, "tddate": null, "forum": "BylIciRcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SGD Converges to Global Minimum in Deep Learning via Star-convex Path", "abstract": "Stochastic gradient descent (SGD) has been found to be surprisingly effective in training a variety of deep neural networks. However, there is still a lack of understanding on how and why SGD can train these complex networks towards a global minimum. In this study, we establish the convergence of SGD to a global minimum for nonconvex optimization problems that are commonly encountered in neural network training. Our argument exploits the following two important properties: 1) the training loss can achieve zero value (approximately), which has been widely observed in deep learning; 2) SGD follows a star-convex path, which is verified by various experiments in this paper.  In such a context, our analysis shows that SGD, although has long been considered as a randomized algorithm, converges in an intrinsically deterministic manner to a global minimum. ", "keywords": ["SGD", "deep learning", "global minimum", "convergence"], "authorids": ["ICLR.cc/2019/Conference/Paper535/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/45efbaf748ed0755b1cbf8d8c15c4f7b1e2ca49f.pdf", "paperhash": "anonymous|sgd_converges_to_global_minimum_in_deep_learning_via_starconvex_path", "_bibtex": "@inproceedings{    \nanonymous2019sgd,    \ntitle={SGD Converges to Global Minimum in Deep Learning via Star-convex Path},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylIciRcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkeU5j0ctQ", "original": "BkxVbkAvK7", "number": 536, "cdate": 1538087821936, "ddate": null, "tcdate": 1538087821936, "tmdate": 1538156148528, "tddate": null, "forum": "BkeU5j0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CEM-RL: Combining evolutionary and gradient-based methods for policy search", "abstract": "Deep neuroevolution and deep reinforcement learning (deep RL) algorithms are two popular approaches to policy search. The former is widely applicable and rather stable, but suffers from low sample efficiency. By contrast, the latter is more sample efficient, but the most sample efficient variants are also rather unstable and highly sensitive to hyper-parameter setting. \nSo far, these families of methods have mostly been compared as competing tools. However, an emerging approach consists in combining them so as to get the best of both worlds. Two previously existing combinations use either a standard evolutionary algorithm or a goal exploration process together with the DDPG algorithm, a sample efficient off-policy deep RL algorithm.\nIn this paper, we propose a different combination scheme using the simple cross-entropy method (CEM) and TD3, another off-policy deep RL algorithm which improves over DDPG.\nWe evaluate the resulting algorithm, CEMRL, on a set of benchmarks classically used in deep RL. We show that \\cemrl benefits from several advantages over its competitors and offers a satisfactory trade-off between performance and sample efficiency.", "keywords": ["evolution strategy", "deep reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper536/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new combination of evolution strategy and deep reinforcement learning which takes the best of both worlds", "pdf": "/pdf/bc4d59ef0ca7885c9d5a2769ddc6f461fd072769.pdf", "paperhash": "anonymous|cemrl_combining_evolutionary_and_gradientbased_methods_for_policy_search", "_bibtex": "@inproceedings{    \nanonymous2019cem-rl:,    \ntitle={CEM-RL: Combining evolutionary and gradient-based methods for policy search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeU5j0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkl85oRqYX", "original": "HJeFwQ-5KQ", "number": 537, "cdate": 1538087822136, "ddate": null, "tcdate": 1538087822136, "tmdate": 1538156148319, "tddate": null, "forum": "rkl85oRqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploiting Invariant Structures for Compression in Neural Networks", "abstract": "Modern neural networks often require deep compositions of high-dimensional nonlinear functions (wide architecture) to achieve high test accuracy, and thus can have overwhelming number of parameters. Repeated high cost in prediction at test-time makes neural networks ill-suited for devices with constrained memory or computational power. We introduce an efficient mechanism, reshaped tensor decomposition, to compress neural networks by exploiting three types of invariant structures: periodicity, modulation and low rank. Our reshaped tensor decomposition method exploits such invariance structures using a technique called tensorization (reshaping the layers into higher-order tensors) combined with higher order tensor decompositions on top of the tensorized layers. Our compression method improves low rank approximation methods and can be incorporated to (is complementary to) most of the existing compression methods for neural networks to achieve better compression. Experiments on LeNet-5 (MNIST), ResNet-32 (CI- FAR10) and ResNet-50 (ImageNet) demonstrate that our reshaped tensor decomposition outperforms (5% test accuracy improvement universally on CIFAR10) the state-of-the-art low-rank approximation techniques under same compression rate, besides achieving orders of magnitude faster convergence rates.", "keywords": ["Neural Network Compression", "Low Rank Approximation", "Higher Order Tensor Decomposition"], "authorids": ["ICLR.cc/2019/Conference/Paper537/Authors"], "authors": ["Anonymous"], "TL;DR": "Compression of neural networks which improves the state-of-the-art low rank approximation techniques and is complementary to most of other compression techniques. ", "pdf": "/pdf/eaea084a6c8a756ac920494b10dd31a7077a4f07.pdf", "paperhash": "anonymous|exploiting_invariant_structures_for_compression_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019exploiting,    \ntitle={Exploiting Invariant Structures for Compression in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl85oRqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJzLciCqKm", "original": "HylVJKz5K7", "number": 538, "cdate": 1538087822323, "ddate": null, "tcdate": 1538087822323, "tmdate": 1538156148105, "tddate": null, "forum": "rJzLciCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning from Positive and Unlabeled Data with a Selection Bias", "abstract": "We consider the problem of learning a binary classifier only from positive data and unlabeled data (PU learning). Recent methods of PU learning commonly assume that the labeled positive data are identically distributed as the unlabeled positive data. However, this assumption is unrealistic in many instances of PU learning because it fails to capture the existence of a selection bias in the labeling process. When the data has a selection bias, it is difficult to learn the Bayes optimal classifier by conventional methods of PU learning. In this paper, we propose a method to partially identify the classifier. The proposed algorithm learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. Through experiments, we show that the method outperforms previous methods for PU learning on various real-world datasets.", "keywords": ["PU learning", "deep learning", "machine learning", "anomaly detection", "sampling bias"], "authorids": ["ICLR.cc/2019/Conference/Paper538/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a8b7c2909757ce9ba1b6d2a9b080b9b9235b994f.pdf", "paperhash": "anonymous|learning_from_positive_and_unlabeled_data_with_a_selection_bias", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning from Positive and Unlabeled Data with a Selection Bias},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJzLciCqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJeI5i0cYQ", "original": "BylcSjY9tQ", "number": 539, "cdate": 1538087822500, "ddate": null, "tcdate": 1538087822500, "tmdate": 1538156147899, "tddate": null, "forum": "SJeI5i0cYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "EXPLORING DEEP LEARNING USING INFORMATION THEORY TOOLS AND PATCH ORDERING", "abstract": "We present a framework for automatically ordering image patches that enables in-depth analysis of dataset relationship to learnability of a classification task using convolutional neural network. An image patch is a group of pixels residing in a continuous area contained in the sample. Our preliminary experimental results show that an informed smart shuffling of patches at a sample level can expedite training by exposing important features at early stages of training. In addition, we conduct systematic experiments and provide evidence that CNN\u2019s generalization capabilities do not correlate with human recognizable features present in training samples. We utilized the framework not only to show that spatial locality of features within samples do not correlate with generalization, but also to expedite convergence while achieving similar generalization performance. Using multiple network architectures and datasets, we show that ordering image regions using mutual information measure between adjacent patches, enables CNNs to converge in a third of the total steps required to train the same network without patch ordering.", "keywords": ["CNN", "Deep Learning", "Feature Extraction", "Patch Ordering", "Convergence", "Image Classification"], "authorids": ["ICLR.cc/2019/Conference/Paper539/Authors"], "authors": ["Anonymous"], "TL;DR": "Develop new techniques that rely on patch reordering to enable detailed analysis of data-set relationship to training and generalization performances.", "pdf": "/pdf/cc6bba04cbc1e6d44299e7d0f2c5bcd12d1ba109.pdf", "paperhash": "anonymous|exploring_deep_learning_using_information_theory_tools_and_patch_ordering", "_bibtex": "@inproceedings{    \nanonymous2019exploring,    \ntitle={EXPLORING DEEP LEARNING USING INFORMATION THEORY TOOLS AND PATCH ORDERING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJeI5i0cYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgv9oRqtQ", "original": "HJeXxwc9tQ", "number": 540, "cdate": 1538087822674, "ddate": null, "tcdate": 1538087822674, "tmdate": 1538156147683, "tddate": null, "forum": "rkgv9oRqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Compound Density Networks", "abstract": "Despite the huge success of deep neural networks (NNs), finding good mechanisms for quantifying their prediction uncertainty is still an open problem. It was recently shown, that using an ensemble of NNs trained with a proper scoring rule leads to results competitive to those of Bayesian NNs. This ensemble method can be understood as finite mixture model with uniform mixing weights. We build on this mixture model approach and increase its flexibility by replacing the fixed mixing weights by an adaptive, input-dependent distribution (specifying the probability of each component) represented by an NN, and by considering uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density network. We empirically show that the proposed model results in better uncertainty estimates and is more robust to adversarial examples than previous approaches.", "keywords": ["uncertainty in neural networks", "ensemble", "mixture model"], "authorids": ["ICLR.cc/2019/Conference/Paper540/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/336805bf85a8338834f65549f6f0f68758bab5ae.pdf", "paperhash": "anonymous|compound_density_networks", "_bibtex": "@inproceedings{    \nanonymous2019compound,    \ntitle={Compound Density Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgv9oRqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sklv5iRqYX", "original": "S1l5otVOKX", "number": 541, "cdate": 1538087822856, "ddate": null, "tcdate": 1538087822856, "tmdate": 1538156147472, "tddate": null, "forum": "Sklv5iRqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-Domain Adversarial Learning", "abstract": "Multi-domain learning (MDL) aims at obtaining a model with minimal average risk across multiple domains. Our empirical motivation is automated microscopy data, where cultured cells are imaged after being exposed to known and unknown chemical perturbations, and each dataset displays significant experimental bias. This paper presents a multi-domain adversarial learning approach, MuLANN, to leverage multiple datasets with overlapping but distinct class sets, in a semi-supervised setting. Our contributions include: i) a bound on the average- and worst-domain risk in MDL, obtained using the H-divergence; ii) a new loss to accommodate semi-supervised multi-domain learning and domain adaptation; iii) the experimental validation of the approach, improving on the state-of-the-art on two standard image benchmarks, and a novel bioimage dataset, Cell.", "keywords": ["multi-domain learning", "domain adaptation", "adversarial learning", "H-divergence", "deep representation learning", "high-content microscopy"], "authorids": ["ICLR.cc/2019/Conference/Paper541/Authors"], "authors": ["Anonymous"], "TL;DR": "Adversarial Domain adaptation and Multi-domain learning: a new loss to handle multi- and single-domain classes in the semi-supervised setting.", "pdf": "/pdf/e2c3c4857f5490d30f34d6d55ef39b5f01f8e5d2.pdf", "paperhash": "anonymous|multidomain_adversarial_learning", "_bibtex": "@inproceedings{    \nanonymous2019multi-domain,    \ntitle={Multi-Domain Adversarial Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sklv5iRqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGvcoA5YX", "original": "rylfAb3ttX", "number": 542, "cdate": 1538087823049, "ddate": null, "tcdate": 1538087823049, "tmdate": 1538156147261, "tddate": null, "forum": "ryGvcoA5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Overcoming Catastrophic Forgetting  via Model Adaptation", "abstract": "Learning multiple tasks sequentially is important for the development of AI and lifelong learning systems. However, standard neural network architectures suffer from catastrophic forgetting which makes it difficult to learn a sequence of tasks. Several continual learning methods have been proposed to address the problem. In this paper, we propose a very different approach, called model adaptation, to dealing with the problem. The proposed approach learns to build a model, called the solver, with two sets of parameters. The first set is shared by all tasks learned so far and the second set is dynamically generated to adapt the solver to suit each individual test example in order to classify it. Extensive experiments have been carried out to demonstrate the effectiveness of the proposed approach.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper542/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/45582f4507a5cd9fc7fcaa0ffdd3f267cd2c2804.pdf", "paperhash": "anonymous|overcoming_catastrophic_forgetting_via_model_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019overcoming,    \ntitle={Overcoming Catastrophic Forgetting  via Model Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGvcoA5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xwqjRcY7", "original": "Bkgp0Ns5Km", "number": 543, "cdate": 1538087823231, "ddate": null, "tcdate": 1538087823231, "tmdate": 1538156147052, "tddate": null, "forum": "r1xwqjRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Semantic Embedding", "abstract": "We present an extension of a variational auto-encoder that creates semantically richcoupled probabilistic latent representations that capture the semantics of multiplemodalities of data. We demonstrate this model through experiments using imagesand textual descriptors as inputs and images as outputs. Our latent representationsare not only capable of driving a decoder to generate novel data, but can also be useddirectly for annotation or classification. Using the MNIST and Fashion-MNISTdatasets we show that the embedding not only provides better reconstruction andclassification performance than the current state-of-the-art, but it also allows us toexploit the semantic content of the pretrained word embedding spaces to do taskssuch as image generation from labels outside of those seen during training.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper543/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/594fbfd1ee2daa5e2679158baab8a39e02a6af24.pdf", "paperhash": "anonymous|probabilistic_semantic_embedding", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Semantic Embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xwqjRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xD9sR5Fm", "original": "B1en9AicF7", "number": 544, "cdate": 1538087823412, "ddate": null, "tcdate": 1538087823412, "tmdate": 1538156146842, "tddate": null, "forum": "H1xD9sR5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Minimum Divergence vs. Maximum Margin: an Empirical Comparison on Seq2Seq Models", "abstract": "Sequence to sequence (seq2seq) models have become a popular framework for neural sequence prediction. While traditional seq2seq models are trained by Maximum Likelihood Estimation (MLE), much recent work has made various attempts to optimize evaluation scores directly to solve the mismatch between training and evaluation, since model predictions are usually evaluated by a task specific evaluation metric like BLEU or ROUGE scores instead of perplexity. This paper for the first time puts this existing work into two categories, a) minimum divergence, and b) maximum margin. We introduce a new training criterion based on the analysis of existing work, and empirically compare models in the two categories. Our experimental results show that training criteria based on the idea of minimum divergence can usually work better than maximum margin methods, on both the tasks of machine translation and sentence summarization. ", "keywords": ["sequence to sequence", "training criteria"], "authorids": ["ICLR.cc/2019/Conference/Paper544/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/022ac18cac035af3a687fa3512a8cb6266526242.pdf", "paperhash": "anonymous|minimum_divergence_vs_maximum_margin_an_empirical_comparison_on_seq2seq_models", "_bibtex": "@inproceedings{    \nanonymous2019minimum,    \ntitle={Minimum Divergence vs. Maximum Margin: an Empirical Comparison on Seq2Seq Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xD9sR5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxu5iR9KQ", "original": "S1gaBAo5tQ", "number": 545, "cdate": 1538087823582, "ddate": null, "tcdate": 1538087823582, "tmdate": 1538156146629, "tddate": null, "forum": "SJxu5iR9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Schedule Communication in Multi-agent Reinforcement Learning", "abstract": "Many real-world reinforcement learning tasks require multiple agents to make sequential decisions under the agents\u2019 interaction, where well-coordinated actions among the agents are crucial to achieve the target goal better at these tasks. One way to accelerate the coordination effect is to enable multiple agents to communicate with each other in a distributed manner and behave as a group. In this paper, we study a practical scenario when (i) the communication bandwidth is limited and (ii) the agents share the communication medium so that only a restricted number of agents are able to simultaneously use the medium, as in the state-of-the-art wireless networking standards. This calls for a certain form of communication scheduling. In that regard, we propose a multi-agent deep reinforcement learning framework, called SchedNet, in which agents learn how to schedule themselves, how to encode the messages, and how to select actions based on received messages. SchedNet is capable of deciding which agents should be entitled to broadcasting their (encoded) messages, by learning the importance of each agent\u2019s partially observed information. We evaluate SchedNet against multiple baselines under two different applications, namely, cooperative communication and navigation, and predator-prey. Our experiments show a non-negligible performance gap between SchedNet and other mechanisms such as the ones without communication and with vanilla scheduling methods, e.g., round robin, ranging from 32% to 43%.", "keywords": ["Multi agent reinforcement learning", "deep reinforcement learning", "Communication"], "authorids": ["ICLR.cc/2019/Conference/Paper545/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/774f61f72b471cb29166f8d1ff17d0976fbe88bc.pdf", "paperhash": "anonymous|learning_to_schedule_communication_in_multiagent_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Schedule Communication in Multi-agent Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxu5iR9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkxdqj0cFQ", "original": "S1xG1J2cKm", "number": 546, "cdate": 1538087823756, "ddate": null, "tcdate": 1538087823756, "tmdate": 1538156146422, "tddate": null, "forum": "Bkxdqj0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Calibration of neural network logit vectors to combat adversarial attacks", "abstract": "Adversarial examples remain an issue for contemporary neural networks. This paper draws on Background Check (Perello-Nieto et al., 2016), a technique in model calibration, to assist two-class neural networks in detecting adversarial examples, using the one dimensional difference between logit values as the underlying measure. This method interestingly tends to achieve the highest average recall on image sets that are generated with large perturbation vectors, which is unlike the existing literature on adversarial attacks (Cubuk et al., 2017). The proposed method does not need knowledge of the attack parameters or methods at training time, unlike a great deal of the literature that uses deep learning based methods to detect adversarial examples, such as Metzen et al. (2017), imbuing the proposed method with additional flexibility.", "keywords": ["Adversarial attacks", "calibration", "probability", "adversarial defence"], "authorids": ["ICLR.cc/2019/Conference/Paper546/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper uses principles from the field of calibration in machine learning on the logits of a neural network to defend against adversarial attacks", "pdf": "/pdf/9076625201c7930f54c5f98d51c5d00273de4763.pdf", "paperhash": "anonymous|calibration_of_neural_network_logit_vectors_to_combat_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019calibration,    \ntitle={Calibration of neural network logit vectors to combat adversarial attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkxdqj0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eO9oA5Km", "original": "ryxR9PK9t7", "number": 547, "cdate": 1538087823942, "ddate": null, "tcdate": 1538087823942, "tmdate": 1538156146214, "tddate": null, "forum": "B1eO9oA5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Guider Network for Multi-Dual Learning", "abstract": "A large amount of parallel data is needed to train a strong neural machine translation (NMT) system. This is a major challenge for low-resource languages. Building on recent work on unsupervised and semi-supervised methods, we propose a multi-dual learning framework to improve the performance of NMT by using an almost infinite amount of available monolingual data and some parallel data of other languages. Since our framework involves multiple languages and components, we further propose a timing optimization method that uses reinforcement learning (RL) to optimally schedule the different components in order to avoid imbalanced training. Experimental results  demonstrate the validity of our model, and confirm its superiority to existing dual learning methods.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper547/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/650795e676ea63ab875bbd9b7f8a8d1868916338.pdf", "paperhash": "anonymous|a_guider_network_for_multidual_learning", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Guider Network for Multi-Dual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eO9oA5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1G_cj05YQ", "original": "Ske2Xyn5t7", "number": 548, "cdate": 1538087824139, "ddate": null, "tcdate": 1538087824139, "tmdate": 1538156146003, "tddate": null, "forum": "S1G_cj05YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Activity Regularization for Continual Learning", "abstract": "While deep neural networks have achieved remarkable successes, they suffer the well-known catastrophic forgetting issue when switching from existing tasks to tackle a new one. In this paper, we study continual learning with deep neural networks that learn from tasks arriving sequentially. We first propose an approximated multi-task learning framework that unifies a family of popular regularization based continual learning methods. We then analyze the weakness of existing approaches, and propose a novel regularization method named \u201cActivity Regularization\u201d (AR), which alleviates forgetting meanwhile keeping model\u2019s plasticity to acquire new knowledge. Extensive experiments show that our method outperform state-of-the-art methods and effectively overcomes catastrophic forgetting.\n", "keywords": ["continual learning", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper548/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper develops a novel regularization for continual learning", "pdf": "/pdf/8a3c59331b09c02b7d70fa9b9901df65d7ee59ca.pdf", "paperhash": "anonymous|activity_regularization_for_continual_learning", "_bibtex": "@inproceedings{    \nanonymous2019activity,    \ntitle={Activity Regularization for Continual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1G_cj05YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byl_ciRcY7", "original": "rJg6lJ7tYQ", "number": 549, "cdate": 1538087824341, "ddate": null, "tcdate": 1538087824341, "tmdate": 1538156145791, "tddate": null, "forum": "Byl_ciRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ON BREIMAN\u2019S DILEMMA IN NEURAL NETWORKS: SUCCESS AND FAILURE OF NORMALIZED MARGINS", "abstract": "A belief persists long in machine learning that enlargement of margins over training data accounts for the resistance of models to overfitting by increasing the robustness. Yet Breiman shows a dilemma (Breiman, 1999) that a uniform improvement on margin distribution \\emph{does not} necessarily reduces generalization error. In this paper, we revisit Breiman's dilemma in deep neural networks with recently proposed normalized margins using Lipschitz constant bound by spectral norm products. With both simplified theory and extensive experiments, Breiman's dilemma is shown to rely on dynamics of normalized margin distributions, that reflects the trade-off between model expression power and data complexity. When the complexity of data is comparable to the model expression power in the sense that training and test data share similar phase transitions in normalized margin dynamics, two efficient ways are derived via classic margin-based generalization bounds to successfully predict the trend of generalization error. On the other hand, over-expressed models that exhibit uniform improvements on training normalized margins may lose such a prediction power and fail to prevent the overfitting. \n", "keywords": ["Bregman's Dilemma", "Generalization Error", "Margin", "Spectral normalization"], "authorids": ["ICLR.cc/2019/Conference/Paper549/Authors"], "authors": ["Anonymous"], "TL;DR": "Bregman's dilemma is shown in deep learning that improvement of margins of over-parameterized models may result in overfitting, and dynamics of normalized margin distributions are proposed to predict generalization error and identify such a dilemma. ", "pdf": "/pdf/edadfd588bc7fe6ca4efbb24a20910a34b2785ba.pdf", "paperhash": "anonymous|on_breimans_dilemma_in_neural_networks_success_and_failure_of_normalized_margins", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={ON BREIMAN\u2019S DILEMMA IN NEURAL NETWORKS: SUCCESS AND FAILURE OF NORMALIZED MARGINS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byl_ciRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgFqiAqFX", "original": "S1eEAD9qY7", "number": 550, "cdate": 1538087824525, "ddate": null, "tcdate": 1538087824525, "tmdate": 1538156145584, "tddate": null, "forum": "BkgFqiAqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Recovering the Lowest Layer of Deep Networks with High Threshold Activations", "abstract": "Giving provable guarantees for learning neural networks is a core challenge of machine learning theory. Most prior work gives parameter recovery guarantees for one hidden layer networks, however, the networks used in practice have multiple non-linear layers. In this work, we show how we can strengthen such results to deeper networks -- we address the problem of uncovering the lowest layer in a deep neural network under the assumption that the lowest layer uses a high threshold before applying the activation, the upper network can be modeled as a well-behaved polynomial and the input distribution is gaussian.", "keywords": ["Deep Learning", "Parameter Recovery", "Non-convex optimization", "high threshold activation"], "authorids": ["ICLR.cc/2019/Conference/Paper550/Authors"], "authors": ["Anonymous"], "TL;DR": "We provably recover the lowest layer in a deep neural network assuming that the lowest layer uses a \"high threshold\" activation and the above network is a \"well-behaved\" polynomial.", "pdf": "/pdf/4cc79578da931d704ba05aa316ce6d8e139f0471.pdf", "paperhash": "anonymous|recovering_the_lowest_layer_of_deep_networks_with_high_threshold_activations", "_bibtex": "@inproceedings{    \nanonymous2019recovering,    \ntitle={Recovering the Lowest Layer of Deep Networks with High Threshold Activations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgFqiAqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgFcj0qKX", "original": "rylaCdlqt7", "number": 551, "cdate": 1538087824700, "ddate": null, "tcdate": 1538087824700, "tmdate": 1538156145373, "tddate": null, "forum": "BJgFcj0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stacked U-Nets: A No-Frills Approach to Natural Image Segmentation", "abstract": "Many imaging tasks require global information about all pixels in an image. Conventional bottom-up classification networks globalize information by decreasing resolution; features are pooled and down-sampled into a single output. But for semantic segmentation and object detection tasks, a network must provide higher-resolution pixel-level outputs. To globalize information while preserving resolution, many researchers propose the inclusion of sophisticated auxiliary blocks, but these come at the cost of a considerable increase in network size and computational cost. This paper proposes stacked u-nets (SUNets), which iteratively combine features from different resolution scales while maintaining resolution. SUNets leverage the information globalization power of u-nets in a deeper net- work architectures that is capable of handling the complexity of natural images. SUNets perform extremely well on semantic segmentation tasks using a small number of parameters.", "keywords": ["semantic segmentation", "stacked u-nets", "classification"], "authorids": ["ICLR.cc/2019/Conference/Paper551/Authors"], "authors": ["Anonymous"], "TL;DR": "Presents new architecture which leverages information globalization power of u-nets in a deeper networks and performs well across tasks without any bells and whistles.", "pdf": "/pdf/083bbe21a2813dea08690a92c6d24c7324860433.pdf", "paperhash": "anonymous|stacked_unets_a_nofrills_approach_to_natural_image_segmentation", "_bibtex": "@inproceedings{    \nanonymous2019stacked,    \ntitle={Stacked U-Nets: A No-Frills Approach to Natural Image Segmentation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgFcj0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgYciAqF7", "original": "rklubsL5K7", "number": 552, "cdate": 1538087824878, "ddate": null, "tcdate": 1538087824878, "tmdate": 1538156145161, "tddate": null, "forum": "SkgYciAqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Skim-PixelCNN", "abstract": "Pixel convolutional neural network (PixelCNN) has provided promising results in image generation. However, it requires heavy computation time for inference, which deters its use in practice. Here, we propose a new generation method based on PixelCNN, dubbed Skim-PixelCNN that remarkably reduces inference time by skimming easy pixels. On top of a vanilla PixelCNN, we introduce two main components: an efficient generator that generates a set of next pixels in one shot and a confidence estimator that measures the confidence of the generated pixels. Based on the confidence, our model decides whether it skims or redraw the pixel using the vanilla PixelCNN. From the quantitative and qualitative experiments on diverse public image datasets, we show that our method can significantly reduce the computational overhead while its generation performance is comparable to or even improved that of the vanilla PixelCNN.", "keywords": ["Autoregressive Image Generation Model", "Faster Inference", "Skimming"], "authorids": ["ICLR.cc/2019/Conference/Paper552/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a new PixelCNN-based auto-regressive generation approach that enhances the generation time by skimming the pixels.", "pdf": "/pdf/645b4b80772b9b1f963cc073d3c351980dd0361f.pdf", "paperhash": "anonymous|skimpixelcnn", "_bibtex": "@inproceedings{    \nanonymous2019skim-pixelcnn,    \ntitle={Skim-PixelCNN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgYciAqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syxt5oC5YQ", "original": "S1gDgen9YX", "number": 553, "cdate": 1538087825138, "ddate": null, "tcdate": 1538087825138, "tmdate": 1538156144922, "tddate": null, "forum": "Syxt5oC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Aggregated Momentum: Stability Through Passive Damping", "abstract": "Momentum is a simple and widely used trick which allows gradient-based optimizers to pick up speed along low curvature directions. Its performance depends crucially on a damping coefficient. Largecamping  coefficients can potentially deliver much larger speedups, but are prone to oscillations and instability; hence one typically resorts to small values such as 0.5 or 0.9. We propose Aggregated Momentum (AggMo), a variant of momentum which combines multiple velocity vectors with different damping coefficients. AggMo is trivial to implement, but significantly dampens oscillations, enabling it to remain stable even for aggressive damping coefficients such as 0.999. We reinterpret Nesterov's accelerated gradient descent as a special case of AggMo and analyze rates of convergence for quadratic objectives. Empirically, we find that AggMo is a suitable drop-in replacement for other momentum methods, and frequently delivers faster convergence with little to no tuning.", "keywords": ["momentum", "optimization", "deep learning", "neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper553/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a simple variant of momentum optimization which is able to outperform classical momentum, Nesterov, and Adam on deep learning tasks with minimal hyperparameter tuning.", "pdf": "/pdf/1e0066c89b437d6fb5529d1a41e46543f8ec59e3.pdf", "paperhash": "anonymous|aggregated_momentum_stability_through_passive_damping", "_bibtex": "@inproceedings{    \nanonymous2019aggregated,    \ntitle={Aggregated Momentum: Stability Through Passive Damping},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syxt5oC5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygYqs0qKX", "original": "BJgYVAI5KX", "number": 554, "cdate": 1538087825334, "ddate": null, "tcdate": 1538087825334, "tmdate": 1538156144716, "tddate": null, "forum": "HygYqs0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["ICLR.cc/2019/Conference/Paper554/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "anonymous|conscious_inference_for_object_detection", "_bibtex": "@inproceedings{    \nanonymous2019conscious,    \ntitle={Conscious Inference for Object Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygYqs0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJlYcoCcKX", "original": "HyxNJSW5tQ", "number": 555, "cdate": 1538087825513, "ddate": null, "tcdate": 1538087825513, "tmdate": 1538156144505, "tddate": null, "forum": "SJlYcoCcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "KNOWLEDGE DISTILL VIA LEARNING NEURON MANIFOLD", "abstract": "Although deep neural networks show their extraordinary power in various tasks, they are not feasible for deploying such large models on embedded systems due to high computational cost and storage space limitation. The recent work knowledge distillation (KD) aims at transferring model knowledge from a well-trained teacher model to a small and fast student model which can significantly help extending the usage of large deep neural networks on portable platform. In this paper, we show that, by properly defining the neuron manifold of deep neuron network (DNN), we can significantly improve the performance of student DNN networks through approximating neuron manifold of powerful teacher network. To make this, we propose several novel methods for learning neuron manifold from DNN model. Empowered with neuron manifold knowledge, our experiments show the great improvement across a variety of DNN architectures and training data. Compared with other KD methods, our Neuron Manifold Transfer (NMT) has best transfer ability of the learned features.", "keywords": ["Deep Learning", "Machine Learning", "Knowledge Distill", "Model Compression"], "authorids": ["ICLR.cc/2019/Conference/Paper555/Authors"], "authors": ["Anonymous"], "TL;DR": "A new knowledge distill method for transfer learning", "pdf": "/pdf/28a2ef2f0e47d6462e9a1bcd5f09276ebb155ac1.pdf", "paperhash": "anonymous|knowledge_distill_via_learning_neuron_manifold", "_bibtex": "@inproceedings{    \nanonymous2019knowledge,    \ntitle={KNOWLEDGE DISTILL VIA LEARNING NEURON MANIFOLD},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlYcoCcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygqqsA9KX", "original": "SkgLGtG_KQ", "number": 556, "cdate": 1538087825688, "ddate": null, "tcdate": 1538087825688, "tmdate": 1538156144289, "tddate": null, "forum": "rygqqsA9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Factorized Multimodal Representations", "abstract": "Learning multimodal representations is a fundamentally complex research problem due to the presence of multiple heterogeneous sources of information. Although the presence of multiple modalities provides additional valuable information, there are two key challenges to address when learning from multimodal data: 1) models must learn the complex intra-modal and cross-modal interactions for prediction and 2) models must be robust to unexpected missing or noisy modalities during testing. In this paper, we propose to optimize for a joint generative-discriminative objective across multimodal data and labels. We introduce a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors. Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as sentiment prediction. Modality-specific generative factors are unique for each modality and contain the information required for generating data. Experimental results show that our model is able to learn meaningful multimodal representations that achieve state-of-the-art or competitive performance on six multimodal datasets. Our model demonstrates flexible generative capabilities by conditioning on independent factors and can reconstruct missing modalities without significantly impacting performance. Lastly, we interpret our factorized representations to understand the interactions that influence multimodal learning.", "keywords": ["multimodal representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper556/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.", "pdf": "/pdf/907d74546ea9f90649acad1e7e38dd9bfe788c99.pdf", "paperhash": "anonymous|learning_factorized_multimodal_representations", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Factorized Multimodal Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygqqsA9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgqqsAct7", "original": "HJgiDMZqYX", "number": 557, "cdate": 1538087825860, "ddate": null, "tcdate": 1538087825860, "tmdate": 1538156144083, "tddate": null, "forum": "BJgqqsAct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach", "abstract": "Modern neural networks are highly overparameterized, with capacity to substantially overfit to training data. Nevertheless, these networks often generalize well in practice. It has also been observed that trained networks can often be ``compressed to much smaller representations. The purpose of this paper is to connect these two empirical observations. Our main technical result is a generalization bound for compressed networks based on the compressed size that, combined with off-the-shelf compression algorithms, leads to state-of-the-art generalization guarantees. In particular, we provide the first non-vacuous generalization guarantees for realistic architectures applied to the ImageNet classification problem. Additionally, we show that compressibility of models that tend to overfit is limited. Empirical results show that an increase in overfitting increases the number of bits required to describe a trained network.", "keywords": ["generalization", "deep-learning", "pac-bayes"], "authorids": ["ICLR.cc/2019/Conference/Paper557/Authors"], "authors": ["Anonymous"], "TL;DR": "We obtain non-vacuous generalization bounds on ImageNet-scale deep neural networks by combining an original PAC-Bayes bound and an off-the-shelf neural network compression method.", "pdf": "/pdf/362b731ca871f53f98d28a8ad5fe9cf2232076e1.pdf", "paperhash": "anonymous|nonvacuous_generalization_bounds_at_the_imagenet_scale_a_pacbayesian_compression_approach", "_bibtex": "@inproceedings{    \nanonymous2019non-vacuous,    \ntitle={Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgqqsAct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skf5qiC5KQ", "original": "rylkR0q5t7", "number": 558, "cdate": 1538087826033, "ddate": null, "tcdate": 1538087826033, "tmdate": 1538156143870, "tddate": null, "forum": "Skf5qiC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Unified View of Deep Metric Learning via Gradient Analysis", "abstract": "Loss functions play a pivotal role in deep metric learning (DML). A large variety of loss functions have been proposed in DML recently. However, it remains difficult to answer this question: what are the intrinsic differences among these loss functions?This paper answers this question by proposing a unified perspective to rethink deep metric loss functions. We show theoretically that most DML methods in deep metric learning, in view of  gradient equivalence, are essentially weight assignment strategies of training pairs. Based on this unified view, we revisit several typical DML methods and disclose their hidden drawbacks. Moreover, we point out the key components of an effective DML approach which drives us to propose our weight assignment framework. We evaluate our method on image retrieval tasks, and show that it outperforms  the state-of-the-art DML approaches by a significant margin on the CUB-200-2011, Cars-196, Stanford Online Products and In-Shop Clothes Retrieval datasets. ", "keywords": ["metric learning", "gradient equivalence", "image retrieval"], "authorids": ["ICLR.cc/2019/Conference/Paper558/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/dfaec45cc1c5650ffdb2e2e899e078a1ec8518ed.pdf", "paperhash": "anonymous|a_unified_view_of_deep_metric_learning_via_gradient_analysis", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Unified View of Deep Metric Learning via Gradient Analysis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skf5qiC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1l9qsA5KQ", "original": "H1e788vOtX", "number": 559, "cdate": 1538087826207, "ddate": null, "tcdate": 1538087826207, "tmdate": 1538156143664, "tddate": null, "forum": "B1l9qsA5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mental Fatigue Monitoring using Brain Dynamics Preferences", "abstract": "Driver's cognitive state of mental fatigue significantly affects driving performance and more importantly public safety. Previous studies leverage the response time (RT) as the metric for mental fatigue and aim at estimating the exact value of RT using electroencephalogram (EEG) signals within a regression model. However, due to the easily corrupted EEG signals and also non-smooth RTs during data collection, regular regression methods generally suffer from poor generalization performance.  Considering that human response time is the reflection of brain dynamics preference rather than a single value, a novel model called Brain Dynamic ranking (BDrank) has been proposed. BDrank could learn from brain dynamics preferences using EEG data robustly and preserve the ordering corresponding to RTs. BDrank model is based on the regularized alternative ordinal classification comparing to regular regression based practices. Furthermore, a transition matrix is introduced to characterize the reliability of each channel used in EEG data, which helps in learning brain dynamics preferences only from informative EEG channels. In order to handle large-scale EEG signals~and obtain higher generalization, an online-generalized Expectation Maximum (OnlineGEM) algorithm also has been proposed to update BDrank in an online fashion. Comprehensive empirical analysis on EEG signals from 44 participants shows that BDrank together with OnlineGEM achieves substantial improvements in reliability while simultaneously detecting possible less informative and noisy EEG channels.", "keywords": ["mental fatigue", "brain dynamics preference", "brain dynamics ranking", "channel reliability", "channel Selection"], "authorids": ["ICLR.cc/2019/Conference/Paper559/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9e31f37d81afabbe95666b63b1e598e46cf9cee2.pdf", "paperhash": "anonymous|mental_fatigue_monitoring_using_brain_dynamics_preferences", "_bibtex": "@inproceedings{    \nanonymous2019mental,    \ntitle={Mental Fatigue Monitoring using Brain Dynamics Preferences},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l9qsA5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1e9csRcFm", "original": "B1esvZ2ctQ", "number": 560, "cdate": 1538087826383, "ddate": null, "tcdate": 1538087826383, "tmdate": 1538156143462, "tddate": null, "forum": "B1e9csRcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Importance of Norm Regularization in Linear Graph Embedding: Theoretical Analysis and Empirical Demonstration", "abstract": "Learning distributed representations for nodes in graphs is a crucial primitive in network analysis with a wide spectrum of applications. Linear graph embedding methods learn such representations by optimizing the likelihood of both positive and negative edges while constraining the dimension of the embedding vectors. We argue that the generalization performance of these methods is not due to the dimensionality constraint as commonly believed, but rather the small norm of embedding vectors. Both theoretical and empirical evidence are provided to support this argument: (a) we prove that the generalization error of these methods can be bounded by limiting the norm of vectors, regardless of the embedding dimension; (b) we show that the generalization performance of linear graph embedding methods is correlated with the norm of embedding vectors, which is small due to the early stopping of SGD and the vanishing gradients. We performed extensive experiments to validate our analysis and showcased the importance of proper norm regularization in practice.", "keywords": ["Graph Embedding", "Generalization Analysis", "Matrix Factorization"], "authorids": ["ICLR.cc/2019/Conference/Paper560/Authors"], "authors": ["Anonymous"], "TL;DR": "We argue that the generalization of linear graph embedding is not due to the dimensionality constraint but rather the small norm of embedding vectors.", "pdf": "/pdf/ca528e3648af939ff729b07433c632a75ebfbb83.pdf", "paperhash": "anonymous|the_importance_of_norm_regularization_in_linear_graph_embedding_theoretical_analysis_and_empirical_demonstration", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Importance of Norm Regularization in Linear Graph Embedding: Theoretical Analysis and Empirical Demonstration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e9csRcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1eiqi09K7", "original": "rJea-bh5KX", "number": 561, "cdate": 1538087826568, "ddate": null, "tcdate": 1538087826568, "tmdate": 1538156143252, "tddate": null, "forum": "r1eiqi09K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Riemannian Adaptive Optimization Methods", "abstract": "Several first order stochastic optimization methods commonly used in the Euclidean domain such as stochastic gradient descent (SGD), accelerated gradient descent or variance reduced methods have already been adapted to certain Riemannian settings. However, some of the most popular of these optimization tools - namely Adam , Adagrad and the more recent Amsgrad - remain to be generalized to Riemannian manifolds. We discuss the difficulty of generalizing such adaptive schemes to the most agnostic Riemannian setting, and then provide algorithms and convergence proofs for geodesically convex objectives in the particular case of a product of Riemannian manifolds, in which adaptivity is implemented across manifolds in the cartesian product. Our generalization is tight in the sense that \n choosing the Euclidean space as Riemannian manifold yields the same algorithms and regret bounds as those that were already known for the standard algorithms. Experimentally, we show faster convergence and to a lower train loss value for Riemannian adaptive methods over their corresponding baselines on the realistic task of embedding the WordNet taxonomy in the Poincare ball.", "keywords": ["Riemannian optimization", "adaptive", "hyperbolic", "curvature", "manifold", "adam", "amsgrad", "adagrad", "rsgd", "convergence"], "authorids": ["ICLR.cc/2019/Conference/Paper561/Authors"], "authors": ["Anonymous"], "TL;DR": "Adapting Adam, Amsgrad, Adagrad to Riemannian manifolds. ", "pdf": "/pdf/e2eb451ccc1ac8a2fd75ad64a814b97dd9fd5400.pdf", "paperhash": "anonymous|riemannian_adaptive_optimization_methods", "_bibtex": "@inproceedings{    \nanonymous2019riemannian,    \ntitle={Riemannian Adaptive Optimization Methods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eiqi09K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygjcsR9Y7", "original": "HJeFJOcqF7", "number": 562, "cdate": 1538087826744, "ddate": null, "tcdate": 1538087826744, "tmdate": 1538156143044, "tddate": null, "forum": "rygjcsR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series", "abstract": "High-dimensional time series are common in many domains. Since human cognition is not optimized to work well in high-dimensional spaces, these areas could benefit from interpretable low-dimensional representations. However, most representation learning algorithms for time series data are difficult to interpret. This is due to non-intuitive mappings from data features to salient properties of the representation and non-smoothness over time.\nTo address this problem, we propose a new representation learning framework building on ideas from interpretable discrete dimensionality reduction and deep generative modeling. This framework allows us to learn discrete representations of time series, which give rise to smooth and interpretable embeddings with superior clustering performance. We introduce a new way to overcome the non-differentiability in discrete representation learning and present a gradient-based version of the traditional self-organizing map algorithm that is more performant than the original. Furthermore, to allow for a probabilistic interpretation of our method, we integrate a Markov model in the representation space.\nThis model uncovers the temporal transition structure, improves clustering performance even further and provides additional explanatory insights as well as a natural representation of uncertainty.\nWe evaluate our model in terms of clustering performance and interpretability on static (Fashion-)MNIST data, a time series of linearly interpolated (Fashion-)MNIST images, a chaotic Lorenz attractor system with two macro states, as well as on a challenging real world medical time series application on the eICU data set. Our learned representations compare favorably with competitor methods and facilitate downstream tasks on the real world data.", "keywords": ["deep learning", "self-organizing map", "variational autoencoder", "representation learning", "time series", "machine learning", "interpretability"], "authorids": ["ICLR.cc/2019/Conference/Paper562/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a method to learn interpretable representations on time series using ideas from variational autoencoders, self-organizing maps and probabilistic models.", "pdf": "/pdf/f5f0c006d49b3ad83ded56aa60fad676183b7889.pdf", "paperhash": "anonymous|deep_selforganization_interpretable_discrete_representation_learning_on_time_series", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygjcsR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xsqj09Fm", "original": "Byl3-zn5Km", "number": 563, "cdate": 1538087826975, "ddate": null, "tcdate": 1538087826975, "tmdate": 1538156142833, "tddate": null, "forum": "B1xsqj09Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper563/Authors"], "authors": ["Anonymous"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/776cfc9c3f0c80c93f3e03f564c8f08348c41abc.pdf", "paperhash": "anonymous|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019large,    \ntitle={Large Scale GAN Training for High Fidelity Natural Image Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xsqj09Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygo9iR9F7", "original": "S1eKgWj5YQ", "number": 564, "cdate": 1538087827154, "ddate": null, "tcdate": 1538087827154, "tmdate": 1538156142628, "tddate": null, "forum": "rygo9iR9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Progressive Weight Pruning Of Deep Neural Networks Using ADMM", "abstract": "Deep neural networks (DNNs) although achieving human-level performance in many domains, have very large model size that hinders their broader applications on edge computing devices. Extensive research work have been conducted on DNN model compression or pruning. However, most of the previous work took heuristic approaches. This work proposes a progressive weight pruning approach based on ADMM (Alternating Direction Method of Multipliers), a powerful technique to deal with non-convex optimization problems with potentially combinatorial constraints. Motivated by dynamic programming, the proposed method reaches extremely high pruning rate by using partial prunings with moderate pruning rates. Therefore, it resolves the accuracy degradation and long convergence time problems when pursuing extremely high pruning ratios. It achieves up to 34\u00d7 pruning rate for ImageNet dataset and 167\u00d7 pruning rate for MNIST dataset, significantly higher than those reached by the literature work. Under the same number of epochs, the proposed method also achieves faster convergence and higher compression rates. The codes and pruned DNN models are released in the anonymous link bit.ly/2zxdlss.", "keywords": ["deep learning", "model compression", "optimization", "ADMM", "weight pruning"], "authorids": ["ICLR.cc/2019/Conference/Paper564/Authors"], "authors": ["Anonymous"], "TL;DR": "We implement a DNN weight pruning approach that achieves the highest pruning rates.", "pdf": "/pdf/6847b73ff155db2542cd4c9e5ab969a9c76fc035.pdf", "paperhash": "anonymous|progressive_weight_pruning_of_deep_neural_networks_using_admm", "_bibtex": "@inproceedings{    \nanonymous2019progressive,    \ntitle={Progressive Weight Pruning Of Deep Neural Networks Using ADMM},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygo9iR9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygjqjR9Km", "original": "SkxDo2iqFm", "number": 565, "cdate": 1538087827345, "ddate": null, "tcdate": 1538087827345, "tmdate": 1538156142419, "tddate": null, "forum": "HygjqjR9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving MMD-GAN Training with Repulsive Loss Function", "abstract": "Generative adversarial nets (GANs) are widely used to learn the data sampling process and their performance heavily depends on the loss functions used in training. This study revisits MMD-GAN that uses the maximum mean discrepancy (MMD) as the loss function for GAN and makes two contributions. First, we argue that the existing MMD loss function may discourage the learning of data structures as it attempts to attract the discriminator outputs of real data. To address this issue, we propose a repulsive loss function to actively learn the difference among the real data by simply rearranging the terms in MMD. Second, inspired by the hinge loss, we propose a bounded Gaussian kernel to stabilize the training of MMD-GAN. The proposed methods are applied to the unsupervised image generation tasks on CIFAR-10, STL-10, CelebA, and LSUN bedroom datasets. Results show that the repulsive loss function significantly improves over the MMD loss at no additional computational cost and outperforms other representative loss functions. The proposed methods achieved an FID score of 16.21 on the CIFAR-10 dataset using a single DCGAN network and spectral normalization.", "keywords": ["generative adversarial nets", "loss function", "maximum mean discrepancy", "image generation", "unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper565/Authors"], "authors": ["Anonymous"], "TL;DR": "Rearranging the terms in maximum mean discrepancy yields a much better loss function for generative adversarial nets", "pdf": "/pdf/9e8ee721432300236dde50bb29a1fdb33194845e.pdf", "paperhash": "anonymous|improving_mmdgan_training_with_repulsive_loss_function", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving MMD-GAN Training with Repulsive Loss Function},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygjqjR9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bygh9j09KX", "original": "Byelrp_9tX", "number": 566, "cdate": 1538087827521, "ddate": null, "tcdate": 1538087827521, "tmdate": 1538156142206, "tddate": null, "forum": "Bygh9j09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness.", "abstract": "Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies hint to a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNet-trained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on our novel Stylized-ImageNet dataset. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation.", "keywords": ["deep learning", "psychophysics", "representation learning", "object recognition", "robustness", "neural networks", "data augmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper566/Authors"], "authors": ["Anonymous"], "TL;DR": "ImageNet-trained CNNs are biased towards object texture (instead of shape like humans). Overcoming this bias (using a novel data augmentation) yields improved detection performance and previously unseen robustness to image distortions.", "pdf": "/pdf/996bcc58c387ed0b414491539ddb0af5be65fa95.pdf", "paperhash": "anonymous|imagenettrained_cnns_are_biased_towards_texture_increasing_shape_bias_improves_accuracy_and_robustness", "_bibtex": "@inproceedings{    \nanonymous2019imagenet-trained,    \ntitle={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness.},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bygh9j09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Ske25sC9FQ", "original": "SJeJqG2ct7", "number": 567, "cdate": 1538087827697, "ddate": null, "tcdate": 1538087827697, "tmdate": 1538156141993, "tddate": null, "forum": "Ske25sC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Robustness and Equivariance of Neural Networks", "abstract": "Neural networks models are known to be vulnerable to geometric transformations\nas well as small pixel-wise perturbations of input. Convolutional Neural Networks\n(CNNs) are translation-equivariant but can be easily fooled using rotations and\nsmall pixel-wise perturbations. Moreover, CNNs require sufficient translations in\ntheir training data to achieve translation-invariance. Recent work by Cohen &\nWelling (2016), Worrall et al. (2016), Kondor & Trivedi (2018), Cohen & Welling\n(2017), Marcos et al. (2017), and Esteves et al. (2018) has gone beyond translations,\nand constructed rotation-equivariant or more general group-equivariant\nneural network models. In this paper, we do an extensive empirical study of various\nrotation-equivariant neural network models to understand how effectively they\nlearn rotations. This includes Group-equivariant Convolutional Networks (GCNNs)\nby Cohen & Welling (2016), Harmonic Networks (H-Nets) by Worrall et al.\n(2016), Polar Transformer Networks (PTN) by Esteves et al. (2018) and Rotation\nequivariant vector field networks by Marcos et al. (2017). We empirically compare\nthe ability of these networks to learn rotations efficiently in terms of their\nnumber of parameters, sample complexity, rotation augmentation used in training.\nWe compare them against each other as well as Standard CNNs. We observe\nthat as these rotation-equivariant neural networks learn rotations, they instead become\nmore vulnerable to small pixel-wise adversarial attacks, e.g., Fast Gradient\nSign Method (FGSM) and Projected Gradient Descent (PGD), in comparison with\nStandard CNNs. In other words, robustness to geometric transformations in these\nmodels comes at the cost of robustness to small pixel-wise perturbations.", "keywords": ["robust", "adversarial", "equivariance", "rotations", "GCNNs", "CNNs", "steerable", "neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper567/Authors"], "authors": ["Anonymous"], "TL;DR": "Robustness to rotations comes at the cost of robustness of pixel-wise adversarial perturbations.", "pdf": "/pdf/abc57710fa3f933270863cc321eb3dedf9fdfb7a.pdf", "paperhash": "anonymous|robustness_and_equivariance_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019robustness,    \ntitle={Robustness and Equivariance of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Ske25sC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkMn9jAcYQ", "original": "H1gTM7hcKQ", "number": 568, "cdate": 1538087827877, "ddate": null, "tcdate": 1538087827877, "tmdate": 1538156141792, "tddate": null, "forum": "BkMn9jAcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Countering Language Drift via Grounding", "abstract": "While reinforcement learning (RL) shows a lot of promise for natural language processing\u2014e.g. when fine-tuning natural language systems for optimizing a certain objective\u2014there has been little investigation into potential language drift: when an external reward is used to train a system, the agents\u2019 communication protocol may easily and radically diverge from natural language. By re-casting translation as a communication game, we show that language drift indeed happens when pre-trained agents are fine-tuned with policy gradient methods. We contend that simply adding a \"naturalness\" constraint to the reward, e.g. by using language model log likelihood, does not fully address the issue, and argue that (perceptual) grounding is required. That is, while language model constraints impose syntactic conformity, they do not lead to semantic correspondence. Our experiments show that grounded models give the best communication performance, while retaining English syntax along with the ability to convey the intended semantics.", "keywords": ["grounding", "policy gradient", "language drift", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper568/Authors"], "authors": ["Anonymous"], "TL;DR": "Grounding helps avoid language drift during fine-tuning natural language agents with policy gradients.", "pdf": "/pdf/d33beb21c6e460e483a035f21e1457ae1b03873d.pdf", "paperhash": "anonymous|countering_language_drift_via_grounding", "_bibtex": "@inproceedings{    \nanonymous2019countering,    \ntitle={Countering Language Drift via Grounding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMn9jAcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syzn9i05Ym", "original": "BkeDhrOqKQ", "number": 569, "cdate": 1538087828049, "ddate": null, "tcdate": 1538087828049, "tmdate": 1538156141584, "tddate": null, "forum": "Syzn9i05Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Neural Random Fields with Inclusive Auxiliary Generators", "abstract": "Neural random fields (NRFs), which are defined by using neural networks to implement potential functions in undirected models, provide an interesting family of model spaces for machine learning. In this paper we develop a new approach to learning NRFs with inclusive-divergence minimized auxiliary generator - the inclusive-NRF approach. The new approach enables us to flexibly use NRFs in unsupervised, supervised and semi-supervised settings and successfully train them in a black-box manner. Empirically, inclusive-NRFs achieve state-of-the-art sample generation quality on CIFAR-10 in both unsupervised and supervised settings. Semi-supervised inclusive-NRFs show strong classification results on par with state-of-the-art generative model based semi-supervised learning methods, and simultaneously achieve superior generation, on the widely benchmarked datasets - MNIST, SVHN and CIFAR-10.", "keywords": ["Neural random fields", "Deep generative models", "Unsupervised learning", "Semi-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper569/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a new approach to learning neural random fields and show that the new approach obtains state-of-the-art sample generation quality and achieves strong semi-supervised learning results on par with state-of-the-art deep generative models.", "pdf": "/pdf/db80a7c91ce8c0d66bdcdfdb15d81eef01f0c60a.pdf", "paperhash": "anonymous|learning_neural_random_fields_with_inclusive_auxiliary_generators", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Neural Random Fields with Inclusive Auxiliary Generators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syzn9i05Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S14h9sCqYm", "original": "Syl7tKYqYX", "number": 570, "cdate": 1538087828219, "ddate": null, "tcdate": 1538087828219, "tmdate": 1538156141375, "tddate": null, "forum": "S14h9sCqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Weakly-supervised Knowledge Graph Alignment with Adversarial Learning", "abstract": "Aligning knowledge graphs from different sources or languages, which aims to align both the entity and relation, is critical to a variety of applications such as knowledge graph construction and question answering. Existing methods of knowledge graph alignment usually rely on a large number of aligned knowledge triplets to train effective models. However, these aligned triplets may not be available or are expensive to obtain for many domains. Therefore, in this paper we study how to design fully-unsupervised methods or weakly-supervised methods, i.e., to align knowledge graphs without or with only a few aligned triplets. We propose an unsupervised framework based on adversarial training, which is able to map the entities and relations in a source knowledge graph to those in a target knowledge graph. This framework can be further seamlessly integrated with existing supervised methods, where only a limited number of aligned triplets are utilized as guidance. Experiments on real-world datasets prove the effectiveness of our proposed approach in both the weakly-supervised and unsupervised settings.", "keywords": ["Knowledge Graph Alignment", "Generative Adversarial Network", "Weakly Supervised"], "authorids": ["ICLR.cc/2019/Conference/Paper570/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper studies weakly-supervised knowledge graph alignment with adversarial training frameworks.", "pdf": "/pdf/ae6b06b831804268b11ea0acb359857b63aef179.pdf", "paperhash": "anonymous|weaklysupervised_knowledge_graph_alignment_with_adversarial_learning", "_bibtex": "@inproceedings{    \nanonymous2019weakly-supervised,    \ntitle={Weakly-supervised Knowledge Graph Alignment with Adversarial Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S14h9sCqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1g29oAqtm", "original": "rkecW9i5YX", "number": 571, "cdate": 1538087828393, "ddate": null, "tcdate": 1538087828393, "tmdate": 1538156141171, "tddate": null, "forum": "B1g29oAqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding the Asymptotic Performance of Model-Based RL Methods", "abstract": "In complex simulated environments, model-based reinforcement learning methods typically lag the asymptotic performance of model-free approaches. This paper uses two MuJoCo environments to understand this gap through a series of ablation experiments designed to separate the contributions of the dynamics model and planner. These reveal the importance of long planning horizons, beyond those typically used. A dynamics model that directly predicts distant states, based on current state and a long sequence of actions, is introduced. This avoids the need for many recursions during long-range planning, and thus is able to yield more accurate state estimates. These accurate predictions allow us to uncover the relationship between model accuracy and performance, and translate to higher task reward that matches or exceeds current state-of-the-art model-free approaches.", "keywords": ["model-based reinforcement learning", "mbrl", "reinforcement learning", "predictive models", "predictive learning", "forward models", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper571/Authors"], "authors": ["Anonymous"], "TL;DR": "Long-term prediction accuracy limits the performance of model-based RL, and can be improved with a simple change to the form of the model.", "pdf": "/pdf/d731d4b23de9877c7d6995fc71a4fc75d2908bac.pdf", "paperhash": "anonymous|understanding_the_asymptotic_performance_of_modelbased_rl_methods", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding the Asymptotic Performance of Model-Based RL Methods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1g29oAqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygT9oRqFX", "original": "ryx0fINqKm", "number": 572, "cdate": 1538087828572, "ddate": null, "tcdate": 1538087828572, "tmdate": 1538156140968, "tddate": null, "forum": "HygT9oRqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MixFeat: Mix Feature in Latent Space Learns Discriminative Space", "abstract": "Deep learning methods perform well in various tasks. However, the over-fitting problem remains, where the performance decreases for unknown data. We here provide a novel method named MixFeat, which directly makes the latent space discriminative. MixFeat mixes two feature maps in each latent space and uses one of their labels for learning. We report improved results obtained using existing network models with MixFeat on CIFAR-10/100 datasets. In addition, we show that MixFeat effectively reduces the over-fitting problem even in the case that the training dataset is small or contains errors. We argue that MixFeat is complementary with existing methods that mix both images and labels, in that MixFeat is suitable for discrimination tasks while existing methods are suitable for regression tasks. MixFeat is easy to implement and can be added to various network models without additional computational cost in the inference phase.", "keywords": ["regularization", "generalization", "image classification", "latent space", "feature learning"], "authorids": ["ICLR.cc/2019/Conference/Paper572/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide a novel method named MixFeat, which directly makes the latent space discriminative.", "pdf": "/pdf/872df99f5de914bda6f57c4b378ae5db73f9425e.pdf", "paperhash": "anonymous|mixfeat_mix_feature_in_latent_space_learns_discriminative_space", "_bibtex": "@inproceedings{    \nanonymous2019mixfeat:,    \ntitle={MixFeat: Mix Feature in Latent Space Learns Discriminative Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygT9oRqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxacs0qY7", "original": "S1guqpKcK7", "number": 573, "cdate": 1538087828740, "ddate": null, "tcdate": 1538087828740, "tmdate": 1538156140761, "tddate": null, "forum": "rkxacs0qY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS", "abstract": "Variational Bayesian neural networks (BNN) perform variational inference over weights, but it is difficult to specify meaningful priors and approximating posteriors in a high-dimensional weight space. We introduce functional variational Bayesian neural networks (fBNNs), which maximize an Evidence Lower BOund (ELBO) defined directly on stochastic processes, i.e. distributions over functions. We prove that the KL divergence between stochastic processes is equal to the supremum of marginal KL divergences over all finite sets of inputs. Based on this, we introduce a practical training objective which approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. With fBNNs, we can specify priors which entail rich structure, including Gaussian processes and implicit stochastic processes. Empirically, we find that fBNNs extrapolate well using various structured priors, provide reliable uncertainty estimates, and can scale to large datasets.", "keywords": ["functional variational inference", "Bayesian neural networks", "stochastic processes"], "authorids": ["ICLR.cc/2019/Conference/Paper573/Authors"], "authors": ["Anonymous"], "TL;DR": "We perform functional variational inference on the stochastic processes defined by Bayesian neural networks.", "pdf": "/pdf/6711942cd7a62b0b6dffed98db204e4e2870bd3c.pdf", "paperhash": "anonymous|functional_variational_bayesian_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019functional,    \ntitle={FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxacs0qY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1l6qiR5F7", "original": "HklP3Bi9Y7", "number": 574, "cdate": 1538087828909, "ddate": null, "tcdate": 1538087828909, "tmdate": 1538156140549, "tddate": null, "forum": "B1l6qiR5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks", "abstract": "Recurrent neural network (RNN) models are widely used for processing sequential data governed by a latent tree structure. Previous work shows that RNN models (especially Long Short-Term Memory (LSTM) based models) could learn to exploit the underlying tree structure. However, its performance consistently lags behind that of tree-based models. This work proposes a new inductive bias Ordered Neurons, which enforces an order of updating frequencies between hidden state neurons. We show that the ordered neurons could explicitly integrate the latent tree structure into recurrent models. To this end, we propose a new RNN unit: ON-LSTM, which achieve good performances on four different tasks: language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference.", "keywords": ["Deep Learning", "Natural Language Processing", "Recurrent Neural Networks", "Language Modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper574/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a new inductive bias that integrates tree structures in recurrent neural networks.", "pdf": "/pdf/f044a7ef19d1540fa91b9ff5105336fc3bb99437.pdf", "paperhash": "anonymous|ordered_neurons_integrating_tree_structures_into_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019ordered,    \ntitle={Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l6qiR5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJl65sA9tm", "original": "Bkg70-DqKX", "number": 575, "cdate": 1538087829081, "ddate": null, "tcdate": 1538087829081, "tmdate": 1538156140342, "tddate": null, "forum": "BJl65sA9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations", "abstract": "Imitation learning aims to learn an optimal policy from expert demonstrations and its recent combination with deep learning has shown impressive performance. However, collecting a large number of expert demonstrations for deep learning is time-consuming and requires much expert effort. In this paper, we propose a method to improve generative adversarial imitation learning by using additional information from non-expert demonstrations which are easier to obtain. The key idea of our method is to perform multiclass classification to learn discriminator functions where non-expert demonstrations are regarded as being drawn from an extra class. Experiments in continuous control tasks demonstrate that our method learns optimal policies faster and has more stable performance than the  generative adversarial imitation learning baseline.", "keywords": ["Imitation learning", "Generative adversarial imitation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper575/Authors"], "authors": ["Anonymous"], "TL;DR": "We improve GAIL by learning discriminators using multiclass classification with non-expert regarded as an extra class.", "pdf": "/pdf/b13ad24c22a48938252e7db6c0d71f388763cdf0.pdf", "paperhash": "anonymous|improving_generative_adversarial_imitation_learning_with_nonexpert_demonstrations", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl65sA9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgTciR9tm", "original": "r1xdOVh9tQ", "number": 576, "cdate": 1538087829252, "ddate": null, "tcdate": 1538087829252, "tmdate": 1538156140133, "tddate": null, "forum": "rJgTciR9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy", "abstract": "\tExtracting relevant information, causally inferring and predicting the future states with high accuracy is a crucial task for modeling complex systems. On one hand, the aforementioned challenges require a rigorous mathematical analysis capable of dealing with high-dimensional heterogeneous data streams. On the other hand, this rigorous mathematical framework allows us to learn precise, compact information and be able to coherently propagate measures of uncertainty across spatio-temporal states. To efficiently and rigorously process high-dimensional data coming from complex systems, we advocate for an information theory inspired approach that incorporates stochastic calculus and seeks to determine a trade-off between the predictive accuracy and compactness of the mathematical representation. Mathematically, such a model construction is cast as an optimization problem that maximizes the compression such that the predictive ability and correlation (relatedness) constraints between the original data and compact model are closely bounded. To learn this compact representation of a time-varying complex system and solve the above-mentioned optimization problem we use variational calculus and derive its general solution expressions. Moreover, we provide theoretical guarantees concerning the convergence of the proposed algorithm. To further test the proposed framework, we consider a high-dimensional Gaussian case study and describe an iterative scheme for updating the new model parameters. Using numerical experiments, we demonstrate the benefits on compression and prediction accuracy for a class of dynamical systems. Finally, we apply the proposed algorithm to the real-world dataset of multimodal sentiment intensity and show improvements in prediction with reduced dimensions.", "keywords": ["compact representation", "perception", "dynamical systems", "information bottleneck"], "authorids": ["ICLR.cc/2019/Conference/Paper576/Authors"], "authors": ["Anonymous"], "TL;DR": "Compact perception of dynamical process", "pdf": "/pdf/a9d91d8da20cf20162fdc443fb017e7fab314a79.pdf", "paperhash": "anonymous|learning_information_propagation_in_the_dynamical_systems_via_information_bottleneck_hierarchy", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgTciR9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJea5oAqK7", "original": "Hyez1sicYm", "number": 577, "cdate": 1538087829425, "ddate": null, "tcdate": 1538087829425, "tmdate": 1538156139931, "tddate": null, "forum": "SJea5oAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PASS: Phased Attentive State Space Modeling of Disease Progression Trajectories", "abstract": "Disease progression models are instrumental in predicting individual-level health\ntrajectories and understanding disease dynamics. Existing models are capable\nof providing either accurate predictions of patients\u2019 prognoses or clinically interpretable\nrepresentations of disease pathophysiology, but not both. In this paper,\nwe develop the phased attentive state space (PASS) model of disease progression,\na deep probabilistic model that captures complex representations for disease progression\nwhile maintaining clinical interpretability. Unlike Markovian state space\nmodels which assume memoryless dynamics, PASS uses an attention mechanism\nto induce \"memoryful\" state transitions, whereby repeatedly updated attention\nweights are used to focus on past state realizations that best predict future states.\nThis gives rise to complex, non-stationary state dynamics that remain interpretable\nthrough the generated attention weights, which designate the relationships between\nthe realized state variables for individual patients. PASS uses phased LSTM\nunits (with time gates controlled by parametrized oscillations) to generate the attention\nweights in continuous time, which enables handling irregularly-sampled\nand potentially missing medical observations. Experiments on data from a realworld\ncohort of patients show that PASS successfully balances the tradeoff between\naccuracy and interpretability: it demonstrates superior predictive accuracy\nand learns insightful individual-level representations of disease progression.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper577/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f958ea21416a47303fa13f130be61dda69fa1cee.pdf", "paperhash": "anonymous|pass_phased_attentive_state_space_modeling_of_disease_progression_trajectories", "_bibtex": "@inproceedings{    \nanonymous2019pass:,    \ntitle={PASS: Phased Attentive State Space Modeling of Disease Progression Trajectories},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJea5oAqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gR5iR5FX", "original": "SkeboAP5KX", "number": 578, "cdate": 1538087829599, "ddate": null, "tcdate": 1538087829599, "tmdate": 1538156139709, "tddate": null, "forum": "H1gR5iR5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Analysing Mathematical Reasoning Abilities of Neural Models", "abstract": "Mathematical reasoning---a core ability within human intelligence---presents some unique challenges as a domain: we do not come to understand and solve mathematical problems primarily on the back of experience and evidence, but on the basis of inferring, learning, and exploiting laws, axioms, and symbol manipulation rules. In this paper, we present a new challenge for the evaluation (and eventually the design) of neural architectures and similar system, developing a task suite of mathematics problems involving sequential questions and answers in a free-form textual input/output format. The structured nature of the mathematics domain, covering arithmetic, algebra, probability and calculus, enables the construction of training and test spits designed to clearly illuminate the capabilities and failure-modes of different architectures, as well as evaluate their ability to compose and relate knowledge and learned processes. Having described the data generation process and its potential future expansions, we conduct a comprehensive analysis of models from two broad classes of the most powerful sequence-to-sequence architectures and find notable differences in their ability to resolve mathematical problems and generalize their knowledge.\n", "keywords": ["mathematics", "dataset", "algebraic", "reasoning"], "authorids": ["ICLR.cc/2019/Conference/Paper578/Authors"], "authors": ["Anonymous"], "TL;DR": "A dataset for testing mathematical reasoning (and algebraic generalization), and results on current sequence-to-sequence models.", "pdf": "/pdf/c7f804cebb30b93c365832593a2a74dccceb83f8.pdf", "paperhash": "anonymous|analysing_mathematical_reasoning_abilities_of_neural_models", "_bibtex": "@inproceedings{    \nanonymous2019analysing,    \ntitle={Analysing Mathematical Reasoning Abilities of Neural Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gR5iR5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxAcjCqt7", "original": "HylcBJrKYX", "number": 579, "cdate": 1538087829769, "ddate": null, "tcdate": 1538087829769, "tmdate": 1538156139503, "tddate": null, "forum": "ByxAcjCqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Point Cloud GAN", "abstract": "Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions on different types of data. In this paper, we first show a straightforward extension of existing GAN algorithm is not applicable to point clouds, because the constraint required for discriminators is undefined for set data. We propose a two fold modification to GAN algorithm for learning to generate point clouds (PC-GAN). First, we combine ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process. A key component of our method is that we train a posterior inference network for the hidden variables. Second, PC-GAN defines a generic framework that can incorporate many existing GAN algorithms. We further propose a sandwiching objective, which results in a tighter Wasserstein distance estimate than the commonly used dual form in WGAN. We validate our claims on ModelNet40 benchmark dataset. PC-GAN trained by the sandwiching objective achieves better results on test data than the existing methods by comparing with true meshes quantitatively. We also conduct studies on several tasks, including generalization on unseen point clouds, latent space interpolation, classification, and image to point clouds, to demonstrate the versatility of the proposed PC-GAN.", "keywords": ["Point Cloud", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper579/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a GAN variant which learns to generate point clouds. Different studies have been explores, including tighter Wasserstein distance estimate,  conditional generation, generalization to unseen point clouds and image to point cloud.", "pdf": "/pdf/f13ea1c59bfeb88a90154bdcfee4de413d62faba.pdf", "paperhash": "anonymous|point_cloud_gan", "_bibtex": "@inproceedings{    \nanonymous2019point,    \ntitle={Point Cloud GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxAcjCqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMCcjAcYX", "original": "rklemVjYYm", "number": 580, "cdate": 1538087829940, "ddate": null, "tcdate": 1538087829940, "tmdate": 1538156139289, "tddate": null, "forum": "HJMCcjAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Representations of Sets through Optimised Permutations", "abstract": "Representations of sets are challenging to learn because operations on sets should be permutation-invariant. To this end, we propose a Permutation-Optimisation module that learns how to permute a set end-to-end. The permuted set can be further processed to learn a permutation-invariant representation of that set, avoiding a bottleneck in traditional set models. We demonstrate our model's ability to learn permutations and set representations with either explicit or implicit supervision on four datasets, on which we achieve state-of-the-art results: number sorting, image mosaics, classification from image mosaics, and visual question answering.\n", "keywords": ["sets", "representation learning", "permutation invariance"], "authorids": ["ICLR.cc/2019/Conference/Paper580/Authors"], "authors": ["Anonymous"], "TL;DR": "Learn how to permute a set, then encode permuted set with RNN to obtain a set representation.", "pdf": "/pdf/e8281f4e6762d519e478aff8e5b2f35419339dee.pdf", "paperhash": "anonymous|learning_representations_of_sets_through_optimised_permutations", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Representations of Sets through Optimised Permutations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMCcjAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJz05o0qK7", "original": "HJgAvvg5Km", "number": 581, "cdate": 1538087830117, "ddate": null, "tcdate": 1538087830117, "tmdate": 1538156139082, "tddate": null, "forum": "HJz05o0qK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Measuring Compositionality in Representation Learning", "abstract": "Many machine learning algorithms represent input data with vector embeddings or discrete codes. When inputs exhibit compositional structure (e.g. objects built from parts or procedures from subroutines), it is natural to ask whether this compositional structure is reflected in the the inputs\u2019 learned representations. While the assessment of compositionality in languages has received significant attention in linguistics and adjacent fields, the machine learning literature lacks general-purpose tools for producing graded measurements of compositional structure in more general (e.g. vector-valued) representation spaces. In this paper we describe a simple procedure for evaluating compositionality of learned representations. We use the procedure to provide formal and empirical characterizations of compositional structure in a variety of settings, exploring the relationship between compositionality and learning dynamics, human judgments, representational similarity, and generalization.", "keywords": ["compositionality", "representation learning", "evaluation"], "authorids": ["ICLR.cc/2019/Conference/Paper581/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes a simple procedure for evaluating compositional structure in learned representations, and uses the procedure to explore the role of compositionality in four learning problems.", "pdf": "/pdf/23b9419438744f5b2545c620aba7a86e4d9b2b16.pdf", "paperhash": "anonymous|measuring_compositionality_in_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019measuring,    \ntitle={Measuring Compositionality in Representation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJz05o0qK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyNA5iRcFQ", "original": "BygQdirOYX", "number": 582, "cdate": 1538087830293, "ddate": null, "tcdate": 1538087830293, "tmdate": 1538156138875, "tddate": null, "forum": "HyNA5iRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Detecting Egregious Responses in Neural Sequence-to-sequence Models", "abstract": "In this work, we attempt to answer a critical question: whether there exists some input sequence that will cause a well-trained discrete-space neural network sequence-to-sequence (seq2seq)  model to generate egregious outputs (aggressive, malicious, attacking, etc.). And if such inputs exist, how to find them efficiently. We adopt an empirical methodology, in which we first create lists of egregious output sequences, and then design a discrete optimization algorithm to find input sequences that will cause the model to generate them. Moreover, the optimization algorithm is enhanced for large vocabulary search and constrained to search for input sequences that are likely to be input by real-world users. In our experiments, we apply this approach to  dialogue response generation models trained on three real-world dialogue data-sets: Ubuntu, Switchboard and OpenSubtitles, testing whether the model can generate malicious responses. We demonstrate that given the trigger inputs our algorithm finds, a significant number of malicious sentences are assigned large probability by the model, which reveals an undesirable consequence of standard seq2seq training. ", "keywords": ["Deep Learning", "Natural Language Processing", "Adversarial Attacks", "Dialogue Response Generation"], "authorids": ["ICLR.cc/2019/Conference/Paper582/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper aims to provide an empirical answer to the question of whether well-trained dialogue response model can output malicious responses.", "pdf": "/pdf/d5f1c5a53a0646ec5b1c09538cac1389b0c84152.pdf", "paperhash": "anonymous|detecting_egregious_responses_in_neural_sequencetosequence_models", "_bibtex": "@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Egregious Responses in Neural Sequence-to-sequence Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyNA5iRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ERcs09KQ", "original": "H1ghEieDK7", "number": 583, "cdate": 1538087830476, "ddate": null, "tcdate": 1538087830476, "tmdate": 1538156138669, "tddate": null, "forum": "H1ERcs09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchically Clustered Representation Learning", "abstract": "The joint optimization of representation learning and clustering in the embedding space has experienced a breakthrough in recent years. In spite of the advance, clustering with representation learning has been limited to flat-level categories, which oftentimes involves cohesive clustering with a focus on instance relations. To overcome the limitations of flat clustering, we introduce hierarchically clustered representation learning (HCRL), which simultaneously optimizes representation learning and hierarchical clustering in the embedding space. Specifically, we place a nonparametric Bayesian prior on embeddings to handle dynamic mixture hierarchies under the variational autoencoder framework, and to adopt the generative process of a hierarchical-versioned Gaussian mixture model. Compared with a few prior works focusing on unifying representation learning and hierarchical clustering, HCRL is the first model to consider a generation of deep embeddings from every component of the hierarchy, not just leaf components. This generation process enables more meaningful separations and mergers of clusters via branches in a hierarchy. In addition to obtaining hierarchically clustered embeddings, we can reconstruct data by the various abstraction levels, infer the intrinsic hierarchical structure, and learn the level-proportion features. We conducted evaluations with image and text domains, and our quantitative analyses showed competent likelihoods and the best accuracies compared with the baselines.", "keywords": ["Representation learning", "Hierarchical clustering", "Nonparametric Bayesian modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper583/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce hierarchically clustered representation learning (HCRL), which simultaneously optimizes representation learning and hierarchical clustering in the embedding space.", "pdf": "/pdf/41f41434d68c0c9b4dbd6576869e176a8194a454.pdf", "paperhash": "anonymous|hierarchically_clustered_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019hierarchically,    \ntitle={Hierarchically Clustered Representation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ERcs09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxkijC5FQ", "original": "Hyg3U1c5FQ", "number": 584, "cdate": 1538087830645, "ddate": null, "tcdate": 1538087830645, "tmdate": 1538156138456, "tddate": null, "forum": "ByxkijC5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Persistence: A Complexity Measure for Deep Neural Networks Using Algebraic Topology", "abstract": "While many approaches to make neural networks more fathomable have been proposed, they are restricted to interrogating the network with input data. Measures for characterizing and monitoring structural properties, however, have not been developed. In this work, we propose neural persistence, a complexity measure for neural network architectures based on topological data analysis on weighted stratified graphs. To demonstrate the usefulness of our approach, we show that neural persistence agrees with best practices developed in the deep learning community such as dropout and batch normalization. Moreover, we derive a neural persistence-based stopping criterion that shortens the training process while preserving accuracy compared to validation-loss based early stopping.", "keywords": ["Algebraic topology", "persistent homology", "network complexity", "neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper584/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a new topological complexity measure for deep neural networks and demonstrate that it captures their salient properties.", "pdf": "/pdf/a700db00bd698013d12c85ad9eb9d437925db926.pdf", "paperhash": "anonymous|neural_persistence_a_complexity_measure_for_deep_neural_networks_using_algebraic_topology", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Persistence: A Complexity Measure for Deep Neural Networks Using Algebraic Topology},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxkijC5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1eJssCqY7", "original": "BJlnZsccKX", "number": 585, "cdate": 1538087830819, "ddate": null, "tcdate": 1538087830819, "tmdate": 1538156138239, "tddate": null, "forum": "r1eJssCqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TabNN: A Universal Neural Network Solution for Tabular Data", "abstract": "Neural Network (NN) has achieved state-of-the-art performances in many tasks within image, speech, and text domains. Such great success is mainly due to special structure design to fit the particular data patterns, such as CNN capturing spatial locality and RNN modeling sequential dependency. Essentially, these specific NNs achieve good performance by leveraging the prior knowledge over corresponding domain data. Nevertheless, there are many applications with all kinds of tabular data in other domains. Since there are no shared patterns among these diverse tabular data, it is hard to design specific structures to fit them all. Without careful architecture design based on domain knowledge, it is quite challenging for NN to reach satisfactory performance in these tabular data domains. To fill the gap of NN in tabular data learning, we propose a universal neural network solution, called TabNN, to derive effective NN architectures for tabular data in all kinds of tasks automatically. Specifically, the design of TabNN follows two principles: \\emph{to explicitly leverages expressive feature combinations} and \\emph{to reduce model complexity}. Since GBDT has empirically proven its strength in modeling tabular data, we use GBDT to power the implementation of TabNN. Comprehensive experimental analysis on a variety of tabular datasets demonstrate that TabNN can achieve much better performance than many baseline solutions.", "keywords": ["neural network", "machine learning", "tabular data"], "authorids": ["ICLR.cc/2019/Conference/Paper585/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a universal neural network solution to derive effective NN architectures for tabular data automatically.", "pdf": "/pdf/a34f2a5fe5011db3059293570c340e5d8066fd00.pdf", "paperhash": "anonymous|tabnn_a_universal_neural_network_solution_for_tabular_data", "_bibtex": "@inproceedings{    \nanonymous2019tabnn:,    \ntitle={TabNN: A Universal Neural Network Solution for Tabular Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eJssCqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1fysiAqK7", "original": "ryglwI2cFm", "number": 586, "cdate": 1538087830997, "ddate": null, "tcdate": 1538087830997, "tmdate": 1538156138028, "tddate": null, "forum": "B1fysiAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Binary Neural Networks", "abstract": "Low bit-width weights and activations are an effective way of combating the increasing need for both memory and compute power of Deep Neural Networks. In this work, we present a probabilistic training method for Neural Network with both binary weights and activations, called PBNet. By embracing stochasticity during training, we circumvent the need to approximate the gradient of functions for which the derivative is zero almost always, such as $\\textrm{sign}(\\cdot)$, while still obtaining a fully Binary Neural Network at test time. Moreover, it allows for anytime ensemble predictions for improved performance and uncertainty estimates by sampling from the weight distribution. Since all operations in a layer of the PBNet operate on random variables, we introduce stochastic versions of Batch Normalization and max pooling, which transfer well to a deterministic network at test time.  We evaluate two related training methods for the PBNet: one in which activation distributions are propagated throughout the network, and one in which binary activations are sampled in each layer. Our experiments indicate that sampling the binary activations is an important element for stochastic training of binary Neural Networks.\n", "keywords": ["binary neural Network", "efficient deep learning", "stochastic training", "discrete neural network", "efficient inference"], "authorids": ["ICLR.cc/2019/Conference/Paper586/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a stochastic training method for training Binary Neural Network with both binary weights and activations.", "pdf": "/pdf/160d573e5ae2b492a8047e3ccd64d7d6ef7267d0.pdf", "paperhash": "anonymous|probabilistic_binary_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Binary Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1fysiAqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJGkisCcKm", "original": "BylHvzUqKQ", "number": 587, "cdate": 1538087831231, "ddate": null, "tcdate": 1538087831231, "tmdate": 1538156137817, "tddate": null, "forum": "HJGkisCcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Autoencoder-based Music Translation", "abstract": "We present a method for translating music across musical instruments and styles. This method is based on unsupervised training of a multi-domain wavenet autoencoder, with a shared encoder and a disentangled latent space that is trained end-to-end on waveforms. Employing a diverse training dataset and large net capacity, the domain-independent encoder allows us to translate also from musical domains that were not seen during training. We evaluate our method on a dataset collected from professional musicians, and achieve convincing translations. We also study the properties of the obtained translation and  demonstrate translating even from a whistle, potentially enabling the creation of instrumental music by untrained humans. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper587/Authors"], "authors": ["Anonymous"], "TL;DR": "An automatic method for converting music between instruments and styles", "pdf": "/pdf/9f342e5cdd2367a4d4da31906e07768b12d34595.pdf", "paperhash": "anonymous|autoencoderbased_music_translation", "_bibtex": "@inproceedings{    \nanonymous2019autoencoder-based,    \ntitle={Autoencoder-based Music Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJGkisCcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkNksoRctQ", "original": "r1lACSrOFQ", "number": 588, "cdate": 1538087831396, "ddate": null, "tcdate": 1538087831396, "tmdate": 1538156137612, "tddate": null, "forum": "SkNksoRctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fluctuation-dissipation relations for stochastic gradient descent", "abstract": "The notion of the stationary equilibrium ensemble has played a central role in statistical mechanics. In machine learning as well, training serves as generalized equilibration that drives the probability distribution of model parameters toward stationarity. Here, we derive stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in the stochastic gradient descent algorithm. These relations hold exactly for any stationary state and can in particular be used to adaptively set training schedule. We can further use the relations to efficiently extract information pertaining to a loss-function landscape such as the magnitudes of its Hessian and anharmonicity. Our claims are empirically verified.", "keywords": ["stochastic gradient descent", "adaptive method", "loss surface", "Hessian"], "authorids": ["ICLR.cc/2019/Conference/Paper588/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces.", "pdf": "/pdf/9945c1ec00768eee3bf691c0f331672ffb91b34c.pdf", "paperhash": "anonymous|fluctuationdissipation_relations_for_stochastic_gradient_descent", "_bibtex": "@inproceedings{    \nanonymous2019fluctuation-dissipation,    \ntitle={Fluctuation-dissipation relations for stochastic gradient descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkNksoRctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hklgis0cF7", "original": "Ske_ekjqK7", "number": 589, "cdate": 1538087831571, "ddate": null, "tcdate": 1538087831571, "tmdate": 1538156137396, "tddate": null, "forum": "Hklgis0cF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks", "abstract": "The linear and non-flexible nature of deep convolutional models makes them vulnerable to carefully crafted adversarial perturbations. To tackle this problem, in this paper, we propose a nonlinear radial basis convolutional feature transformation by learning the Mahalanobis distance function that maps the input convolutional features from the same class into tight clusters. In such a space, the clusters become compact and well-separated, which prevent small adversarial perturbations from forcing a sample to cross the decision boundary. We test the proposed method on three publicly available image classification and segmentation data-sets namely, MNIST, ISBI ISIC skin lesion, and NIH ChestX-ray14. We evaluate the robustness of our method to different gradient (targeted and untargeted) and non-gradient based attacks and compare it to several non-gradient masking defense strategies. Our results demonstrate that the proposed method can boost the performance of deep convolutional neural networks against adversarial perturbations without accuracy drop on clean data.", "keywords": ["Radial basis feature transformation", "convolutional neural networks", "adversarial defense"], "authorids": ["ICLR.cc/2019/Conference/Paper589/Authors"], "authors": ["Anonymous"], "TL;DR": "A new nonlinear defense against adversarial attacks.", "pdf": "/pdf/700f48ea9496b3c89098cf3407f85f98199f6faf.pdf", "paperhash": "anonymous|radial_basis_feature_transformation_to_arm_cnns_against_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019radial,    \ntitle={Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hklgis0cF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1ggosR9Ym", "original": "SygVjGl5K7", "number": 590, "cdate": 1538087831746, "ddate": null, "tcdate": 1538087831746, "tmdate": 1538156137186, "tddate": null, "forum": "B1ggosR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Using Deep Siamese Neural Networks to Speed up Natural Products Research", "abstract": "Natural products (NPs, compounds derived from plants and animals) are an important source of novel disease treatments. A bottleneck in the search for new NPs is structure determination. One method is to use 2D Nuclear Magnetic Resonance (NMR) imaging, which indicates bonds between nuclei in the compound, and hence is the \"fingerprint\" of the compound. Computing a similarity score between 2D NMR spectra for a novel compound and a compound whose structure is known helps determine the structure of the novel compound. Standard approaches to this problem do not appear to scale to larger databases of compounds. Here we use deep convolutional Siamese networks to map NMR spectra to a cluster space, where similarity is given by the distance in the space. This approach results in an AUC score that is more than four times better than an approach using Latent Dirichlet Allocation.", "keywords": ["clustering", "deep learning", "application", "chemistry", "natural products"], "authorids": ["ICLR.cc/2019/Conference/Paper590/Authors"], "authors": ["Anonymous"], "TL;DR": "We learn a direct mapping from NMR spectra of small molecules to a molecular structure based cluster space. ", "pdf": "/pdf/4b8bc24d0b32e3cad97d2e3a1d51fba9e6b98552.pdf", "paperhash": "anonymous|using_deep_siamese_neural_networks_to_speed_up_natural_products_research", "_bibtex": "@inproceedings{    \nanonymous2019using,    \ntitle={Using Deep Siamese Neural Networks to Speed up Natural Products Research},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1ggosR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1MgjoR9tQ", "original": "SJefsz4KYX", "number": 591, "cdate": 1538087831924, "ddate": null, "tcdate": 1538087831924, "tmdate": 1538156136978, "tddate": null, "forum": "H1MgjoR9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CBOW Is Not All You Need: Combining CBOW with the Compositional Matrix Space Model", "abstract": "Continuous Bag of Words (CBOW) is a powerful text embedding method. Due to its strong capabilities to encode word content, CBOW embeddings perform well on a wide range of downstream tasks while being efficient to compute. However, CBOW is not capable of capturing the word order. The reason is that the computation of CBOW's word embeddings is commutative, i.e., embeddings of XYZ and ZYX are the same. In order to address this shortcoming, we propose a learning algorithm for the Continuous Matrix Space Model, which we call Continual Multiplication of Words (CMOW). Our algorithm is an adaptation of word2vec, so that it can be trained on large quantities of unlabeled text. We empirically show that CMOW better captures linguistic properties, but it is inferior to CBOW in memorizing word content. Motivated by these findings, we propose a hybrid model that combines the strengths of CBOW and CMOW. Our results show that the hybrid CBOW-CMOW-model improves the performance over CBOW for 8 out of 11 supervised downstream tasks with an average improvement of 1.2%.", "keywords": ["Text representation learning", "Sentence embedding", "Efficient training scheme", "word2vec"], "authorids": ["ICLR.cc/2019/Conference/Paper591/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel training scheme for efficiently obtaining order-aware sentence representations.", "pdf": "/pdf/3c7e65108ecdb333404e2ece6b58e73281c37463.pdf", "paperhash": "anonymous|cbow_is_not_all_you_need_combining_cbow_with_the_compositional_matrix_space_model", "_bibtex": "@inproceedings{    \nanonymous2019cbow,    \ntitle={CBOW Is Not All You Need: Combining CBOW with the Compositional Matrix Space Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1MgjoR9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1zxjsCqKQ", "original": "SygRDYo5YX", "number": 592, "cdate": 1538087832093, "ddate": null, "tcdate": 1538087832093, "tmdate": 1538156136768, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper592/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0abfd0500814ac536fc51500beb13699cfa30bdc.pdf", "paperhash": "anonymous|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@inproceedings{    \nanonymous2019gradient-based,    \ntitle={Gradient-based learning for F-measure and other performance metrics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1zxjsCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B14ejsA5YQ", "original": "rklhtMAqtm", "number": 594, "cdate": 1538087832430, "ddate": null, "tcdate": 1538087832430, "tmdate": 1538156136552, "tddate": null, "forum": "B14ejsA5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Causal Discovery with Learnable Input Noise", "abstract": "Learning causal relations from observational time series with nonlinear interactions and complex causal structures is a key component of human intelligence, and has a wide range of applications. Although neural nets have demonstrated their effectiveness in a variety of fields, their application in learning causal relations has been scarce.\nThis is due to both a lack of theoretical results connecting risk minimization and causality (enabling function approximators like neural nets to apply), and a lack of scalability in prior causal measures to allow for expressive function approximators like neural nets to apply. In this work, we propose a novel causal measure and algorithm using risk minimization to infer causal relations from time series. We prove that under certain conditions, the positiveness of our measure can deduce a stringent direct structural causality. We demonstrate the effectiveness and scalablility of our algorithms to learn nonlinear causal models in synthetic datasets as comparing to other methods, and its effectiveness in inferring causal relations in a video game environment and real-world heart-rate vs. breath-rate and rat brain EEG datasets.", "paperhash": "anonymous|neural_causal_discovery_with_learnable_input_noise", "authorids": ["ICLR.cc/2019/Conference/Paper594/Authors"], "authors": ["Anonymous"], "keywords": ["neural causal learning", "learnable noise"], "pdf": "/pdf/9f4e9419d598b055e9400f979191eb6087c26562.pdf", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Causal Discovery with Learnable Input Noise},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B14ejsA5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl0r3R9KX", "original": "HkeaLA39Ym", "number": 1592, "cdate": 1538088006157, "ddate": null, "tcdate": 1538088006157, "tmdate": 1538156135688, "tddate": null, "forum": "rJl0r3R9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Regularized Learning for  Domain Adaptation under Label Shifts", "abstract": "We propose Regularized Learning under Label shifts (RLLS), a principled and practical approach to correct for shifts in the label distribution between the source and target domains, and is a special case of domain adaptation. We estimate the importance weights using both labeled source and unlabeled target data and then train a classifier on the weighted source samples. Depending on the number of source and target samples, we regularize the influence of these estimated weights and train a corrected classifier on the source set with the estimated weights. We derive a generalization bound for the loss of the classifier on the target set. This bound is independent of the (ambient) data dimensions and instead depends on the complexity of the function class. To the best of our knowledge, this is the first generalization bound for label-shift problems where the labels in the target domain are unknown. Based on this bound, we design a regularized estimator for importance weights that allows us to adapt to the uncertainty in the estimated weights for the small-sample regime. Experiments show that regularized RLLS significantly improves accuracy in the low (target) sample and large-shift regimes compared to previous methods.", "keywords": ["Deep Learning", "Domain Adaptation", "Label Shift", "Importance Weights", "Generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1592/Authors"], "authors": ["Anonymous"], "TL;DR": "A practical and provably guaranteed approach   for efficiently training a classifier when there is a label shift between Source and Target", "pdf": "/pdf/2464f0c59fe78effe3469ff7d1d7d2c51d49c06d.pdf", "paperhash": "anonymous|regularized_learning_for_domain_adaptation_under_label_shifts", "_bibtex": "@inproceedings{    \nanonymous2019regularized,    \ntitle={Regularized Learning for  Domain Adaptation under Label Shifts},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl0r3R9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SylCrnCcFX", "original": "Hyl5Mc3qtX", "number": 1591, "cdate": 1538088005971, "ddate": null, "tcdate": 1538088005971, "tmdate": 1538156135399, "tddate": null, "forum": "SylCrnCcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards Robust, Locally Linear Deep Networks", "abstract": "Deep networks realize complex mappings that are often understood by their locally linear behavior around or at points of interest. For example, we use the derivative of the mapping with respect to its inputs for sensitivity analysis, or to explain (obtain coordinate relevance for) a prediction. One key challenge is that such derivates are themselves inherently unstable. In this paper, we propose a new learning problem to encourage deep networks to have stable derivatives over larger regions. While the problem is challenging in general, we focus on networks with piecewise linear activation functions. Our algorithm consists of an inference step that identifies a region around a point where linear approximation is provably stable, and an optimization step to expand such regions. We propose a novel relaxation to scale the algorithm to realistic models. We demonstrate algorithm and the resulting solutions with residual and recurrent networks on image and sequence datasets.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1591/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8f8155f743b1efbff5ec591e7a27c6100f849288.pdf", "paperhash": "anonymous|towards_robust_locally_linear_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Robust, Locally Linear Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SylCrnCcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xAH2RqK7", "original": "SkgjyZRcKm", "number": 1590, "cdate": 1538088005802, "ddate": null, "tcdate": 1538088005802, "tmdate": 1538156135179, "tddate": null, "forum": "H1xAH2RqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Adversarial Models for Learning Private and Fair Representations", "abstract": "We present Generative Adversarial Privacy and Fairness (GAPF), a data-driven framework for learning private and fair representations. GAPF leverages recent advancements in adversarial learning to allow a data holder to learn \"universal\" representations that decouple a set of sensitive attributes from the rest of the dataset. Under GAPF, finding the optimal privacy mechanism is formulated as a constrained minimax game between a private/fair encoder and an adversary. We show that for appropriately chosen adversarial loss functions, GAPF provides privacy guarantees against strong information-theoretic adversaries and enforces demographic parity. We also evaluate the performance of GAPF on multi-dimensional Gaussian mixture models and real datasets, and show how a designer can certify that representations learned under an adversary with a fixed architecture perform well against more complex adversaries. ", "keywords": ["Data Privacy", "Fairness", "Adversarial Learning", "Generative Adversarial Networks", "Minimax Games", "Information Theory"], "authorids": ["ICLR.cc/2019/Conference/Paper1590/Authors"], "authors": ["Anonymous"], "TL;DR": "We present Generative Adversarial Privacy and Fairness (GAPF), a data-driven framework for learning private and fair representations with certified privacy/fairness guarantees", "pdf": "/pdf/b620d25287031201236e900d3c6f1534fe1906b2.pdf", "paperhash": "anonymous|generative_adversarial_models_for_learning_private_and_fair_representations", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Adversarial Models for Learning Private and Fair Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xAH2RqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeABnCqKQ", "original": "BJe1HWOtK7", "number": 1589, "cdate": 1538088005641, "ddate": null, "tcdate": 1538088005641, "tmdate": 1538156134967, "tddate": null, "forum": "HJeABnCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Adversarial Self-Imitation Learning", "abstract": "This paper explores a simple regularizer for reinforcement learning by proposing Generative Adversarial Self-Imitation Learning (GASIL), which encourages the agent to imitate past good trajectories via generative adversarial imitation learning framework. Instead of directly maximizing rewards, GASIL focuses on reproducing past good trajectories, which can potentially make long-term credit assignment easier when rewards are sparse and delayed. GASIL can be easily combined with any policy gradient objective by using GASIL as a learned reward shaping function. Our experimental results show that GASIL improves the performance of proximal policy optimization on 2D Point Mass and MuJoCo environments with delayed reward and stochastic dynamics.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1589/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ecd2ae93ec2b48e8629064b717eb460869864e25.pdf", "paperhash": "anonymous|generative_adversarial_selfimitation_learning", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Adversarial Self-Imitation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeABnCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyVpB2RqFX", "original": "HyeS8-RqFX", "number": 1588, "cdate": 1538088005479, "ddate": null, "tcdate": 1538088005479, "tmdate": 1538156134749, "tddate": null, "forum": "SyVpB2RqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "INFORMATION MAXIMIZATION AUTO-ENCODING", "abstract": "We propose the Information Maximization Autoencoder (IMAE), an information theoretic approach to simultaneously learn continuous and discrete representations in an unsupervised setting. Unlike the Variational Autoencoder (VAE) framework, IMAE starts from a stochastic encoder that seeks to map each input data to a hy- brid discrete and continuous representation with the objective of maximizing the mutual information between the data and the representation. A decoder is included for approximating the posterior distribution of the data given their representations, where a high fidelity approximation can be achieved by leveraging our informa- tive learned representations. We show that our objective is theoretically valid and provides a principled framework for understanding the tradeoffs among the infor- mativeness of each representation factor, disentanglement of representations, and the decoding quality.", "keywords": ["Information maximization", "unsupervised learning of hybrid of discrete and continuous representations"], "authorids": ["ICLR.cc/2019/Conference/Paper1588/Authors"], "authors": ["Anonymous"], "TL;DR": "Information theoretical approach for unsupervised learning of unsupervised learning of a hybrid of discrete and continuous representations, ", "pdf": "/pdf/11b48aa95023a16a7d64b01f9551ee9048d4ffa5.pdf", "paperhash": "anonymous|information_maximization_autoencoding", "_bibtex": "@inproceedings{    \nanonymous2019information,    \ntitle={INFORMATION MAXIMIZATION AUTO-ENCODING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyVpB2RqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJf6BhAqK7", "original": "S1gVAfRqtQ", "number": 1587, "cdate": 1538088005312, "ddate": null, "tcdate": 1538088005312, "tmdate": 1538156134546, "tddate": null, "forum": "SJf6BhAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way).  To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs.  We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. BANDE achieves a) state-of-the-art results on semi-supervised classification of Omniglot and mini-ImageNet, b)impressive 75% classification accuracy on the 1692-way, 10-shot classification task of Omniglot while only training for 5-way 1-shot classification, c)94.37% accuracy on CIFAR-10 by episodic optimization, comparable to state-of-the-art supervised learning techniques, and d) strong unsupervised clustering performance, with the ability to discover character classes given no character supervision.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "authors": ["Anonymous"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/8b90731d89361b7fe376429b11976154132da888.pdf", "paperhash": "anonymous|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@inproceedings{    \nanonymous2019variadic,    \ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJf6BhAqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1faSn0qY7", "original": "rklzyMA5FQ", "number": 1586, "cdate": 1538088005143, "ddate": null, "tcdate": 1538088005143, "tmdate": 1538156134335, "tddate": null, "forum": "H1faSn0qY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DL2: Training and Querying Neural Networks with Logic", "abstract": "We present DL2, a system for training and querying neural networks with logical constraints. The key idea is to translate these constraints into a differentiable loss with desirable mathematical properties and to then either train with this loss in an iterative manner or to use the loss for querying the network for inputs subject to the constraints. We empirically demonstrate that DL2 is effective in both training and querying scenarios, across a range of constraints and data sets.", "keywords": ["neural networks", "training with constraints", "querying networks", "semantic training"], "authorids": ["ICLR.cc/2019/Conference/Paper1586/Authors"], "authors": ["Anonymous"], "TL;DR": "A differentiable loss for logic constraints for training and querying neural networks.", "pdf": "/pdf/076107e45aefed914e05fc9e707d454c588c71c8.pdf", "paperhash": "anonymous|dl2_training_and_querying_neural_networks_with_logic", "_bibtex": "@inproceedings{    \nanonymous2019dl2:,    \ntitle={DL2: Training and Querying Neural Networks with Logic},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1faSn0qY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgTHnActQ", "original": "S1gEek2qKQ", "number": 1585, "cdate": 1538088004968, "ddate": null, "tcdate": 1538088004968, "tmdate": 1538156134117, "tddate": null, "forum": "HJgTHnActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Local Image-to-Image Translation via Pixel-wise Highway Adaptive Instance Normalization", "abstract": "Recently, image-to-image translation has seen a significant success. Among them, image translation based on an exemplar image, which contains the target style information, has been popular, owing to its capability to handle multimodality as well as its suitability for practical use. However, most of the existing methods extract the style information from an entire exemplar and apply it to the entire input image, which introduces excessive image translation in irrelevant image regions. In response, this paper proposes a novel approach that jointly extracts out the local masks of the input image and the exemplar as targeted regions to be involved for image translation. In particular, the main novelty of our model lies in (1) co-segmentation networks for local mask generation and (2) the local mask-based highway adaptive instance normalization technique. We demonstrate the quantitative and the qualitative evaluation results to show the advantages of our proposed approach. Finally, our code is available at https://github.com/WonwoongCho/Highway-Adaptive-Instance-Normalization.", "keywords": ["image to image translation", "image translation", "exemplar"], "authorids": ["ICLR.cc/2019/Conference/Paper1585/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/31b2539dfa6a6c2910e19050440622918af094e3.pdf", "paperhash": "anonymous|local_imagetoimage_translation_via_pixelwise_highway_adaptive_instance_normalization", "_bibtex": "@inproceedings{    \nanonymous2019local,    \ntitle={Local Image-to-Image Translation via Pixel-wise Highway Adaptive Instance Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgTHnActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylTBhA5tQ", "original": "ByxzSCs5K7", "number": 1584, "cdate": 1538088004802, "ddate": null, "tcdate": 1538088004802, "tmdate": 1538156133910, "tddate": null, "forum": "HylTBhA5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Limitations of Adversarial Training and the Blind-Spot Attack", "abstract": "The adversarial training procedure proposed by Madry et. al. is one of the most effective methods to defend against adversarial examples on deep neuron networks (DNNs). Despite being very effective on MNIST, adversarial training on larger datasets like CIFAR and ImageNet achieves much worse results. In our paper, we shed some lights on the practicality and hardness of adversarial training by first showing that the effectiveness of adversarial training procedure on test set has a strong correlation with the distance between the test point and the manifold of training data. The test examples that are relatively far away from the distribution of training dataset are more likely to be vulnerable to adversarial examples. Consequentially, adversarial training based defense is susceptible to a new class of attacks (\u201cblind-spot attack\u201d) where the input image resides in a \u201cblind-spot\u201d in the empirical distribution of training data but is still on the ground-truth data manifold. For MNIST, we found that these blind-spots can be easily found by simply scaling and shifting image pixel values. Most importantly, for large datasets with high dimensional and complex data manifold (CIFAR, ImageNet, etc), the existence of blind-spots in adversarial training makes the defense on any valid test examples almost impossible due to the curse of dimensionality.", "keywords": ["Adversarial Examples", "Adversarial Training", "Blind-Spot Attack"], "authorids": ["ICLR.cc/2019/Conference/Paper1584/Authors"], "authors": ["Anonymous"], "TL;DR": " We show that the effectiveness of adversarial training procedure on test set has a strong correlation with the distance between the test point and the manifold of training data.", "pdf": "/pdf/dbf39ee0dbdc55c7eb50fa903193136f1ce98dec.pdf", "paperhash": "anonymous|the_limitations_of_adversarial_training_and_the_blindspot_attack", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Limitations of Adversarial Training and the Blind-Spot Attack},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylTBhA5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gTShAct7", "original": "HJlhT3T5K7", "number": 1583, "cdate": 1538088004639, "ddate": null, "tcdate": 1538088004639, "tmdate": 1538156133696, "tddate": null, "forum": "B1gTShAct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Learn without Forgetting By Maximizing Transfer and Minimizing Interference", "abstract": "Lack of performance when it comes to continual learning over non-stationary distributions of data remains a major challenge in scaling neural network learning to more human realistic settings. In this work we propose a new conceptualization of the continual learning problem in terms of a trade-off between transfer and interference. We then propose a new algorithm, Meta-Experience Replay (MER), that directly exploits this view by combining experience replay with optimization based meta-learning. This method learns parameters that make interference based on future gradients less likely and transfer based on future gradients more likely. We conduct experiments across continual lifelong supervised learning benchmarks and non-stationary reinforcement learning environments demonstrating that our approach consistently outperforms recently proposed baselines for continual learning. Our experiments show that the gap between the performance of MER and baseline algorithms grows both as the environment gets more non-stationary and as the fraction of the total experiences stored gets smaller. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1583/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1344be41679c5313a4a0ef0bbcdee3daba037261.pdf", "paperhash": "anonymous|learning_to_learn_without_forgetting_by_maximizing_transfer_and_minimizing_interference", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Learn without Forgetting By Maximizing Transfer and Minimizing Interference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gTShAct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJehSnCcFX", "original": "rye6KapqtQ", "number": 1582, "cdate": 1538088004477, "ddate": null, "tcdate": 1538088004477, "tmdate": 1538156133488, "tddate": null, "forum": "HJehSnCcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Inference of unobserved event streams with neural Hawkes particle smoothing", "abstract": "Events that we observe in the world may be caused by other, unobserved events. We consider sequences of discrete events in continuous time. When only some of the events are observed, we propose particle smoothing to infer the missing events. Particle smoothing is an extension of particle filtering in which proposed events are conditioned on the future as well as the past. For our setting, we develop a novel proposal distribution that is a type of continuous-time bidirectional LSTM. We use the sampled particles in an approximate minimum Bayes risk decoder that outputs a single low-risk prediction of the missing events. We experiment in multiple synthetic and real domains, modeling the complete sequences in each domain with a neural Hawkes process (Mei & Eisner, 2017). On held-out incomplete sequences, our method is effective at inferring the ground-truth unobserved events. In particular, particle smoothing consistently improves upon particle filtering, showing the benefit of training a bidirectional proposal distribution.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1582/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/369ede3e44dc5cb188d7bb1b35d64e4b14ae0654.pdf", "paperhash": "anonymous|inference_of_unobserved_event_streams_with_neural_hawkes_particle_smoothing", "_bibtex": "@inproceedings{    \nanonymous2019inference,    \ntitle={Inference of unobserved event streams with neural Hawkes particle smoothing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJehSnCcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxnHhRqFm", "original": "ryl8EsY9tm", "number": 1581, "cdate": 1538088004311, "ddate": null, "tcdate": 1538088004311, "tmdate": 1538156133282, "tddate": null, "forum": "ryxnHhRqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Global-to-local Memory Pointer Networks for Task-Oriented Dialogue", "abstract": "End-to-end task-oriented dialogue is challenging since knowledge bases are usually large, dynamic and hard to incorporate into a learning framework. We propose the global-to-local memory pointer (GLMP) networks to address this issue. In our model, a global memory encoder and a local memory decoder are proposed to share an external knowledge. The encoder encodes dialogue history, modifies global contextual representation that is shared with the decoder, and generates a global memory pointer. The decoder first generates a sketch response with unfilled slots. Next, it passes the global memory pointer to filter the external knowledge for relevant information, then instantiates the slots via the local memory pointers which points to specific entries in the external knowledge. We empirically show that our model can improve copy accuracy and mitigate the common out-of-vocabulary problem. As a result, GLMP is able to improve over the previous state-of-the-art models in both simulated bAbI Dialogue and human-human Stanford Multi-domain Dialogue datasets on automatic and human evaluation.", "keywords": ["pointer networks", "memory networks", "task-oriented dialogue systems", "natural language processing"], "authorids": ["ICLR.cc/2019/Conference/Paper1581/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a global memory encoder and a global memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. ", "pdf": "/pdf/c39f17b482fa7078f104ab28a09f512d00f51d1c.pdf", "paperhash": "anonymous|globaltolocal_memory_pointer_networks_for_taskoriented_dialogue", "_bibtex": "@inproceedings{    \nanonymous2019global-to-local,    \ntitle={Global-to-local Memory Pointer Networks for Task-Oriented Dialogue},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxnHhRqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlnB3C5Ym", "original": "SygFAapcYX", "number": 1580, "cdate": 1538088004145, "ddate": null, "tcdate": 1538088004145, "tmdate": 1538156133076, "tddate": null, "forum": "rJlnB3C5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Rethinking the Value of Network Pruning", "abstract": "Network pruning is widely used for reducing the heavy computational cost of deep networks. A typical pruning algorithm is a three-stage pipeline, i.e., training (a large model), pruning and fine-tuning, and each of the three stages is considered as indispensable. In this work, we make several surprising observations which contradict common beliefs. For all the six state-of-the-art pruning algorithms we examined, fine-tuning a pruned model only gives comparable or even worse performance than training that model with randomly initialized weights. For pruning algorithms which assume a predefined architecture of the target pruned network, one can completely get rid of the pipeline and directly train the target network from scratch. Our observations are consistent for a wide variety of pruning algorithms with multiple network architectures, datasets and tasks. Our results have several implications: 1) training an over-parameterized model  is not necessary  to obtain an efficient final model, 2) learned ``important'' weights of the large model are not necessarily helpful for the small pruned model, 3)  the pruned architecture itself, rather than a set of inherited ``important'' weights, is what leads to the efficiency benefit in the final model, which suggests that some pruning algorithms could be seen as performing network architecture search.", "keywords": ["network pruning", "network compression", "architecture search", "train from scratch"], "authorids": ["ICLR.cc/2019/Conference/Paper1580/Authors"], "authors": ["Anonymous"], "TL;DR": "In network pruning, fine-tuning a pruned model only gives comparable or worse performance than training it from scratch.", "pdf": "/pdf/14c162c4a573be29ea7c977c9d4c3a502c0a82d9.pdf", "paperhash": "anonymous|rethinking_the_value_of_network_pruning", "_bibtex": "@inproceedings{    \nanonymous2019rethinking,    \ntitle={Rethinking the Value of Network Pruning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlnB3C5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1x3SnAcYQ", "original": "Bye5qIacK7", "number": 1579, "cdate": 1538088003971, "ddate": null, "tcdate": 1538088003971, "tmdate": 1538156132866, "tddate": null, "forum": "H1x3SnAcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Better Baseline for Second Order Gradient Estimation in Stochastic Computation Graphs", "abstract": "Motivated by the need for higher order gradients in multi-agent reinforcement learning and meta-learning, this paper studies the construction of baselines for second order Monte Carlo gradient estimators in order to reduce the sample variance. Following the construction of a stochastic computation graph (SCG), the Infinitely Differentiable Monte-Carlo Estimator (DiCE) can generate correct estimates of arbitrary order gradients through differentiation. However, a baseline term that serves as a control variate for reducing variance is currently provided only for first order gradient estimation, limiting the utility of higher-order gradient estimates. To improve the sample efficiency of DiCE, we propose a new baseline term for higher order gradient estimation. This term may be easily included in the objective, and produces unbiased variance-reduced estimators under (automatic) differentiation, without affecting the estimate of the objective itself or of the first order gradient. We provide theoretical analysis and numerical evaluations of our baseline term, which demonstrate that it can dramatically reduce the variance of second order gradient estimators produced by DiCE. This computational tool can be easily used to estimate second order gradients with unprecedented efficiency wherever automatic differentiation is utilised, and has the potential to unlock applications of higher order gradients in reinforcement learning and meta-learning.", "keywords": ["Reinforcement learning", "meta-learning", "higher order derivatives", "gradient estimation", "stochastic computation graphs"], "authorids": ["ICLR.cc/2019/Conference/Paper1579/Authors"], "authors": ["Anonymous"], "TL;DR": "We extend the DiCE formalism of higher order gradient estimation with a new baseline for variance reduction of second order derivatives, improving sample efficiency by two orders of magnitude. ", "pdf": "/pdf/932da89ced7b4d18614d2a9e13fad9659305985e.pdf", "paperhash": "anonymous|a_better_baseline_for_second_order_gradient_estimation_in_stochastic_computation_graphs", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Better Baseline for Second Order Gradient Estimation in Stochastic Computation Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1x3SnAcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxhB3CcK7", "original": "Hyl3WuT5FQ", "number": 1578, "cdate": 1538088003804, "ddate": null, "tcdate": 1538088003804, "tmdate": 1538156132655, "tddate": null, "forum": "ryxhB3CcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Neural-Symbolic Models for Interpretable Visual Question Answering", "abstract": "We propose a new class of probabilistic neural-symbolic models for visual question answering (VQA) that provide interpretable explanations of their decision making in the form of programs, given a small annotated set of human programs. The key idea of our approach is to learn a rich latent space which effectively propagates program annotations from known questions to novel questions. We do this by formalizing prior work on VQA, called module networks (Andreas, 2016) as discrete, structured, latent variable models on the joint distribution over questions and answers given images, and devise a procedure to train the model effectively. Our results on a dataset of compositional questions about SHAPES (Andreas, 2016) show that our model generates more interpretable programs and obtains better accuracy on VQA in the low-data regime than prior work. ", "keywords": ["Neural-symbolic models", "visual question answering", "reasoning", "interpretability", "graphical models", "variational inference"], "authorids": ["ICLR.cc/2019/Conference/Paper1578/Authors"], "authors": ["Anonymous"], "TL;DR": "A probabilistic neural symbolic model with a latent program space, for more interpretable question answering", "pdf": "/pdf/345a9804ca5fe0fdc18bca898b48dab9ebafeb08.pdf", "paperhash": "anonymous|probabilistic_neuralsymbolic_models_for_interpretable_visual_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Neural-Symbolic Models for Interpretable Visual Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxhB3CcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl3S2A9t7", "original": "Skg-0h5tt7", "number": 1577, "cdate": 1538088003615, "ddate": null, "tcdate": 1538088003615, "tmdate": 1538156132442, "tddate": null, "forum": "rJl3S2A9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Policy Optimization via Stochastic Recursive Gradient Algorithm", "abstract": "This paper proposes the StochAstic Recursive graAdient Policy Optimization (SARAPO) algorithm based on the SARAH algorithm, which is a novel variance reduction algorithm in machine learning. We provide first some theoretical analysis using stochastic differential equations. Furthermore, rich experiments further exemplify its advantages over existing policy gradient methods such as SVRPO and TRPO from both theory and experiments.\n", "keywords": ["reinforcement learning", "policy gradient", "variance reduction", "stochastic recursive gradient algorithm"], "authorids": ["ICLR.cc/2019/Conference/Paper1577/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes the StochAstic Recursive Gradient Policy Optimization (SARAPO) algorithm based on the novel SARAH method, and exemplifies its advantages over existing policy gradient methods from both theory and experiments.", "pdf": "/pdf/f4de2d7d80d2f9fad804dd84904a75da98c323be.pdf", "paperhash": "anonymous|policy_optimization_via_stochastic_recursive_gradient_algorithm", "_bibtex": "@inproceedings{    \nanonymous2019policy,    \ntitle={Policy Optimization via Stochastic Recursive Gradient Algorithm},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl3S2A9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkesr205t7", "original": "H1l2DJR5tQ", "number": 1576, "cdate": 1538088003445, "ddate": null, "tcdate": 1538088003445, "tmdate": 1538156132237, "tddate": null, "forum": "Hkesr205t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning shared manifold representation of images and attributes for generalized zero-shot learning", "abstract": "The most prior methods of zero-shot learning have realized predicting labels of unseen images by learning a mapping from images to pre-defined class-attributes. However, recent studies show that these approaches severely suffers from the issue of biased prediction under the more realistic generalized zero-shot learning (GZSL) scenarios, i.e., their classifier tends to predict all the examples from both seen and unseen class as one of the seen classes. The cause of this problem is that we can not obtain training data of the unseen class and that the representation of attributes is poor. To solve this, we propose a concept to learn a mapping that embeds both images and attributes to a space that is robust to such representations and generalized even for unseen data, which we refer to shared manifold learning. Furthermore, we propose modality invariant variational autoencoders, which can perform shared manifold learning by training variational autoencoders with both images and attributes as inputs. The empirical validation of well-known datasets in GZSL shows that our method achieves the significantly superior performances to the existing relation-based works.", "keywords": ["zero-shot learning", "variational autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper1576/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b8386bd1ea984a2c7b81e12d8977850e24a88911.pdf", "paperhash": "anonymous|learning_shared_manifold_representation_of_images_and_attributes_for_generalized_zeroshot_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning shared manifold representation of images and attributes for generalized zero-shot learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkesr205t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygjB3AcYX", "original": "ryeveo65tQ", "number": 1575, "cdate": 1538088003278, "ddate": null, "tcdate": 1538088003278, "tmdate": 1538156132026, "tddate": null, "forum": "SygjB3AcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generalized Label Propagation Methods for Semi-Supervised Learning", "abstract": "The key challenge in semi-supervised learning is how to effectively leverage unlabeled data to improve learning performance. The classical label propagation method, despite its popularity, has limited modeling capability in that it only exploits graph information for making predictions. In this paper, we consider label propagation from a graph signal processing perspective and decompose it into three components: signal, filter, and classifier. By extending the three components, we propose a simple generalized label propagation (GLP) framework for semi-supervised learning. GLP naturally integrates graph and data feature information, and offers the flexibility of selecting appropriate filters and domain-specific classifiers for different applications. Interestingly, GLP also provides new insight into the popular graph convolutional network and elucidates its working mechanisms. Extensive experiments on three citation networks, one knowledge graph, and one image dataset demonstrate the efficiency and effectiveness of GLP.", "keywords": ["semi-supervised learning", "label propagation"], "authorids": ["ICLR.cc/2019/Conference/Paper1575/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cfb7db7f0a214bfcbc0555687fd2b2cc076a762f.pdf", "paperhash": "anonymous|generalized_label_propagation_methods_for_semisupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019generalized,    \ntitle={Generalized Label Propagation Methods for Semi-Supervised Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygjB3AcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyesB2RqFQ", "original": "H1e8r1CcY7", "number": 1574, "cdate": 1538088003111, "ddate": null, "tcdate": 1538088003111, "tmdate": 1538156131819, "tddate": null, "forum": "HyesB2RqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bridging HMMs and RNNs through Architectural Transformations", "abstract": "A distinct commonality between HMMs and RNNs is that they both learn hidden representations for sequential data. In addition, it has been noted that the backward computation  of  the  Baum-Welch  algorithm  for  HMMs  is  a  special  case  of  the back propagation algorithm used for neural networks (Eisner (2016)).  Do these observations  suggest  that,  despite  their  many apparent  differences,  HMMs  are a special case of RNNs?   In this paper,  we investigate a series of architectural transformations between HMMs and RNNs, both through theoretical derivations and empirical hybridization, to answer this question. In particular, we investigate three key design factors\u2014independence assumptions between the hidden states and the observation, the placement of softmax, and the use of non-linearity\u2014in order to pin down their empirical effects.  We present a comprehensive empirical study to provide insights on the interplay between expressivity and interpretability with respect to language modeling and parts-of-speech induction. ", "keywords": ["rnns", "hmms", "latent variable models", "language modelling", "interpretability", "sequence modelling"], "authorids": ["ICLR.cc/2019/Conference/Paper1574/Authors"], "authors": ["Anonymous"], "TL;DR": "Are HMMs a special case of RNNs? We investigate a series of architectural transformations between HMMs and RNNs, both through theoretical derivations and empirical hybridization and provide new insights.", "pdf": "/pdf/b486ea654c05277b3fdf1e894bf11956a5b8ca77.pdf", "paperhash": "anonymous|bridging_hmms_and_rnns_through_architectural_transformations", "_bibtex": "@inproceedings{    \nanonymous2019bridging,    \ntitle={Bridging HMMs and RNNs through Architectural Transformations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyesB2RqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxjH3R5KQ", "original": "ryxvAnacF7", "number": 1573, "cdate": 1538088002931, "ddate": null, "tcdate": 1538088002931, "tmdate": 1538156131618, "tddate": null, "forum": "ryxjH3R5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Single Shot Neural Architecture Search Via Direct Sparse Optimization", "abstract": "Recently Neural Architecture Search (NAS) has aroused great interest in both academia and industry, however it remains challenging because of its huge and non-continuous search space. Instead of applying evolutionary algorithm or reinforcement learning as previous works, this paper proposes a Direct Sparse Optimization NAS (DSO-NAS) method. In DSO-NAS, we provide a novel model pruning view to NAS problem. In specific, we start from a completely connected block, and then introduce scaling factors to scale the information flow between operations. Next, we impose sparse regularizations to prune useless connections in the architecture. Lastly, we derive an efficient and theoretically sound optimization method to solve it. Our method enjoys both advantages of differentiability and efficiency, therefore can be directly applied to large datasets like ImageNet. Particularly, On CIFAR-10 dataset, DSO-NAS achieves an average test error 2.84%, while on the ImageNet dataset DSO-NAS achieves 25.4% test error under 600M FLOPs with 8 GPUs in 18 hours.", "keywords": ["Neural Architecture Search", "Sparse Optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1573/Authors"], "authors": ["Anonymous"], "TL;DR": "single shot neural architecture search via direct sparse optimization", "pdf": "/pdf/17ae1074f66ce6ca87fc3376b19ad8049e847177.pdf", "paperhash": "anonymous|single_shot_neural_architecture_search_via_direct_sparse_optimization", "_bibtex": "@inproceedings{    \nanonymous2019single,    \ntitle={Single Shot Neural Architecture Search Via Direct Sparse Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxjH3R5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxsS3A5Km", "original": "Syl32na9tQ", "number": 1572, "cdate": 1538088002765, "ddate": null, "tcdate": 1538088002765, "tmdate": 1538156131413, "tddate": null, "forum": "ryxsS3A5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Continual Learning via Explicit Structure Learning", "abstract": "Despite recent advances in deep learning, neural networks suffer catastrophic forgetting when tasks are learned sequentially. In this paper, we propose a conceptually simple and general framework for continual learning, where structure optimization is considered explicitly during learning. We implement this idea by separating the structure and parameter learning. During structure learning, the model optimizes for the best structure for the current task. The model learns when to reuse or modify structure from previous tasks, or create new ones in case necessary. The model parameters are then estimated with the optimal structure. Empirically, we found that our approach leads to sensible structures when learning multiple tasks continuously. Additionally, catastrophic forgetting is also largely alleviated from explicit learning of structures. Our method also outperforms all other baselines on the Visual Domain Decathlon Dataset with reasonable parameter overhead.", "keywords": ["continuous learning", "catastrophic forgetting", "architecture learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1572/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c9c77455921e1ede4a442d0c314e4264d3e7a555.pdf", "paperhash": "anonymous|continual_learning_via_explicit_structure_learning", "_bibtex": "@inproceedings{    \nanonymous2019continual,    \ntitle={Continual Learning via Explicit Structure Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxsS3A5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxiHnCqKQ", "original": "HylNAGa9YX", "number": 1571, "cdate": 1538088002598, "ddate": null, "tcdate": 1538088002598, "tmdate": 1538156131205, "tddate": null, "forum": "SJxiHnCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MCTSBug: Generating Adversarial Text Sequences via Monte Carlo Tree Search and Homoglyph Attack", "abstract": "Crafting adversarial examples on discrete inputs like text sequences is fundamentally different from generating such examples for continuous inputs like images. This paper tries to answer the question: under a black-box setting, can we create adversarial examples automatically to effectively fool deep learning classifiers on texts by making imperceptible changes? Our answer is a firm yes. Previous efforts mostly replied on using gradient evidence, and they are less effective either due to finding the nearest neighbor word (wrt meaning) automatically is difficult or relying heavily on hand-crafted linguistic rules. We, instead, use Monte Carlo tree search (MCTS) for finding the most important few words to perturb and perform homoglyph attack by replacing one character in each selected word with a symbol of identical shape.  Our novel algorithm, we call MCTSBug, is black-box and extremely effective at the same time. Our experimental results indicate that MCTSBug can fool deep learning classifiers at the success rates of 95% on seven large-scale benchmark datasets, by perturbing only a few characters.  Surprisingly, MCTSBug, without relying on gradient information at all, is more effective than the gradient-based white-box baseline. Thanks to the nature of homoglyph attack, the generated adversarial perturbations are almost imperceptible to human eyes. ", "keywords": ["Adversarial sample", "Text", "Black-box", "MCTS", "Homoglyph"], "authorids": ["ICLR.cc/2019/Conference/Paper1571/Authors"], "authors": ["Anonymous"], "TL;DR": "Use Monte carlo Tree Search and Homoglyphs to generate indistinguishable adversarial samples on text data", "pdf": "/pdf/3b7dc1da510d6522620e1c54f017587e13438f3a.pdf", "paperhash": "anonymous|mctsbug_generating_adversarial_text_sequences_via_monte_carlo_tree_search_and_homoglyph_attack", "_bibtex": "@inproceedings{    \nanonymous2019mctsbug:,    \ntitle={MCTSBug: Generating Adversarial Text Sequences via Monte Carlo Tree Search and Homoglyph Attack},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxiHnCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByzcS3AcYX", "original": "ryeyFG0qYQ", "number": 1570, "cdate": 1538088002430, "ddate": null, "tcdate": 1538088002430, "tmdate": 1538156130996, "tddate": null, "forum": "ByzcS3AcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TTS-GAN: a generative adversarial network for style modeling in a text-to-speech system", "abstract": "The modeling of style when synthesizing natural human speech from text has been the focus of significant attention. Some state-of-the-art approaches train an encoder-decoder network on paired text and audio samples (x_txt, x_aud) by encouraging its output to reconstruct x_aud. The synthesized audio waveform is expected to contain the verbal content of x_txt and the auditory style of x_aud. Unfortunately, modeling style in TTS is somewhat under-determined and training models with a reconstruction loss alone is insufficient to disentangle content and style from other factors of variation. In this work, we introduce TTS-GAN, an end-to-end TTS model that offers enhanced content-style disentanglement ability and controllability. We achieve this by combining a pairwise training procedure, an adversarial game, and a collaborative game into one training scheme. The adversarial game concentrates the true data distribution, and the collaborative game minimizes the distance between real samples and generated samples in both the original space and the latent space. As a result, TTS-GAN delivers a highly controllable generator, and a disentangled representation. Benefiting from the separate modeling of style and content, TTS-GAN can generate human fidelity speech that satisfies the desired style conditions. TTS-GAN achieves start-of-the-art results across multiple tasks, including style transfer (content and style swapping), emotion modeling, and identity transfer (fitting a new speaker's voice).", "keywords": ["Text-To-Speech synthesis", "GANs"], "authorids": ["ICLR.cc/2019/Conference/Paper1570/Authors"], "authors": ["Anonymous"], "TL;DR": "a generative adversarial network for style modeling in a text-to-speech system", "pdf": "/pdf/c63bcac36efffb8055642e07663d0d5198c03c0e.pdf", "paperhash": "anonymous|ttsgan_a_generative_adversarial_network_for_style_modeling_in_a_texttospeech_system", "_bibtex": "@inproceedings{    \nanonymous2019tts-gan:,    \ntitle={TTS-GAN: a generative adversarial network for style modeling in a text-to-speech system},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByzcS3AcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJfcrn0qKX", "original": "ryxdpGCctQ", "number": 1569, "cdate": 1538088002249, "ddate": null, "tcdate": 1538088002249, "tmdate": 1538156130788, "tddate": null, "forum": "SJfcrn0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Realistic Adversarial Examples in 3D Meshes", "abstract": "Highly expressive models especially deep neural networks (DNNs) have been widely applied to various applications and achieved increasing success. However, recent studies show that such machine learning models appear to be vulnerable against adversarial examples. So far adversarial examples have been heavily explored for 2D images, while few work has tried to understand the vulnerabilities of 3D objects which exist in real world, where 3D objects are projected to 2D domains by photo taking for different learning (recognition) tasks. In this paper we consider adversarial behaviors in practical scenarios by manipulating the shape and texture of a given 3D mesh representation of an object. Our goal is to project the optimized \"adversarial meshes\" to 2D with photo-realistic rendering engine, and still able to mislead different machine learning models.\nExtensive experiments show that by generating unnoticeable 3D adversarial perturbation on shape or texture for a 3D mesh, the corresponding projected 2D instance can either lead classifiers to misclassify the victim object arbitrary malicious target, or hide any target object within the scene from state-of-the-art object detectors. We conduct human studies to show that our optimized adversarial 3D perturbation is highly unnoticeable for human vision systems. In addition to the subtle perturbation on a given 3D mesh, we also propose to synthesize a realistic 3D mesh to put in a scene mimicking similar rendering conditions and therefore attack existing objects within it. In-depth analysis for transferability among different 3D rendering engines and vulnerable regions of meshes are provided to help better understand adversarial behaviors in practice and motivate potential defenses. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1569/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/03109e809e97c0af6b7d9c29fe232b5e3e5eca25.pdf", "paperhash": "anonymous|realistic_adversarial_examples_in_3d_meshes", "_bibtex": "@inproceedings{    \nanonymous2019realistic,    \ntitle={Realistic Adversarial Examples in 3D Meshes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfcrn0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxcHnRqYQ", "original": "r1eVxIlqKQ", "number": 1568, "cdate": 1538088002076, "ddate": null, "tcdate": 1538088002076, "tmdate": 1538156130580, "tddate": null, "forum": "rJxcHnRqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Local Binary Pattern Networks for Character Recognition", "abstract": "Memory and computation efficient deep learning architectures are crucial to the continued proliferation of machine learning capabilities to new platforms and systems. Binarization of operations in convolutional neural networks has shown promising results in reducing the model size and computing efficiency. \nIn this paper, we tackle the character recognition problem using a strategy different from the existing literature by proposing local binary pattern networks or LBPNet that can learn and perform bit-wise operations in an end-to-end fashion. LBPNet uses local binary comparisons and random projection in place of conventional convolution (or approximation of convolution) operations, providing important means to improve memory and speed efficiency that is particularly suited for small footprint devices and hardware accelerators. These operations can be implemented efficiently on different platforms including direct hardware implementation. LBPNet demonstrates its particular advantage on the character classification task where the content is composed of strokes. We applied LBPNet to benchmark datasets like MNIST, SVHN, DHCD, ICDAR, and Chars74K and observed encouraging results.", "keywords": ["deep learning", "local binary pattern", "supervised learning", "hardware-friendly"], "authorids": ["ICLR.cc/2019/Conference/Paper1568/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/12add576a4bd28c613238425cd3022178e0a0f6c.pdf", "paperhash": "anonymous|local_binary_pattern_networks_for_character_recognition", "_bibtex": "@inproceedings{    \nanonymous2019local,    \ntitle={Local Binary Pattern Networks for Character Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxcHnRqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJe9rh0cFX", "original": "HJgBavactX", "number": 1567, "cdate": 1538088001887, "ddate": null, "tcdate": 1538088001887, "tmdate": 1538156130379, "tddate": null, "forum": "SJe9rh0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks", "abstract": "Compression is a key step to deploy large neural networks on resource-constrained platforms. As a popular compression technique, quantization constrains the number of distinct weight values and thus reducing the number of bits required to represent and store each weight. In this paper, we study the representation power of quantized neural networks. First, we prove the universal approximability of quantized ReLU networks on a wide class of functions. Then we provide upper bounds on the number of weights and the memory size for a given approximation error bound and the bit-width of weights for function-independent and function-dependent structures. Our results reveal that, to attain an approximation error bound of $\\epsilon$, the number of weights needed by a quantized network is no more than $\\mathcal{O}\\left(\\log^5(1/\\epsilon)\\right)$ times that of an unquantized network. This overhead is of much lower order than the lower bound of the number of weights needed for the error bound, supporting the empirical success of various quantization techniques. To the best of our knowledge, this is the first in-depth study on the complexity bounds of quantized neural networks.", "keywords": ["Quantized Neural Networks", "Universial Approximability", "Complexity Bounds"], "authorids": ["ICLR.cc/2019/Conference/Paper1567/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proves the universal  approximability of quantized ReLU neural networks and puts forward the complexity bound given arbitrary error.", "pdf": "/pdf/a6889afcaa37802578dfd5c02c7312fb38667d07.pdf", "paperhash": "anonymous|on_the_universal_approximability_and_complexity_bounds_of_quantized_relu_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJe9rh0cFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syx9rnRcYm", "original": "HyeQI8C9tX", "number": 1566, "cdate": 1538088001718, "ddate": null, "tcdate": 1538088001718, "tmdate": 1538156130173, "tddate": null, "forum": "Syx9rnRcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS", "abstract": "Over the passage of time Unmanned Autonomous Vehicles (UAVs), especially\nAutonomous flying drones grabbed a lot of attention in Artificial Intelligence.\nSince electronic technology is getting smaller, cheaper and more efficient, huge\nadvancement in the study of UAVs has been observed recently. From monitoring\nfloods, discerning the spread of algae in water bodies to detecting forest trail, their\napplication is far and wide. Our work is mainly focused on autonomous flying\ndrones where we establish a case study towards efficiency, robustness and accuracy\nof UAVs where we showed our results well supported through experiments.\nWe provide details of the software and hardware architecture used in the study. We\nfurther discuss about our implementation algorithms and present experiments that\nprovide a comparison between three different state-of-the-art algorithms namely\nTrailNet, InceptionResnet and MobileNet in terms of accuracy, robustness, power\nconsumption and inference time. In our study, we have shown that MobileNet has\nproduced better results with very less computational requirement and power consumption.\nWe have also reported the challenges we have faced during our work\nas well as a brief discussion on our future work to improve safety features and\nperformance.", "keywords": ["Energy Efficiency", "Autonomous Flying", "Trail Detection"], "authorids": ["ICLR.cc/2019/Conference/Paper1566/Authors"], "authors": ["Anonymous"], "TL;DR": "case study on optimal deep learning model for UAVs", "pdf": "/pdf/4bd81f6bd9cccfb76f9015e4c9c9127300dacacc.pdf", "paperhash": "anonymous|a_case_study_on_optimal_deep_learning_model_for_uavs", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A CASE STUDY ON OPTIMAL DEEP LEARNING MODEL FOR UAVS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syx9rnRcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Ske5r3AqK7", "original": "Byx9hfA9F7", "number": 1565, "cdate": 1538088001537, "ddate": null, "tcdate": 1538088001537, "tmdate": 1538156129965, "tddate": null, "forum": "Ske5r3AqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Poincare Glove: Hyperbolic Word Embeddings", "abstract": "Words are not created equal. In fact, they form an aristocratic graph with a latent hierarchical structure that the next generation of unsupervised learned word embeddings should reveal. In this paper, driven by the notion of delta-hyperbolicity or tree-likeliness of a space, we propose to embed words in a Cartesian product of hyperbolic spaces which we theoretically connect with the Gaussian word embeddings and their Fisher distance. We adapt the well-known Glove algorithm to learn unsupervised word embeddings in this type of Riemannian manifolds. We explain how concepts from the Euclidean space such as parallel transport (used to solve analogy tasks) generalize to this new type of geometry. Moreover, we show that our embeddings exhibit hierarchical and hypernymy detection capabilities. We back up our findings with extensive experiments in which we outperform strong and popular baselines on the tasks of similarity, analogy and hypernymy detection.", "keywords": ["word embeddings", "hyperbolic spaces", "poincare ball", "hypernymy", "analogy", "similarity", "gaussian embeddings"], "authorids": ["ICLR.cc/2019/Conference/Paper1565/Authors"], "authors": ["Anonymous"], "TL;DR": "We embed words in the hyperbolic space and make the connection  with the Gaussian word embeddings.", "pdf": "/pdf/da10247a2010341ae16579a248dc9d176ccc9e3e.pdf", "paperhash": "anonymous|poincare_glove_hyperbolic_word_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019poincare,    \ntitle={Poincare Glove: Hyperbolic Word Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Ske5r3AqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lKS2AqtX", "original": "SJlLk02qFQ", "number": 1564, "cdate": 1538088001362, "ddate": null, "tcdate": 1538088001362, "tmdate": 1538156129758, "tddate": null, "forum": "B1lKS2AqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Eidetic 3D LSTM: A Model for Video Prediction and Beyond", "abstract": "Spatiotemporal predictive learning, though long considered to be a promising self-supervised feature learning method, seldom shows its effectiveness beyond future video prediction. The reason is that it is difficult to learn good representations for both short-term frame dependency and long-term high-level relations. We present a new model, Eidetic 3D LSTM (E3D-LSTM), that integrates 3D convolutions into RNNs. The encapsulated 3D-Conv makes local perceptrons of RNNs motion aware and enables the memory cell to store better short-term features. For long-term relations, we make the present memory state interact with its historical records via a gate-controlled self-attention module. We describe this memory transition mechanism eidetic as it is able to effectively recall the stored memories across multiple timestamps even after long periods of disturbance. We first evaluate the spatiotemporal modeling capability of the E3D-LSTM model on two widely-used future video prediction datasets and achieve the state of the art performance. Then we demonstrate that with a self-supervised auxiliary learning strategy, the E3D-LSTM network performs well on early activity recognition to infer what is happening after observing only limited frames of video.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1564/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8673a20b2867abd797c6fe2a841df073ba6b0528.pdf", "paperhash": "anonymous|eidetic_3d_lstm_a_model_for_video_prediction_and_beyond", "_bibtex": "@inproceedings{    \nanonymous2019eidetic,    \ntitle={Eidetic 3D LSTM: A Model for Video Prediction and Beyond},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lKS2AqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxKH2AcFm", "original": "BkekHR_qFm", "number": 1563, "cdate": 1538088001190, "ddate": null, "tcdate": 1538088001190, "tmdate": 1538156129544, "tddate": null, "forum": "HkxKH2AcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards GAN Benchmarks Which Require Generalization", "abstract": "For many evaluation metrics commonly used as benchmarks for unconditional image generation, trivially memorizing the training set attains a better score than models which are considered state-of-the-art. We clarify a necessary condition for an evaluation metric not to behave this way: estimating the function must require a large sample from the model. In search of such a metric, we turn to neural network divergences (NNDs), which are defined in terms of a neural network trained to distinguish between distributions. These metrics cannot be \"solved\" by training set memorization, while still being perceptually correlated and computationally tractable. We survey past work on using NNDs for evaluation and implement an example black-box metric based on these ideas. Through experimental validation we show that it can effectively measure diversity, sample quality, and generalization.", "keywords": ["evaluation", "generative adversarial networks", "adversarial divergences"], "authorids": ["ICLR.cc/2019/Conference/Paper1563/Authors"], "authors": ["Anonymous"], "TL;DR": "We argue that GAN benchmarks must require a large sample from the model to penalize memorization and investigate whether neural network divergences have this property.", "pdf": "/pdf/22ecb5c2db746e7b9ba7de63c2e8a83a1398e904.pdf", "paperhash": "anonymous|towards_gan_benchmarks_which_require_generalization", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards GAN Benchmarks Which Require Generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxKH2AcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygtHnR5tQ", "original": "BylqmMC9KQ", "number": 1562, "cdate": 1538088001027, "ddate": null, "tcdate": 1538088001027, "tmdate": 1538156129342, "tddate": null, "forum": "HygtHnR5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Adversarial Networks for Extreme Learned Image Compression", "abstract": "We propose a framework for extreme learned image compression based on Generative Adversarial Networks (GANs), obtaining visually pleasing images at significantly lower bitrates than previous methods. This is made possible through our GAN formulation of learned compression combined with a generator/decoder which operates on the full-resolution image and is trained in combination with a multi-scale discriminator. Additionally, if a semantic label map of the original image is available, our method can fully synthesize unimportant regions in the decoded image such as streets and trees from the label map, therefore only requiring the storage of the preserved region and the semantic label map. A user study confirms that for low bitrates, our approach is preferred to state-of-the-art methods, even when they use more than double the bits.", "keywords": ["Learned compression", "generative adversarial networks", "extreme compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1562/Authors"], "authors": ["Anonymous"], "TL;DR": "GAN-based extreme image compression method using less than half the bits of the SOTA engineered codec while preserving visual quality", "pdf": "/pdf/6a576b0feb932eb4717ce7a832c00cee3a967609.pdf", "paperhash": "anonymous|generative_adversarial_networks_for_extreme_learned_image_compression", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Adversarial Networks for Extreme Learned Image Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygtHnR5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylKB3A9Fm", "original": "SJeO6fA5FX", "number": 1561, "cdate": 1538088000857, "ddate": null, "tcdate": 1538088000857, "tmdate": 1538156129141, "tddate": null, "forum": "rylKB3A9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Assessing Generalization in Deep Reinforcement Learning", "abstract": "Deep reinforcement learning (RL) has achieved breakthrough results on many tasks, but has been shown to be sensitive to system changes at test time. As a result, building deep RL agents that generalize has become an active research area. Our aim is to catalyze and streamline community-wide progress on this problem by providing the first benchmark and a common experimental protocol for investigating generalization in RL. Our benchmark contains a diverse set of environments and our evaluation methodology covers both in-distribution and out-of-distribution generalization. To provide a set of baselines for future research, we conduct a systematic evaluation of state-of-the-art algorithms, including those that specifically tackle the problem of generalization. The experimental results indicate that in-distribution generalization may be within the capacity of current algorithms, while out-of-distribution generalization is an exciting challenge for future work.", "keywords": ["reinforcement learning", "generalization", "benchmark"], "authorids": ["ICLR.cc/2019/Conference/Paper1561/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/6bc740e3f1070ceaa8c576a0ca7d77230d236cad.pdf", "paperhash": "anonymous|assessing_generalization_in_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019assessing,    \ntitle={Assessing Generalization in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylKB3A9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xYr3C5t7", "original": "HJe8KQT9Y7", "number": 1560, "cdate": 1538088000696, "ddate": null, "tcdate": 1538088000696, "tmdate": 1538156128916, "tddate": null, "forum": "r1xYr3C5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph2Graph Networks for Multi-Label Classification", "abstract": "Multi-label classification (MLC) is the task of assigning a set of target labels for a given sample. Modeling the combinatorial label interactions in MLC has been along-haul challenge. Recurrent neural network (RNN) based encoder-decoder models have recently shown state-of-the-art performance for solving MLC. However,the sequential nature of modeling label dependencies through an RNN limits its ability in parallel computation, predicting dense labels, and providing interpretable results. In this paper, we propose Graph2Graph Networks, graph neural network models aiming to provide fast, accurate, and interpretable MLC. Graph2Graph networks replace all RNNs in the encoder-decoder architecture with graph attention mechanisms and dispense with autoregressive inference entirely. Our Graph2Graph decoder for MLC uses a modified graph attention network on an unknown and conditional graph to estimate how the labels and label interactions attend to the components of an input. Similarly, the Graph2Graph encoder adapts another graph attention network to learn representations about inputs via an unknown graph. This enables it to freely model interactions among input components and is not limited to sequential inputs. The proposed models are simple, fast, accurate, interpretable,and structure-agnostic (as long as input and output structures can each be described as graphs). Experiments on six real-world MLC datasets show the proposed models outperform autoregressive RNN models across five different metrics with a significant speedup during training and testing time.", "keywords": ["Multi-label Classification", "Graph Neural Networks", "Attention", "Graph Attention"], "authorids": ["ICLR.cc/2019/Conference/Paper1560/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Graph2Graph networks for a fast and accurate way of modelling label dependencies for multi-label classification.", "pdf": "/pdf/b3f60bef04d5cd00be194a51adc9a243cddc0979.pdf", "paperhash": "anonymous|graph2graph_networks_for_multilabel_classification", "_bibtex": "@inproceedings{    \nanonymous2019graph2graph,    \ntitle={Graph2Graph Networks for Multi-Label Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xYr3C5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgKBhA5Y7", "original": "HklMVx0cYQ", "number": 1559, "cdate": 1538088000531, "ddate": null, "tcdate": 1538088000531, "tmdate": 1538156128710, "tddate": null, "forum": "rkgKBhA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average", "abstract": "Presently the most successful approaches to semi-supervised learning are based on consistency regularization, whereby a model is trained to be robust to small perturbations of its inputs and parameters. The consistency loss dramatically improves generalization performance over supervised-only training; however, we show that SGD struggles to converge on the consistency loss and continues to make large steps that lead to changes in predictions on the test data. We show that averaging weights can significantly improve their generalization performance. Motivated by these observations, we propose to train consistency-based methods with Stochastic Weight Averaging (SWA), a recent approach which averages weights along the trajectory of SGD with a modified learning rate schedule. We also propose fast-SWA, which further accelerates convergence by averaging multiple points within each cycle of a cyclical learning rate schedule. With weight averaging, we achieve the best known semi-supervised results on CIFAR-10 and CIFAR-100 over many different settings of training labels. For example, we achieve 5.0% error on CIFAR-10 with only 4000 labels, compared to the previous best result in the literature of 6.3%.", "keywords": ["semi-supervised learning", "computer vision", "classification", "consistency regularization", "flatness", "weight averaging", "stochastic weight averaging"], "authorids": ["ICLR.cc/2019/Conference/Paper1559/Authors"], "authors": ["Anonymous"], "TL;DR": "Consistency-based models for semi-supervised learning do not converge to a single point but continue to explore a diverse set of plausible solutions on the perimeter of a flat region. Weight averaging helps improve generalization performance.", "pdf": "/pdf/762f752f75d44b2d622feda0e4db5ddacac725db.pdf", "paperhash": "anonymous|there_are_many_consistent_explanations_of_unlabeled_data_why_you_should_average", "_bibtex": "@inproceedings{    \nanonymous2019there,    \ntitle={There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgKBhA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeOSnAqYm", "original": "SkgQ2C65Km", "number": 1558, "cdate": 1538088000365, "ddate": null, "tcdate": 1538088000365, "tmdate": 1538156128496, "tddate": null, "forum": "ryeOSnAqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Synthetic Datasets for Neural Program Synthesis", "abstract": "The goal of program synthesis is to automatically generate programs in a particular language from corresponding specifications, e.g. input-output behavior.\nMany current approaches achieve impressive results after training on randomly generated I/O examples in limited domain-specific languages (DSLs), as with string transformations in RobustFill.\nHowever, we empirically discover that applying test input generation techniques for languages with control flow and rich input space causes deep networks to generalize poorly to certain data distributions;\nto correct this, we propose a new methodology for controlling and evaluating the bias of synthetic data distributions over both programs and specifications.\nWe demonstrate, using the Karel DSL and a small Calculator DSL, that training deep networks on these distributions leads to improved cross-distribution generalization performance. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1558/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e88c87f83b18fea3d0a334425679adce77ab7a23.pdf", "paperhash": "anonymous|synthetic_datasets_for_neural_program_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019synthetic,    \ntitle={Synthetic Datasets for Neural Program Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeOSnAqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xdH3CcKX", "original": "rkgR1Sa9Y7", "number": 1557, "cdate": 1538088000194, "ddate": null, "tcdate": 1538088000194, "tmdate": 1538156128288, "tddate": null, "forum": "r1xdH3CcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Predicting the Present and Future States of Multi-agent Systems from Partially-observed Visual Data", "abstract": "We present a method which learns to integrate temporal information, from a learned dynamics model, with ambiguous visual information, from a learned vision model, in the context of interacting agents. Our method is based on a graph-structured variational recurrent neural network, which is trained end-to-end to infer the current state of the (partially observed) world, as well as to forecast future states. We show that our method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine.", "keywords": ["Dynamics modeling", "partial observations", "multi-agent interactions", "predictive models"], "authorids": ["ICLR.cc/2019/Conference/Paper1557/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a method which learns to integrate temporal information and ambiguous visual information in the context of interacting agents.", "pdf": "/pdf/93e550ba610fe66dd383d499ad2e4a5d5153a357.pdf", "paperhash": "anonymous|predicting_the_present_and_future_states_of_multiagent_systems_from_partiallyobserved_visual_data", "_bibtex": "@inproceedings{    \nanonymous2019predicting,    \ntitle={Predicting the Present and Future States of Multi-agent Systems from Partially-observed Visual Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xdH3CcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xurn0cKQ", "original": "Hkgzb6cqYQ", "number": 1556, "cdate": 1538088000027, "ddate": null, "tcdate": 1538088000027, "tmdate": 1538156128081, "tddate": null, "forum": "r1xurn0cKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Correction Networks: Meta-Learning for Zero-Shot Learning", "abstract": "We propose a model that learns to perform zero-shot classification using a meta-learner that is trained to anticipate and correct errors based on the learner's training data. The model consists of two modules: a task module that supplies an initial prediction, and a correction module that updates the prediction. The task module is the learner and the correction module is the meta-learner. The correction module takes as input the task module's training data, input, and initial prediction, and updates the initial prediction to be closer to the target value. We demonstrate that this approach leads to state-of-the-art performance on fine-grained zero-shot classification on natural language class descriptions on the CUB and NAB datasets. Correction Networks are independent of the architectures of the modules and can be used for problems for which an updated prediction can be obtained by applying a correction. ", "keywords": ["zero-shot learning", "image classification", "fine-grained classification", "meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1556/Authors"], "authors": ["Anonymous"], "TL;DR": "A model learns to perform zero-shot classification using a meta-learner that is trained to anticipate and correct errors based on the learner's training data.", "pdf": "/pdf/e1eb45f1c8b7793b1385a1d64fb3657cd5e14768.pdf", "paperhash": "anonymous|correction_networks_metalearning_for_zeroshot_learning", "_bibtex": "@inproceedings{    \nanonymous2019correction,    \ntitle={Correction Networks: Meta-Learning for Zero-Shot Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xurn0cKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byldr3RqKX", "original": "HklGrCTqK7", "number": 1555, "cdate": 1538087999845, "ddate": null, "tcdate": 1538087999845, "tmdate": 1538156127872, "tddate": null, "forum": "Byldr3RqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Looking inside the black box: assessing the modular structure of deep generative models with counterfactuals", "abstract": "Deep generative models such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) are important tools to capture and investigate the properties of complex empirical data. However, the complexity of their inner\nelements makes their functionment challenging to assess and modify. In this respect, these architectures behave as black box models. In order to better understand the function of such networks, we analyze their modularity based on the counterfactual manipulation of their internal variables. Our experiments on the generation of human faces with VAEs and GANs support that modularity between activation maps distributed over channels of generator architectures is achieved to some degree, can be used to better understand how these systems operate and edit the content of generated images.", "keywords": ["generatice models", "causality", "disentangled representations"], "authorids": ["ICLR.cc/2019/Conference/Paper1555/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate the modularity of deep generative models.", "pdf": "/pdf/550264ede07ed6db558e20cf661fa64c75fe093c.pdf", "paperhash": "anonymous|looking_inside_the_black_box_assessing_the_modular_structure_of_deep_generative_models_with_counterfactuals", "_bibtex": "@inproceedings{    \nanonymous2019looking,    \ntitle={Looking inside the black box: assessing the modular structure of deep generative models with counterfactuals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byldr3RqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1e_H3AqYQ", "original": "SygovbaqF7", "number": 1554, "cdate": 1538087999682, "ddate": null, "tcdate": 1538087999682, "tmdate": 1538156127665, "tddate": null, "forum": "S1e_H3AqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploiting Cross-Lingual Subword Similarities in Low-Resource Document Classification", "abstract": "Text classification must sometimes be applied in situations with no training data in a target language.  However, training data may be available in a related language.  We introduce a cross-lingual document classification framework CACO between related language pairs.  To best use limited training data, our transfer learning scheme exploits cross-lingual subword similarity by jointly training a character-based embedder and a word-based classifier.  The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors.  We use a joint character representation for both the source language and the target language, which allows the embedder to generalize knowledge about source language words to target language words with similar forms.  We propose a multi-task objective that can further improve the model if additional cross-lingual or monolingual resources are available.  CACO models trained under low-resource settings rival cross-lingual word embedding models trained under high-resource settings on related language pairs.\n", "keywords": ["cross-lingual transfer", "character-based method", "low-resource language"], "authorids": ["ICLR.cc/2019/Conference/Paper1554/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a cross-lingual document classification framework for related language pairs.", "pdf": "/pdf/894fdeb2e176d14395c9396b5b40fa15fa3a4195.pdf", "paperhash": "anonymous|exploiting_crosslingual_subword_similarities_in_lowresource_document_classification", "_bibtex": "@inproceedings{    \nanonymous2019exploiting,    \ntitle={Exploiting Cross-Lingual Subword Similarities in Low-Resource Document Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1e_H3AqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyePrhR5KX", "original": "BygPPxRctX", "number": 1553, "cdate": 1538087999505, "ddate": null, "tcdate": 1538087999505, "tmdate": 1538156127459, "tddate": null, "forum": "HyePrhR5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DyReP: Learning Representations over Dynamic Graphs", "abstract": "Representation Learning over graph structured data has received significant attention recently due to its ubiquitous applicability. However, most advancements have been made in static graph settings while efforts for jointly learning dynamic of the graph and dynamic on the graph are still in an infant stage. Two fundamental questions arise in learning over dynamic graphs: (i) How to elegantly model dynamical processes over graphs? (ii) How to leverage such a model to effectively encode evolving graph information into low-dimensional representations? We present DyRep - a novel modeling framework for dynamic graphs that posits representation learning as a latent mediation process bridging two observed processes namely -- dynamics of the network (realized as topological evolution) and dynamics on the network (realized as activities between nodes). Concretely, we propose a two-time scale deep temporal point process model that captures the interleaved dynamics of the observed processes. This model is further parameterized by a temporal-attentive representation network that encodes temporally evolving structural information into node representations which in turn drives the nonlinear evolution of the observed graph dynamics. Our unified framework has inductive capability to generalize over unseen nodes and we design an efficient unsupervised procedure for end-to-end training. We demonstrate that DyRep outperforms state-of-art baselines in quantitative analysis using dynamic link prediction and time prediction tasks. We further present extensive qualitative insights into our framework to discern indispensable role of various components of our framework.", "keywords": ["Dynamic Graphs", "Representation Learning", "Dynamic Processes", "Temporal Point Process", "Attention", "Latent Representation"], "authorids": ["ICLR.cc/2019/Conference/Paper1553/Authors"], "authors": ["Anonymous"], "TL;DR": "Models Representation Learning over dynamic graphs as latent hidden process bridging two observed processes of Topological Evolution of and Interactions on dynamic graphs.", "pdf": "/pdf/776adcd06cd6fec3352526d59a1426e4a9984335.pdf", "paperhash": "anonymous|dyrep_learning_representations_over_dynamic_graphs", "_bibtex": "@inproceedings{    \nanonymous2019dyrep:,    \ntitle={DyReP: Learning Representations over Dynamic Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyePrhR5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxwShA9Ym", "original": "ryxWcmhqKQ", "number": 1552, "cdate": 1538087999341, "ddate": null, "tcdate": 1538087999341, "tmdate": 1538156127249, "tddate": null, "forum": "rkxwShA9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Label super-resolution networks", "abstract": "We present a deep learning-based method for super-resolving coarse (low-resolution) labels assigned to groups of image pixels into pixel-level (high-resolution) labels, given the joint distribution between those low- and high-resolution labels. This method involves a novel loss function that minimizes the distance between a distribution determined by a set of model outputs and the corresponding distribution given by low-resolution labels over the same set of outputs. This setup does not require that the high-resolution classes match the low-resolution classes and can be used in high-resolution semantic segmentation tasks where high-resolution labeled data is not available. Furthermore, our proposed method is able to utilize both data with low-resolution labels and any available high-resolution labels, which we show improves performance compared to a network trained only with the same amount of high-resolution data.\nWe test our proposed algorithm in a challenging land cover mapping task to super-resolve labels at a 30m resolution to a separate set of labels at a 1m resolution. We compare our algorithm with models that are trained on high-resolution data and show that 1) we can achieve similar performance using only low-resolution data; and 2) we can achieve better performance when we incorporate a small amount of high-resolution data in our training. We also test our approach on a medical imaging problem, resolving low-resolution probability maps into high-resolution segmentation of lymphocytes with accuracy equal to that of fully supervised models.", "keywords": ["weakly supervised segmentation", "land cover mapping", "medical imaging"], "authorids": ["ICLR.cc/2019/Conference/Paper1552/Authors"], "authors": ["Anonymous"], "TL;DR": "Super-resolving coarse labels into pixel-level labels, applied to aerial imagery and medical scans.", "pdf": "/pdf/64210e0d942519811c6854239c521a6047d2c7ef.pdf", "paperhash": "anonymous|label_superresolution_networks", "_bibtex": "@inproceedings{    \nanonymous2019label,    \ntitle={Label super-resolution networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxwShA9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkfPSh05K7", "original": "r1eauzCcYm", "number": 1551, "cdate": 1538087999164, "ddate": null, "tcdate": 1538087999164, "tmdate": 1538156127045, "tddate": null, "forum": "HkfPSh05K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-step Reasoning for Open-domain Question Answering", "abstract": "This paper introduces a new framework for open-domain question answering in which the retriever and the reader \\emph{iteratively} interact with each other. The framework is agnostic to the architecture of the machine reading model and the retriever uses fast nearest neighbor search algorithms that allow it to scale to corpus containing millions of paragraphs. We show the efficacy of our architecture by achieving state-of-the-art results on large open domain datasets such as TriviaQA-unfiltered \\citep{joshi2017triviaqa}. We also show that our multi-step-reasoning framework brings uniform improvements when applied to two different reader architectures. ", "keywords": ["Open domain Question Answering", "Reinforcement Learning", "Query reformulation"], "authorids": ["ICLR.cc/2019/Conference/Paper1551/Authors"], "authors": ["Anonymous"], "TL;DR": "Paragraph retriever and machine reader interacts with each other via reinforcement learning to yield large improvements on open domain datasets", "pdf": "/pdf/fe0a4c1d713851eba4cc155f5a32554de199848a.pdf", "paperhash": "anonymous|multistep_reasoning_for_opendomain_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019multi-step,    \ntitle={Multi-step Reasoning for Open-domain Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkfPSh05K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lPShAqFm", "original": "SklnT10ct7", "number": 1550, "cdate": 1538087998975, "ddate": null, "tcdate": 1538087998975, "tmdate": 1538156126832, "tddate": null, "forum": "S1lPShAqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Empirically Characterizing Overparameterization Impact on Convergence", "abstract": "A long-held conventional wisdom states that larger models train more slowly when using gradient descent. This work challenges this widely-held belief, showing that larger models can potentially train faster despite the increasing computational requirements of each training step. In particular, we study the effect of network structure (depth and width) on halting time and show that larger models---wider models in particular---take fewer training steps to converge.\n\nWe design simple experiments to quantitatively characterize the effect of overparametrization on weight space traversal. Results show that halting time improves when growing model's width for three different applications, and the improvement comes from each factor: The distance from initialized weights to converged weights shrinks with a power-law-like relationship, the average step size grows with a power-law-like relationship, and gradient vectors become more aligned with each other during traversal.\n", "keywords": ["gradient descent", "optimization", "convergence time", "halting time", "characterization"], "authorids": ["ICLR.cc/2019/Conference/Paper1550/Authors"], "authors": ["Anonymous"], "TL;DR": "Empirically shows that larger models train in fewer training steps, because all factors in weight space traversal improve.", "pdf": "/pdf/e74b6e80a2c948d26e7630664b62caffbec89029.pdf", "paperhash": "anonymous|empirically_characterizing_overparameterization_impact_on_convergence", "_bibtex": "@inproceedings{    \nanonymous2019empirically,    \ntitle={Empirically Characterizing Overparameterization Impact on Convergence},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lPShAqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xwS3RqKQ", "original": "r1l5j4a9tm", "number": 1549, "cdate": 1538087998805, "ddate": null, "tcdate": 1538087998805, "tmdate": 1538156126625, "tddate": null, "forum": "r1xwS3RqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Differential Equation Networks", "abstract": "Most deep neural networks use simple, fixed activation functions, such\nas sigmoids or rectified linear units, regardless of domain or\nnetwork structure. We introduce differential equation networks, an\nimprovement to modern neural networks in which each neuron learns the\nparticular nonlinear activation function that it requires. We show\nthat enabling each neuron with the ability to learn its own activation\nfunction results in a more compact network capable of achieving\ncomperable, if not superior performance when compared to much larger\nnetworks. We\nalso showcase the capability of a differential equation neuron to\nlearn behaviors, such as oscillation, currently only obtainable by a\nlarge group of neurons. The ability of\ndifferential equation networks to essentially compress a large neural network, without loss of overall performance\nmakes them suitable for on-device applications, where predictions must\nbe computed locally. Our experimental evaluation of real-world and toy\ndatasets show that differential equation networks outperform fixed activatoin networks in several areas.", "keywords": ["deep learning", "activation function", "differential equations"], "authorids": ["ICLR.cc/2019/Conference/Paper1549/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a method to learn the nonlinear activation function for each neuron in the network.", "pdf": "/pdf/1a074a19f96caf2b5de5ad4f5b7253c1c7c3a439.pdf", "paperhash": "anonymous|differential_equation_networks", "_bibtex": "@inproceedings{    \nanonymous2019differential,    \ntitle={Differential Equation Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xwS3RqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlPB2CqYQ", "original": "B1xCqVR5K7", "number": 1548, "cdate": 1538087998639, "ddate": null, "tcdate": 1538087998639, "tmdate": 1538156126416, "tddate": null, "forum": "HJlPB2CqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ISONETRY : GEOMETRY OF CRITICAL INITIALIZATIONS AND TRAINING", "abstract": "Recent work on critical initializations of deep neural networks has shown that by constraining the spectrum of input-output Jacobians allows for fast training of very deep networks without skip connections. The current understanding of this class of initializations is limited with respect to classical notions from optimization. In particular, the connections between Jacobian eigenvalues and curvature of the parameter space are unknown. Similarly, there is no firm understanding of the effects of maintaining orthogonality during training. With this work we complement the existing understanding of critical initializations and show that the curvature is proportional to the maximum singular value of the Jacobian. Furthermore we show that optimization under orthogonality constraints ameliorates the dependence on choice of initial parameters, but is not strictly necessary.", "keywords": ["Deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1548/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/207f8f6b3a8286498b9a632bdca7962730e5fd69.pdf", "paperhash": "anonymous|isonetry_geometry_of_critical_initializations_and_training", "_bibtex": "@inproceedings{    \nanonymous2019isonetry,    \ntitle={ISONETRY : GEOMETRY OF CRITICAL INITIALIZATIONS AND TRAINING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlPB2CqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxLH2AcYX", "original": "rkxs2GA9F7", "number": 1547, "cdate": 1538087998465, "ddate": null, "tcdate": 1538087998465, "tmdate": 1538156126207, "tddate": null, "forum": "BJxLH2AcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Multi-Target Domain Adaptation: An Information Theoretic Approach", "abstract": "Unsupervised domain adaptation (uDA) models focus on pairwise adaptation settings where there is a single, labeled, source and a single target domain. However, in many real-world settings one seeks to adapt to multiple, but somewhat similar, target domains. Applying pairwise adaptation approaches to this setting may be suboptimal, as they would fail to leverage shared information among the multiple domains.  In this work we propose an information theoretic approach for domain adaptation in the novel context of multiple target domains with unlabeled instances and one source domain with labeled instances.  Our model aims to find a shared latent space common to all domains, while simultaneously accounting for the remaining private, domain-specific factors.  Disentanglement of shared and private information is accomplished using a unified information-theoretic approach, which also serves to provide a stronger link between the latent representations and the observed data.  The resulting single model, accompanied by an efficient optimization algorithm, allows simultaneous adaptation from a single source to multiple target domains.\nWe test our approach on three publicly-available datasets, showing that it outperforms several popular domain adaptation methods.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1547/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9705076964fd6aa492038a397f1490f9eece801f.pdf", "paperhash": "anonymous|unsupervised_multitarget_domain_adaptation_an_information_theoretic_approach", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Multi-Target Domain Adaptation: An Information Theoretic Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxLH2AcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GIB3A9YX", "original": "HJg4jC65KX", "number": 1546, "cdate": 1538087998293, "ddate": null, "tcdate": 1538087998293, "tmdate": 1538156125996, "tddate": null, "forum": "B1GIB3A9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Explicit Recall for Efficient Exploration", "abstract": "In this paper, we advocate the use of explicit memory for efficient exploration in reinforcement learning.  This memory records structured trajectories that have led to interesting states in the past, and can be used by the agent to revisit those states more effectively.  In high-dimensional decision making problems, where deep reinforcement learning is considered crucial, our approach provides a simple, transparent and effective way that can be naturally combined with complex, deep learning models.  We show how such explicit memory may be used to enhance existing exploration algorithms such as intrinsically motivated ones and count-based ones, and demonstrate our method's advantages in various simulated environments.", "keywords": ["Exploration", "goal-directed", "deep reinforcement learning", "explicit memory"], "authorids": ["ICLR.cc/2019/Conference/Paper1546/Authors"], "authors": ["Anonymous"], "TL;DR": "We advocate the use of explicit memory for efficient exploration in reinforcement learning", "pdf": "/pdf/72b577ce98ac76872d3b6104d0d19aae026f7772.pdf", "paperhash": "anonymous|explicit_recall_for_efficient_exploration", "_bibtex": "@inproceedings{    \nanonymous2019explicit,    \ntitle={Explicit Recall for Efficient Exploration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GIB3A9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl8BhRqF7", "original": "BklWKIp5KQ", "number": 1545, "cdate": 1538087998118, "ddate": null, "tcdate": 1538087998118, "tmdate": 1538156125778, "tddate": null, "forum": "rJl8BhRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1545/Authors"], "authors": ["Anonymous"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "anonymous|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving machine classification using human uncertainty measurements},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl8BhRqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byl8BnRcYm", "original": "SJlsyl39KX", "number": 1544, "cdate": 1538087997944, "ddate": null, "tcdate": 1538087997944, "tmdate": 1538156125568, "tddate": null, "forum": "Byl8BnRcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Capsules Graph Neural Network", "abstract": "The high-quality node embeddings learned by GNN have been applied to a wide range of node-based graph structured applications and some of them have achieved state-of-the-art (SOTA) performance. However, when applying node embeddings learned from GNN to generate graph embeddings, the scalar node representation typically used in GNN may not suffice to preserve the node/graph relationships, resulting in sub-optimal graph embeddings.\n\nInspired by the Capsule Neural Network (CapsNet), we propose the Capsules Graph Neural Network (CapsGNN), which adopts the concept of capsules to address the weakness in existing GNN-based graph embeddings algorithms. By extracting node features in the form of capsules, routing mechanism can be utilized to capture important statistic information at the graph level. As a result, our model generates multiple embeddings for each graph to capture significant graph properties from different aspects. The attention module incorporated in CapsGNN is used to tackle graphs with various sizes which also enables the model to focus on critical parts of the graphs.\n\nOur extensive evaluations with 9 graph-structured datasets demonstrate that CapsGNN has a high potential for large graph data analysis and powerful capability in capturing macroscopic properties of the whole graph. It outperforms other SOTA techniques on several graph classification tasks.", "keywords": ["CapsNet", "Graph embedding", "GNN"], "authorids": ["ICLR.cc/2019/Conference/Paper1544/Authors"], "authors": ["Anonymous"], "TL;DR": "Inspired by CapsNet, we propose a novel architecture for graph embeddings on the basis of node features extracted from GNN.", "pdf": "/pdf/f1aff0e99159af740db5d815d9889d949ee06ea3.pdf", "paperhash": "anonymous|capsules_graph_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019capsules,    \ntitle={Capsules Graph Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byl8BnRcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syl8Sn0cK7", "original": "BJeFqsnqF7", "number": 1543, "cdate": 1538087997775, "ddate": null, "tcdate": 1538087997775, "tmdate": 1538156125355, "tddate": null, "forum": "Syl8Sn0cK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning a Meta-Solver for Syntax-Guided Program Synthesis", "abstract": "We study a general formulation of program synthesis called syntax-guided synthesis(SyGuS) that concerns synthesizing a program that follows a given grammar and satisfies a given logical specification. Both the logical specification and the grammar have complex structures and can vary from task to task, posing significant challenges for learning across different tasks. Furthermore, training data is often unavailable for domain specific synthesis tasks. To address these challenges, we propose a meta-learning framework that learns a transferable policy from only weak supervision. Our framework consists of three components: 1) an encoder, which embeds both the logical specification and grammar at the same time using a graph neural network; 2) a grammar adaptive policy network which enables learning a transferable policy; and 3) a reinforcement learning algorithm that jointly trains the specification and grammar embedding and adaptive policy. We evaluate the framework on 210 cryptographic circuit synthesis tasks. It solves 141 of them in the out-of-box solver setting, outperforming two state-of-the-art classical synthesis engines, which solve 129 and 31 respectively.  In the meta-solver setting, the framework can efficiently adapt to unseen tasks and achieves speedup ranging from 2\u00d7 up to 100x.", "keywords": ["Syntax-guided Synthesis", "Context Free Grammar", "Logical Specification", "Representation Learning", "Meta Learning", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1543/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a meta-learning framework that learns a transferable policy from only weak supervision to solve synthesis tasks with different logical specifications and grammars.", "pdf": "/pdf/1b2672db9a9d4f94c86d21b8010c2d88a006d88d.pdf", "paperhash": "anonymous|learning_a_metasolver_for_syntaxguided_program_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning a Meta-Solver for Syntax-Guided Program Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syl8Sn0cK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sye8S209KX", "original": "SylGGIFQFm", "number": 1542, "cdate": 1538087997607, "ddate": null, "tcdate": 1538087997607, "tmdate": 1538156125145, "tddate": null, "forum": "Sye8S209KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Robust, Transferable Sentence Representations for Text Classification", "abstract": "Despite deep recurrent neural networks (RNNs) demonstrate strong performance in text classification, training RNN models are often expensive and requires an extensive collection of annotated data which may not be available. To overcome the data limitation issue, existing approaches leverage either pre-trained word embedding or sentence representation to lift the burden of training RNNs from scratch. In this paper, we show that jointly learning sentence representations from multiple text classification tasks and combining them with pre-trained word-level and sentence level encoders result in robust sentence representations that are useful for transfer learning. Extensive experiments and analyses using a wide range of transfer and linguistic tasks endorse the effectiveness of our approach.", "keywords": ["sentence representations learning", "multi-task learning", "transfer learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1542/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a248efaf6ed8b2725113da8e16542af15cff0534.pdf", "paperhash": "anonymous|learning_robust_transferable_sentence_representations_for_text_classification", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Robust, Transferable Sentence Representations for Text Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sye8S209KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eSS3CcKX", "original": "BygdWi6qKX", "number": 1541, "cdate": 1538087997425, "ddate": null, "tcdate": 1538087997425, "tmdate": 1538156124935, "tddate": null, "forum": "H1eSS3CcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Optimization of Sorting Networks via Continuous Relaxations", "abstract": "Sorting input objects is an important step within many machine learning pipelines. However, the sorting operator is non-differentiable w.r.t. its inputs, which prohibits end-to-end gradient-based optimization. In this work, we propose a general-purpose continuous relaxation of the output of the sorting operator from permutation matrices to the set of \"unimodal matrices\". Further, we use this relaxation to enable more efficient stochastic optimization over the combinatorially large space of permutations. In particular, we derive a reparameterized gradient estimator for the widely used Plackett-Luce family of distributions. We demonstrate the usefulness of our framework on three tasks that require learning semantic orderings of high-dimensional objects. ", "keywords": ["continuous relaxations", "sorting", "stochastic computation graphs"], "authorids": ["ICLR.cc/2019/Conference/Paper1541/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide a continuous relaxation to the sorting operator, enabling end-to-end, gradient-based stochastic optimization.", "pdf": "/pdf/c660ee86e93981ed1a53215eb038f614c844184a.pdf", "paperhash": "anonymous|stochastic_optimization_of_sorting_networks_via_continuous_relaxations", "_bibtex": "@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Optimization of Sorting Networks via Continuous Relaxations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eSS3CcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylBr3C9K7", "original": "BJgKEA65tX", "number": 1540, "cdate": 1538087997252, "ddate": null, "tcdate": 1538087997252, "tmdate": 1538156124726, "tddate": null, "forum": "BylBr3C9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Energy-Constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking", "abstract": "Deep Neural Networks (DNN) are increasingly deployed in highly energy-constrained environments such as autonomous drones and wearable devices while at the same time must operate in real-time. Therefore, reducing the energy consumption has become a major design consideration in DNN training. This paper proposes the first end-to-end DNN training framework that provides quantitative energy consumption guarantees via weighted sparse projection and input masking. The key idea is to formulate the DNN training as an optimization problem in which the energy budget imposes a previously unconsidered optimization constraint. We integrate the quantitative DNN energy estimation into the DNN training process to assist the constrained optimization. We prove that an approximate algorithm can be used to efficiently solve the optimization problem. Compared to the best prior energy-saving techniques, our framework trains DNNs that provide higher accuracies under same or lower energy budgets.", "keywords": ["model compression", "inference energy saving", "deep neural network pruning"], "authorids": ["ICLR.cc/2019/Conference/Paper1540/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5dbf017183d07777aa1d0294c958b7bb212ba02d.pdf", "paperhash": "anonymous|energyconstrained_compression_for_deep_neural_networks_via_weighted_sparse_projection_and_layer_input_masking", "_bibtex": "@inproceedings{    \nanonymous2019energy-constrained,    \ntitle={Energy-Constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylBr3C9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxSBh09t7", "original": "r1glR0pcY7", "number": 1539, "cdate": 1538087997077, "ddate": null, "tcdate": 1538087997077, "tmdate": 1538156124509, "tddate": null, "forum": "HyxSBh09t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Generation via Scattering", "abstract": "Generative networks have made it possible to generate meaningful signals such as images and texts from simple noise. Recently, generative methods based on GAN and VAE were developed for graphs and graph signals. However, some of these methods are complex as well as difficult to train and fine-tune. This work proposes a graph generation model that uses a recent adaptation of Mallat's scattering transform to graphs. The proposed model is naturally composed of an encoder and a decoder. The encoder is a Gaussianized graph scattering transform. The decoder is a simple fully connected network that is adapted to specific tasks, such as link prediction, signal generation on graphs and full graph and signal generation. The training of our proposed system is efficient since it is only applied to the decoder and the hardware requirement is moderate. Numerical results demonstrate state-of-the-art performance of the proposed system for both link prediction and graph and signal generation. These results are in contrast to experience with Euclidean data, where it is difficult to form a generative scattering network that performs as well as state-of-the-art methods. We believe that this is because of the discrete and simpler nature of graph applications, unlike the more complex and high-frequency nature of Euclidean data, in particular, of some natural images. ", "keywords": ["graph generative neural network", "link prediction", "graph and signal generation", "scattering network"], "authorids": ["ICLR.cc/2019/Conference/Paper1539/Authors"], "authors": ["Anonymous"], "TL;DR": "This work proposes a graph generation system based on scattering and demonstrates competitive performance as well as indicates better promise of the generative scattering framework to datasets with a graph structure.", "pdf": "/pdf/e9df2b364948cec5279a6f0c8c9aa3c0d288d20d.pdf", "paperhash": "anonymous|graph_generation_via_scattering", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Generation via Scattering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxSBh09t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklrrhRqFX", "original": "HJlCW8T9Km", "number": 1538, "cdate": 1538087996904, "ddate": null, "tcdate": 1538087996904, "tmdate": 1538156124297, "tddate": null, "forum": "SklrrhRqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Physics Priors for Deep Reinforcement Learing", "abstract": "While model-based deep reinforcement learning (RL) holds great promise for sample efficiency and generalization, learning an accurate dynamics model is challenging and often requires substantial interactions with the environment. Further, a wide variety of domains have dynamics that share common foundations like the laws of physics, which are rarely exploited by these algorithms. Humans often acquire such physics priors that allow us to easily adapt to the dynamics of any environment. In this work, we propose an approach to learn such physics priors and incorporate them into an RL agent. Our method involves pre-training a frame predictor on raw videos and then using it to initialize the dynamics prediction model on a target task. Our prediction model, SpatialNet, is designed to implicitly capture localized physical phenomena and interactions.  We show the value of incorporating this prior through empirical experiments on two different domains \u2013 a newly created PhysWorld and games from the Atari benchmark, outperforming competitive approaches and demonstrating effective transfer learning.", "keywords": ["Model-Based Reinforcement Learning", "Intuitive Physics"], "authorids": ["ICLR.cc/2019/Conference/Paper1538/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new approach to pre-train a physics prior from raw videos and incorporate it into an RL framework that allows for better learning and efficient generalization.", "pdf": "/pdf/e2db4c4ae0f282b96f454e12b3bf4aab0e1ad1aa.pdf", "paperhash": "anonymous|learning_physics_priors_for_deep_reinforcement_learing", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Physics Priors for Deep Reinforcement Learing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklrrhRqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygrBhC5tQ", "original": "rJganF8h_Q", "number": 1537, "cdate": 1538087996736, "ddate": null, "tcdate": 1538087996736, "tmdate": 1538156124095, "tddate": null, "forum": "rygrBhC5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction", "abstract": "Intelligent creatures acquire complex skills by exploiting previously learned skills and learning to transition between them. To empower machines with this ability, we propose transition policies which effectively connect primitive skills to perform sequential tasks without handcrafted rewards. To effectively train our transition policies, we introduce proximity predictors which induce rewards gauging proximity to suitable initial states for the next skill. The proposed method is evaluated on a diverse set of experiments for continuous control in both bi-pedal locomotion and robotic arm manipulation tasks in MuJoCo. We demonstrate that transition policies enable us to effectively learn complex tasks and the induced proximity reward computed using the initiation predictor improves training efficiency. Videos of policies learned by our algorithm and baselines can be found at https://sites.google.com/view/transitions-iclr2019.", "keywords": ["reinforcement learning", "hierarchical reinforcement learning", "continuous control", "modular network"], "authorids": ["ICLR.cc/2019/Conference/Paper1537/Authors"], "authors": ["Anonymous"], "TL;DR": "Transition policies enable agents to execute learned skills smoothly to perform complex tasks.", "pdf": "/pdf/c53f1b674343794b30c0a5f5d783ffadbe7c148e.pdf", "paperhash": "anonymous|composing_complex_skills_by_learning_transition_policies_with_proximity_reward_induction", "_bibtex": "@inproceedings{    \nanonymous2019composing,    \ntitle={Composing Complex Skills by Learning Transition Policies with Proximity Reward Induction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygrBhC5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxSrhC9KX", "original": "Bke09e6cKQ", "number": 1536, "cdate": 1538087996564, "ddate": null, "tcdate": 1538087996564, "tmdate": 1538156123881, "tddate": null, "forum": "ryxSrhC9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Revealing interpretable object representations from human behavior", "abstract": "To study how mental object representations are related to behavior, we estimated sparse, non-negative representations of objects using human behavioral judgments on images representative of 1,854 object categories. These representations predicted a latent similarity structure between objects, which captured most of the explainable variance in human behavioral judgments. Individual dimensions in the low-dimensional embedding were found to be highly reproducible and interpretable as conveying degrees of taxonomic membership, functionality, and perceptual attributes. We further demonstrated the predictive power of the embeddings for explaining other forms of human behavior, including categorization, typicality judgments, and feature ratings, suggesting that the dimensions reflect human conceptual representations of objects beyond the specific task.", "keywords": ["category representation", "sparse coding", "representation learning", "interpretable representations"], "authorids": ["ICLR.cc/2019/Conference/Paper1536/Authors"], "authors": ["Anonymous"], "TL;DR": "Human behavioral judgments are used to obtain sparse and interpretable representations of objects that generalize to other tasks", "pdf": "/pdf/5adc1c7575b6a52abdfec48f074321613ab26953.pdf", "paperhash": "anonymous|revealing_interpretable_object_representations_from_human_behavior", "_bibtex": "@inproceedings{    \nanonymous2019revealing,    \ntitle={Revealing interpretable object representations from human behavior},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxSrhC9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGNrnC9FQ", "original": "SylB1y05K7", "number": 1535, "cdate": 1538087996389, "ddate": null, "tcdate": 1538087996389, "tmdate": 1538156123668, "tddate": null, "forum": "SkGNrnC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Manifold Alignment via Feature Correspondence", "abstract": "We propose a novel framework for combining datasets via alignment of their associated intrinsic dimensions. Our approach assumes that the two datasets are sampled from a common latent space, i.e., they measure equivalent systems. Thus, we expect there to exist a natural (albeit unknown) alignment of the data manifolds associated with the intrinsic geometry of these datasets, which are perturbed by measurement artifacts in the sampling process. Importantly, we do not assume any individual correspondence (partial or complete) between data points. Instead, we rely on our assumption that a subset of data features have correspondence across datasets. We leverage this assumption to estimate relations between intrinsic manifold dimensions, which are given by diffusion map coordinates over each of the datasets. We compute a correlation matrix between diffusion coordinates of the datasets by considering graph (or manifold) Fourier coefficients of corresponding data features. We then orthogonalize this correlation matrix to form an isometric transformation between the diffusion maps of the datasets. Finally, we apply this transformation to the diffusion coordinates and construct a unified diffusion geometry of the datasets together. We show that this approach successfully corrects misalignment artifacts, and allows for integrated data.", "keywords": ["graph signal processing", "graph alignment", "manifold alignment", "spectral graph wavelet transform", "diffusion geometry", "harmonic analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper1535/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method for aligning the latent features learned from different datasets using harmonic correlations.", "pdf": "/pdf/6ef1462d5fc32677006cbffe389e1874946c266d.pdf", "paperhash": "anonymous|manifold_alignment_via_feature_correspondence", "_bibtex": "@inproceedings{    \nanonymous2019manifold,    \ntitle={Manifold Alignment via Feature Correspondence},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGNrnC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylVB3AqYm", "original": "HygMGr1qFm", "number": 1534, "cdate": 1538087996212, "ddate": null, "tcdate": 1538087996212, "tmdate": 1538156123455, "tddate": null, "forum": "HylVB3AqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Proxy-less Architecture Search via Binarized Path Learning", "abstract": "Neural architecture search (NAS) has great impact automatically designing efficient neural network architectures.  However, the computation demand is prohibitive with conventional NAS algorithms (e.g. $10^4$ GPU hours), making it difficult to \\emph{directly} search the architecture on large-scale tasks (e.g. ImageNet). As a result, NAS needs to utilize~\\emph{proxy} tasks, such as training on a smaller dataset (e.g. CIFAR-10), or learning with only a few blocks rather than the full depth, or training only for a few epochs rather than till convergence. These architectures optimized on proxy tasks are not guaranteed to be optimal on target task. In this paper, we present \\emph{Proxy-less Architecture Search} that can directly learn the architectures on a large-scale target task. We reduce the computational cost (GPU hours and GPU memory) of architecture search to the same level of normal training. Additionally, by using the measured hardware latency (rather than FLOPs) as a \\emph{direct} objective, we can specialize neural network architectures for different hardware architectures. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness. On CIFAR-10, our model achieves 2.08\\% test error with only 5.7M parameters, better than the previous state-of-the-art architecture AmoebaNet-B, while using 6$\\times$ fewer parameters. On ImageNet, our model achieves 2.5\\% better top-1 accuracy than MobileNetV2, while being 1.2$\\times$ faster with measured GPU latency. Compared with previous architecture search algorithms, we saved the GPU hours by two orders of magnitude, GPU memory by one orders of magnitude, both on ImageNet. We also analyzed the insights of efficient CNN models specialized for different hardware platforms.\n\n\n\n\n", "keywords": ["Neural Architecture Search", "Efficient Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1534/Authors"], "authors": ["Anonymous"], "TL;DR": "Proxy-less neural architecture search for directly learning architectures on large-scale target task (ImageNet) while reducing the cost to the same level of normal training.", "pdf": "/pdf/a707a8f57bc4227bfb81357908f435c75348fd7c.pdf", "paperhash": "anonymous|proxyless_architecture_search_via_binarized_path_learning", "_bibtex": "@inproceedings{    \nanonymous2019proxy-less,    \ntitle={Proxy-less Architecture Search via Binarized Path Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylVB3AqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1x4BnCqKX", "original": "Ske3MyacY7", "number": 1533, "cdate": 1538087996033, "ddate": null, "tcdate": 1538087996033, "tmdate": 1538156123245, "tddate": null, "forum": "r1x4BnCqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Generative Model For Electron Paths", "abstract": "Chemical reactions can be described as the stepwise redistribution of electrons in molecules. As such, reactions are often depicted using \"arrow-pushing\" diagrams which show this movement as a sequence of arrows. We propose an electron path prediction model (ELECTRO) to learn these sequences directly from raw reaction data. Instead of predicting product molecules directly from reactant molecules in one shot, learning a model of electron movement has the benefits of (a) being easy for chemists to interpret, (b) incorporating constraints of chemistry, such as balanced atom counts before and after the reaction, and (c) naturally encoding the sparsity of chemical reactions, which usually involve changes in only a small number of atoms in the reactants. We design a method to extract approximate reaction paths from any dataset of atom-mapped reaction SMILES strings. Our model achieves excellent performance on an important subset of the USPTO reaction dataset, comparing favorably to the strongest baselines. Furthermore, we show that our model recovers a basic knowledge of chemistry without being explicitly trained to do so.", "keywords": ["Molecules", "Reaction Prediction", "Graph Neural Networks", "Deep Generative Models"], "authorids": ["ICLR.cc/2019/Conference/Paper1533/Authors"], "authors": ["Anonymous"], "TL;DR": "A generative model for reaction prediction that learns the mechanistic electron steps of a reaction directly from raw reaction data.", "pdf": "/pdf/aebf13234235cdaa22390b4652cb7fb256b9407d.pdf", "paperhash": "anonymous|a_generative_model_for_electron_paths", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Generative Model For Electron Paths},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1x4BnCqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylNH20qFQ", "original": "H1xqKCTcYX", "number": 1532, "cdate": 1538087995849, "ddate": null, "tcdate": 1538087995849, "tmdate": 1538156123039, "tddate": null, "forum": "rylNH20qFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Infer and Execute 3D Shape Programs", "abstract": "Human perception of 3D shapes goes beyond reconstructing them as a set of points or a composition of geometric primitives: we also effortlessly understand higher-level shape structure such as the repetition and reflective symmetry of object parts. In contrast, recent advances in 3D shape sensing focus more on low-level geometry but less on these higher-level relationships. In this paper, we propose 3D shape programs, integrating bottom-up recognition systems with top-down, symbolic program structure to capture both low-level geometry and high-level structural priors for 3D shapes. Because there are no annotations of shape programs for real shapes, we develop neural modules that not only learn to infer 3D shape programs from raw, unannotated shapes, but also to execute these programs for shape reconstruction. After initial bootstrapping, our end-to-end differentiable model learns 3D shape programs by reconstructing shapes in a self-supervised manner. Experiments demonstrate that our model accurately infers and executes 3D shape programs for highly complex shapes from various categories. It can also be integrated with an image-to-shape module to infer 3D shape programs directly from an RGB image, leading to 3D shape reconstructions that are both more accurate and more physically plausible.", "keywords": ["Program Synthesis", "3D Shape Modeling", "Self-supervised Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1532/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose 3D shape programs, a structured, compositional shape representation. Our model learns to infer and execute shape programs to explain 3D shapes.", "pdf": "/pdf/782b485fe3a8905f05be5545d31ecb1ff8d59a44.pdf", "paperhash": "anonymous|learning_to_infer_and_execute_3d_shape_programs", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Infer and Execute 3D Shape Programs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylNH20qFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJe4ShAcF7", "original": "HklwWl09KX", "number": 1531, "cdate": 1538087995673, "ddate": null, "tcdate": 1538087995673, "tmdate": 1538156122829, "tddate": null, "forum": "rJe4ShAcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Music Transformer", "abstract": "Music relies heavily on repetition to build structure and meaning.  Self-reference occurs on multiple timescales, from motifs to phrases to reusing of entire sections of music, such as in pieces with ABA structure.  The Transformer (Vaswani et al., 2017), a sequence model based on self-attention, has achieved compelling results in many generation tasks that require maintaining long-range coherence. This suggests that self-attention might also be well-suited to modeling music. In musical composition and performance, however, relative timing is critically important.  Existing approaches for representing relative positional information in the Transformer modulate attention based on pairwise distance (Shaw et al., 2018).  This is impractical for long sequences such as musical compositions since their memory complexity is quadratic in the sequence length.  We propose an algorithm that reduces the intermediate memory requirements to linear in the sequence length. This enables us to demonstrate that a Transformer with our modified relative attention mechanism can generate minute-long (thousands of steps) compositions with compelling structure, generate continuations that coherently elaborate on a given motif, and in a seq2seq setup generate accompaniments conditioned on melodies.   We evaluate the Transformer with our relative attention mechanism on two datasets, JSB Chorales and Piano-e-competition, and obtain state-of-the-art results on the latter.", "keywords": ["music generation"], "authorids": ["ICLR.cc/2019/Conference/Paper1531/Authors"], "authors": ["Anonymous"], "TL;DR": "We show the first successful use of Transformer in generating music that exhibits long-term structure. ", "pdf": "/pdf/6c87c6786f6a8a4733a6c3884ae393c6c900e13e.pdf", "paperhash": "anonymous|music_transformer", "_bibtex": "@inproceedings{    \nanonymous2019music,    \ntitle={Music Transformer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJe4ShAcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1f7S3C9YQ", "original": "SylcJg-9Y7", "number": 1530, "cdate": 1538087995497, "ddate": null, "tcdate": 1538087995497, "tmdate": 1538156122627, "tddate": null, "forum": "H1f7S3C9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SynonymNet: Multi-context Bilateral Matching for Entity Synonyms", "abstract": "Being able to automatically discover synonymous entities from a large free-text corpus has transformative effects on structured knowledge discovery. Existing works either require structured annotations, or fail to incorporate context information effectively, which lower the efficiency of information usage. In this paper, we propose a framework for synonym discovery from free-text corpus with minimal human annotation. As one of the key components in synonym discovery, we introduce a novel neural network model SynonymNet to determine whether or not two given entities are synonym with each other. Instead of using entities features, SynonymNet makes use of multiple pieces of contexts in which the entity is mentioned, and compares the context-level similarity via a bilateral matching schema to determine synonymity. Experimental results demonstrate that the proposed model achieves state-of-the-art results on both generic and domain-specific synonym datasets: Wiki+Freebase, PubMed+UMLS and MedBook+MKG, with up to 4.16% improvement in terms of Area Under the Curve (AUC) and 3.19% in terms of Mean Average Precision (MAP) compare to the best baseline method.", "keywords": ["deep learning", "entity synonym"], "authorids": ["ICLR.cc/2019/Conference/Paper1530/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce SynonymNet, a deep model for entity synonym discovery by a bilateral matching among multiple pieces of contexts in which an entity is mentioned.", "pdf": "/pdf/e979fbc526e254c52c01bbebb0db64aba3dd02ef.pdf", "paperhash": "anonymous|synonymnet_multicontext_bilateral_matching_for_entity_synonyms", "_bibtex": "@inproceedings{    \nanonymous2019synonymnet:,    \ntitle={SynonymNet: Multi-context Bilateral Matching for Entity Synonyms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1f7S3C9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1MmH30cY7", "original": "rJx5fJ_cY7", "number": 1529, "cdate": 1538087995320, "ddate": null, "tcdate": 1538087995320, "tmdate": 1538156122422, "tddate": null, "forum": "r1MmH30cY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Confidence Regularized Self-Training", "abstract": "Recent advances in domain adaptation show that self-training with deep networks presents a powerful means for unsupervised domain adaptation. Specifically, these methods often involve an iterative process of predicting on target domain and then taking the confident predictions as pseudo-labels for retraining. Basic self-training treats selected pseudo-labels equally as one-hot vectors, and the selection process is often modeled to be progressive via self-paced learning. While one-hot vector is a natural choice to model multiclass targets, such encoding scheme does not consider the difference between selected samples. As a result, the approach sometimes generates overconfident false pseudo-labels that lead to the convergence to deviated solutions with propagated errors, especially when there is a large domain gap. To address this problem, we generalize self-training as an expectation maximization (EM) problem which treats pseudo-labels as latent variables, and solves maximum marginal likelihood estimation (MMLE) by maximizing its lower bound. We then propose confidence regularized self-training, where we introduce multiple confidence regularizers along with their solutions. These regularizers mainly consider the control of pseudo-label confidence from two aspects: model regularization and label refinement. Experiments on both semantic segmentation and image classification show that self-training with different confidence regularizers comprehensively outperform their non-regularized counterparts.", "keywords": ["Neural network", "domain adaptation", "self-training", "maximum marginal likelihood estimation", "Expectation-Maximization", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper1529/Authors"], "authors": ["Anonymous"], "TL;DR": "A self-training optimization framework with pseudo-label confidence regularization ", "pdf": "/pdf/ba0dc0e19b927f76c30b17006b2eedd7ff57cd37.pdf", "paperhash": "anonymous|confidence_regularized_selftraining", "_bibtex": "@inproceedings{    \nanonymous2019confidence,    \ntitle={Confidence Regularized Self-Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1MmH30cY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylXHhA9Km", "original": "H1eY2SC5Y7", "number": 1528, "cdate": 1538087995145, "ddate": null, "tcdate": 1538087995145, "tmdate": 1538156122219, "tddate": null, "forum": "HylXHhA9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Statistical Characterization of Deep Neural Networks and their Sensitivity", "abstract": "Despite their ubiquity, it remains an active area of research to fully understand deep neural networks (DNNs) and the reasons of their empirical success. We contribute to this effort by introducing a principled approach to statistically characterize DNNs and their sensitivity. By distinguishing between randomness from input data and from model parameters, we study how central and non-central moments of network activation and sensitivity evolve during propagation. Thereby, we provide novel statistical insights on the hypothesis space of input-output mappings encoded by different architectures. Our approach applies both to fully-connected and convolutional networks and incorporates most ingredients of modern DNNs: rectified linear unit (ReLU) activation, batch normalization, skip connections.", "keywords": ["Statistics", "Sensitivity", "Exploding Gradient", "Convolutional Neural Networks", "Residual Neural Networks", "Batch Normalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1528/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/6c596efd134a2c1efb646443780339bb5c3b1f93.pdf", "paperhash": "anonymous|statistical_characterization_of_deep_neural_networks_and_their_sensitivity", "_bibtex": "@inproceedings{    \nanonymous2019statistical,    \ntitle={Statistical Characterization of Deep Neural Networks and their Sensitivity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylXHhA9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgQBn0cF7", "original": "r1g4dF65YX", "number": 1527, "cdate": 1538087994964, "ddate": null, "tcdate": 1538087994964, "tmdate": 1538156122016, "tddate": null, "forum": "SkgQBn0cF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Modeling the Long Term Future in Model-Based Reinforcement Learning", "abstract": "In model-based reinforcement learning, the agent interleaves between model learning and planning.  These two components are  inextricably intertwined. If the model is not able to provide sensible long-term prediction, the executed planer would exploit model flaws, which can yield catastrophic failures. This paper focuses on building a model that reasons about the long-term future and demonstrates how to use this for efficient planning and exploration. To this end, we build a latent-variable autoregressive model by leveraging recent ideas in variational inference. We argue that forcing latent variables to carry future information through an auxiliary task substantially improves long-term predictions. Moreover, by planning in the latent space, the planner's solution is ensured to be within regions where the model is valid. An exploration strategy can be devised by searching for unlikely trajectories under the model. Our methods achieves higher reward faster compared to baselines on a variety of tasks and environments in both the imitation learning and model-based reinforcement learning settings. ", "keywords": ["model-based reinforcement learning", "variation inference"], "authorids": ["ICLR.cc/2019/Conference/Paper1527/Authors"], "authors": ["Anonymous"], "TL;DR": "incorporating, in the model, latent variables that encode future content improves the long-term prediction accuracy, which is critical for better planning in model-based RL.", "pdf": "/pdf/9ba8510eaff5d07f15245619f369062195d9dc59.pdf", "paperhash": "anonymous|modeling_the_long_term_future_in_modelbased_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019modeling,    \ntitle={Modeling the Long Term Future in Model-Based Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgQBn0cF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgQB20qFQ", "original": "HkxxGqb5Fm", "number": 1526, "cdate": 1538087994796, "ddate": null, "tcdate": 1538087994796, "tmdate": 1538156121812, "tddate": null, "forum": "BJgQB20qFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Progressively Plan", "abstract": "For problem solving, making reactive decisions based on problem description is fast but inaccurate, while search-based planning using heuristics gives better solutions but could be exponentially slow. In this paper, we propose a new approach that improves an existing solution by iteratively picking and rewriting its local components until convergence. The rewriting policy employs a neural network trained with reinforcement learning. We evaluate our approach in two domains: job scheduling and expression simplification. Compared to common effective heuristics, baseline deep models and search algorithms, our approach efficiently gives solutions with higher quality.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1526/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5bf1f0dd5fd48724549186ecb5421a4c6752ca7d.pdf", "paperhash": "anonymous|learning_to_progressively_plan", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Progressively Plan},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgQB20qFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygQBn0cYm", "original": "B1xPk6sqK7", "number": 1525, "cdate": 1538087994625, "ddate": null, "tcdate": 1538087994625, "tmdate": 1538156121613, "tddate": null, "forum": "HygQBn0cYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic", "abstract": "  Learning a policy using only observational data is challenging because the distribution of states it induces at execution time may differ from the distribution observed during training. In this work, we propose to train a policy while explicitly penalizing the mismatch between these two distributions over a fixed time horizon. We do this by using a learned model of the environment dynamics which is unrolled for multiple time steps, and training a policy network to minimize a differentiable cost over this rolled-out trajectory. This cost contains two terms: a policy cost which represents the objective the policy seeks to optimize, and an uncertainty cost which represents its divergence from the states it is trained on. We propose to measure this second cost by using the uncertainty of the dynamics model about its own predictions, using recent ideas from uncertainty estimation for deep networks. We evaluate our approach using a large-scale observational dataset of driving behavior recorded from traffic cameras, and show that we are able to learn effective driving policies from purely observational data, with no environment interaction. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1525/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7b47b854a4521321036c7d10d8612a4c442300cc.pdf", "paperhash": "anonymous|modelpredictive_policy_learning_with_uncertainty_regularization_for_driving_in_dense_traffic", "_bibtex": "@inproceedings{    \nanonymous2019model-predictive,    \ntitle={Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygQBn0cYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeMB3Act7", "original": "HygObw69Km", "number": 1524, "cdate": 1538087994453, "ddate": null, "tcdate": 1538087994453, "tmdate": 1538156121415, "tddate": null, "forum": "ByeMB3Act7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks", "abstract": "Neural language models have been widely used in various NLP tasks, including machine translation, next word prediction and conversational agents. However, it is challenging to deploy these models on mobile devices due to their slow prediction speed, where the bottleneck is to compute top candidates in the softmax layer. In this paper, we introduce a novel softmax layer approximation algorithm by exploiting the clustering structure of context vectors. Our algorithm uses a light-weight screening model to predict a much smaller set of candidate words based on the given context, and then conducts an exact softmax only within that subset. Training such a procedure end-to-end is challenging as traditional clustering methods are discrete and non-differentiable, and thus unable to be used with back-propagation in the training process. Using the Gumbel softmax, we are able to train the screening model end-to-end on the training set to exploit data distribution. The algorithm achieves an order of magnitude faster inference than the original softmax layer for predicting top-k words in various tasks such as beam search in machine translation or next words prediction. For example, for machine translation task on German to English dataset with around 25K vocabulary, we can achieve 20.4 times speed up with 98.9% precision@1 and 99.3% precision@5 with the original softmax layer prediction, while state-of-the-art (Zhang et al., 2018) only achieves 6.7x speedup with 98.7% precision@1 and 98.1% precision@5 for the same task.", "keywords": ["fast inference", "softmax computation", "natural language processing"], "authorids": ["ICLR.cc/2019/Conference/Paper1524/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ecb895abf7d8c58f71c0ca99dee71111c02bf73f.pdf", "paperhash": "anonymous|learning_to_screen_for_fast_softmax_inference_on_large_vocabulary_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Screen for Fast Softmax  Inference on Large Vocabulary Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeMB3Act7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1efr3C9Ym", "original": "S1gVkB6qF7", "number": 1523, "cdate": 1538087994285, "ddate": null, "tcdate": 1538087994285, "tmdate": 1538156121215, "tddate": null, "forum": "r1efr3C9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Interpolation-Prediction Networks for Irregularly Sampled Time Series", "abstract": "In this paper, we present a new deep learning architecture for addressing the problem of supervised learning with sparse and irregularly sampled multivariate time series. The architecture is based on the use of a semi-parametric interpolation network followed by the application of a prediction network. The interpolation network allows for information to be shared across multiple dimensions of a multivariate time series during the interpolation stage, while any standard deep learning model can be used for the prediction network. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. We investigate the performance of this architecture on two datasets for both classification and regression tasks, showing that our approach outperforms a range of baseline and recently proposed models.\n", "keywords": ["irregular sampling", "multivariate time series", "supervised learning", "interpolation", "missing data"], "authorids": ["ICLR.cc/2019/Conference/Paper1523/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a new deep learning architecture for addressing the problem of supervised learning with sparse and irregularly sampled multivariate time series.", "pdf": "/pdf/c87efb8d5f3ab026d5723caa86077c61bc3972b5.pdf", "paperhash": "anonymous|interpolationprediction_networks_for_irregularly_sampled_time_series", "_bibtex": "@inproceedings{    \nanonymous2019interpolation-prediction,    \ntitle={Interpolation-Prediction Networks for Irregularly Sampled Time Series},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1efr3C9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lfHhR9tm", "original": "SJe_6Cc5tX", "number": 1522, "cdate": 1538087994113, "ddate": null, "tcdate": 1538087994113, "tmdate": 1538156121019, "tddate": null, "forum": "B1lfHhR9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "anonymous|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lfHhR9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxfHnCctX", "original": "SJxw9S09Fm", "number": 1521, "cdate": 1538087993938, "ddate": null, "tcdate": 1538087993938, "tmdate": 1538156120811, "tddate": null, "forum": "ryxfHnCctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Main/Subsidiary Network Framework for Simplifying Binary Neural Networks", "abstract": "To reduce memory footprint and run-time latency, techniques such as neural net-work pruning and binarization have been explored separately.  However, it is un-clear how to combine the best of the two worlds to get extremely small and efficient models.  In this paper, we, for the first time, define the filter-level pruning problem for binary neural networks, which cannot be solved by simply migrating existing structural pruning methods for full-precision models.  A novel learning-based approach is proposed to prune filters in our main/subsidiary network frame-work, where the main network is responsible for learning representative features to optimize the prediction performance, and the subsidiary component works as a filter selector on the main network. To avoid gradient mismatch when training the subsidiary component, we propose a layer-wise and bottom-up scheme.  We also provide the theoretical and experimental comparison between our learning-based and greedy rule-based methods.  Finally, we empirically demonstrate the effectiveness of our approach applied on several binary models,  including binarizedNIN, VGG-11, and ResNet-18, on various image classification datasets.  For bi-nary ResNet-18 on ImageNet, we use 78.6% filters but can achieve slightly better test error 49.87% (50.02%-0.15%) than the original model", "keywords": ["efficient machine learning\uff0cbinary neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper1521/Authors"], "authors": ["Anonymous"], "TL;DR": "we define the filter-level pruning problem for binary neural networks for the first time and propose method to solve it.", "pdf": "/pdf/4740fa32f0d74ea3030758268df328c1383f844c.pdf", "paperhash": "anonymous|a_mainsubsidiary_network_framework_for_simplifying_binary_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Main/Subsidiary Network Framework for Simplifying Binary Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxfHnCctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxGB2AcY7", "original": "BkgJH2p5FX", "number": 1520, "cdate": 1538087993764, "ddate": null, "tcdate": 1538087993764, "tmdate": 1538156120589, "tddate": null, "forum": "HyxGB2AcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Contingency-Aware Exploration in Reinforcement Learning", "abstract": "This paper investigates whether learning contingency-awareness and controllable aspects of an environment can lead to better exploration in reinforcement learning. To investigate this question, we consider an instantiation of this hypothesis evaluated on the Arcade Learning Element (ALE). In this study, we develop an attentive dynamics model (ADM) that discovers controllable elements of the observations, which are often associated with the location of the character in Atari games. The ADM is trained in a self-supervised fashion to predict the actions taken by the agent. The learned contingency information is used as a part of the state representation for exploration purposes. We demonstrate that combining A2C with count-based exploration using our representation achieves impressive results on a set of notoriously challenging Atari games due to sparse rewards. For example, we report a state-of-the-art score of >6600 points on Montezuma's Revenge without using expert demonstrations, explicit high-level information (e.g. RAM states), or supervised data. Our experiments confirm our hypothesis that contingency-awareness is an extremely powerful concept for tackling exploration problems in reinforcement learning and opens up interesting research questions for further investigation.", "keywords": ["Reinforcement Learning", "Exploration", "Contingency-Awareness"], "authorids": ["ICLR.cc/2019/Conference/Paper1520/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate contingency-awareness and controllable aspects in exploration and achieve state-of-the-art performance on Montezuma's Revenge without expert demonstrations.", "pdf": "/pdf/9f235853e0e9e1068a2487e901d09cd810863854.pdf", "paperhash": "anonymous|contingencyaware_exploration_in_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019contingency-aware,    \ntitle={Contingency-Aware Exploration in Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxGB2AcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eMBn09Km", "original": "ryx9VOaqK7", "number": 1519, "cdate": 1538087993591, "ddate": null, "tcdate": 1538087993591, "tmdate": 1538156120376, "tddate": null, "forum": "H1eMBn09Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Using GANs for Generation of Realistic City-Scale Ride Sharing/Hailing Data Sets", "abstract": "This paper focuses on the synthetic generation of human mobility data in urban areas. We present a novel and scalable application of Generative Adversarial Networks (GANs) for modeling and generating human mobility data. We leverage actual ride requests from ride sharing/hailing services from four major cities in the US to train our GANs model. Our model captures the spatial and temporal variability of the ride-request patterns observed for all four cities on any typical day and over any typical week. Previous works have succinctly characterized the spatial and temporal properties of human mobility data sets using the fractal dimensionality and the densification power law, respectively, which we utilize to validate our GANs-generated synthetic data sets. Such synthetic data sets can avoid privacy concerns and be extremely useful for researchers and policy makers on urban mobility and intelligent transportation.", "keywords": ["ride-sharing", "generative modeling", "parallelization", "application"], "authorids": ["ICLR.cc/2019/Conference/Paper1519/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper focuses on the synthetic generation of human mobility data in urban areas using GANs. ", "pdf": "/pdf/f9f2f15a6fe4f1d2f105262f6b1e108aa65016d0.pdf", "paperhash": "anonymous|using_gans_for_generation_of_realistic_cityscale_ride_sharinghailing_data_sets", "_bibtex": "@inproceedings{    \nanonymous2019using,    \ntitle={Using GANs for Generation of Realistic City-Scale Ride Sharing/Hailing Data Sets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eMBn09Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgWHnR5tm", "original": "BJgwDtd_YQ", "number": 1518, "cdate": 1538087993407, "ddate": null, "tcdate": 1538087993407, "tmdate": 1538156120167, "tddate": null, "forum": "BkgWHnR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Graph Evolution: Automatic Robot Design", "abstract": "Despite the recent success in robotic locomotion control, the design of robot relies heavily on human engineering. Automatic robot design has been a long studied subject but with limited success due to the large combinatorial search space and the difficulty in evaluating the found solution. In this paper, We propose Neural Graph Evolution (NGE) to address these two challenges. We formulate automatic robot design as a graph search problem and perform evolution search in graph space. NGE uses graph neural networks to parameterize the control polices that allows skill transfer from previously evaluated control policy to a new robot design. The policy sharing and transfer greatly reducing the cost of re-training new candidates. Similar to ES, NGE performs selection on current candidates and evolves new ones iteratively. In addition, NGE applies Graph Mutation by incorporating model uncertainty, which reduces the search space by balancing exploration and exploitation. We show that NGE significantly outperforms both random graph search (RGS) and ES by an order of magnitude. As shown in experiments, NGE is the first algorithm that can automatically discover complex robotic graph structures, such as a fish with two symmetrical flat side-fins and a tail, or a cheetah with athletic front and back legs. Instead of using thousands of cores for weeks, NGE efficiently solves searching problem within a day on a single 64 CPU-core Amazon EC2 machine.\n", "keywords": ["Reinforcement learning", "graph neural networks", "deep learning", "transfer learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1518/Authors"], "authors": ["Anonymous"], "TL;DR": "Automatic robotic design search with graph neural networks and evolutionary algorithms", "pdf": "/pdf/7c2313de10ba5c8d06048b5c04312f11a795430a.pdf", "paperhash": "anonymous|neural_graph_evolution_automatic_robot_design", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Graph Evolution: Automatic Robot Design},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgWHnR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkxbrn0cYX", "original": "SyxCIe_cK7", "number": 1517, "cdate": 1538087993240, "ddate": null, "tcdate": 1538087993240, "tmdate": 1538156119959, "tddate": null, "forum": "Bkxbrn0cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Selfless Sequential Learning", "abstract": "Sequential learning studies the problem of learning tasks in a sequence with access restricted to only the data of the current task. In this paper we look at a scenario with a fixed model capacity, and postulate that the learning process should not be selfish, i.e. it should account for future tasks to be added and thus leave enough capacity for them. To achieve Selfless Sequential Learning we study different regularization strategies and activation functions that could lead to less interference between the different tasks. We find that learning a sparse representation is more beneficial for\nsequential learning than encouraging parameter sparsity. In particular, we propose a novel regularizer, that encourages representation sparsity by means of neural inhibition. It results in few active neurons which in turn leaves more free neurons to be utilized by upcoming tasks. As suppressing all other neurons in a layer can be too drastic, especially for complex tasks requiring strong representations, our regularizer only inhibits other neurons in a local neighborhood, inspired by inhibition processes in the brain. We combine our novel regularizer, Sparse coding\nthrough Local Neural Inhibition (SLNI), with state-of-the-art sequential learning methods that penalize changes to important previously learned parts of the network.\nWe show that our new regularizer leads to increased sparsity which translates in consistent performance improvement on diverse datasets.\n", "keywords": ["Lifelong learning", "Sequential learning", "Regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper1517/Authors"], "authors": ["Anonymous"], "TL;DR": "A regularization strategy for improving the performance of sequential learning", "pdf": "/pdf/51ec9470e0599c03f8f1889790ac4548fa801672.pdf", "paperhash": "anonymous|selfless_sequential_learning", "_bibtex": "@inproceedings{    \nanonymous2019selfless,    \ntitle={Selfless Sequential Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkxbrn0cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJe-Sn0ctm", "original": "H1eS8STcFm", "number": 1516, "cdate": 1538087993060, "ddate": null, "tcdate": 1538087993060, "tmdate": 1538156119750, "tddate": null, "forum": "BJe-Sn0ctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Ain't Nobody Got Time for Coding: Structure-Aware Program Synthesis from Natural Language", "abstract": "Program synthesis from natural language (NL) is practical for humans and, once technically feasible, would significantly facilitate software development and revolutionize end-user programming. We present SAPS, an end-to-end neural network capable of mapping relatively complex, multi-sentence NL specifications to snippets of executable code. The proposed architecture relies exclusively on neural components, and is built upon a tree2tree autoencoder trained on abstract syntax trees, combined with a pretrained word embedding and a bi-directional multi-layer LSTM for NL processing. The decoder features a doubly-recurrent LSTM with a novel signal propagation scheme and soft attention mechanism. When applied to a large dataset of problems proposed in a previous study, SAPS performs on par with or better than the method proposed there, producing correct programs in over 90% of cases. In contrast to other methods, it does not involve any non-neural components to post-process the resulting programs, and uses a fixed-dimensional latent representation as the only link between the NL analyzer and source code generator. ", "keywords": ["Program synthesis", "tree2tree autoencoders", "soft attention", "doubly-recurrent neural networks", "LSTM", "nlp2tree"], "authorids": ["ICLR.cc/2019/Conference/Paper1516/Authors"], "authors": ["Anonymous"], "TL;DR": "We generate source code based on short descriptions in natural language, using deep neural networks.", "pdf": "/pdf/cb64e96754ab281e538a591d454e400f682736f3.pdf", "paperhash": "anonymous|aint_nobody_got_time_for_coding_structureaware_program_synthesis_from_natural_language", "_bibtex": "@inproceedings{    \nanonymous2019ain't,    \ntitle={Ain't Nobody Got Time for Coding: Structure-Aware Program Synthesis from Natural Language},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe-Sn0ctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkeWSnR5Y7", "original": "H1erLXRqt7", "number": 1515, "cdate": 1538087992888, "ddate": null, "tcdate": 1538087992888, "tmdate": 1538156119536, "tddate": null, "forum": "HkeWSnR5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Provable Defenses against Spatially Transformed Adversarial Inputs: Impossibility and Possibility Results", "abstract": "One intriguing property of neural networks is their inherent vulnerability to adversarial inputs, which are maliciously crafted samples to trigger target networks to misbehave. The state-of-the-art attacks generate adversarial inputs using either pixel perturbation or spatial transformation. Thus far, several provable defenses have been proposed against pixel perturbation-based attacks; yet, little is known about whether such solutions exist for spatial transformation-based attacks. This paper bridges this striking gap by conducting the first systematic study on provable defenses against spatially transformed adversarial inputs. Our findings convey mixed messages. On the impossibility side, we show that such defenses may not exist in practice: for any given networks, it is possible to find legitimate inputs and imperceptible transformations to generate adversarial inputs that force arbitrarily large errors. On the possibility side, we show that it is still feasible to construct adversarial training methods to significantly improve the resilience of networks against adversarial inputs over empirical datasets. We believe our findings provide insights for designing more effective defenses against spatially transformed adversarial inputs.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1515/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/59c062c4bca5c470745a50f836ba3f48b3c9d7f4.pdf", "paperhash": "anonymous|provable_defenses_against_spatially_transformed_adversarial_inputs_impossibility_and_possibility_results", "_bibtex": "@inproceedings{    \nanonymous2019provable,    \ntitle={Provable Defenses against Spatially Transformed Adversarial Inputs: Impossibility and Possibility Results},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkeWSnR5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJeZS3RcYm", "original": "SkgPDdact7", "number": 1514, "cdate": 1538087992716, "ddate": null, "tcdate": 1538087992716, "tmdate": 1538156119330, "tddate": null, "forum": "rJeZS3RcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Simple Black-box Adversarial Attacks", "abstract": "The construction of adversarial images is a search problem in high dimensions within a small region around a target image. The goal is to find an imperceptibly modified image that is misclassified by a target model. In the black-box setting, only sporadic feedback is provided through occasional model evaluations. In this paper we provide a new algorithm whose search strategy is based on an intriguingly simple iterative principle: We randomly pick a low frequency component of the discrete cosine transform (DCT) and either add or subtract it to the target image. Model evaluations are only required to identify whether an operation decreases the adversarial loss. Despite its simplicity, the proposed method can be used for targeted and untargeted attacks --- resulting in previously unprecedented query efficiency in both settings. We require a median of 600 black-box model queries (ResNet-50) to produce an adversarial ImageNet image, and we successfully attack Google Cloud Vision with 2500 median queries, averaging to a cost of only $3 per image. We argue that our proposed algorithm should serve as a strong baseline for future adversarial black-box attacks, in particular because it is extremely fast and can be implemented in less than 20 lines of PyTorch code. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1514/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ad663e598452a18cec96b14ce49c7826588629b6.pdf", "paperhash": "anonymous|simple_blackbox_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019simple,    \ntitle={Simple Black-box Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJeZS3RcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgbSn09Ym", "original": "ryxkzip9Ym", "number": 1513, "cdate": 1538087992546, "ddate": null, "tcdate": 1538087992546, "tmdate": 1538156119107, "tddate": null, "forum": "rJgbSn09Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable Objects, and Fluids", "abstract": "Real-life control tasks involve matter of various substances---rigid or soft bodies, liquid, gas---each with distinct physical behaviors. This poses challenges to traditional rigid-body physics engines. Particle-based simulators have been developed to model the dynamics of these complex scenes; however, relying on approximation techniques, their simulation often deviates from real world physics, especially in the long term. In this paper, we propose to learn a particle-based simulator for complex control tasks. Combining learning with particle-based systems brings in two major benefits: first, the learned simulator, just like other particle-based systems, acts widely on objects of different materials; second, the particle-based representation poses strong inductive bias for learning: particles of the same type have the same dynamics within. This enables the model to quickly adapt to new environments of unknown dynamics within a few observations. Using the learned simulator, robots have achieved success in complex manipulation tasks, such as manipulating fluids and deformable foam. The effectiveness of our method has also been demonstrated in real world. Our study helps lay the foundation for robot learning of dynamic scenes with particle-based representations.", "keywords": ["Dynamics modeling", "Control", "Particle-Based Representation"], "authorids": ["ICLR.cc/2019/Conference/Paper1513/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning particle dynamics with dynamic interaction graphs for simulating and control rigid bodies, deformable objects, and fluids. ", "pdf": "/pdf/1c9dc7cd06ac2ab4dce3b2cbffa3ecb419fab790.pdf", "paperhash": "anonymous|learning_particle_dynamics_for_manipulating_rigid_bodies_deformable_objects_and_fluids", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable Objects, and Fluids},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgbSn09Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkMlSnAqYX", "original": "SklHV92qFX", "number": 1512, "cdate": 1538087992375, "ddate": null, "tcdate": 1538087992375, "tmdate": 1538156118896, "tddate": null, "forum": "rkMlSnAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mitigating Bias in Natural Language Inference Using Adversarial Learning", "abstract": "Recognizing the relationship between two texts is an important aspect of natural language understanding (NLU), and a variety of neural network models have been proposed for solving NLU tasks. Unfortunately, recent work showed that the datasets these models are trained on often contain biases that allow models to achieve non-trivial performance without possibly learning the relationship between the two texts. We propose a framework for building robust models by using adversarial learning to encourage models to learn latent, bias-free representations. We test our approach in a Natural Language Inference (NLI) scenario, and show that our adversarially-trained models learn robust representations that ignore known dataset-specific biases. Our experiments demonstrate that our models are more robust to new NLI datasets. ", "keywords": ["natural language inference", "adversarial learning", "bias", "artifacts"], "authorids": ["ICLR.cc/2019/Conference/Paper1512/Authors"], "authors": ["Anonymous"], "TL;DR": "Adversarial learning methods encourage NLI models to ignore dataset-specific biases and help models transfer across datasets.", "pdf": "/pdf/83b96d120c3a685a96940999f8a01601e1c433f6.pdf", "paperhash": "anonymous|mitigating_bias_in_natural_language_inference_using_adversarial_learning", "_bibtex": "@inproceedings{    \nanonymous2019mitigating,    \ntitle={Mitigating Bias in Natural Language Inference Using Adversarial Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMlSnAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1zeHnA9KX", "original": "H1lrLeRqFm", "number": 1511, "cdate": 1538087992205, "ddate": null, "tcdate": 1538087992205, "tmdate": 1538156118691, "tddate": null, "forum": "H1zeHnA9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Finite Automata Can be Linearly Decoded from Language-Recognizing RNNs", "abstract": "We study the internal representations that a recurrent neural network (RNN) uses while learning to recognize a regular formal language. Specifically, we train an RNN on positive and negative examples from a regular language, and ask if there is a simple decoding function that maps states of this RNN to states of the minimal deterministic finite automaton (MDFA) for the language. Our experiments show that such a decoding function exists, that it is in fact linear, but that it maps states of the RNN not to MDFA states, but to states of an abstraction obtained by clustering small sets of MDFA states into \"superstates\". A qualitative analysis reveals that the abstraction often has a simple interpretation. Overall, the results suggest a strong structural relationship between internal representations used by RNNs and finite automata, and explain the well-known ability of RNNs to recognize formal grammatical structure. ", "keywords": ["Language recognition", "Recurrent Neural Networks", "Representation Learning", "deterministic finite automaton"], "authorids": ["ICLR.cc/2019/Conference/Paper1511/Authors"], "authors": ["Anonymous"], "TL;DR": "Finite Automata Can be Linearly decoded from Language-Recognizing RNNs", "pdf": "/pdf/7e14814921a0fde5433c7022554d5e3f3e565406.pdf", "paperhash": "anonymous|finite_automata_can_be_linearly_decoded_from_languagerecognizing_rnns", "_bibtex": "@inproceedings{    \nanonymous2019finite,    \ntitle={Finite Automata Can be Linearly Decoded from Language-Recognizing RNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1zeHnA9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1exrnCcF7", "original": "HyeUOVa5F7", "number": 1510, "cdate": 1538087992037, "ddate": null, "tcdate": 1538087992037, "tmdate": 1538156118480, "tddate": null, "forum": "B1exrnCcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Disjoint Mapping Network for Cross-modal Matching of Voices and Faces", "abstract": "We propose a novel framework, called Disjoint Mapping Network (DIMNet), for cross-modal biometric matching, in particular of voices and faces. Different from the existing methods, DIMNet does not explicitly learn the joint relationship between the modalities. Instead, DIMNet learns a shared representation for different modalities by mapping them individually to their common covariates. These shared representations can then be used to find the correspondences between the modalities. We show empirically that DIMNet is able to achieve better performance than the current state-of-the-art methods, with the additional benefits of being conceptually simpler and less data-intensive.", "keywords": ["cross-modal matching", "voices", "faces"], "authorids": ["ICLR.cc/2019/Conference/Paper1510/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c03c162d9c60e4fd771d2f643fc38932c286701c.pdf", "paperhash": "anonymous|disjoint_mapping_network_for_crossmodal_matching_of_voices_and_faces", "_bibtex": "@inproceedings{    \nanonymous2019disjoint,    \ntitle={Disjoint Mapping Network for Cross-modal Matching of Voices and Faces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1exrnCcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lxH20qtX", "original": "HJgn9GA9YX", "number": 1509, "cdate": 1538087991867, "ddate": null, "tcdate": 1538087991867, "tmdate": 1538156118277, "tddate": null, "forum": "B1lxH20qtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to control self-assembling morphologies: a study of generalization via modularity", "abstract": "Much of contemporary sensorimotor learning assumes that one is already given a complex agent (e.g., a robotic arm) and the goal is to learn to control it. In contrast, this paper investigates a modular co-evolution strategy: a collection of primitive agents learns to self-assemble into increasingly complex collectives in order to jointly solve control tasks. Each primitive agent consists of a limb and a neural controller. When two limbs link up, a joint is added between them, and messages are passed between the two neural controllers. Linking is treated as a dynamic action: to solve a task, agents learn how to self-assemble into a joint morphology and a joint neural net. The resulting policies and morphologies are dynamic and modular, which allows them to better generalize to novel test-time environments.  Experiments in several simulated environments are presented; see project videos at https://doubleblindICLR19.github.io/self-assembly/", "keywords": ["modularity", "compostionality", "graphs", "dynamics", "network"], "authorids": ["ICLR.cc/2019/Conference/Paper1509/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning to control self-assembling agents via dynamic graph networks", "pdf": "/pdf/d327f608eac4c3ec84c900c761b884268f56c4aa.pdf", "paperhash": "anonymous|learning_to_control_selfassembling_morphologies_a_study_of_generalization_via_modularity", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to control self-assembling morphologies: a study of generalization via modularity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lxH20qtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByleB2CcKm", "original": "ByeZXaact7", "number": 1508, "cdate": 1538087991699, "ddate": null, "tcdate": 1538087991699, "tmdate": 1538156118067, "tddate": null, "forum": "ByleB2CcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Procedural Abstractions and Evaluating Discrete Latent Temporal Structure", "abstract": "Clustering methods and latent variable models are often used as tools for pattern mining and discovery of latent structure in time-series data. In this work, we consider the problem of learning procedural abstractions from possibly high-dimensional observational sequences, such as video demonstrations. Given a dataset of time-series, the goal is to identify the latent sequence of steps common to them and label each time-series with the temporal extent of these procedural steps. We introduce a hierarchical Bayesian model called Prism that models the realization of a common procedure across multiple time-series, and can recover procedural abstractions with supervision. We also bring to light two characteristics ignored by traditional evaluation criteria when evaluating latent temporal labelings (temporal clusterings) -- segment structure, and repeated structure -- and develop new metrics tailored to their evaluation. We demonstrate that our metrics improve interpretability and ease of analysis for evaluation on benchmark time-series datasets. Results on benchmark and video datasets indicate that Prism outperforms standard sequence models as well as state-of-the-art techniques in identifying procedural abstractions.", "keywords": ["learning procedural abstractions", "latent variable modeling", "evaluation criteria"], "authorids": ["ICLR.cc/2019/Conference/Paper1508/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/701b67695528beb4750fcc1a6c5fb41c0f43a0c3.pdf", "paperhash": "anonymous|learning_procedural_abstractions_and_evaluating_discrete_latent_temporal_structure", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Procedural Abstractions and Evaluating Discrete Latent Temporal Structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByleB2CcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxeB30cYX", "original": "S1xlI2i5KQ", "number": 1507, "cdate": 1538087991529, "ddate": null, "tcdate": 1538087991529, "tmdate": 1538156117861, "tddate": null, "forum": "ryxeB30cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Quantized Activation: To prevent Overfitting in Fast Adversarial Training", "abstract": "Existing neural networks are vulnerable to \"adversarial examples\"---created by adding maliciously designed small perturbations in inputs to induce a misclassification by the networks. The most investigated defense strategy is adversarial training which augments training data with adversarial examples. However, applying single-step adversaries in adversarial training does not support the robustness of the networks, instead, they will even make the networks to be overfitted. In contrast to the single-step, multi-step training results in the state-of-the-art performance on MNIST and CIFAR10, yet it needs a massive amount of time. Therefore, we propose a method, Stochastic Quantized Activation (SQA) that solves overfitting problems in single-step adversarial training and fastly achieves the robustness comparable to the multi-step. SQA attenuates the adversarial effects by providing random selectivity to activation functions and allows the network to learn robustness with only single-step training. Throughout the experiment, our method demonstrates the state-of-the-art robustness against one of the strongest white-box attacks as PGD training, but with much less computational cost. Finally, we visualize the learning process of the network with SQA to handle strong adversaries, which is different from existing methods.", "keywords": ["adversarial examples", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1507/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes Stochastic Quantized Activation that solves overfitting problems in FGSM adversarial training and fastly achieves the robustness comparable to multi-step training.", "pdf": "/pdf/72bf182e28b9cde5c8ce533b4fdc4145c9aa394c.pdf", "paperhash": "anonymous|stochastic_quantized_activation_to_prevent_overfitting_in_fast_adversarial_training", "_bibtex": "@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Quantized Activation: To prevent Overfitting in Fast Adversarial Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxeB30cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxkHnA5tX", "original": "rJlQM31UKQ", "number": 1506, "cdate": 1538087991361, "ddate": null, "tcdate": 1538087991361, "tmdate": 1538156117644, "tddate": null, "forum": "rkxkHnA5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor", "abstract": "A noisy and diverse demonstration set may hinder the performances of an agent aiming to acquire certain skills via imitation learning. However, state-of-the-art imitation learning algorithms often assume the optimality of the given demonstration set.\nIn this paper, we address such optimal assumption by learning only from the most suitable demonstrations in a given set. Suitability of a demonstration is estimated by whether imitating it produce desirable outcomes for achieving the goals of the tasks. For more efficient demonstration suitability assessments, the learning agent should be capable of imitating a demonstration as quick as possible, which shares similar spirit with fast adaptation in the meta-learning regime. Our framework, thus built on top of Model-Agnostic Meta-Learning, evaluates how desirable the imitated outcomes are, after adaptation to each demonstration in the set. The resulting assessments hence enable us to select suitable demonstration subsets for acquiring better imitated skills. The videos related to our experiments are available at: https://sites.google.com/view/deepdj", "keywords": ["Imitation Learning", "Noisy Demonstration Set", "Meta-Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1506/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a framework to learn a good policy through imitation learning from a noisy demonstration set via meta-training a demonstration suitability assessor.", "pdf": "/pdf/8bffe3ba3be64af2446c6311b3bb7d228cf27bb6.pdf", "paperhash": "anonymous|learning_from_noisy_demonstration_sets_via_metalearned_suitability_assessor", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxkHnA5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkxkH30cFm", "original": "Hkl8Ey0qFX", "number": 1505, "cdate": 1538087991192, "ddate": null, "tcdate": 1538087991192, "tmdate": 1538156117437, "tddate": null, "forum": "BkxkH30cFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Object-Oriented Model Learning through Multi-Level Abstraction", "abstract": "Object-based approaches for learning action-conditioned dynamics has demonstrated promise of strong generalization and interpretability. However, existing  approaches suffer from structural limitations and optimization difficulties for common environments with multiple dynamic objects. In this paper, we present a novel self-supervised learning framework, called Multi-level Abstraction Object-oriented Predictor  (MAOP), for learning object-based dynamics models from raw visual observations. MAOP employs three-level learning archicture that enables efficient dynamics learning for complex environments with a dynamic background. We also design a spatial-temporal relational reasoning mechanism to support instance-level dynamics learning and handle partial observability. Empirical results show that MAOP significantly outperforms previous methods in terms of sample efficiency and generalization over novel environments that have multiple controllable and uncontrollable dynamic objects and different static object layouts. In addition, MAOP learns semantically and visually interpretable disentangled representations.", "keywords": ["action-conditioned dynamics learning", "deep learning", "generalization", "interpretability", "sample efficiency"], "authorids": ["ICLR.cc/2019/Conference/Paper1505/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e08c6c6a5727db997ac14be7bda1cb7bf84e1ba2.pdf", "paperhash": "anonymous|objectoriented_model_learning_through_multilevel_abstraction", "_bibtex": "@inproceedings{    \nanonymous2019object-oriented,    \ntitle={Object-Oriented Model Learning through Multi-Level Abstraction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkxkH30cFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByfyHh05tQ", "original": "Byewn5pcFQ", "number": 1504, "cdate": 1538087991023, "ddate": null, "tcdate": 1538087991023, "tmdate": 1538156117224, "tddate": null, "forum": "ByfyHh05tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Design RNA", "abstract": "Designing RNA molecules has garnered recent interest in medicine, synthetic biology, biotechnology and bioinformatics since many functional RNA molecules were shown to be involved in regulatory processes for transcription, epigenetics and translation. Since an RNA's function depends on its structural properties, the RNA Design problem is to find an RNA molecule that folds into a specified secondary structure. Here, we propose a new algorithm for the RNA Design problem, dubbed LEARNA. LEARNA uses deep reinforcement learning to train a policy network to sequentially design an entire RNA sequence given a specified secondary target structure. By meta-learning across thousands of different RNA target structures, our extension Meta-LEARNA constructs an RNA design policy that can be applied out of the box to solve novel RNA target structures. Comprehensive empirical results on two widely-used RNA secondary structure design benchmarks, as well as a third one that we introduce, show that our approach achieves new state-of-the-art performance on all benchmarks while also being up to 450x faster than any previous approach. We achieve this by a joint optimization of the policy network's architecture, the training hyperparameters, and the state space representation. In an ablation study, we analyze our method's different components.", "keywords": ["bioinformatics", "rna", "rna design", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1504/Authors"], "authors": ["Anonymous"], "TL;DR": "We learn to solve the RNA Design problem with reinforcement learning.", "pdf": "/pdf/158bdd3865dd6ae6b526bcf922dece4e9fedb7a8.pdf", "paperhash": "anonymous|learning_to_design_rna", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Design RNA},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByfyHh05tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxyHnR5tX", "original": "SJeQvMAcFX", "number": 1503, "cdate": 1538087990854, "ddate": null, "tcdate": 1538087990854, "tmdate": 1538156117019, "tddate": null, "forum": "ryxyHnR5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Accelerated Sparse Recovery Under Structured Measurements", "abstract": "Extensive work on compressed sensing has yielded a rich collection of sparse recovery algorithms, each making different tradeoffs between recovery condition and computational efficiency. In this paper, we propose a unified framework for accelerating various existing sparse recovery algorithms without sacrificing recovery guarantees by exploiting structure in the measurement matrix. Unlike fast algorithms that are specific to particular choices of measurement matrices where the columns are Fourier or wavelet filters for example, the proposed approach works on a broad range of measurement matrices that satisfy a particular property. We precisely characterize this property, which quantifies how easy it is to accelerate sparse recovery for the measurement matrix in question. We also derive the time complexity of the accelerated algorithm, which is sublinear in the signal length in each iteration. Moreover, we present experimental results on real world data that demonstrate the effectiveness of the proposed approach in practice. ", "keywords": ["sparse recovery"], "authorids": ["ICLR.cc/2019/Conference/Paper1503/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3c6986dc28c69fa58bf6f77d7a4f405286172472.pdf", "paperhash": "anonymous|accelerated_sparse_recovery_under_structured_measurements", "_bibtex": "@inproceedings{    \nanonymous2019accelerated,    \ntitle={Accelerated Sparse Recovery Under Structured Measurements},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxyHnR5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgJS30qtm", "original": "B1lgFB39tX", "number": 1502, "cdate": 1538087990682, "ddate": null, "tcdate": 1538087990682, "tmdate": 1538156116805, "tddate": null, "forum": "HJgJS30qtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "REVISTING NEGATIVE TRANSFER USING ADVERSARIAL LEARNING", "abstract": "An unintended consequence of feature sharing is the model fitting to correlated tasks within the dataset, termed negative transfer.  In this paper, we revisit the problem of negative transfer in multitask setting and find that its corrosive effects are applicable to a wide range of linear and non-linear models, including neural networks. We first study the effects of negative transfer in a principled way and show that previously proposed counter-measures are insufficient, particularly for trainable features. We propose an adversarial training approach to mitigate the effects of negative transfer by viewing the problem in a domain adaptation setting. Finally, empirical results on attribute prediction multi-task on AWA and CUB datasets further validate the need for correcting negative sharing in an end-to-end manner.", "keywords": ["Negative Transfer", "Adversarial Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1502/Authors"], "authors": ["Anonymous"], "TL;DR": "We look at negative transfer from a domain adaptation point of view to derive an adversarial learning algorithm.", "pdf": "/pdf/8d9cba07e61c67aada049def0cd9e4178391bcad.pdf", "paperhash": "anonymous|revisting_negative_transfer_using_adversarial_learning", "_bibtex": "@inproceedings{    \nanonymous2019revisting,    \ntitle={REVISTING NEGATIVE TRANSFER USING ADVERSARIAL LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgJS30qtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxRVnC5Fm", "original": "HyxQbinFKQ", "number": 1501, "cdate": 1538087990510, "ddate": null, "tcdate": 1538087990510, "tmdate": 1538156116594, "tddate": null, "forum": "BJxRVnC5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mean Replacement Pruning  ", "abstract": "Pruning units in a deep network can help speed up inference and training as wellas reduce the size of the model. We show thatbias propagationis a pruning tech-nique which consistently outperforms the common approach of merely removingunits,  regardless of the architecture and the dataset.   We also show how a sim-ple adaptation to an existing scoring function allows us to select the best units toprune.   Finally,  we show that the units selected by the best performing scoringfunctions are somewhat consistent over the course of training, implying the deadparts of the network appear during the stages of training.", "keywords": ["pruning", "saliency", "neural networks", "optimization", "redundancy", "model compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1501/Authors"], "authors": ["Anonymous"], "TL;DR": "Mean Replacement is an efficient method to improve the loss after pruning and Taylor approximation based scoring functions works better with absolute values. ", "pdf": "/pdf/fcf135ca3293f7ef0ac5c68372020e41077bd569.pdf", "paperhash": "anonymous|mean_replacement_pruning", "_bibtex": "@inproceedings{    \nanonymous2019mean,    \ntitle={Mean Replacement Pruning  },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxRVnC5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygRNn0qYX", "original": "Syxc1baqK7", "number": 1500, "cdate": 1538087990340, "ddate": null, "tcdate": 1538087990340, "tmdate": 1538156116385, "tddate": null, "forum": "BygRNn0qYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "P^2IR: Universal Deep Node Representation via Partial Permutation Invariant Set Functions", "abstract": "Graph node representation learning is a central problem in social network analysis, aiming to learn the vector representation for each node in a graph. The key problem is how to model the dependence  of each node to its neighbor nodes since the neighborhood can uniquely characterize a graph. While most existing approaches rely on defining the specific neighborhood dependence  as the computation mechanism of representations, which may exclude important subtle structures within the graph and dependence among neighbors, we propose a novel graph node embedding method (namely P^2IR) via developing a novel notion, namely partial permutation invariant set function. Our method can 1) learn an arbitrary form of the representation function from the neighborhood, without losing any potential dependence structures, 2) automatically decide the significance of neighbors at different distances, and 3) be applicable to both homogeneous and heterogeneous graph embedding, which may contain multiple types of nodes. Theoretical guarantee for the representation capability of our method has been proved for general homogeneous and heterogeneous graphs. Evaluation results on benchmark data sets show that the proposed P^2IR outperforms the state-of-the-art approaches on producing node vectors for classification tasks.", "keywords": ["graph embedding", "set function", "representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1500/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/333726225f35077ecb42d2fddd741dc4c7fe17aa.pdf", "paperhash": "anonymous|p^2ir_universal_deep_node_representation_via_partial_permutation_invariant_set_functions", "_bibtex": "@inproceedings{    \nanonymous2019p^2ir:,    \ntitle={P^2IR: Universal Deep Node Representation via Partial Permutation Invariant Set Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygRNn0qYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1x0E2C5tQ", "original": "HkxFMW39FX", "number": 1499, "cdate": 1538087990170, "ddate": null, "tcdate": 1538087990170, "tmdate": 1538156116173, "tddate": null, "forum": "B1x0E2C5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "What Is in a Translation Unit?  Comparing Character and Subword Representations Beyond Translation", "abstract": "Recent work has shown that contextualized word representations derived from neural machine translation (NMT) are a viable alternative to such from simple word predictions tasks. This is because the internal understanding that needs to be built in order to be able to translate from one language to another is much more comprehensive. Unfortunately, computational and memory limitations as of present prevent NMT models from using large word vocabularies, and thus alternatives such as subword units (BPE and morphological segmentations) and characters have been used. Here we study the impact of using different kinds of units on the quality of the resulting representations when used to model syntax, semantics, and morphology.  We found that while representations derived from subwords are slightly better for modeling syntax, character-based representations are superior for modeling morphology and are also more robust to noisy input.", "keywords": ["subwords", "representations", "word embeddings", "transfer learning", "machine translation", "natural language processing"], "authorids": ["ICLR.cc/2019/Conference/Paper1499/Authors"], "authors": ["Anonymous"], "TL;DR": "We study the impact of using different kinds of subword units on the quality of the resulting representations when used to model syntax, semantics, and morphology.", "pdf": "/pdf/2d312fa4a5b420f25d1e46c9044bfc739d1d4c88.pdf", "paperhash": "anonymous|what_is_in_a_translation_unit_comparing_character_and_subword_representations_beyond_translation", "_bibtex": "@inproceedings{    \nanonymous2019what,    \ntitle={What Is in a Translation Unit?  Comparing Character and Subword Representations Beyond Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1x0E2C5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgCV205tQ", "original": "Hkebfr0qKm", "number": 1498, "cdate": 1538087989991, "ddate": null, "tcdate": 1538087989991, "tmdate": 1538156115954, "tddate": null, "forum": "SkgCV205tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Accelerating first order optimization algorithms", "abstract": "There exist several stochastic optimization algorithms. However in most cases, it is difficult to tell for a particular problem which will be the best optimizer to choose as each of them are good. Thus, we present a simple and intuitive technique, when applied to first order optimization algorithms, is able to improve the speed of convergence and reaches a better minimum for the loss function compared to the original algorithms. The proposed solution modifies the update rule, based on the variation of the direction of the gradient during training. We conducted several tests with Adam and AMSGrad on two different  datasets. The preliminary results show that the proposed technique improves the performance of existing optimization algorithms and works well in practice.", "keywords": ["Optimization", "Optimizer", "Adam", "Gradient Descent"], "authorids": ["ICLR.cc/2019/Conference/Paper1498/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/916f8b0b2e74846fbd21f36c7c9e0d6ebfcf339d.pdf", "paperhash": "anonymous|accelerating_first_order_optimization_algorithms", "_bibtex": "@inproceedings{    \nanonymous2019accelerating,    \ntitle={Accelerating first order optimization algorithms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgCV205tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxCEhAqtQ", "original": "BJemfeC5KQ", "number": 1497, "cdate": 1538087989825, "ddate": null, "tcdate": 1538087989825, "tmdate": 1538156115734, "tddate": null, "forum": "HkxCEhAqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Accelerated Gradient Flow for Probability Distributions", "abstract": "This paper presents a methodology and numerical algorithms for constructing accelerated gradient flows on the space of probability distributions.  In particular, we  extend the recent variational formulation of accelerated gradient methods in wibisono2016 from vector valued variables to probability distributions.  The variational problem is modeled as a mean-field optimal control problem. The maximum principle of optimal control theory is used to derive Hamilton's equations for the optimal gradient flow. The Hamilton's equation are shown to achieve the accelerated form of density transport from any initial probability distribution to a target probability distribution.  A quantitative estimate on the asymptotic convergence rate is provided based on a Lyapunov function construction, when the objective functional is displacement convex.  Two numerical approximations are presented to implement the Hamilton's equations as a system of N interacting particles.  The continuous limit of the Nesterov's algorithm is shown to be a special case with N=1. The algorithm is illustrated with numerical examples.  ", "keywords": ["Optimal transportation", "Mean-field optimal control", "Wasserstein gradient flow", "Markov-chain Monte-Carlo"], "authorids": ["ICLR.cc/2019/Conference/Paper1497/Authors"], "authors": ["Anonymous"], "TL;DR": "Methodology and numerical algorithms for constructing accelerated gradient flows on the space of probability distributions.", "pdf": "/pdf/f7a0f69d351dd9d233ec7205c164e3ad31d8f609.pdf", "paperhash": "anonymous|accelerated_gradient_flow_for_probability_distributions", "_bibtex": "@inproceedings{    \nanonymous2019accelerated,    \ntitle={Accelerated Gradient Flow for Probability Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxCEhAqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygANhA9tQ", "original": "HygbNPpcFm", "number": 1496, "cdate": 1538087989659, "ddate": null, "tcdate": 1538087989659, "tmdate": 1538156115523, "tddate": null, "forum": "BygANhA9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cost-Sensitive Robustness against Adversarial Examples", "abstract": "Several recent works have developed methods for training classifiers that are certifiably robust against norm-bounded adversarial perturbations. However, these methods assume that all the adversarial transformations provide equal value for adversaries, which is seldom the case in real-world applications. We advocate for cost-sensitive robustness as the criteria for measuring the classifier's performance for specific tasks. We encode the potential harm of different adversarial transformations in a cost matrix, and propose a general objective function to adapt the robust training method of Wong & Kolter (2018) to optimize for cost-sensitive robustness. Our experiments on simple MNIST and CIFAR10 models and a variety of cost matrices show that the proposed approach can produce models with substantially reduced cost-sensitive robust error, while maintaining classification accuracy.", "keywords": ["Cost-sensitive learning", "Certified robustness", "Adversarial examples"], "authorids": ["ICLR.cc/2019/Conference/Paper1496/Authors"], "authors": ["Anonymous"], "TL;DR": "A general method for training certified cost-sensitive robust classifier against adversarial perturbations", "pdf": "/pdf/f6e360caa4cb30a9bb3718eb74ef9b49cda7b602.pdf", "paperhash": "anonymous|costsensitive_robustness_against_adversarial_examples", "_bibtex": "@inproceedings{    \nanonymous2019cost-sensitive,    \ntitle={Cost-Sensitive Robustness against Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygANhA9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lTEh09FQ", "original": "rJxe6zAqKm", "number": 1495, "cdate": 1538087989486, "ddate": null, "tcdate": 1538087989486, "tmdate": 1538156115314, "tddate": null, "forum": "S1lTEh09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Combinatorial Attacks on Binarized Neural Networks", "abstract": "Binarized Neural Networks (BNNs) have recently attracted significant interest due to their computational efficiency. Concurrently, it has been shown that neural networks may be overly sensitive to \"attacks\" -- tiny adversarial changes in the input -- which may be detrimental to their use in safety-critical domains. Designing attack algorithms that effectively fool trained models is a key step towards learning robust neural networks.\nThe discrete, non-differentiable nature of BNNs, which distinguishes them from their full-precision counterparts, poses a challenge to gradient-based attacks. In this work, we study the problem of attacking a BNN through the lens of combinatorial and integer optimization. We propose a Mixed Integer Linear Programming (MILP) formulation of the problem. While exact and flexible, the MILP quickly becomes intractable as the network and perturbation space grow. To address this issue, we propose IProp, a decomposition-based algorithm that solves a sequence of much smaller MILP problems. Experimentally, we evaluate both proposed methods against the standard gradient-based attack (FGSM) on MNIST and Fashion-MNIST, and show that IProp performs favorably compared to FGSM, while scaling beyond the limits of the MILP.", "keywords": ["binarized neural networks", "combinatorial optimization", "integer programming"], "authorids": ["ICLR.cc/2019/Conference/Paper1495/Authors"], "authors": ["Anonymous"], "TL;DR": "Gradient-based attacks on binarized neural networks are not effective due to the non-differentiability of such networks; Our IPROP algorithm solves this problem using integer optimization", "pdf": "/pdf/c08b27e9e883af3d19638c7a4101bc2e74c7477e.pdf", "paperhash": "anonymous|combinatorial_attacks_on_binarized_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019combinatorial,    \ntitle={Combinatorial Attacks on Binarized Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lTEh09FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gTE2AcKQ", "original": "S1gakg0qKQ", "number": 1494, "cdate": 1538087989300, "ddate": null, "tcdate": 1538087989300, "tmdate": 1538156115108, "tddate": null, "forum": "B1gTE2AcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "From Amortised to Memoised Inference: Combining Wake-Sleep and Variational-Bayes for Unsupervised Few-Shot Program Learning", "abstract": "Given a large database of concepts but only one or a few examples of each, can we learn models for each concept that are not only generalisable, but interpretable? In this work, we aim to tackle this problem through hierarchical Bayesian program induction. We present a novel learning algorithm which can infer concepts as short, generative, stochastic programs, while learning a global prior over programs to improve generalisation and a recognition network for efficient inference. Our algorithm, Wake-Sleep-Remember (WSR), combines gradient learning for continuous parameters with neurally-guided search over programs. We show that WSR learns compelling latent programs in two tough symbolic domains: cellular automata and Gaussian process kernels. We also collect and evaluate on a new dataset, Text-Concepts, for discovering structured patterns in natural text data.", "keywords": ["wake-sleep", "variational", "amortised inference", "hierarchical bayes", "program learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1494/Authors"], "authors": ["Anonymous"], "TL;DR": "We extend the wake-sleep algorithm and use it to learn to learn structured models from few examples, ", "pdf": "/pdf/6b4afd038aded2639886e8adf9c9fb2b4f1c7dfe.pdf", "paperhash": "anonymous|from_amortised_to_memoised_inference_combining_wakesleep_and_variationalbayes_for_unsupervised_fewshot_program_learning", "_bibtex": "@inproceedings{    \nanonymous2019from,    \ntitle={From Amortised to Memoised Inference: Combining Wake-Sleep and Variational-Bayes for Unsupervised Few-Shot Program Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gTE2AcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxpNnRcFX", "original": "rkxLDyBuFX", "number": 1493, "cdate": 1538087989129, "ddate": null, "tcdate": 1538087989129, "tmdate": 1538156114887, "tddate": null, "forum": "HyxpNnRcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Modulating transfer between tasks in gradient-based meta-learning", "abstract": "Learning-to-learn or meta-learning leverages data-driven inductive bias to increase the efficiency of learning on a novel task. This approach encounters difficulty when transfer is not mutually beneficial, for instance, when tasks are sufficiently dissimilar or change over time. Here, we use the connection between gradient-based meta-learning and hierarchical Bayes to propose a mixture of hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. Generalizing the model-agnostic meta-learning (MAML) algorithm, we present a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of hyperparameters. Our experiments demonstrate better generalization on the standard miniImageNet benchmark for 1-shot classification. We further derive a novel and scalable non-parametric variant of our method that captures the evolution of a task distribution over time as demonstrated on a set of synthetic regression tasks as well as an evolving dataset adapted from miniImageNet.", "keywords": ["meta-learning", "clustering", "learning-to-learn", "mixture", "hierarchical Bayes", "hierarchical model", "gradient-based meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1493/Authors"], "authors": ["Anonymous"], "TL;DR": "We use the connection between gradient-based meta-learning and hierarchical Bayes to learn a mixture of meta-learners that is appropriate for a heterogeneous and evolving task distribution.", "pdf": "/pdf/92e15fe379e96ac1027327f3f81930072390a20d.pdf", "paperhash": "anonymous|modulating_transfer_between_tasks_in_gradientbased_metalearning", "_bibtex": "@inproceedings{    \nanonymous2019modulating,    \ntitle={Modulating transfer between tasks in gradient-based meta-learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxpNnRcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygTE309t7", "original": "Hyx_e8nqF7", "number": 1492, "cdate": 1538087988951, "ddate": null, "tcdate": 1538087988951, "tmdate": 1538156114674, "tddate": null, "forum": "HygTE309t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Outlier Detection from Image Data", "abstract": "Modern applications from Autonomous Vehicles to Video Surveillance generate massive amounts of image data. In this work we propose a novel image outlier detection approach (IOD for short) that leverages the cutting-edge image classifier to discover outliers without using any labeled outlier. We observe that although intuitively the confidence that a convolutional neural network (CNN) has that an image belongs to a particular class could serve as outlierness measure to each image, directly applying this confidence to detect outlier does not work well. This is because CNN often has high confidence on an outlier image that does not belong to any target class due to its generalization ability that ensures the high accuracy in classification. To solve this issue, we propose a Deep Neural Forest-based approach that harmonizes the contradictory requirements of accurately classifying images and correctly detecting the outlier images. Our experiments using several benchmark image datasets including MNIST, CIFAR-10, CIFAR-100, and SVHN demonstrate the effectiveness of our IOD approach for outlier detection, capturing more than 90% of outliers generated by injecting one image dataset into another, while still preserving the classification accuracy of the multi-class classification problem.", "keywords": ["Image outlier", "CNN", "Deep Neural Forest"], "authorids": ["ICLR.cc/2019/Conference/Paper1492/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel approach that detects outliers from image data,  while at the same time preserving the classification accuracy of the multi-class classification problem", "pdf": "/pdf/3ae3145edf80407dbbe8b60292004d6514c400f1.pdf", "paperhash": "anonymous|outlier_detection_from_image_data", "_bibtex": "@inproceedings{    \nanonymous2019outlier,    \ntitle={Outlier Detection from Image Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygTE309t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1laEnA5Ym", "original": "rJlqs7_vFX", "number": 1491, "cdate": 1538087988778, "ddate": null, "tcdate": 1538087988778, "tmdate": 1538156114468, "tddate": null, "forum": "r1laEnA5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Variational Inequality Perspective on Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) form a generative modeling approach known for producing appealing samples, but they are notably difficult to train. One common way to tackle this issue has been to propose new formulations of the GAN objective. Yet, surprisingly few studies have looked at optimization methods designed for this adversarial training. In this work, we cast GAN optimization problems in the general variational inequality framework. Tapping into the mathematical programming literature, we counter some common misconceptions about the difficulties of saddle point optimization and propose to extend methods designed for variational inequalities to the training of GANs. We apply averaging, extrapolation and a novel computationally cheaper variant that we call extrapolation from the past to the stochastic gradient method (SGD) and Adam.", "keywords": ["optimization", "variational inequality", "games", "saddle point", "extrapolation", "averaging", "extragradient", "generative modeling", "generative adversarial network"], "authorids": ["ICLR.cc/2019/Conference/Paper1491/Authors"], "authors": ["Anonymous"], "TL;DR": "We cast GANs in the variational inequality framework and import techniques from this literature to optimize GANs better; we give algorithmic extensions and empirically test their performance for training GANs.", "pdf": "/pdf/b3a8d84e98e49bf84ecf9ca3f852a5c9496ef76f.pdf", "paperhash": "anonymous|a_variational_inequality_perspective_on_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Variational Inequality Perspective on Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1laEnA5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hye64hA9tm", "original": "HJlL7-RqtQ", "number": 1490, "cdate": 1538087988612, "ddate": null, "tcdate": 1538087988612, "tmdate": 1538156114262, "tddate": null, "forum": "Hye64hA9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Measuring Density and Similarity of Task Relevant Information in Neural Representations", "abstract": "Neural models achieve state-of-the-art performance due to their ability to extract salient features useful to downstream tasks. However, our understanding of how this task-relevant information is included in these networks is still incomplete. In this paper, we examine two questions (1) how densely is information included in extracted representations, and (2) how similar is the encoding of relevant information between related tasks. We propose metrics to measure information density and cross-task similarity, and perform an extensive analysis in the domain of natural language processing, using four varieties of sentence representation and 13 tasks. We also demonstrate how the proposed analysis tools can find immediate use in choosing tasks for transfer learning.", "keywords": ["Neural Networks", "Representation", "Information density", "Transfer Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1490/Authors"], "authors": ["Anonymous"], "TL;DR": "Measuring information density and cross-task similarity in neural models and its application in transfer learning.", "pdf": "/pdf/a09c333bba24c78483deee1ff093b4b63deb70f6.pdf", "paperhash": "anonymous|measuring_density_and_similarity_of_task_relevant_information_in_neural_representations", "_bibtex": "@inproceedings{    \nanonymous2019measuring,    \ntitle={Measuring Density and Similarity of Task Relevant Information in Neural Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hye64hA9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1g2NhC5KQ", "original": "B1gHXcTqY7", "number": 1489, "cdate": 1538087988424, "ddate": null, "tcdate": 1538087988424, "tmdate": 1538156114051, "tddate": null, "forum": "H1g2NhC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multiple-Attribute Text Rewriting", "abstract": "The dominant approach to unsupervised \"style transfer\" in text is based on the idea of learning a latent representation, which is independent of the attributes specifying its \"style\". In this paper, we show that this condition is not necessary and is not always met in practice, even with domain adversarial training, that explicitly aims at learning such  disentangled representations. We thus propose a new model that controls several factors of variation in textual data where this condition on disentanglement is replaced with a simpler mechanism based on back-translation. Our method allows control over multiple attributes, like gender, sentiment, product type, etc., and a more fine-grained control on the trade-off between content preservation and change of style with a pooling operator in the latent space. Our experiments demonstrate that the fully entangled model produces better generations, even when tested on new and more challenging benchmarks comprising reviews with multiple sentences and multiple attributes.", "keywords": ["controllable text generation", "generative models", "conditional generative models", "style transfer"], "authorids": ["ICLR.cc/2019/Conference/Paper1489/Authors"], "authors": ["Anonymous"], "TL;DR": "A system for rewriting text conditioned on multiple controllable attributes", "pdf": "/pdf/00f16115a71246882359d7d6231dfe61920addc7.pdf", "paperhash": "anonymous|multipleattribute_text_rewriting", "_bibtex": "@inproceedings{    \nanonymous2019multiple-attribute,    \ntitle={Multiple-Attribute Text Rewriting},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g2NhC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1g2V3Cct7", "original": "HylyO_p9tQ", "number": 1488, "cdate": 1538087988253, "ddate": null, "tcdate": 1538087988253, "tmdate": 1538156113840, "tddate": null, "forum": "S1g2V3Cct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Experience replay for continual learning", "abstract": "Continual learning is the problem of learning new tasks or knowledge while protecting old knowledge and ideally generalizing from old experience to learn new tasks faster. Neural networks trained by stochastic gradient descent often degrade on old tasks when trained successively on new tasks with different data distributions. This phenomenon, referred to as catastrophic forgetting, is considered a major hurdle to learning with non-stationary data or sequences of new tasks, and prevents networks from continually accumulating knowledge and skills. We examine this issue in the context of reinforcement learning, in a setting where an agent is exposed to tasks in a sequence. Unlike most other work, we do not provide an explicit indication to the model of task boundaries, which is the most general circumstance for a learning agent exposed to continuous experience. While various methods to counteract catastrophic forgetting have recently been proposed, we explore a straightforward, general, and seemingly overlooked solution - that of using experience replay buffers for all past events - with a mixture of on- and off-policy learning, leveraging behavioral cloning. We show that this strategy can still learn new tasks quickly yet can substantially reduce catastrophic forgetting in both Atari and DMLab domains, even matching the performance of methods that require task identities. When buffer storage is constrained, we confirm that a simple mechanism for randomly discarding data allows a limited size buffer to perform almost as well as an unbounded one.", "keywords": ["continual learning", "catastrophic forgetting", "lifelong learning", "behavioral cloning", "reinforcement learning", "interference", "stability-plasticity"], "authorids": ["ICLR.cc/2019/Conference/Paper1488/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that, in continual learning settings, catastrophic forgetting can be avoided by applying off-policy RL to a mixture of new and replay experience, with a behavioral cloning loss.", "pdf": "/pdf/c9dbcae23880f2bc653197fddc31bd87234774b3.pdf", "paperhash": "anonymous|experience_replay_for_continual_learning", "_bibtex": "@inproceedings{    \nanonymous2019experience,    \ntitle={Experience replay for continual learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1g2V3Cct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkghN205KQ", "original": "H1lwHDp5t7", "number": 1487, "cdate": 1538087988081, "ddate": null, "tcdate": 1538087988081, "tmdate": 1538156113627, "tddate": null, "forum": "SkghN205KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Search-Guided, Lightly-supervised Training of  Structured Prediction Energy Networks", "abstract": " In structured output prediction tasks, labeling ground-truth training output is often expensive. However, for many tasks, even when the true output is unknown, we can evaluate predictions using a scalar reward function, which may be easily assembled from human knowledge or non-differentiable pipelines.  But searching through the entire output space to find the best output with respect to this reward function is typically intractable.  In this paper, we instead use efficient truncated randomized search in this reward function to train structured prediction energy networks (SPENs), which provide efficient test-time inference using gradient-based search on a smooth, learned representation of the score landscape, and have previously yielded state-of-the-art results in structured prediction.  In particular, this truncated randomized search in the reward function yields previously unknown local improvements, providing effective supervision to SPENs, avoiding their traditional need for labeled training data. ", "keywords": ["structured prediction energy networks", "indirect supervision", "search-guided training", "reward functions"], "authorids": ["ICLR.cc/2019/Conference/Paper1487/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/62e92e74e30275e7520f0dc556f8873c5e9c460d.pdf", "paperhash": "anonymous|searchguided_lightlysupervised_training_of_structured_prediction_energy_networks", "_bibtex": "@inproceedings{    \nanonymous2019search-guided,,    \ntitle={Search-Guided, Lightly-supervised Training of  Structured Prediction Energy Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkghN205KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGhN2A5tm", "original": "SJx5ykFqFm", "number": 1486, "cdate": 1538087987897, "ddate": null, "tcdate": 1538087987897, "tmdate": 1538156113419, "tddate": null, "forum": "HyGhN2A5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-Agent Dual Learning", "abstract": "Dual learning has attracted much attention in machine learning, computer vision and natural language processing communities. The core idea of dual learning is to leverage the duality between the primal task (mapping from domain X to domain Y) and dual task (mapping from domain Y to X) to boost the performances of both tasks. Existing dual learning framework forms a system with two agents (one primal model and one dual model) to utilize such duality. In this paper, we extend this framework by introducing more primal and dual models, and propose the multi-agent dual learning framework. Experiments on neural machine translation and image translation tasks demonstrate the effectiveness of the new framework. \nIn particular, our framework achieves state-of-the-art performance on IWSLT 2014 German-to-English translation with a 35.44 BLEU score and achieves a 30.67 BLEU score on WMT 2014 English-to-German translation, with over 2.2 BLEU improvement over the strong Transformer baseline. ", "keywords": ["dual learning", "machine learning", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1486/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9878047fa7b50f4a2f3300158468f2e6ba6d5123.pdf", "paperhash": "anonymous|multiagent_dual_learning", "_bibtex": "@inproceedings{    \nanonymous2019multi-agent,    \ntitle={Multi-Agent Dual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGhN2A5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl2E3AcF7", "original": "H1xd-Fa5F7", "number": 1485, "cdate": 1538087987702, "ddate": null, "tcdate": 1538087987702, "tmdate": 1538156113207, "tddate": null, "forum": "rJl2E3AcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference", "abstract": "Computations for the softmax function in neural network models are expensive when the number of output classes is large. This can become a significant issue in both training and inference for such models. In this paper, we present Doubly Sparse Softmax (DS-Softmax), Sparse Mixture of Sparse of Sparse Experts, to improve the efficiency for softmax inference. During training, our method learns a two-level class hierarchy by dividing entire output class space into several partially overlapping experts. Each expert is responsible for a learned subset of the output class space and each output class only belongs to a small number of those experts. During inference, our method quickly locates the most probable expert to compute small-scale softmax. Our method is learning-based and requires no knowledge of the output class partition space a priori. We empirically evaluate our method on several real-world tasks and demonstrate that we can achieve significant computation reductions without loss of performance.", "keywords": ["hierarchical softmax", "model compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1485/Authors"], "authors": ["Anonymous"], "TL;DR": "We present doubly sparse softmax, the sparse mixture of sparse of sparse experts, to improve the efficiency for softmax inference through exploiting the two-level overlapping hierarchy. ", "pdf": "/pdf/3fb5edb29718ac6e1b0fbc79cd135494fbf62808.pdf", "paperhash": "anonymous|doubly_sparse_sparse_mixture_of_sparse_experts_for_efficient_softmax_inference", "_bibtex": "@inproceedings{    \nanonymous2019doubly,    \ntitle={Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl2E3AcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkghV209tm", "original": "rJgogeCqKQ", "number": 1484, "cdate": 1538087987531, "ddate": null, "tcdate": 1538087987531, "tmdate": 1538156112997, "tddate": null, "forum": "HkghV209tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimistic Acceleration for Optimization", "abstract": "We consider new variants of optimization algorithms. Our algorithms are based on the observation that mini-batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. Inspired by the similar setting in online learning literature called Optimistic Online learning, we propose two new algorithms, Optimistic-AMSGrad and Optimistic-Adam that exploit the predictability of gradients. Optimistic-AMSGrad and Optimistic-Adam combine the idea of momentum method, adaptive gradient method, and algorithms in Optimistic Online learning, which leads to speed up in training deep neural nets in practice.\n", "keywords": ["optimization", "Adam", "AMSGrad"], "authorids": ["ICLR.cc/2019/Conference/Paper1484/Authors"], "authors": ["Anonymous"], "TL;DR": "We consider new variants of optimization algorithms for training deep nets.", "pdf": "/pdf/accce94957d383360bc97c48433b01bfaabebc4c.pdf", "paperhash": "anonymous|optimistic_acceleration_for_optimization", "_bibtex": "@inproceedings{    \nanonymous2019optimistic,    \ntitle={Optimistic Acceleration for Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkghV209tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygjN3C9F7", "original": "Hkl7x1RqYm", "number": 1483, "cdate": 1538087987360, "ddate": null, "tcdate": 1538087987360, "tmdate": 1538156112792, "tddate": null, "forum": "rygjN3C9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Variational Deficiency Bottleneck", "abstract": "We introduce a bottleneck method for learning data representations based on channel deficiency, rather than the more traditional information sufficiency. A variational upper bound allows us to implement this method efficiently. The bound itself is bounded above by the variational information bottleneck objective, and the two methods coincide in the regime of single shot Monte Carlo approximations. The notion of deficiency provides a principled way of approximating complicated channels by relatively simpler ones. The deficiency of one channel w.r.t. another has an operational interpretation in terms of the optimal risk gap of general decision problems, capturing classification as a special case. Unsupervised generalizations are possible, such as the deficiency autoencoder, which also can be formulated in a variational form. Experiments demonstrate that the deficiency bottleneck can provide advantages in terms of minimal sufficiency as measured by information bottleneck curves, while retaining a good test performance in classification and reconstruction tasks. \n", "keywords": ["Variational Information Bottleneck", "Blackwell Sufficiency", "Le Cam Deficiency", "Information Channel"], "authorids": ["ICLR.cc/2019/Conference/Paper1483/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a new bottleneck method based on channel deficiency.", "pdf": "/pdf/c9b1f1782999d3c1bc7bb3809be9fadde2de49bd.pdf", "paperhash": "anonymous|the_variational_deficiency_bottleneck", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Variational Deficiency Bottleneck},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygjN3C9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgsN3R9Km", "original": "SJgKy0n9tX", "number": 1482, "cdate": 1538087987187, "ddate": null, "tcdate": 1538087987187, "tmdate": 1538156112589, "tddate": null, "forum": "BJgsN3R9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "AntMan: Sparse Low-Rank Compression To Accelerate RNN Inference", "abstract": "Wide adoption of complex RNN based models is hindered by their inference performance, cost and memory requirements. To address this issue, we develop AntMan, combining structured sparsity with low-rank decomposition synergistically, to reduce model computation, size and execution time of RNNs while attaining desired accuracy. AntMan extends knowledge distillation based training to learn the compressed models efficiently. Our evaluation shows that AntMan offers up to 100x computation reduction with less than 1pt accuracy drop for language and machine reading comprehension models. Our evaluation also shows that for a given accuracy target, AntMan produces 5x smaller models than the state-of-art. Lastly, we show that AntMan offers super-linear speed gains compared to theoretical speedup, demonstrating its practical value on commodity hardware.", "keywords": ["model compression", "RNN", "perforamnce optimization", "langugage model", "machine reading comprehension", "knowledge distillation", "teacher-student"], "authorids": ["ICLR.cc/2019/Conference/Paper1482/Authors"], "authors": ["Anonymous"], "TL;DR": "Reducing computation and memory complexity of RNN models by up to 100x using sparse low-rank compression modules, trained via knowledge distillation.", "pdf": "/pdf/63f811408b36239906dc0de5a44d2f2b2f719103.pdf", "paperhash": "anonymous|antman_sparse_lowrank_compression_to_accelerate_rnn_inference", "_bibtex": "@inproceedings{    \nanonymous2019antman:,    \ntitle={AntMan: Sparse Low-Rank Compression To Accelerate RNN Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgsN3R9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxsV2R5FQ", "original": "BkghyT29YX", "number": 1481, "cdate": 1538087987012, "ddate": null, "tcdate": 1538087987012, "tmdate": 1538156112379, "tddate": null, "forum": "SJxsV2R5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning sparse relational transition models", "abstract": "We present a representation for describing transition models in complex uncertain domains using relational rules.  For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state.  An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state.   Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties.  This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.", "keywords": ["Deictic reference", "relational model", "rule-based transition model"], "authorids": ["ICLR.cc/2019/Conference/Paper1481/Authors"], "authors": ["Anonymous"], "TL;DR": "A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ", "pdf": "/pdf/663a61127c0528d30720e09bc5bd11a948ac20a9.pdf", "paperhash": "anonymous|learning_sparse_relational_transition_models", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning sparse relational transition models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxsV2R5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryljV2A5KX", "original": "SyeK3Cv5KQ", "number": 1480, "cdate": 1538087986836, "ddate": null, "tcdate": 1538087986836, "tmdate": 1538156112168, "tddate": null, "forum": "ryljV2A5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "IB-GAN: Disentangled Representation Learning with Information Bottleneck GAN", "abstract": "We present a novel architecture of GAN for a disentangled representation learning. The new model architecture is inspired by Information Bottleneck (IB) theory thereby named IB-GAN. IB-GAN objective is similar to that of InfoGAN but has a crucial difference; a capacity regularization for mutual information is adopted, thanks to which the generator of IB-GAN can harness a latent representation in disentangled and interpretable manner. To facilitate the optimization of IB-GAN in practice, a new variational upper-bound is derived. With experiments on CelebA, 3DChairs, and dSprites datasets, we demonstrate that the visual quality of samples generated by IB-GAN is often better than those by \u03b2-VAEs. Moreover, IB-GAN achieves much higher disentanglement metrics score than \u03b2-VAEs or InfoGAN on the dSprites dataset.", "keywords": ["Unsupervised disentangled representation learning", "GAN", "Information Bottleneck", "Variational Inference"], "authorids": ["ICLR.cc/2019/Conference/Paper1480/Authors"], "authors": ["Anonymous"], "TL;DR": "Inspired by Information Bottleneck theory,  we propose a new architecture of GAN for a disentangled representation learning", "pdf": "/pdf/b105db21f43332bf06385a059e8c0ef7a0e2992e.pdf", "paperhash": "anonymous|ibgan_disentangled_representation_learning_with_information_bottleneck_gan", "_bibtex": "@inproceedings{    \nanonymous2019ib-gan:,    \ntitle={IB-GAN: Disentangled Representation Learning with Information Bottleneck GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryljV2A5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxoNnC5FQ", "original": "S1eTjcitt7", "number": 1479, "cdate": 1538087986661, "ddate": null, "tcdate": 1538087986661, "tmdate": 1538156111954, "tddate": null, "forum": "rkxoNnC5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SPIGAN: Privileged Adversarial Learning from Simulation", "abstract": "Deep Learning for Computer Vision depends mainly on the source of supervision.Photo-realistic simulators can generate large-scale automatically labeled syntheticdata, but introduce a domain gap negatively impacting performance. We propose anew unsupervised domain adaptation algorithm, called SPIGAN, relying on Simu-lator Privileged Information (PI) and Generative Adversarial Network (GAN). Weuse internal data structures of the simulator as PI only available during training ofa target task network. We experimentally evaluate our approach on semantic seg-mentation.  We use the real-world Cityscapes and Vistas datasets, training usingonly unlabeled real-world images with synthetic labeled data and z-buffer (depth)PI  from  the  SYNTHIA  dataset.   Our  method  improves  over  no  adaptation  andstate-of-the-art unsupervised domain adaptation techniques.", "keywords": ["domain adaptation", "GAN", "semantic segmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper1479/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8b52ac0ad79431eb1eba8f8e60df6d6aaf1f1eb1.pdf", "paperhash": "anonymous|spigan_privileged_adversarial_learning_from_simulation", "_bibtex": "@inproceedings{    \nanonymous2019spigan:,    \ntitle={SPIGAN: Privileged Adversarial Learning from Simulation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxoNnC5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlcV2Actm", "original": "S1eDL9jcFQ", "number": 1478, "cdate": 1538087986484, "ddate": null, "tcdate": 1538087986484, "tmdate": 1538156111746, "tddate": null, "forum": "rJlcV2Actm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MahiNet: A Neural Network for Many-Class Few-Shot Learning with Class Hierarchy", "abstract": "We study many-class few-shot (MCFS) problem in both supervised learning and meta-learning scenarios. Compared to the well-studied many-class many-shot and few-class few-shot problems, MCFS problem commonly occurs in practical applications but is rarely studied. MCFS brings new challenges because it needs to distinguish between many classes, but only a few samples per class are available for training. In this paper, we propose ``memory-augmented hierarchical-classification network (MahiNet)'' for MCFS learning. It addresses the ``many-class'' problem by exploring the class hierarchy, e.g., the coarse-class label that covers a subset of fine classes, which helps to narrow down the candidates for the fine class and is cheaper to obtain. MahiNet uses a convolutional neural network (CNN) to extract features, and integrates a memory-augmented attention module with a multi-layer perceptron (MLP) to produce the probabilities over coarse and fine classes. While the MLP extends the linear classifier, the attention module extends a KNN classifier, both together targeting the ``few-shot'' problem. We design different training strategies of MahiNet for supervised learning and meta-learning. Moreover, we propose two novel benchmark datasets ''mcfsImageNet'' (as a subset of ImageNet) and ''mcfsOmniglot'' (re-splitted Omniglot) specifically for MCFS problem. In experiments, we show that MahiNet outperforms several state-of-the-art models on MCFS classification tasks in both supervised learning and meta-learning scenarios.", "keywords": ["deep learning", "many-class few-shot", "class hierarchy", "meta learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1478/Authors"], "authors": ["Anonymous"], "TL;DR": "A memory-augmented neural network that addresses many-class few-shot problem by leveraging class hierarchy in both supervised learning and meta-learning.", "pdf": "/pdf/dfa29f04380569c27fbfbb637f77d2b9f405cc88.pdf", "paperhash": "anonymous|mahinet_a_neural_network_for_manyclass_fewshot_learning_with_class_hierarchy", "_bibtex": "@inproceedings{    \nanonymous2019mahinet:,    \ntitle={MahiNet: A Neural Network for Many-Class Few-Shot Learning with Class Hierarchy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlcV2Actm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeq43AqF7", "original": "BJe4d2nqYm", "number": 1477, "cdate": 1538087986316, "ddate": null, "tcdate": 1538087986316, "tmdate": 1538156111537, "tddate": null, "forum": "HJeq43AqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders ", "abstract": "Syntax is a powerful abstraction for language understanding. Many downstream tasks require segmenting input text into meaningful constituent chunks (e.g., noun phrases or entities); more generally, models for learning semantic representations of text benefit from integrating syntax in the form of parse trees (e.g., tree-LSTMs). Supervised parsers have traditionally been used to obtain these trees, but lately interest has increased in unsupervised methods that induce syntactic representations directly from unlabeled text. To this end, we propose the deep inside-outside recursive autoencoder (DIORA), a fully-unsupervised method for discovering syntax that simultaneously learns representations for constituents within the induced tree. Unlike many prior approaches, DIORA does not rely on supervision from auxiliary downstream tasks and is thus not constrained to particular domains. Furthermore, competing approaches do not learn explicit phrase representations along with tree structures, which limits their applicability to phrase-based tasks. Extensive experiments on unsupervised parsing, segmentation, and phrase clustering demonstrate the efficacy of our method. DIORA achieves the state of the art in unsupervised parsing (46.9 F1) on the benchmark WSJ dataset.", "keywords": ["latent-tree-learning", "unsupervised-parsing"], "authorids": ["ICLR.cc/2019/Conference/Paper1477/Authors"], "authors": ["Anonymous"], "TL;DR": "In this work we propose deep inside-outside recursive auto-encoders(DIORA)  a  fully  unsupervised  method  of  discovering  syntax  while  simultaneously learning representations for discovered constituents. ", "pdf": "/pdf/c302a86a9f11dd4707d605f7a2e3afc5b5d1e3b7.pdf", "paperhash": "anonymous|unsupervised_latent_tree_induction_with_deep_insideoutside_recursive_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeq43AqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1g9N2A5FX", "original": "Skl1WVLFtQ", "number": 1476, "cdate": 1538087986140, "ddate": null, "tcdate": 1538087986140, "tmdate": 1538156111325, "tddate": null, "forum": "S1g9N2A5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1476/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/7bb0683184d6c4f34931cae9e8186d62c3648820.pdf", "paperhash": "anonymous|interpretable_continual_learning", "_bibtex": "@inproceedings{    \nanonymous2019interpretable,    \ntitle={Interpretable Continual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1g9N2A5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syx5V2CcFm", "original": "S1eOc62ctX", "number": 1475, "cdate": 1538087985965, "ddate": null, "tcdate": 1538087985965, "tmdate": 1538156111118, "tddate": null, "forum": "Syx5V2CcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions", "abstract": "Although stochastic gradient descent (SGD) method and its variants (e.g., stochastic momentum methods, AdaGrad) are algorithms of choice for solving non-convex problems (especially deep learning),  big gaps still remain between the theory and the practice with many questions unresolved. For example, there is still a lack of theories of convergence for SGD and its variants that use stagewise step size and return an averaged solution in practice. In addition, theoretical insights of why adaptive step size of AdaGrad could improve non-adaptive step size of SGD is still missing for non-convex optimization.   This paper aims to address these questions and fill the gap between theory and practice. We propose a universal stagewise optimization framework for a broad family of non-smooth non-convex problems with the following key features: (i) at each stage any suitable stochastic convex optimization algorithms (e.g., SGD  or AdaGrad)  that return an averaged solution can be employed for minimizing a regularized convex problem; (ii) the step size is decreased in  a stagewise manner; (iii)  an averaged solution  is returned as the final solution. % that is selected from all stagewise averaged solutions with sampling probabilities  increasing as the stage number. \nOur theoretical results of stagewise {\\ada}  exhibit its adaptive convergence, therefore shed insights on its faster convergence than stagewise SGD  for problems with slowly growing cumulative stochastic gradients. To the best of our knowledge, these new results are the first of their kind for addressing the unresolved issues of existing theories  mentioned earlier. Besides theoretical contributions, our empirical studies show that our stagewise variants of SGD, AdaGrad  improve the generalization performance of existing variants/implementations of SGD and AdaGrad. ", "keywords": ["optimization", "sgd", "adagrad"], "authorids": ["ICLR.cc/2019/Conference/Paper1475/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4f68a5215c8c3bca51d880d29ce14a4818d31d1c.pdf", "paperhash": "anonymous|universal_stagewise_learning_for_nonconvex_problems_with_convergence_on_averaged_solutions", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal  Stagewise Learning for Non-Convex Problems with  Convergence on  Averaged Solutions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syx5V2CcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJx9EhC9tQ", "original": "rJgerzR9Km", "number": 1474, "cdate": 1538087985783, "ddate": null, "tcdate": 1538087985783, "tmdate": 1538156110907, "tddate": null, "forum": "HJx9EhC9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reasoning About Physical Interactions with Object-Centric Models", "abstract": "Object-based factorizations provide a useful level of abstraction for interacting with the world. Building explicit object representations, however, often requires supervisory signals that are difficult to obtain in practice. We present a paradigm for learning object-centric representations for physical scene understanding without direct supervision of object properties. Our model, object-oriented prediction and planning (O2P2), jointly learns a perception function to map from image observations to object representations, a pairwise physics interaction function to predict the time evolution of a collection of objects, and a rendering function to map objects back to pixels. For evaluation, we consider not only the accuracy of the physical predictions of the model, but also its utility for downstream tasks that require an actionable representation of intuitive physics. After training our model on an image prediction task, we can use its learned representations to build block towers more complicated than those observed during training.", "keywords": ["structured scene representation", "predictive models", "intuitive physics", "self-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1474/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a framework for learning object-centric representations suitable for planning in tasks that require an understanding of physics.", "pdf": "/pdf/310b0d78886f4a3e05506b1020f702e520ea48a3.pdf", "paperhash": "anonymous|reasoning_about_physical_interactions_with_objectcentric_models", "_bibtex": "@inproceedings{    \nanonymous2019reasoning,    \ntitle={Reasoning About Physical Interactions with Object-Centric Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJx9EhC9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkltNhC9FX", "original": "r1xhUNY5tX", "number": 1473, "cdate": 1538087985481, "ddate": null, "tcdate": 1538087985481, "tmdate": 1538156110700, "tddate": null, "forum": "BkltNhC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Posterior Attention Models for Sequence to Sequence Learning", "abstract": "Modern neural architectures critically rely on attention for mapping structured\ninputs to sequences. In this paper we show that prevalent attention architectures\ndo not adequately model the dependence among the attention and output variables\nalong the length of a predicted sequence. We present an alternative architecture\ncalled Posterior Attention Models that relying on a principled factorization of\nthe full joint distribution of the attention and output variables propose two major\nchanges. First, the position where attention is marginalized is changed from the\ninput to the output. Second, the attention propagated to the next decoding stage\nis a posterior attention distribution conditioned on the output. Empirically on five\ntranslation and two morphological inflection tasks the proposed posterior attention\nmodels yield better predictions and alignment accuracy than existing attention\nmodels.", "keywords": ["posterior inference", "attention", "seq2seq learning", "translation"], "authorids": ["ICLR.cc/2019/Conference/Paper1473/Authors"], "authors": ["Anonymous"], "TL;DR": "Computing attention based on posterior distribution leads to more meaningful attention and better performance", "pdf": "/pdf/f72256a266619038f3cf247811fbb46a7290ef3a.pdf", "paperhash": "anonymous|posterior_attention_models_for_sequence_to_sequence_learning", "_bibtex": "@inproceedings{    \nanonymous2019posterior,    \ntitle={Posterior Attention Models for Sequence to Sequence Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkltNhC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xFE3Rqt7", "original": "HJx8A_h5FX", "number": 1472, "cdate": 1538087985303, "ddate": null, "tcdate": 1538087985303, "tmdate": 1538156110485, "tddate": null, "forum": "r1xFE3Rqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Mixture of Low-Rank Factorizations for Compact Neural Modeling", "abstract": "Modern deep neural networks have a large amount of weights, which make them difficult to deploy on computation constrained devices such as mobile phones. One common approach to reduce the model size and computational cost is to use low-rank factorization to approximate a weight matrix. However, performing standard low-rank factorization with a small rank can hurt the model expressiveness and significantly decrease the performance. In this work, we propose to use a mixture of multiple low-rank factorizations to model a large weight matrix, and the mixture coefficients are computed dynamically depending on its input. We demonstrate the effectiveness of the proposed approach on both language modeling and image classification tasks. Experiments show that our method not only improves the computation efficiency but also maintains (sometimes outperforms) its accuracy compared with the full-rank counterparts.", "keywords": ["Low-Rank Factorization", "Compact Neural Nets", "Efficient Modeling", "Mixture models"], "authorids": ["ICLR.cc/2019/Conference/Paper1472/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a simple modification to low-rank factorization that improves performances (in both image and language tasks) while still being compact.", "pdf": "/pdf/cbdb0a5e01b6a291e2e42e270fba1ed87e183335.pdf", "paperhash": "anonymous|adaptive_mixture_of_lowrank_factorizations_for_compact_neural_modeling", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Mixture of Low-Rank Factorizations for Compact Neural Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xFE3Rqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxFN3RcFX", "original": "rygpNFdttQ", "number": 1471, "cdate": 1538087985131, "ddate": null, "tcdate": 1538087985131, "tmdate": 1538156110266, "tddate": null, "forum": "SJxFN3RcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Functional Bayesian Neural Networks for Model Uncertainty Quantification", "abstract": "In this paper, we extend the Bayesian neural network to functional Bayesian neural network with functional Monte Carlo methods that use the samples of functionals instead of samples of networks' parameters for inference to overcome the curse of dimensionality for uncertainty quantification. Based on the previous work on Riemannian Langevin dynamics, we propose the stochastic gradient functional Riemannian dynamics for training functional Bayesian neural network. We show the effectiveness and efficiency of our proposed approach with various experiments. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1471/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fe97ef2b6f7b5b3638974684d53486c021f80bb3.pdf", "paperhash": "anonymous|functional_bayesian_neural_networks_for_model_uncertainty_quantification", "_bibtex": "@inproceedings{    \nanonymous2019functional,    \ntitle={Functional Bayesian Neural Networks for Model Uncertainty Quantification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxFN3RcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xFVhActm", "original": "Bkxyqh6cF7", "number": 1470, "cdate": 1538087984950, "ddate": null, "tcdate": 1538087984950, "tmdate": 1538156110054, "tddate": null, "forum": "B1xFVhActm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fake Sentence Detection as a Training Task for Sentence Encoding", "abstract": "    Sentence encoders are typically trained on generative language modeling tasks with large unlabeled datasets. While these encoders achieve strong results on many sentence-level tasks, they are difficult to train with long training cycles. \n    We introduce fake sentence detection as a new discriminative training task for learning sentence encoders. We automatically generate fake sentences by corrupting original sentences from a source collection and train the encoders to produce representations that are effective at detecting fake sentences. This binary classification task turns to be quite efficient for training sentence encoders. We compare a basic BiLSTM encoder trained on this task with strong sentence encoding models (Skipthought and FastSent) trained on a language modeling task. We find that the BiLSTM trains much faster on fake sentence detection (20 hours instead of weeks) using smaller amounts of data (1M instead of 64M sentences). Further analysis shows the learned representations also capture many syntactic and semantic properties expected from good sentence representations.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1470/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ff615585a038354569f35c6b087a30d26505851a.pdf", "paperhash": "anonymous|fake_sentence_detection_as_a_training_task_for_sentence_encoding", "_bibtex": "@inproceedings{    \nanonymous2019fake,    \ntitle={Fake Sentence Detection as a Training Task for Sentence Encoding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xFVhActm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxtE3C5Fm", "original": "rkxvw-R5KQ", "number": 1469, "cdate": 1538087984768, "ddate": null, "tcdate": 1538087984768, "tmdate": 1538156109841, "tddate": null, "forum": "ryxtE3C5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "From Adversarial Training to Generative Adversarial Networks", "abstract": "In this paper, we are interested in two seemingly different concepts: \\textit{adversarial training} and \\textit{generative adversarial networks (GANs)}. Particularly, how these techniques work to improve each other. To this end, we analyze the limitation of adversarial training as a defense method, starting from questioning how well the robustness of a model can generalize. Then, we successfully improve the generalizability via data augmentation by the ``fake'' images sampled from generative adversarial network. After that, we are surprised to see that the resulting robust classifier leads to a better generator, for free. We intuitively explain this interesting phenomenon and leave the theoretical analysis for future work.\nMotivated by these observations, we propose a system that combines generator, discriminator, and adversarial attacker together in a single network. After end-to-end training and fine tuning, our method can simultaneously improve the robustness of classifiers, measured by accuracy under strong adversarial attacks, and the quality of generators, evaluated both aesthetically and quantitatively. In terms of the classifier, we achieve better robustness than the state-of-the-art adversarial training algorithm proposed in (Madry \\textit{et al.}, 2017), while our generator achieves competitive performance compared with SN-GAN (Miyato and Koyama, 2018).", "keywords": ["adversarial training", "conditional GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper1469/Authors"], "authors": ["Anonymous"], "TL;DR": "We found adversarial training not only speeds up the GAN training but also increases the image quality", "pdf": "/pdf/a79fb08d697cc5661f91d1953c42fe0d1d350d2d.pdf", "paperhash": "anonymous|from_adversarial_training_to_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019from,    \ntitle={From Adversarial Training to Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxtE3C5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkeKVh05Fm", "original": "BJlHnIc5KX", "number": 1468, "cdate": 1538087984593, "ddate": null, "tcdate": 1538087984593, "tmdate": 1538156109628, "tddate": null, "forum": "HkeKVh05Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-Grained Entity Proposal Network for Named Entity Recognition", "abstract": "In this paper, we focus on a new Named Entity Recognition (NER) task, i.e., the Multi-grained NER task. This task aims to simultaneously detect both fine-grained and coarse-grained entities in sentences. Correspondingly, we develop a novel Multi-grained Entity Proposal Network (MGEPN). Different from traditional NER models which regard NER as a sequential labeling task, MGEPN provides a new method that proposes entity candidates in the Proposal Network and classifies entities into different categories in the Classification Network. All possible entity candidates including fine-grained ones and coarse-grained ones are proposed in the Proposal Network, which enables the MGEPN model to identify multi-grained entities. In order to better identify named entities and determine their categories, context information is utilized and transferred from the Proposal Network to the Classification Network during the learning process. A novel Entity-Context attention mechanism is also introduced to help the model focus on entity-related context information. Experiments show that our model can obtain state-of-the-art performance on two real-world datasets for both the Multi-grained NER task and the traditional NER task.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1468/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/eb1789c490a32c66f7047f7b7ff5550c8c03c846.pdf", "paperhash": "anonymous|multigrained_entity_proposal_network_for_named_entity_recognition", "_bibtex": "@inproceedings{    \nanonymous2019multi-grained,    \ntitle={Multi-Grained Entity Proposal Network for Named Entity Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkeKVh05Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJl_VnR9Km", "original": "r1lvTbRcYQ", "number": 1467, "cdate": 1538087984418, "ddate": null, "tcdate": 1538087984418, "tmdate": 1538156109418, "tddate": null, "forum": "BJl_VnR9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A  model cortical network for spatiotemporal sequence learning and prediction", "abstract": "In this paper, we developed a hierarchical network model, neurally inspired and constrained,  to understand how spatiotemporal memories might be learned and encoded in the visual hierarchy that can be used for predicting future episodic events.  Our model assumes recurrent connections within each layer and   between different layers learn to encode spatial and temporal memories of patterns and context for prediction.  Its feedforward analysis path uses  a DCNN to develop hierarchical feature representation, while  its internal models and feedback synthesis path is modeled by a stack of  LSTM.  The network learns by minimizing its internal model's prediction error against the incoming  visual sequences. It operates on spatiotemporal blocks, rather than individual frames. This allows learning and prediction to be made at the  sequence or movement level, yielding superior performance in predicting or extrapolating video sequences. Its computation is efficient because its convolution is operated on  residual signals between successive blocks, and between bottom-up representation and synthesized representation generated by feedback.  This model is effective in producing  state-of-the-art performance in predicting visual sequences in  benchmark datasets.  Furthermore, we showed that this neurally inspired and constrained model  exhibit  video familiarity or prediction suppression effects observed  along the ventral stream of the primate  visual system, suggesting that it  is a viable candidate model for hierarchical learning and computation in the visual cortex. ", "keywords": ["cortical models", "spatiotemporal memory", "video prediction", "predictive coding"], "authorids": ["ICLR.cc/2019/Conference/Paper1467/Authors"], "authors": ["Anonymous"], "TL;DR": "A new hierarchical cortical model for encoding spatiotemporal memory and video prediction", "pdf": "/pdf/12d3b15f567f110953a151d42ee2e7eefcfc249a.pdf", "paperhash": "anonymous|a_model_cortical_network_for_spatiotemporal_sequence_learning_and_prediction", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A  model cortical network for spatiotemporal sequence learning and prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl_VnR9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl_NhR9K7", "original": "rylSAfn5tX", "number": 1466, "cdate": 1538087984245, "ddate": null, "tcdate": 1538087984245, "tmdate": 1538156109213, "tddate": null, "forum": "rJl_NhR9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ISA-VAE: Independent Subspace Analysis with Variational Autoencoders", "abstract": "We provide a natural approach to encourage interpretable representations in variational autoencoders.\nBuilding on previous work on Independent Component Analysis (ICA) and Independent Subspace Analysis (ISA)\nwe show that simply choosing an appropriate prior for the latent distribution breaks the degeneracy of the standard prior and leads to a interpretable laten representations.\nThe proposed family of prior distributions leads to a factorized representation and its rotational\nasymmetry allows interpretability of individual latent dimensions.\nIn our experiments we show that the commonly used higher weight (e.g. $\\beta$-VAE) of the Kullback-Leibler divergence\nterm in the evidence lower bound (ELBO) amplifies two biases of variational inference: over-pruning and over-orthogonalization.\nExtensive quantitative experiments demonstrate the performance of the proposed approach for disentanglement in variational autoencoders.\n", "keywords": ["representation learning", "disentanglement", "interpretability", "variational autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper1466/Authors"], "authors": ["Anonymous"], "TL;DR": "We present structured priors for unsupervised learning of disentangled representations in VAEs that significantly mitigate the trade-off between disentanglement and reconstruction loss.", "pdf": "/pdf/2bf1959db43872b359262c4fc0ad19328bd4c99f.pdf", "paperhash": "anonymous|isavae_independent_subspace_analysis_with_variational_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019isa-vae:,    \ntitle={ISA-VAE: Independent Subspace Analysis with Variational Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl_NhR9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkMON20ctX", "original": "rJxB5g0qKX", "number": 1465, "cdate": 1538087984071, "ddate": null, "tcdate": 1538087984071, "tmdate": 1538156109011, "tddate": null, "forum": "SkMON20ctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Trajectory of Stochastic Gradient Descent in the Information Plane", "abstract": "Studying the evolution of information theoretic quantities during Stochastic Gradient Descent (SGD) learning of Artificial Neural Networks (ANNs) has gained popularity in recent years.  \nNevertheless, this type of experiments require estimating mutual information and entropy which becomes intractable for moderately large problems.\nIn this work we propose an experimental framework for understanding SGD based only on the output labels of ANNs.\nWe look at SGD learning as a trajectory in the space of probability measures and define a notion of shortest learning path using a total variation metric.\nUsing this formulation we provide a connection between learning and Markov processes that allows us characterize the trajectory of information theoretic quantities during learning.\nIn addition, a simple Markov chain model for SGD learning, that moves along the shortest learning path is constructed and compared  with SGD through empirical simulations.\nExperiments show that SGD moves in a similar trajectory as a Markov chain along the shortest learning path.", "keywords": ["Stochastic gradient descent", "Deep neural networks", "Entropy", "Information theory", "Markov chains", "Hidden Markov process."], "authorids": ["ICLR.cc/2019/Conference/Paper1465/Authors"], "authors": ["Anonymous"], "TL;DR": "We look at SGD as a trajectory in the space of probability measures, show its connection to Markov processes, propose a simple Markov model of SGD learning, and experimentally compare it with SGD using information theoretic quantities. ", "pdf": "/pdf/c1ed6902985e8ca81dbe0604dfe6b85af59e5f8d.pdf", "paperhash": "anonymous|on_the_trajectory_of_stochastic_gradient_descent_in_the_information_plane", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Trajectory of Stochastic Gradient Descent in the Information Plane},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkMON20ctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeu43ActQ", "original": "r1guzLFcK7", "number": 1464, "cdate": 1538087983886, "ddate": null, "tcdate": 1538087983886, "tmdate": 1538156108805, "tddate": null, "forum": "HJeu43ActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Provable Online Dictionary Learning and Sparse Coding", "abstract": "We consider the dictionary learning problem, where the aim is to model the given data as a linear combination of a few columns of a matrix known as a dictionary, where the sparse weights forming the linear combination are known as coefficients. Since both the dictionary and coefficients parameterizing the linear model are unknown, the corresponding optimization is inherently non-convex. This was a major challenge until recently, when provable algorithms for dictionary learning were proposed. Yet, these provide guarantees only on the recovery of the dictionary, without explicit recovery guarantees on the coefficients. Moreover, any estimation error in the dictionary adversely impacts the ability to successfully localize and estimate the coefficients. This potentially limits the utility of existing provable dictionary learning methods in applications where coefficient recovery is of interest. To this end, we develop a simple online alternating optimization-based algorithm for dictionary learning, which recovers both the dictionary and coefficients exactly. Specifically, we show that -- when initialized appropriately -- the algorithm linearly converges to the true factors. Our algorithm is also scalable and amenable for large scale distributed implementations in neural architectures, by which we mean that it only involves simple linear and non-linear operations. Finally, we corroborate these theoretical results via empirical evaluation of convergence properties, and phase transition in sample complexity.", "keywords": ["provable dictionary learning", "sparse coding", "support recovery", "iterative hard thresholding"], "authorids": ["ICLR.cc/2019/Conference/Paper1464/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a provable algorithm for exactly recovering both factors of the dictionary learning model. ", "pdf": "/pdf/e7feb0bab6ca5d4201e34c679c6a7e129a407c55.pdf", "paperhash": "anonymous|provable_online_dictionary_learning_and_sparse_coding", "_bibtex": "@inproceedings{    \nanonymous2019provable,    \ntitle={Provable Online Dictionary Learning and Sparse Coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeu43ActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkguE30ct7", "original": "Hyll2gAcFQ", "number": 1463, "cdate": 1538087983694, "ddate": null, "tcdate": 1538087983694, "tmdate": 1538156108597, "tddate": null, "forum": "SkguE30ct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Model-Based Reinforcement Learning for Recommendation", "abstract": "There is a great interest in applying reinforcement learning (RL) to recommendation systems. However, in this setting, an online user is the environment; neither the reward function nor the environment dynamics is clearly defined, making the application of RL challenging. \n In this paper, we propose a novel model-based reinforcement learning framework for recommendation systems, where we developed a generative adversarial network to imitate user behavior dynamics and learn her reward function. Using this user model as the simulation environment, we develop a novel DQN algorithm to obtain a combinatorial recommendation policy which can handle a large number of candidate items efficiently.  In our experiments with real data, we show this generative adversarial user model can better explain user behavior than alternatives, and the RL policy based on this model can lead to better long turn reward for the user and higher click rate for the system.", "keywords": ["Generative adversarial user model", "Recommendation system", "model-based reinforcement learning", "combinatorial recommendation policy", "deep Q-networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1463/Authors"], "authors": ["Anonymous"], "TL;DR": "A new insight of designing a RL recommendation policy based on user behavior model along with some technical highlights.", "pdf": "/pdf/3d62f927d2add4a90d127ebc08fa8a6c35addf72.pdf", "paperhash": "anonymous|neural_modelbased_reinforcement_learning_for_recommendation", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Model-Based Reinforcement Learning for Recommendation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkguE30ct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJedV3R5tm", "original": "B1xaOP8FtQ", "number": 1462, "cdate": 1538087983522, "ddate": null, "tcdate": 1538087983522, "tmdate": 1538156108393, "tddate": null, "forum": "rJedV3R5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RelGAN: Relational Generative Adversarial Networks for Text Generation", "abstract": "Generative adversarial networks (GANs) have achieved great success at generating realistic images. However, the text generation still remains a challenging task for modern GAN architectures. In this work, we propose RelGAN, a new GAN architecture for text generation, consisting of three main components: a relational memory based generator for the long-distance dependency modeling, the Gumbel-Softmax relaxation for training GANs on discrete data, and multiple embedded representations in the discriminator to provide a more informative signal for the generator updates. Our experiments show that RelGAN outperforms current state-of-the-art models in terms of sample quality and diversity, and we also reveal via ablation studies that each component of RelGAN contributes critically to its performance improvements. Moreover, a key advantage of our method, that distinguishes it from other GANs, is the ability to control the trade-off between sample quality and diversity via the use of a single adjustable parameter. Finally, RelGAN is the first architecture that makes GANs with Gumbel-Softmax relaxation succeed in generating realistic text.", "keywords": ["RelGAN", "text generation", "relational memory", "Gumbel-Softmax relaxation", "multiple embedded representations"], "authorids": ["ICLR.cc/2019/Conference/Paper1462/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/24a4b682c97891929a5fa30aa761042326d126b6.pdf", "paperhash": "anonymous|relgan_relational_generative_adversarial_networks_for_text_generation", "_bibtex": "@inproceedings{    \nanonymous2019relgan:,    \ntitle={RelGAN: Relational Generative Adversarial Networks for Text Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJedV3R5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xwNhCcYm", "original": "rylp1lR5tQ", "number": 1461, "cdate": 1538087983348, "ddate": null, "tcdate": 1538087983348, "tmdate": 1538156108185, "tddate": null, "forum": "H1xwNhCcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Do Deep Generative Models Know What They Don't Know? ", "abstract": "A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data.  A plethora of work has demonstrated that it is easy to find or synthesize inputs for which a neural network is highly confident yet wrong. Generative models are generally viewed to be robust to such overconfidence mistakes as modeling the density of the input features can be used to detect novel,  out-of-distribution inputs. \nIn this paper we challenge this assumption, focusing our analysis on flow-based generative models in particular since they are trained and evaluated via the exact marginal likelihood. We find that the model density cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former.  We find such behavior persists even when we restrict the flow models to constant-volume transformations.  These admit some theoretical analysis, and we show that the difference in likelihoods can be explained by the location and variances of the data and the model curvature, which shows that such behavior is more general and not just restricted to the pairs of datasets used in our experiments. Our results suggest caution when using density estimates of deep generative models on out-of-distribution inputs. ", "keywords": ["deep generative models", "out-of-distribution inputs", "flow-based models", "uncertainty", "density"], "authorids": ["ICLR.cc/2019/Conference/Paper1461/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/21db6108b3e13ef9184f5ab5cc48d499880c2528.pdf", "paperhash": "anonymous|do_deep_generative_models_know_what_they_dont_know", "_bibtex": "@inproceedings{    \nanonymous2019do,    \ntitle={Do Deep Generative Models Know What They Don't Know? },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xwNhCcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryewE3R5YX", "original": "BJxuzlCcFQ", "number": 1460, "cdate": 1538087983178, "ddate": null, "tcdate": 1538087983178, "tmdate": 1538156107977, "tddate": null, "forum": "ryewE3R5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Characterizing Vulnerabilities of Deep Reinforcement Learning", "abstract": "Deep Reinforcement learning (DRL) has achieved great success in various applications, such as playing computer games and controlling robotic manipulation. However, recent studies show that machine learning models are vulnerable to adversarial examples, which are carefully crafted instances that aim to mislead learning models to make arbitrarily incorrect prediction, and raised severe security concerns. DRL has been attacked by adding perturbation to each observed frame. However, such observation based attacks are not quite realistic considering that it would be hard for adversaries to directly manipulate pixel values in practice. Therefore, we propose to understand the vulnerabilities of DRL from various perspectives and  provide a throughout taxonomy of adversarial perturbation against DRL, and we conduct the first experiments on unexplored parts of this taxonomy.  In addition to current observation based attacks against DRL, we  propose attacks based on the actions and environment dynamics.  Among these experiments, we introduce a novel sequence-based attack to attack a sequence of frames for real-time scenarios such as autonomous driving, and the first targeted attack that perturbs environment dynamics to let the agent fail in a specific way. We show empirically that our sequence-based attack can generate effective perturbations in a blackbox setting in real time with a small number of queries, independent of episode length. We conduct extensive experiments to compare the effectiveness of different attacks with several baseline attack methods in several game playing, robotics control, and autonomous driving environments.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1460/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a9158539cc9a1002f806d23fad4975713de0c313.pdf", "paperhash": "anonymous|characterizing_vulnerabilities_of_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019characterizing,    \ntitle={Characterizing Vulnerabilities of Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryewE3R5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1fPNh0cYm", "original": "S1lMlcw5YQ", "number": 1459, "cdate": 1538087983005, "ddate": null, "tcdate": 1538087983005, "tmdate": 1538156107761, "tddate": null, "forum": "H1fPNh0cYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised classification into unknown k classes", "abstract": "We propose a novel spectral decomposition framework for the unsupervised classification\ntask. Unlike the widely used classification method, this architecture does\nnot require the labels of data and the number of classes. Our key idea is to introduce\na piecewise linear map and a spectral decomposition method on the dimension\nreduced space into generative adversarial networks. Inspired by the human visual\nrecognition system, the proposed framework can classify and also generate images\nas the human brains do. We build a piecewise linear connection analogous to the\ncerebral cortex, between the discriminator D and the generator G. This connection\nallows us to estimate the number of classes k and extract the vectors that represent\neach class. We show that our framework has the reasonable performance in the\nexperiment.", "keywords": ["unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1459/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/646ba46c9105f2379b8714575be931e8d1210870.pdf", "paperhash": "anonymous|unsupervised_classification_into_unknown_k_classes", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised classification into unknown k classes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1fPNh0cYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxvEh0cFQ", "original": "ByxHgT35KQ", "number": 1458, "cdate": 1538087982834, "ddate": null, "tcdate": 1538087982834, "tmdate": 1538156107504, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multitask learning. The basic approach is to allow a model patch - a small set of parameters - to specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases allows a network to learn a completely different embedding that could be used for different tasks (such as converting an SSD detection model into a 1000-class classification model while reusing 98% of parameters of the feature extractor). Similarly, we show that re-learning the existing low-parameter layers (such as depth-wise convolutions) also improves accuracy significantly. Our approach allows both simultaneous (multi-task) learning as well as sequential transfer learning wherein we adapt pretrained networks to solve new problems. For multi-task learning, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task-based performance. ", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1458/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/17b0c108e2ce85cb5e8339c7b6f93953e498ac88.pdf", "paperhash": "anonymous|k_for_the_price_of_1_parameter_efficient_multitask_and_transfer_learning", "_bibtex": "@inproceedings{    \nanonymous2019k,    \ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxvEh0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lDV3RcKm", "original": "SJejon9cKQ", "number": 1457, "cdate": 1538087982657, "ddate": null, "tcdate": 1538087982657, "tmdate": 1538156107292, "tddate": null, "forum": "S1lDV3RcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning from Incomplete Data with Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to provide an effective way to model complex distributions and have obtained impressive results on various challenging tasks. However, typical GANs require fully-observed data during training. In this paper, we present a modular approach to learning GANs from incomplete observations that can be combined with different generator and discriminator networks and is amenable for use with complex, high-dimensional inputs. The proposed framework learns a complete data generator along with a mask generator that models the missingness. We further demonstrate how to impute missing data by equipping our framework with an adversarially trained imputer. We evaluate the proposed framework using a series of experiments with several types of missing completely at random missing data processes.\n", "keywords": ["generative models", "missing data"], "authorids": ["ICLR.cc/2019/Conference/Paper1457/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a model for learning the distribution from high-dimensional incomplete data using GANs.", "pdf": "/pdf/d7b27bf5cebee57b71d163b33e3b537b87ac10fe.pdf", "paperhash": "anonymous|learning_from_incomplete_data_with_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning from Incomplete Data with Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lDV3RcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklUN3RcFX", "original": "B1xMC2h9Fm", "number": 1456, "cdate": 1538087982488, "ddate": null, "tcdate": 1538087982488, "tmdate": 1538156107087, "tddate": null, "forum": "HklUN3RcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Confidence-based Graph Convolutional Networks for Semi-Supervised Learning", "abstract": "Predicting properties of nodes in a graph is an important problem with applications in a variety of domains. Graph-based Semi Supervised Learning (SSL) methods aim to address this problem by labeling a small subset of the nodes as seeds, and then utilizing the graph structure to predict label scores for the rest of the nodes in the graph. Recently, Graph Convolutional Networks (GCNs) have achieved impressive performance on the graph-based SSL task. In addition to label scores, it is also desirable to have a confidence score associated with them. Unfortunately, confidence estimation in the context of GCN has not been previously explored. We fill this important gap in this paper and propose ConfGCN, which estimates labels scores along with their confidences jointly in GCN-based setting. ConfGCN uses these estimated confidences to determine the influence of one node on another during neighborhood aggregation, thereby acquiring anisotropic capabilities. Through extensive analysis and experiments on standard benchmarks, we find that ConfGCN is able to significantly outperform state-of-the-art baselines. We have made ConfGCN\u2019s source code available to encourage reproducible research.", "keywords": ["Graph Convolutional Networks", "GCN", "Confidence", "Semi-Supervised Learning", "Deep Learning", "Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1456/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a confidence based Graph Convolutional Network for Semi-Supervised Learning.", "pdf": "/pdf/6951b9755540a31c3f1e9194e4febe3db9b3d18c.pdf", "paperhash": "anonymous|confidencebased_graph_convolutional_networks_for_semisupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019confidence-based,    \ntitle={Confidence-based Graph Convolutional Networks for Semi-Supervised Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklUN3RcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xLN3C9YX", "original": "BJl8cQ35Fm", "number": 1455, "cdate": 1538087982316, "ddate": null, "tcdate": 1538087982316, "tmdate": 1538156106881, "tddate": null, "forum": "S1xLN3C9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learnable Embedding Space for Efficient Neural Architecture Compression", "abstract": "We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS). In this paper, we focus on the task of network architecture compression. Given a teacher network, we search for a compressed network architecture by using Bayesian Optimization (BO) with a kernel function defined over our proposed embedding space to select architectures for evaluation. We demonstrate that our search algorithm can significantly outperform various baseline methods, such as random search and N2N (Ashok et al.,2018). The compressed architectures found by our method are also better than the state-of-the-art manually-designed compact architecture ShuffleNet (Zhang et al., 2018). We also demonstrate that the learned embedding space can be transferred to new settings for architecture search, such as a larger teacher network or a teacher network in a different architecture family, without any training.\n", "keywords": ["Network Compression", "Neural Architecture Search", "Bayesian Optimization", "Architecture Embedding"], "authorids": ["ICLR.cc/2019/Conference/Paper1455/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method to incrementally learn an embedding space over the domain of network architectures, to enable the careful selection of architectures for evaluation during neural architecture search (NAS).", "pdf": "/pdf/bcaff4de904152ada269add5c881857412514428.pdf", "paperhash": "anonymous|learnable_embedding_space_for_efficient_neural_architecture_compression", "_bibtex": "@inproceedings{    \nanonymous2019learnable,    \ntitle={Learnable Embedding Space for Efficient Neural Architecture Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xLN3C9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkzL4hR9Ym", "original": "HylpAbC9FQ", "number": 1454, "cdate": 1538087982146, "ddate": null, "tcdate": 1538087982146, "tmdate": 1538156106676, "tddate": null, "forum": "HkzL4hR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Shaping representations through communication", "abstract": "Good representations facilitate transfer learning and few-shot learning. Motivated by theories of language and communication that explain why communities with large number of speakers have, on average, simpler languages with more regularity, we cast the representation learning problem in terms of learning to communicate. Our starting  point sees traditional autoencoders as  a single encoder with a fixed decoder partner that must learn to communicate. Generalizing from there, we introduce community-based autoencoders in which multiple encoders and decoders collectively learn representations by being randomly paired up on successive training iterations. Our experiments show that increasing community sizes reduce idiosyncrasies in the learned codes, resulting in more invariant representations with increased reusability and structure.", "keywords": ["communication", "language", "representation learning", "autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper1454/Authors"], "authors": ["Anonymous"], "TL;DR": "Motivated by theories of language and communication, we introduce community-based autoencoders, in which multiple encoders and decoders collectively learn structured and reusable representations.", "pdf": "/pdf/9d214dc113ef31d4b8071ed6b3ace7e96f05d757.pdf", "paperhash": "anonymous|shaping_representations_through_communication", "_bibtex": "@inproceedings{    \nanonymous2019shaping,    \ntitle={Shaping representations through communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzL4hR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyM8V2A9Km", "original": "S1gyQ-RqKQ", "number": 1453, "cdate": 1538087981981, "ddate": null, "tcdate": 1538087981981, "tmdate": 1538156106466, "tddate": null, "forum": "HyM8V2A9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ACTRCE: Augmenting Experience via Teacher\u2019s Advice", "abstract": "Sparse reward is one of the most challenging problems in reinforcement learning (RL). Hindsight Experience Replay (HER) attempts to address this issue by converting a failure experience to a successful one by relabeling the goals. Despite its effectiveness, HER has limited applicability because it lacks a compact and universal goal representation. We present Augmenting experienCe via TeacheR's adviCE (ACTRCE), an efficient reinforcement learning technique that extends the HER framework using natural language as the goal representation. We first analyze the differences among goal representation, and show that ACTRCE can efficiently solve difficult reinforcement learning problems in challenging 3D navigation tasks, whereas HER with non-language goal representation failed to learn. We also show that with language goal representations, the agent can generalize to unseen instructions, and even generalize to instructions with unseen lexicons. We further demonstrate it is crucial to use hindsight advice to solve challenging tasks, but we also found that little amount of hindsight advice is sufficient for the learning to take off, showing the practical aspect of the method.", "keywords": ["language goals", "task generalization", "hindsight experience replays", "language grounding"], "authorids": ["ICLR.cc/2019/Conference/Paper1453/Authors"], "authors": ["Anonymous"], "TL;DR": "Combine language goal representation with hindsight experience replays.", "pdf": "/pdf/4224cdf2babd5625389c5336add253259e526aac.pdf", "paperhash": "anonymous|actrce_augmenting_experience_via_teachers_advice", "_bibtex": "@inproceedings{    \nanonymous2019actrce:,    \ntitle={ACTRCE: Augmenting Experience via Teacher\u2019s Advice},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyM8V2A9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygIV2CcKm", "original": "Byx2L5n9tQ", "number": 1452, "cdate": 1538087981811, "ddate": null, "tcdate": 1538087981811, "tmdate": 1538156106256, "tddate": null, "forum": "BygIV2CcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Augment Influential Data", "abstract": "Data augmentation is a technique to reduce overfitting and to improve generalization by increasing the number of labeled data by performing label preserving transformations; however, it is currently conducted in a trial and error manner. A composition of predefined transformations such as rotation, scaling, and cropping is performed on training samples, and its effect on performance over test samples can only be empirically evaluated and cannot be predicted. This paper considers an influence function that predicts how generalization is affected by a particular augmented training sample in terms of validation loss, without comparing the performance that includes and excludes the sample in the training process. A differentiable augmentation model that generalizes the conventional composition of predefined transformations is proposed. The differentiable augmentation model and reformulation of the influence function allow the augmented model parameters to be updated by backpropagation to minimize the validation loss. The experimental results show that the proposed method provides better generalization over conventional data augmentation methods.", "keywords": ["data augmentation", "influence function", "generative adversarial network"], "authorids": ["ICLR.cc/2019/Conference/Paper1452/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b157b01a00a454523b924596598c8c93689a795e.pdf", "paperhash": "anonymous|learning_to_augment_influential_data", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Augment Influential Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygIV2CcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xU4nAqK7", "original": "HyxAtgRctQ", "number": 1451, "cdate": 1538087981636, "ddate": null, "tcdate": 1538087981636, "tmdate": 1538156106052, "tddate": null, "forum": "B1xU4nAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Exploration with Deep Model-Based Reinforcement Learning", "abstract": "Reinforcement learning (RL) often requires large numbers of trials to solve a single specific task. This is in sharp contrast to human and animal learning: humans and animals can use past experience to acquire an understanding about the world, which they can then use to perform new tasks with minimal additional learning. In this work, we study how an unsupervised exploration phase can be used to build up such prior knowledge, which can then be utilized in a second phase to perform new tasks, either directly without any additional exploration, or through minimal fine-tuning. A critical question with this approach is: what kind of knowledge should be transferred from the unsupervised phase to the goal-directed phase? We argue that model-based RL offers an appealing solution. By transferring models, which are task-agnostic, we can perform new tasks without any additional learning at all. However, this relies on having a suitable exploration method during unsupervised training, and a model-based RL method that can effectively utilize modern high-capacity parametric function classes, such as deep neural networks. We show that both challenges can be addressed by representing model-uncertainty, which can both guide exploration in the unsupervised phase and ensure that the errors in the model are not exploited by the planner in the goal-directed phase. We illustrate, on simple simulated benchmark tasks, that our method can perform various goal-directed skills on the first attempt, and can improve further with fine-tuning, exceeding the performance of alternative exploration methods.", "keywords": ["exploration", "model based reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1451/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/175cb1413aa109f9ab1332986c8926a2441b1541.pdf", "paperhash": "anonymous|unsupervised_exploration_with_deep_modelbased_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Exploration with Deep Model-Based Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xU4nAqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJ4BVhRcYX", "original": "ryxWWNRctm", "number": 1450, "cdate": 1538087981470, "ddate": null, "tcdate": 1538087981470, "tmdate": 1538156105842, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "anonymous|interpretable_convolutional_filter_pruning", "_bibtex": "@inproceedings{    \nanonymous2019interpretable,    \ntitle={INTERPRETABLE CONVOLUTIONAL FILTER PRUNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJ4BVhRcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgSEnA5KQ", "original": "rJeh69n5FX", "number": 1449, "cdate": 1538087981292, "ddate": null, "tcdate": 1538087981292, "tmdate": 1538156105632, "tddate": null, "forum": "HkgSEnA5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning Language-Guided Policy Learning", "abstract": "Behavioral skills or policies for autonomous agents are conventionally learned from reward functions, via reinforcement learning, or from demonstrations, via imitation learning. However, both modes of task specification have their disadvantages: reward functions require manual engineering, while demonstrations require a human expert to be able to actually perform the task in order to generate the demonstration. Instruction following from natural language instructions provides an appealing alternative: in the same way that we can specify goals to other humans simply by speaking or writing, we would like to be able to specify tasks for our machines. However, a single instruction may be insufficient to fully communicate our intent or, even if it is, may be insufficient for an autonomous agent to actually understand how to perform the desired task. In this work, we propose an interactive formulation of the task specification problem, where iterative language corrections are provided to an autonomous agent, guiding it in acquiring the desired skill. Our proposed language-guided policy learning algorithm can integrate an instruction and a sequence of corrections to acquire new skills very quickly. In our experiments, we show that this method can enable a policy to follow instructions and corrections for simulated navigation and manipulation tasks, substantially outperforming direct, non-interactive instruction following.", "keywords": ["meta-learning", "language grounding", "interactive"], "authorids": ["ICLR.cc/2019/Conference/Paper1449/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a meta-learning method for interactively correcting policies with natural language.", "pdf": "/pdf/2e865f6ae479632f7a00d48295dd33cccd0fbc30.pdf", "paperhash": "anonymous|metalearning_languageguided_policy_learning", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning Language-Guided Policy Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgSEnA5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJfSEnRqKQ", "original": "BJgyw_T9K7", "number": 1448, "cdate": 1538087981126, "ddate": null, "tcdate": 1538087981126, "tmdate": 1538156105428, "tddate": null, "forum": "HJfSEnRqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Active Learning with Partial Feedback", "abstract": "While many active learning papers assume that the learner can simply ask for a label\nand receive it, real annotation often presents a mismatch between the form of a label\n(say, one among many classes), and the form of an annotation (typically yes/no binary\nfeedback). To annotate examples corpora for multiclass classification, we might need to\nask multiple yes/no questions, exploiting a label hierarchy if one is available. To address\nthis more realistic setting, we propose active learning with partial feedback (ALPF), where\nthe learner must actively choose both which example to label and which binary question to\nask. At each step, the learner selects an example, asking if it belongs to a chosen (possibly\ncomposite) class. Each answer eliminates some classes, leaving the learner with a partial\nlabel. The learner may then either ask more questions about the same example (until\nan exact label is uncovered) or move on immediately, leaving the first example partially\nlabeled. Active learning with partial labels requires (i) a sampling strategy to choose\n(example, class) pairs, and (ii) learning from partial labels between rounds. Experiments\non Tiny ImageNet demonstrate that our most effective method improves 26% (relative) in\ntop-1 classification accuracy compared to i.i.d. baselines and standard active learners given\n30% of the annotation budget that would be required (naively) to annotate the dataset.\nMoreover, ALPF-learners fully annotate TinyImageNet at 42% lower cost. Surprisingly,\nwe observe that accounting for per-example annotation costs can alter the conventional\nwisdom that active learners should solicit labels for hard examples.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1448/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b2c8f83746f7a84b557f17f320295dd1d2c40d50.pdf", "paperhash": "anonymous|active_learning_with_partial_feedback", "_bibtex": "@inproceedings{    \nanonymous2019active,    \ntitle={Active Learning with Partial Feedback},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJfSEnRqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgSV3AqKQ", "original": "rJx187qYYX", "number": 1447, "cdate": 1538087980956, "ddate": null, "tcdate": 1538087980956, "tmdate": 1538156105221, "tddate": null, "forum": "rJgSV3AqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Combining adaptive algorithms and hypergradient method: a performance and robustness study", "abstract": "Wilson et al. (2017) showed that, when the stepsize schedule is properly designed, stochastic gradient generalizes better than ADAM (Kingma & Ba, 2014). In light of recent work on hypergradient methods (Baydin et al., 2018), we revisit these claims to see if such methods close the gap between the most popular optimizers. As a byproduct, we analyze the true benefit of these hypergradient methods compared to more classical schedules, such as the fixed decay of Wilson et al. (2017). In particular, we observe they are of marginal help since their performance varies significantly when tuning their hyperparameters. Finally, as robustness is a critical quality of an optimizer, we provide a sensitivity analysis of these gradient based optimizers to assess how challenging their tuning is.", "keywords": ["optimization", "adaptive methods", "learning rate decay"], "authorids": ["ICLR.cc/2019/Conference/Paper1447/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide a study trying to see how the recent online learning rate adaptation extends the conclusion made by Wilson et al. 2018 about adaptive gradient methods, along with comparison and sensitivity analysis.", "pdf": "/pdf/8ecf4971fff5e08d16f8b3a45e73f7ad52932a84.pdf", "paperhash": "anonymous|combining_adaptive_algorithms_and_hypergradient_method_a_performance_and_robustness_study", "_bibtex": "@inproceedings{    \nanonymous2019combining,    \ntitle={Combining adaptive algorithms and hypergradient method: a performance and robustness study},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgSV3AqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJerEhR5Km", "original": "BJeYyEA9tQ", "number": 1446, "cdate": 1538087980789, "ddate": null, "tcdate": 1538087980789, "tmdate": 1538156105017, "tddate": null, "forum": "SJerEhR5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Novel positional encodings to enable tree-structured transformers", "abstract": "With interest in program synthesis and similarly \ufb02avored problems rapidly increasing, neural models optimized for tree-domain problems are of great value. In the sequence domain, transformers can learn relationships across arbitrary pairs of positions with less bias than recurrent models. Under the intuition that a similar property would be beneficial in the tree domain, we propose a method to extend transformers to tree-structured inputs and/or outputs. Our approach abstracts transformer\u2019s default sinusoidal positional encodings, allowing us to substitute in a novel custom positional encoding scheme that represents node positions within a tree. We evaluated our model in tree-to-tree program translation settings, achieving superior performance to other models from the literature on several tasks.\n", "keywords": ["program translation", "tree structures", "transformer"], "authorids": ["ICLR.cc/2019/Conference/Paper1446/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop novel positional encodings for tree-structured data, enabling transformers to be applied to tree structured problems.", "pdf": "/pdf/9a59df3e599e1359e2f13999065a5f325a7b30c5.pdf", "paperhash": "anonymous|novel_positional_encodings_to_enable_treestructured_transformers", "_bibtex": "@inproceedings{    \nanonymous2019novel,    \ntitle={Novel positional encodings to enable tree-structured transformers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJerEhR5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eH4n09KX", "original": "rJexAm05K7", "number": 1445, "cdate": 1538087980618, "ddate": null, "tcdate": 1538087980618, "tmdate": 1538156104807, "tddate": null, "forum": "H1eH4n09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Audio Super-Resolution with Unsupervised Feature Losses", "abstract": "Neural network-based methods have recently demonstrated state-of-the-art results on image synthesis and super-resolution tasks, in particular by using variants of generative adversarial networks (GANs) with supervised feature losses. Nevertheless, previous feature loss formulations rely on the availability of large auxiliary classifier networks, and labeled datasets that enable such classifiers to be trained. Furthermore, there has been comparatively little work to explore the applicability of GAN-based methods to domains other than images and video. In this work we explore a GAN-based method for audio processing, and develop a convolutional neural network architecture to perform audio super-resolution. In addition to several new architectural building blocks for audio processing, a key component of our approach is the use of an autoencoder-based loss that enables training in the GAN framework, with feature losses derived from unlabeled data. We explore the impact of our architectural choices, and demonstrate significant improvements over previous works in terms of both objective and perceptual quality.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1445/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5f0667613f08279a811889fbb0827322d0ba9f40.pdf", "paperhash": "anonymous|adversarial_audio_superresolution_with_unsupervised_feature_losses", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Audio Super-Resolution with Unsupervised Feature Losses},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eH4n09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygVV205KQ", "original": "SylVIb39Fm", "number": 1444, "cdate": 1538087980443, "ddate": null, "tcdate": 1538087980443, "tmdate": 1538156104599, "tddate": null, "forum": "rygVV205KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visual Imitation with a Minimal Adversary", "abstract": "High-dimensional sparse reward tasks present major challenges for reinforcement learning agents.  In this work we use imitation learning to address two of these challenges:  how to learn a useful representation of the world e.g.  from pixels, and how to explore efficiently given the rarity of a reward signal? We show that adversarial imitation can work well even in this high dimensional observation space. Surprisingly the adversary itself, acting as the learned reward function, can be tiny, comprising as few as 128 parameters, and can be easily trained using the most basic GAN formulation. Our approach removes limitations present in most contemporary imitation approaches: requiring no demonstrator actions (only video), no special initial conditions or warm starts, and no explicit tracking of any single demo. The proposed agent can solve a challenging robot manipulation task of block stacking from only video demonstrations and sparse reward, in which the non-imitating agents fail to learn completely.  Furthermore, our agent learns much faster than competing approaches that depend on hand-crafted, staged dense reward functions, and also better compared to standard GAIL baselines. Finally, we develop a new adversarial goal recognizer that in some cases allows the agent to learn stacking without any task reward, purely from imitation.", "keywords": ["imitation", "from pixels", "adversarial"], "authorids": ["ICLR.cc/2019/Conference/Paper1444/Authors"], "authors": ["Anonymous"], "TL;DR": "Imitation from pixels, with sparse or no reward, using off-policy RL and a tiny adversarially-learned reward function.", "pdf": "/pdf/d2433f5e54c14a167852d8a7ac32028e53de92d0.pdf", "paperhash": "anonymous|visual_imitation_with_a_minimal_adversary", "_bibtex": "@inproceedings{    \nanonymous2019visual,    \ntitle={Visual Imitation with a Minimal Adversary},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygVV205KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xNEhR9KX", "original": "r1xarz05Y7", "number": 1443, "cdate": 1538087980268, "ddate": null, "tcdate": 1538087980268, "tmdate": 1538156104327, "tddate": null, "forum": "S1xNEhR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Sensitivity of Adversarial Robustness to Input Data Distributions", "abstract": "Neural networks are vulnerable to small adversarial perturbations. Existing literature largely focused on understanding and mitigating the vulnerability of learned models. In this paper, we demonstrate an intriguing phenomenon about adversarial training, arguably the most popular robust training method in the literature: Adversarial robustness, unlike clean accuracy, is sensitive to the input data distribution. Even a semantics-preserving transformations on the input data distribution can cause a significantly different robustness for the adversarial trained model that is both trained and evaluated on the new distribution. Our discovery of such sensitivity on data distribution is based on a study which disentangles the behaviors of clean accuracy and robust accuracy of the Bayes classifier. Further empirical investigation on MNIST and CIFAR10 confirms our finding that numerous MNIST and CIFAR10 variants achieve comparable clean accuracies in various different neural nets under standard training but significantly different robustness under adversarial training. This counter-intuitive phenomenon indicates that input data distribution alone can affect the adversarial robustness of trained neural networks, not necessarily the tasks themselves. Lastly, we discuss the practical implications on evaluating adversarial robustness, and make initial attempts to understand this complex phenomenon.\n", "keywords": ["adversarial robustness", "PGD training", "adversarial perturbation", "input data distribution"], "authorids": ["ICLR.cc/2019/Conference/Paper1443/Authors"], "authors": ["Anonymous"], "TL;DR": "Robustness performance of PGD trained models are sensitive to semantics-preserving transformation of image datasets, which implies the trickiness of evaluation of robust learning algorithms in practice.", "pdf": "/pdf/409a181f2b7a07a6b16333977b6a9c3d0be78545.pdf", "paperhash": "anonymous|on_the_sensitivity_of_adversarial_robustness_to_input_data_distributions", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Sensitivity of Adversarial Robustness to Input Data Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xNEhR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByME42AqK7", "original": "S1xC3liqFQ", "number": 1442, "cdate": 1538087980100, "ddate": null, "tcdate": 1538087980100, "tmdate": 1538156104108, "tddate": null, "forum": "ByME42AqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution", "abstract": "Architecture search aims at automatically finding neural architectures that are competitive with architectures designed by human experts. While recent approaches have achieved state-of-the-art predictive performance for image recognition, they are problematic under resource constraints for two reasons: (1) the neural architectures found are solely optimized for high predictive performance, without penalizing excessive resource consumption; (2)most architecture search methods require vast computational resources. We address the first shortcoming by proposing LEMONADE, an evolutionary algorithm for multi-objective architecture search that allows approximating the Pareto-front of architectures under multiple objectives, such as predictive performance and number of parameters, in a single run of the method. We address the second shortcoming by proposing a Lamarckian inheritance mechanism for LEMONADE which generates children networks that are warmstarted with the predictive performance of their trained parents. This is accomplished by using (approximate) network morphism operators for generating children. The combination of these two contributions allows finding models that are on par or even outperform different-sized NASNets, MobileNets, MobileNets V2 and Wide Residual Networks on CIFAR-10 and ImageNet64x64 within only one week on eight GPUs, which is about 20-40x less compute power than previous architecture search methods that yield state-of-the-art performance.", "keywords": ["Neural Architecture Search", "AutoML", "AutoDL", "Deep Learning", "Evolutionary Algorithms", "Multi-Objective Optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1442/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method for efficient Multi-Objective Neural Architecture Search based on Lamarckian inheritance and evolutionary algorithms.", "pdf": "/pdf/f05f1e070934107e259d08875ef22e90d1360a78.pdf", "paperhash": "anonymous|efficient_multiobjective_neural_architecture_search_via_lamarckian_evolution", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByME42AqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklEEnC5tQ", "original": "B1l9wazqKQ", "number": 1441, "cdate": 1538087979932, "ddate": null, "tcdate": 1538087979932, "tmdate": 1538156103901, "tddate": null, "forum": "SklEEnC5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DISTRIBUTIONAL CONCAVITY REGULARIZATION FOR GANS", "abstract": "We propose Distributional Concavity (DC) regularization for GANs, a functional gradient-based method that promotes the entropy of the generator distribution and works against mode collapse. Our DC regularization is an easy-to-implement method that can be used in combination with the current state of the art methods like Spectral Normalization and WGAN-GP to further improve the performance. We will not only show that our DC regularization can achieve highly competi- tive results on ImageNet and CIFAR datasets in terms of Inception score and FID score, but also provide a mathematical guarantee that our method can always in- crease the entropy of the generator distribution. We will also show an intimate theoretical connection between our method and the theory of optimal transport.\n", "keywords": ["Generative Adversarial Networks", "regularization", "optimal transport", "functional gradient", "convex analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper1441/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fde7e616e056e9a60cbc6af7ad89c4dc5fdad3ca.pdf", "paperhash": "anonymous|distributional_concavity_regularization_for_gans", "_bibtex": "@inproceedings{    \nanonymous2019distributional,    \ntitle={DISTRIBUTIONAL CONCAVITY REGULARIZATION FOR GANS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklEEnC5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklVEnR5K7", "original": "S1xhXLpcKm", "number": 1440, "cdate": 1538087979766, "ddate": null, "tcdate": 1538087979766, "tmdate": 1538156103696, "tddate": null, "forum": "SklVEnR5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Making Convolutional Networks Shift-Invariant Again", "abstract": "Modern convolutional networks are not shift-invariant, despite their convolutional nature: small shifts in the input can cause drastic changes in the internal feature maps and output. In this paper, we isolate the cause -- the downsampling operation in convolutional and pooling layers -- and apply the appropriate signal processing fix -- low-pass filtering before downsampling. This simple architectural modification boosts the shift-equivariance of the internal representations and consequently, shift-invariance of the output. Importantly, this is achieved while maintaining downstream classification performance. In addition, incorporating the inductive bias of shift-invariance largely removes the need for shift-based data augmentation. Lastly, we observe that the modification induces spatially-smoother learned convolutional kernels. Our results suggest that this classical signal processing technique has a place in modern deep networks.", "keywords": ["convolutional networks", "signal processing", "shift", "translation", "invariance", "equivariance"], "authorids": ["ICLR.cc/2019/Conference/Paper1440/Authors"], "authors": ["Anonymous"], "TL;DR": "Modern networks are not shift-invariant, due to naive downsampling; we apply a signal processing tool -- anti-aliasing low-pass filtering before downsampling -- to improve shift-invariance", "pdf": "/pdf/4cee868d56632d1fe745912ca3f8a267260680f0.pdf", "paperhash": "anonymous|making_convolutional_networks_shiftinvariant_again", "_bibtex": "@inproceedings{    \nanonymous2019making,    \ntitle={Making Convolutional Networks Shift-Invariant Again},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklVEnR5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1g4E3C9t7", "original": "rkeToK69tQ", "number": 1439, "cdate": 1538087979594, "ddate": null, "tcdate": 1538087979594, "tmdate": 1538156103486, "tddate": null, "forum": "r1g4E3C9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1439/Authors"], "authors": ["Anonymous"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/a66124595b2e6c98d3215b58e77de6ea6728e935.pdf", "paperhash": "anonymous|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{    \nanonymous2019characterizing,    \ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g4E3C9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1zmVhCqKm", "original": "BygO_bA9tm", "number": 1438, "cdate": 1538087979413, "ddate": null, "tcdate": 1538087979413, "tmdate": 1538156103277, "tddate": null, "forum": "r1zmVhCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Text Infilling", "abstract": "Recent years have seen remarkable progress of text generation in different contexts, including the most common setting of generating text from scratch, the increasingly popular paradigm of retrieval and editing, and others. Text infilling, which fills missing text portions of a sentence or paragraph, is also of numerous use in real life. Previous work has focused on restricted settings, by either assuming single word per missing portion, or limiting to single missing portion to the end of text. This paper studies the general task of text infilling, where the input text can have an arbitrary number of portions to be filled, each of which may require an arbitrary unknown number of tokens. \nWe develop a self-attention model with segment-aware position encoding for precise global context modeling.\nWe further create a variety of supervised data by masking out text in different domains with varying missing ratios and mask strategies. Extensive experiments show the proposed model performs significantly better than other methods, and generates meaningful text patches.", "keywords": ["text generation", "text infilling", "self attention", "sequence to sequence"], "authorids": ["ICLR.cc/2019/Conference/Paper1438/Authors"], "authors": ["Anonymous"], "TL;DR": "We study a general task of text infilling that fills missing portions of given text; an self-attention model is developed.", "pdf": "/pdf/734c0abdadc7d3ec99c79257c376f6dbac0c65ae.pdf", "paperhash": "anonymous|text_infilling", "_bibtex": "@inproceedings{    \nanonymous2019text,    \ntitle={Text Infilling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1zmVhCqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xQVn09FX", "original": "B1ex_t6ctQ", "number": 1437, "cdate": 1538087979234, "ddate": null, "tcdate": 1538087979234, "tmdate": 1538156103067, "tddate": null, "forum": "H1xQVn09FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GANSynth: Adversarial Neural Audio Synthesis", "abstract": "Efficient audio synthesis is an inherently difficult machine learning task, as human perception is sensitive to both global structure and fine-scale waveform coherence. Autoregressive models, such as WaveNet, model local structure at the expense of global latent structure and slow iterative sampling, while Generative Adversarial Networks (GANs), have global latent conditioning and efficient parallel sampling, but struggle to generate locally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact generate high-fidelity and locally-coherent audio by modelling log magnitudes and instantaneous frequencies  with sufficient frequency resolution in the spectral domain. Through extensive empirical investigations on the NSynth dataset, we demonstrate that GANs are able to outperform strong WaveNet baselines on automated and human evaluation metrics, and efficiently generate audio ~54,000 times faster than their autoregressive counterparts.\n", "keywords": ["GAN", "Audio", "WaveNet", "NSynth"], "authorids": ["ICLR.cc/2019/Conference/Paper1437/Authors"], "authors": ["Anonymous"], "TL;DR": "High-quality audio synthesis with GANs", "pdf": "/pdf/c7233c2671bc1491a93f0de0a7ec372e4973d156.pdf", "paperhash": "anonymous|gansynth_adversarial_neural_audio_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019gansynth:,    \ntitle={GANSynth: Adversarial Neural Audio Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xQVn09FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylQV305YQ", "original": "BygM95O5YQ", "number": 1436, "cdate": 1538087979068, "ddate": null, "tcdate": 1538087979068, "tmdate": 1538156102857, "tddate": null, "forum": "BylQV305YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Toward Understanding the Impact of Staleness in Distributed Machine Learning", "abstract": "Most distributed machine learning (ML) systems store a copy of the model parameters locally on each machine to minimize network communication. In practice, in order to reduce synchronization waiting time, these copies of the model are not necessarily updated in lock-steps, and can become stale. Despite much development in large-scale ML, the effect of staleness on the learning efficiency is inconclusive, mainly because it is challenging to control or monitor the staleness in complex distributed environments. In this work, we study the convergence behaviors of a wide array of ML models and algorithms under delayed updates. Our extensive experiments reveal the rich diversity of the effects of staleness on the convergence of ML algorithms, and offer insights into seemingly contradictory reports in the literature. The empirical findings also inspire a new convergence analysis of SGD in non-convex optimization under staleness, matching the best known convergence rate of O(1/\\sqrt{T}).", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1436/Authors"], "authors": ["Anonymous"], "TL;DR": "Empirical and theoretical study of the effects of staleness in non-synchronous execution on machine learning algorithms.", "pdf": "/pdf/0b0c788e77de16291b68462b5178c49f3bf2aa2f.pdf", "paperhash": "anonymous|toward_understanding_the_impact_of_staleness_in_distributed_machine_learning", "_bibtex": "@inproceedings{    \nanonymous2019toward,    \ntitle={Toward Understanding the Impact of Staleness in Distributed Machine Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylQV305YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyg74h05tX", "original": "rylKFSe5Km", "number": 1435, "cdate": 1538087978893, "ddate": null, "tcdate": 1538087978893, "tmdate": 1538156102653, "tddate": null, "forum": "Hyg74h05tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Flow++: Improving Flow-Based Generative Models  with  Variational Dequantization and Architecture Design  ", "abstract": "Flow-based generative models are powerful exact likelihood models with the benefit of efficient sampling and inference. \nDespite their computational efficiency, flow-based models generally have much worse density modeling performance compared to state-of-the-art autoregressive models. In this paper, we carefully investigate three design choices employed by prior flow-based models that turn out to be limiting: (1) uniform noise is a sub-optimal dequantization choice that hurts both training loss and generalization; (2) commonly used affine coupling flows are not expressive enough; (3) conv-net based parametrization of flows fails to capture the global image context. Based on our findings, we propose Flow++, a set of alternative design choices that significantly improve the density modeling capacity of flow-based models. ", "keywords": ["Deep Generative Models", "Normalizing Flows", "RealNVP", "Density Estimation"], "authorids": ["ICLR.cc/2019/Conference/Paper1435/Authors"], "authors": ["Anonymous"], "TL;DR": "Improved training of current flow-based generative models (Glow and RealNVP) on density estimation benchmarks", "pdf": "/pdf/b5c88521dcccea19e3002c14537c126436532318.pdf", "paperhash": "anonymous|flow_improving_flowbased_generative_models_with_variational_dequantization_and_architecture_design", "_bibtex": "@inproceedings{    \nanonymous2019flow++:,    \ntitle={Flow++: Improving Flow-Based Generative Models  with  Variational Dequantization and Architecture Design  },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyg74h05tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xX42R5Fm", "original": "BklYfoa5F7", "number": 1434, "cdate": 1538087978659, "ddate": null, "tcdate": 1538087978659, "tmdate": 1538156102438, "tddate": null, "forum": "r1xX42R5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Beyond Greedy Ranking: Slate Optimization via List-CVAE", "abstract": "The conventional approach to solving the recommendation problem greedily ranks\nindividual document candidates by prediction scores. However, this method fails to\noptimize the slate as a whole, and hence, often struggles to capture biases caused\nby the page layout and document interdepedencies. The slate recommendation\nproblem aims to directly find the optimally ordered subset of documents (i.e.\nslates) that best serve users\u2019 interests. Solving this problem is hard due to the\ncombinatorial explosion of document candidates and their display positions on the\npage. In this paper, we introduce List Conditional Variational Auto-Encoders (ListCVAE),\nwhich learn the joint distribution of documents on the slate conditioned\non user responses, and directly generate full slates. Experiments on simulated\nand real-world data show that List-CVAE outperforms greedy ranking methods\nconsistently on various scales of documents corpora.", "keywords": ["CVAE", "VAE", "recommendation system", "slate optimization", "whole page optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1434/Authors"], "authors": ["Anonymous"], "TL;DR": "We used a CVAE type model structure to learn to directly generate slates/whole pages for recommendation systems.", "pdf": "/pdf/c144e4698717b3f1a55efdf309477ad976ab0d4c.pdf", "paperhash": "anonymous|beyond_greedy_ranking_slate_optimization_via_listcvae", "_bibtex": "@inproceedings{    \nanonymous2019beyond,    \ntitle={Beyond Greedy Ranking: Slate Optimization via List-CVAE},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xX42R5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lG42C9Km", "original": "ryeV-H25Km", "number": 1433, "cdate": 1538087978476, "ddate": null, "tcdate": 1538087978476, "tmdate": 1538156102230, "tddate": null, "forum": "B1lG42C9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Intrinsic Social Motivation via Causal Influence in Multi-Agent RL", "abstract": "We derive a new intrinsic social motivation for multi-agent reinforcement learning (MARL), in which agents are rewarded for having causal influence over another agent's actions, where causal influence is assessed using counterfactual reasoning. The reward does not depend on observing another agent's reward function, and is thus a more realistic approach to MARL than taken in previous work. We show that the causal influence reward is related to maximizing the mutual information between agents' actions. We test the approach in challenging social dilemma environments, where it consistently leads to enhanced cooperation between agents and higher collective reward. Moreover, we find that rewarding influence can lead agents to develop emergent communication protocols. Therefore, we also employ influence to train agents to use an explicit communication channel, and find that it leads to more effective communication and higher collective reward. Finally, we show that influence can be computed by equipping each agent with an internal model that predicts the actions of other agents. This allows the social influence reward to be computed without the use of a centralised controller, and as such represents a significantly more general and scalable inductive bias for MARL with independent agents.", "keywords": ["multi-agent reinforcement learning", "causal inference", "game theory", "social dilemma", "intrinsic motivation", "counterfactual reasoning", "empowerment", "communication"], "authorids": ["ICLR.cc/2019/Conference/Paper1433/Authors"], "authors": ["Anonymous"], "TL;DR": "We reward agents for having a causal influence on the actions of other agents, and show that this gives rise to better cooperation and more meaningful emergent communication protocols. ", "pdf": "/pdf/2c3d9a7f18323409c45b6dcf38a4363e9094a33b.pdf", "paperhash": "anonymous|intrinsic_social_motivation_via_causal_influence_in_multiagent_rl", "_bibtex": "@inproceedings{    \nanonymous2019intrinsic,    \ntitle={Intrinsic Social Motivation via Causal Influence in Multi-Agent RL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lG42C9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byxz4n09tQ", "original": "Sklm8rpqtm", "number": 1432, "cdate": 1538087978299, "ddate": null, "tcdate": 1538087978299, "tmdate": 1538156102018, "tddate": null, "forum": "Byxz4n09tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Model Compression with Generative Adversarial Networks", "abstract": "The ever-increasing accuracy of machine learning models often comes at the expense of higher computational costs and memory requirements at test time, making them impractical to deploy on memory-constrained or CPU-constrained devices. Model compression (also known as distillation) is a technique to compress a complex model into a simpler one while maintaining most of the original accuracy. This can be done by using the same dataset for both the model training and compression tasks or by exploiting additional data. However, in many real-world applications, additional data are not available, and the repeated use of the original training data leads to suboptimal compression. In this work, we propose to use generative adversarial networks (GANs) to approximately sample from the distribution of the original data, thus generating ''unlimited'' synthetic data that can be used to perform the compression task. Our GAN-assisted model compression approach shows significant improvement in compressing complex models such as deep neural networks and large random forests on both image and tabular datasets. Furthermore, based on the model compression results, we propose a comprehensive metric\u2014the Compression Score\u2014to evaluate the quality of generative models, which captures both the discriminability and the diversity of the synthetic data. We show that the Compression Score performs well in cases when the popular Inception Score fails. ", "keywords": ["Model compression", "distillation", "generative adversarial network", "GAN", "deep neural network", "random forest", "ensemble", "decision tree", "convolutional neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper1432/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/44e0cfbf6a78270dcb612ab4a8912f9c7c40e776.pdf", "paperhash": "anonymous|model_compression_with_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019model,    \ntitle={Model Compression with Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byxz4n09tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxfEn09Y7", "original": "BklLeyEROQ", "number": 1431, "cdate": 1538087978124, "ddate": null, "tcdate": 1538087978124, "tmdate": 1538156101813, "tddate": null, "forum": "SyxfEn09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space", "abstract": "It is well known that neural networks with rectified linear units (ReLU) activation functions are positively scale-invariant. Conventional algorithms like stochastic gradient descent optimize the neural networks in the vector space of weights, which is, however, not positively scale-invariant. This mismatch may lead to problems during the optimization process. Then, a natural question is: \\emph{can we construct a new vector space that is positively scale-invariant and sufficient to represent ReLU neural networks so as to better facilitate the optimization process }? In this paper, we provide our positive answer to this question. First, we conduct a formal study on the positive scaling operators which forms a transformation group, denoted as $\\mathcal{G}$. We prove that the value of a path (i.e. the product of the weights along the path) in the neural network is invariant to positive scaling and the value vector of all the paths is sufficient to represent the neural networks under mild conditions. Second, we show that one can identify some basis paths out of all the paths and prove that the linear span of their value vectors (denoted as $\\mathcal{G}$-space) is an invariant space with lower dimension under the positive scaling group. Finally, we design stochastic gradient descent algorithm in $\\mathcal{G}$-space (abbreviated as $\\mathcal{G}$-SGD) to optimize the value vector of the basis paths of neural networks with little extra cost by leveraging back-propagation. Our experiments show that $\\mathcal{G}$-SGD significantly outperforms the conventional SGD algorithm in optimizing ReLU networks on benchmark datasets. ", "keywords": ["optimization", "neural network", "irreducible positively scale-invariant space", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1431/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/524a14cf2a62e271d607b44ec5812c5d85b38038.pdf", "paperhash": "anonymous|gsgd_optimizing_relu_neural_networks_in_its_positively_scaleinvariant_space", "_bibtex": "@inproceedings{    \nanonymous2019g-sgd:,    \ntitle={G-SGD: Optimizing ReLU Neural Networks in its Positively Scale-Invariant Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxfEn09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygGNnCqKQ", "original": "B1g7CmacFm", "number": 1430, "cdate": 1538087977946, "ddate": null, "tcdate": 1538087977946, "tmdate": 1538156101606, "tddate": null, "forum": "BygGNnCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Architecture Compression", "abstract": "In this paper we propose a novel approach to model compression termed Architecture Compression. Instead of operating on the weight or filter space of the network like classical model compression methods, our approach operates on the architecture space. A 1-D CNN encoder/decoder is trained to learn a mapping from discrete architecture space to a continuous embedding and back. Additionally, this embedding is jointly trained to regress accuracy and parameter count in order to incorporate information about the architecture's effectiveness on the dataset. During the compression phase, we first encode the network and then perform gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder. We demonstrate the merits of this approach on visual recognition tasks such as CIFAR-10/100, FMNIST and SVHN and achieve a greater than 20x compression on CIFAR-10.", "keywords": ["compression", "architecture search"], "authorids": ["ICLR.cc/2019/Conference/Paper1430/Authors"], "authors": ["Anonymous"], "TL;DR": "Novel gradient descent approach to perform model compression in architecture space", "pdf": "/pdf/7f9686ba45c4d620ba0f632556272266c5f5f9f6.pdf", "paperhash": "anonymous|architecture_compression", "_bibtex": "@inproceedings{    \nanonymous2019architecture,    \ntitle={Architecture Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygGNnCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgMNnC9YQ", "original": "r1gOq7Rctm", "number": 1429, "cdate": 1538087977780, "ddate": null, "tcdate": 1538087977780, "tmdate": 1538156101399, "tddate": null, "forum": "rkgMNnC9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ATTENTIVE EXPLAINABILITY FOR PATIENT TEMPO- RAL EMBEDDING", "abstract": "Learning explainable patient temporal embeddings from observational data has mostly ignored the use of RNN architecture that excel in capturing temporal data dependencies but at the expense of explainability. This paper addresses this problem by introducing and applying an information theoretic approach to estimate the degree of explainability of such architectures. Using a communication paradigm, we formalize metrics of explainability by estimating the amount of information that an AI model needs to convey to a human end user to explain and rationalize its outputs. A key aspect of this work is to model human prior knowledge at the receiving end and measure the lack of explainability as a deviation from human prior knowledge. We apply this paradigm to medical concept representation problems by regularizing loss functions of temporal autoencoders according to the derived explainability metrics to guide the learning process towards models producing explainable outputs. We illustrate the approach with convincing experimental results for the generation of explainable temporal embeddings for critical care patient data.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1429/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ff8e8f39f8926b2aec69c8da245e4aa6f6570f8d.pdf", "paperhash": "anonymous|attentive_explainability_for_patient_tempo_ral_embedding", "_bibtex": "@inproceedings{    \nanonymous2019attentive,    \ntitle={ATTENTIVE EXPLAINABILITY FOR PATIENT TEMPO- RAL EMBEDDING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgMNnC9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lf43A5Y7", "original": "rke_052ctQ", "number": 1428, "cdate": 1538087977602, "ddate": null, "tcdate": 1538087977602, "tmdate": 1538156101191, "tddate": null, "forum": "B1lf43A5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How to learn (and how not to learn) multi-hop reasoning with memory networks", "abstract": "Answering questions about a text frequently requires aggregating information from multiple places in that text. End-to-end neural network models, the dominant approach in the current literature, can theoretically learn how to distill and manipulate representations of the text without explicit supervision about how to do so. We investigate a canonical architecture for this task, the memory network, and analyze how effective it really is in the context of three multi-hop reasoning settings. In a simple synthetic setting, the path-finding task of the bAbI dataset, the model fails to learn the correct reasoning without additional supervision of its attention mechanism. However, with this supervision, it can perform well. On a real text dataset, WikiHop, the memory network gives nearly state-of-the-art performance, but does so without using its multi-hop capabilities. A tougher anonymized version of the WikiHop dataset is qualitatively similar to bAbI: the model fails to perform well unless it has additional supervision. We hypothesize that many \"multi-hop\" architectures do not truly learn this reasoning as advertised, though they could learn this reasoning if appropriately supervised.", "keywords": ["NLP", "Reading Comprehension", "Memory Networks", "Multi-hop Reasoning"], "authorids": ["ICLR.cc/2019/Conference/Paper1428/Authors"], "authors": ["Anonymous"], "TL;DR": "Memory Networks do not learn multi-hop reasoning unless we supervise them.", "pdf": "/pdf/efe68d4f90d5ae5c7fc90e811b84fff053c5de24.pdf", "paperhash": "anonymous|how_to_learn_and_how_not_to_learn_multihop_reasoning_with_memory_networks", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How to learn (and how not to learn) multi-hop reasoning with memory networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lf43A5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylWVnR5YQ", "original": "BkeA4W05K7", "number": 1427, "cdate": 1538087977422, "ddate": null, "tcdate": 1538087977422, "tmdate": 1538156100983, "tddate": null, "forum": "rylWVnR5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Context Dependent Modulation of Activation Function", "abstract": "We propose a modification to traditional Artificial Neural Networks (ANNs), which provides the ANNs with new aptitudes motivated by biological neurons.  Biological neurons work far beyond linearly summing up synaptic inputs and then transforming the integrated information.  A biological neuron change firing modes accordingly to peripheral factors (e.g., neuromodulators) as well as intrinsic ones.  Our modification connects a new type of ANN nodes, which mimic the function of biological neuromodulators and are termed modulators, to enable other traditional ANN nodes to adjust their activation sensitivities in run-time based on their input patterns.  In this manner, we enable the slope of the activation function to be context dependent.  This modification produces statistically significant improvements in comparison with traditional ANN nodes in the context of Convolutional Neural Networks and Long Short-Term Memory networks. ", "keywords": ["Artificial Neural Network", "Convolution Neural Network", "Long Short-Term Memory", "Activation Function", "Neuromodulation"], "authorids": ["ICLR.cc/2019/Conference/Paper1427/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a modification to traditional Artificial Neural Networks motivated by the biology of neurons to enable the shape of the activation function to be context dependent.", "pdf": "/pdf/85e33c31a700088c018192fcd653ce8f15607852.pdf", "paperhash": "anonymous|context_dependent_modulation_of_activation_function", "_bibtex": "@inproceedings{    \nanonymous2019context,    \ntitle={Context Dependent Modulation of Activation Function},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylWVnR5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SylWNnA5FQ", "original": "rJgn8GR9t7", "number": 1426, "cdate": 1538087977247, "ddate": null, "tcdate": 1538087977247, "tmdate": 1538156100777, "tddate": null, "forum": "SylWNnA5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Program Synthesis with Learned Code Idioms", "abstract": "Program synthesis of general-purpose source code from natural language specifi-\ncations is challenging due to the need to reason about high-level patterns in the\ntarget program and low-level implementation details at the same time. In this work,\nwe present PATOIS , the first system that allows a neural program synthesizer to\nexplicitly interleave high-level and low-level reasoning at every generation step. It\naccomplishes this by automatically mining common code idioms from a given cor-\npus and then incorporating them into the underlying language for neural synthesis.\nWe evaluate PATOIS on a challenging program synthesis dataset NAPS and show\nthat using learned code idioms improves the synthesizer\u2019s accuracy.", "keywords": ["program synthesis", "semantic parsing", "code idioms", "domain-specific languages"], "authorids": ["ICLR.cc/2019/Conference/Paper1426/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4df46d32f166659647231f7afcda8c5bc453cf07.pdf", "paperhash": "anonymous|program_synthesis_with_learned_code_idioms", "_bibtex": "@inproceedings{    \nanonymous2019program,    \ntitle={Program Synthesis with Learned Code Idioms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SylWNnA5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gZV30qKQ", "original": "rygTXswmKQ", "number": 1425, "cdate": 1538087977073, "ddate": null, "tcdate": 1538087977073, "tmdate": 1538156100570, "tddate": null, "forum": "H1gZV30qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transfer Value or Policy? A Value-centric Framework Towards Transferrable Continuous Reinforcement Learning", "abstract": "Transferring learned knowledge from one environment to another is an important step towards practical reinforcement learning (RL). In this paper, we investigate the problem of transfer learning across environments with different dynamics while accomplishing the same task in the continuous control domain. We start by illustrating the limitations of policy-centric methods (policy gradient, actor- critic, etc.) when transferring knowledge across environments. We then propose a general model-based value-centric (MVC) framework for continuous RL. MVC learns a dynamics approximator and a value approximator simultaneously in the source domain, and makes decision based on both of them. We evaluate MVC against popular baselines on 5 benchmark control tasks in a training from scratch setting and a transfer learning setting. Our experiments demonstrate MVC achieves comparable performance with the baselines when it is trained from scratch, while it significantly surpasses them when it is used in the transfer setting.\n", "keywords": ["Reinforcement Learning", "Transfer Learning", "Control", "Value function"], "authorids": ["ICLR.cc/2019/Conference/Paper1425/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e32bb20e479f994a726ab9400847002a029b18b4.pdf", "paperhash": "anonymous|transfer_value_or_policy_a_valuecentric_framework_towards_transferrable_continuous_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer Value or Policy? A Value-centric Framework Towards Transferrable Continuous Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gZV30qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgZNnR5tX", "original": "BkgF5atqt7", "number": 1424, "cdate": 1538087976897, "ddate": null, "tcdate": 1538087976897, "tmdate": 1538156100367, "tddate": null, "forum": "SkgZNnR5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Uncovering Surprising Behaviors in Reinforcement Learning via Worst-case Analysis", "abstract": "Reinforcement-learning (RL) agents are typically trained and evaluated according to their performance averaged over some distribution of environment settings. But does the distribution over environment settings contain important biases? Do these lead to agents that fail in certain cases despite high average-case performance? In this work, we consider worst-case evaluation of agents over environment settings in order to detect whether there are directions in which agents may have failed to generalize. Specifically, we consider a 3D first-person task where agents must navigate procedurally generated mazes, and where RL agents have recently achieved human-level average-case performance. Using a method which can be described as evolution over mazes, we find that despite impressive average-case performance, agents still suffer from catastrophic failures on certain mazes, including some surprisingly simple mazes. Additionally, we find that these failures transfer between different agents and even significantly different architectures. We believe our findings highlight an important role for worst-case evaluation in identifying whether there are directions in which agents have failed to generalize. Our hope is that the ability to automatically identify failures of generalization will facilitate development of more general, robust agents.", "keywords": ["Reinforcement learning", "Adversarial examples", "Navigation", "Evaluation", "Analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper1424/Authors"], "authors": ["Anonymous"], "TL;DR": "We find environment settings in which SOTA agents trained on navigation tasks display extreme failures suggesting failures in generalizaation.", "pdf": "/pdf/7e898420ac7e7574618a39614154b94c015b4ace.pdf", "paperhash": "anonymous|uncovering_surprising_behaviors_in_reinforcement_learning_via_worstcase_analysis", "_bibtex": "@inproceedings{    \nanonymous2019uncovering,    \ntitle={Uncovering Surprising Behaviors in Reinforcement Learning via Worst-case Analysis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgZNnR5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeZEhR5FQ", "original": "HJxVnVfcKX", "number": 1423, "cdate": 1538087976732, "ddate": null, "tcdate": 1538087976732, "tmdate": 1538156100160, "tddate": null, "forum": "SkeZEhR5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Graph Decomposition", "abstract": "We propose a novel end-to-end trainable framework for the graph decomposition problem. The minimum cost multicut problem is first converted to an unconstrained binary cubic formulation where cycle consistency constraints are incorporated into the objective function. The new optimization problem can be viewed as a Conditional Random Field (CRF) in which the random variables are associated with the binary edge labels of the initial graph and the hard constraints are introduced in the CRF as high-order potentials. The parameters of a standard Neural Network and the fully differentiable CRF can be optimized in an end-to-end manner.  We demonstrate the proposed learning algorithm in the context of clustering of hand written digits, particularly in a setting where no direct supervision for the graph decomposition task is available, and multiple person pose estimation from images in the wild. The experiments validate the effectiveness of our approach both for the feature learning and for the final clustering task.", "keywords": ["multicut graph decomposition", "optimization by learning", "pose estimation", "clustering"], "authorids": ["ICLR.cc/2019/Conference/Paper1423/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4a6c48b7a47e057623462da1e3110782a9d9b98d.pdf", "paperhash": "anonymous|learning_graph_decomposition", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Graph Decomposition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeZEhR5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkl-43C9FQ", "original": "r1gdrYT5F7", "number": 1422, "cdate": 1538087976563, "ddate": null, "tcdate": 1538087976563, "tmdate": 1538156099958, "tddate": null, "forum": "Bkl-43C9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Spherical CNNs on Unstructured Grids", "abstract": "We present an efficient convolution kernel for Convolutional Neural Networks (CNNs) on unstructured grids using parameterized differential operators while focusing on spherical signals such as panorama images or planetary signals. \nTo this end, we replace conventional convolution kernels with linear combinations of differential operators that are weighted by learnable parameters. Differential operators can be efficiently estimated on unstructured grids using one-ring neighbors, and learnable parameters can be optimized through standard back-propagation. As a result, we obtain extremely efficient neural networks that match or outperform state-of-the-art network architectures in terms of performance but with a significantly lower number of network parameters. We evaluate our algorithm in an extensive series of experiments on a variety of computer vision and climate science tasks, including shape classification, climate pattern segmentation, and omnidirectional image semantic segmentation. Overall, we present (1) a novel CNN approach on unstructured grids using parameterized differential operators for spherical signals, and (2) we show that our unique kernel parameterization allows our model to achieve the same or higher accuracy with significantly fewer network parameters.", "keywords": ["Spherical CNN", "unstructured grid", "panoramic", "semantic segmentation", "parameter efficiency"], "authorids": ["ICLR.cc/2019/Conference/Paper1422/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a new CNN kernel for unstructured grids for spherical signals, and show significant accuracy and parameter efficiency gain on tasks such as 3D classfication and omnidirectional image segmentation.", "pdf": "/pdf/371a81e723e65cee49f5acf90b9b551af52e51a7.pdf", "paperhash": "anonymous|spherical_cnns_on_unstructured_grids", "_bibtex": "@inproceedings{    \nanonymous2019spherical,    \ntitle={Spherical CNNs on Unstructured Grids},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkl-43C9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgeEh09KQ", "original": "rkeLZbCcYX", "number": 1421, "cdate": 1538087976394, "ddate": null, "tcdate": 1538087976394, "tmdate": 1538156099751, "tddate": null, "forum": "HJgeEh09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Robustness Certification with Refinement", "abstract": "We present a novel approach for verification of neural networks which combines scalable over-approximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state of the art verifiers on feed forward neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1421/Authors"], "authors": ["Anonymous"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/211afa9e28200b480ed8d4bff94031830ac96868.pdf", "paperhash": "anonymous|robustness_certification_with_refinement", "_bibtex": "@inproceedings{    \nanonymous2019robustness,    \ntitle={Robustness Certification with Refinement},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgeEh09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJleN20qK7", "original": "rkgqtWRqYm", "number": 1420, "cdate": 1538087976230, "ddate": null, "tcdate": 1538087976230, "tmdate": 1538156099546, "tddate": null, "forum": "rJleN20qK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Two-Timescale Networks for Nonlinear Value Function Approximation", "abstract": "A key component for many reinforcement learning agents is to learn a value function, either for policy evaluation or control. Many of the algorithms for learning values, however, are designed for linear function approximation---with a fixed basis or fixed representation. Though there have been a few sound extensions to nonlinear function approximation, such as nonlinear gradient temporal difference learning, these methods have largely not been adopted, eschewed in favour of simpler but not sound methods like temporal difference learning and Q-learning. In this work, we provide a two-timescale network (TTN) architecture that enables linear methods to be used to learn values, with the representation learned at a slower timescale. The approach facilitates use of algorithms developed for the linear setting, such as data-efficient least-squares methods, eligibility traces and the myriad of recently developed linear policy evaluation algorithms. We prove convergence for TTNs, with particular care given to ensure convergence of the fast linear component under potentially dependent features provided by the learned representation. We empirically demonstrate the benefits of TTNs, compared to other nonlinear value function approximation algorithms, both for policy evaluation and control.    ", "keywords": ["Reinforcement learning", "policy evaluation", "nonlinear function approximation"], "authorids": ["ICLR.cc/2019/Conference/Paper1420/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an architecture for learning value functions which allows the use of any linear policy evaluation algorithm in tandem with nonlinear feature learning.", "pdf": "/pdf/d542fd342c5cbe3ffb1adb4d173052050891303f.pdf", "paperhash": "anonymous|twotimescale_networks_for_nonlinear_value_function_approximation", "_bibtex": "@inproceedings{    \nanonymous2019two-timescale,    \ntitle={Two-Timescale Networks for Nonlinear Value Function Approximation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJleN20qK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlgNh0qKQ", "original": "rJeyvH6cF7", "number": 1419, "cdate": 1538087976052, "ddate": null, "tcdate": 1538087976052, "tmdate": 1538156099343, "tddate": null, "forum": "BJlgNh0qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder", "abstract": "Human annotation for syntactic parsing is expensive, and large resources are available only for a  fraction of languages. A question we ask is whether one can leverage abundant unlabeled texts to improve syntactic parsers, beyond just using the texts to obtain more generalisable lexical features (i.e. beyond word embeddings). To this end, we propose a novel latent-variable generative model for semi-supervised syntactic dependency parsing. As exact inference is intractable, we introduce a differentiable relaxation to obtain approximate samples and compute gradients with respect to the parser parameters. Our method (Differentiable Perturb-and-Parse) relies on differentiable dynamic programming over stochastically perturbed edge scores. We demonstrate effectiveness of our approach with experiments on English, French and Swedish.", "keywords": ["differentiable dynamic programming", "variational auto-encoder", "dependency parsing", "semi-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1419/Authors"], "authors": ["Anonymous"], "TL;DR": "Differentiable dynamic programming over perturbed input weights with application to semi-supervised VAE", "pdf": "/pdf/a13c10f7431392ef25c0c02103fb43831a644f04.pdf", "paperhash": "anonymous|differentiable_perturbandparse_semisupervised_parsing_with_a_structured_variational_autoencoder", "_bibtex": "@inproceedings{    \nanonymous2019differentiable,    \ntitle={Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a Structured Variational Autoencoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlgNh0qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sygx4305KQ", "original": "S1lRj5D9Ym", "number": 1418, "cdate": 1538087975885, "ddate": null, "tcdate": 1538087975885, "tmdate": 1538156099136, "tddate": null, "forum": "Sygx4305KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Small steps and giant leaps: Minimal Newton solvers for Deep Learning", "abstract": "We propose a fast second-order method that can be used as a drop-in replacement for current deep learning solvers. Compared to stochastic gradient descent (SGD), it only requires two additional forward-mode automatic differentiation operations per iteration, which has a computational cost comparable to two standard forward passes and is easy to implement. Our method addresses long-standing issues with current second-order solvers, which invert an approximate Hessian matrix every iteration exactly or by conjugate-gradient methods, procedures that are much slower than a SGD step. Instead, we propose to keep a single estimate of the gradient projected by the inverse Hessian matrix, and update it once per iteration with just two passes over the network. This estimate has the same size and is similar to the momentum variable that is commonly used in SGD. No estimate of the Hessian is maintained.\nWe first validate our method, called CurveBall, on small problems with known solutions (noisy Rosenbrock function and degenerate 2-layer linear networks), where current deep learning solvers struggle. We then train several large models on CIFAR and ImageNet, including ResNet and VGG-f networks, where we demonstrate faster convergence with no hyperparameter tuning. We also show our optimiser's generality by testing on a large set of randomly-generated architectures.", "keywords": ["deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1418/Authors"], "authors": ["Anonymous"], "TL;DR": "minimal newton solver for deep learning", "pdf": "/pdf/41f625df56e735ef917db63b4cedcf23b5fa89d1.pdf", "paperhash": "anonymous|small_steps_and_giant_leaps_minimal_newton_solvers_for_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019small,    \ntitle={Small steps and giant leaps: Minimal Newton solvers for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sygx4305KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1exVhActQ", "original": "BJeve3hcF7", "number": 1417, "cdate": 1538087975712, "ddate": null, "tcdate": 1538087975712, "tmdate": 1538156098928, "tddate": null, "forum": "r1exVhActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DEEP-TRIM: REVISITING L1 REGULARIZATION FOR CONNECTION PRUNING OF DEEP NETWORK", "abstract": "State-of-the-art deep neural networks (DNNs) typically have tens of millions of parameters, which might not fit into the upper levels of the memory hierarchy, thus increasing the inference time and energy consumption significantly, and prohibiting their use on edge devices such as mobile phones. The compression of DNN models has therefore become an active area of research recently, with \\emph{connection pruning} emerging as one of the most successful strategies. A very natural approach is to prune connections of DNNs via $\\ell_1$ regularization, but recent empirical investigations have suggested that this does not work as well in the context of DNN compression. In this work, we revisit this simple strategy and analyze it rigorously, to show that: (a) any \\emph{stationary point} of an $\\ell_1$-regularized layerwise-pruning objective has its number of non-zero elements bounded by the number of penalized prediction logits, regardless of the strength of the regularization; (b) successful pruning highly relies on an accurate optimization solver, and there is a trade-off between compression speed and distortion of prediction accuracy, controlled by the strength of regularization. Our theoretical results thus suggest that $\\ell_1$ pruning could be successful provided we use an accurate optimization solver. We corroborate this in our experiments, where we show that simple $\\ell_1$ regularization with an Adamax-L1(cumulative) solver gives pruning ratio competitive to the state-of-the-art.", "keywords": ["L1 regularization", "deep neural network", "deep compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1417/Authors"], "authors": ["Anonymous"], "TL;DR": "We revisit the simple idea of pruning connections of DNNs through $\\ell_1$ regularization achieving state-of-the-art results on multiple datasets with theoretic guarantees.", "pdf": "/pdf/7cd8d009f57f2b744cf982ce1e178a2f63a5287c.pdf", "paperhash": "anonymous|deeptrim_revisiting_l1_regularization_for_connection_pruning_of_deep_network", "_bibtex": "@inproceedings{    \nanonymous2019deep-trim:,    \ntitle={DEEP-TRIM: REVISITING L1 REGULARIZATION FOR CONNECTION PRUNING OF DEEP NETWORK},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1exVhActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lx42A9Ym", "original": "SylDeYN9FQ", "number": 1416, "cdate": 1538087975547, "ddate": null, "tcdate": 1538087975547, "tmdate": 1538156098721, "tddate": null, "forum": "B1lx42A9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Rendering Model: Joint Generation and Prediction for Semi-Supervised Learning", "abstract": "Unsupervised and semi-supervised learning are important problems that are especially challenging with complex data like natural images. Progress on these problems would accelerate if we had access to appropriate generative models under which to pose the associated inference tasks. Inspired by the success of Convolutional Neural Networks (CNNs) for supervised prediction in images, we design the Neural Rendering Model (NRM), a new hierarchical probabilistic generative model whose inference calculations correspond to those in a CNN. The NRM introduces a small set of latent variables at each level of the model and enforces dependencies among all the latent variables via a conjugate prior distribution. The conjugate prior yields a new regularizer for learning based on the paths rendered in the generative model for training CNNs\u2013the Rendering Path Normalization (RPN). We demonstrate that this regularizer improves generalization both in theory and in practice. Likelihood estimation in the NRM yields the new Max-Min cross entropy training loss, which suggests a new deep network architecture\u2013the Max- Min network\u2013which exceeds or matches the state-of-art for semi-supervised and supervised learning on SVHN, CIFAR10, and CIFAR100.", "keywords": ["neural nets", "generative models", "semi-supervised learning", "cross-entropy"], "authorids": ["ICLR.cc/2019/Conference/Paper1416/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a new deep generative model for semi-supervised learning and propose a new Max-Min cross-entropy for training CNNs.", "pdf": "/pdf/5073ce4bebe1104748df9bbe70b5f5360e0e42b5.pdf", "paperhash": "anonymous|neural_rendering_model_joint_generation_and_prediction_for_semisupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Rendering Model: Joint Generation and Prediction for Semi-Supervised Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lx42A9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJeyV2AcKX", "original": "HJgF2pp9YQ", "number": 1415, "cdate": 1538087975374, "ddate": null, "tcdate": 1538087975374, "tmdate": 1538156098517, "tddate": null, "forum": "rJeyV2AcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Network Reparameterization for Unseen Class Categorization", "abstract": "Many problems with large-scale labeled training data have been impressively solved by deep learning. However, Unseen Class Categorization (UCC) with minimal information provided about target classes is the most commonly encountered setting in industry, which remains a challenging research problem in machine learning. Previous approaches to UCC either fail to generate a powerful discriminative feature extractor or fail to learn a flexible classifier that can be easily adapted to unseen classes. In this paper, we propose to address these issues through network reparameterization, \\textit{i.e.}, reparametrizing the learnable weights of a network as a function of other variables, by which we decouple the feature extraction part and the classification part of a deep classification model to suit the special setting of UCC, securing both strong discriminability and excellent adaptability. Extensive experiments for UCC on several widely-used benchmark datasets in the settings of zero-shot and few-shot learning demonstrate that, our method with network reparameterization achieves state-of-the-art performance.", "keywords": ["Unseen class categorization", "network reparameterization", "few-shot learning", "zero-shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1415/Authors"], "authors": ["Anonymous"], "TL;DR": "A unified frame for both few-shot learning and zero-shot learning based on network reparameterization", "pdf": "/pdf/eb98361351aba2ddc9c40f83e35017f38d44991e.pdf", "paperhash": "anonymous|network_reparameterization_for_unseen_class_categorization", "_bibtex": "@inproceedings{    \nanonymous2019network,    \ntitle={Network Reparameterization for Unseen Class Categorization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJeyV2AcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxyV209Y7", "original": "SJgqv7R9tm", "number": 1414, "cdate": 1538087975202, "ddate": null, "tcdate": 1538087975202, "tmdate": 1538156098311, "tddate": null, "forum": "HyxyV209Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DATA POISONING  ATTACK  AGAINST NODE EMBEDDING  METHODS", "abstract": "Unsupervised node embedding methods (e.g., DeepWalk, LINE, and node2vec) are attracting growing interests due to their simplicity and effectiveness. However, although these methods have been proved effective in a variety of applications, none of the existing work has analyzed the robustness of these methods. This could be very risky if these methods are attacked by an adversarial party. In this paper, we take the task of link prediction as an example, which is one of the most fundamental problems for graph analysis, and introduce a data positioning attack to node embedding methods. We give a complete characterization of attacker's utilities and present efficient solutions to adversarial attacks for two popular node embedding methods: DeepWalk and LINE. We evaluate our proposed attack model on multiple real-world graphs. Experimental results show that our proposed model can significantly affect the results of link prediction by slightly changing the graph structures (e.g., adding or removing a few edges). We also show that our proposed model is very general and can be transferable across different embedding methods.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1414/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/88de23b9eee21f46ffb4a6ecbd6d97c08fafc3b1.pdf", "paperhash": "anonymous|data_poisoning_attack_against_node_embedding_methods", "_bibtex": "@inproceedings{    \nanonymous2019data,    \ntitle={DATA POISONING  ATTACK  AGAINST NODE EMBEDDING  METHODS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxyV209Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyfyN30qt7", "original": "SkeRrqp5FQ", "number": 1413, "cdate": 1538087975024, "ddate": null, "tcdate": 1538087975024, "tmdate": 1538156098106, "tddate": null, "forum": "HyfyN30qt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NICE: noise injection and clamping estimation for neural network quantization", "abstract": "Convolutional Neural Networks (CNN) are very popular in many fields including computer vision, speech recognition, natural language processing, to name a few. Though deep learning leads to groundbreaking performance in these domains, the networks used are very demanding computationally and are far from real-time even on a GPU, which is not power efficient and therefore does not suit low power systems such as mobile devices. To overcome this challenge, some solutions have been proposed for quantizing the weights and activations of these networks, which accelerate the runtime significantly. Yet, this acceleration comes at the cost of a larger error. The NICE method proposed in this work trains quantized neural networks by noise injection and a learned clamping, which improve the accuracy. This leads to state-of-the-art results on various regression and classification tasks, e.g., ImageNet classification with architectures such as ResNet-18/34/50 with low as 3-bit weights and 3 -bit activations. We implement the proposed solution on an FPGA to demonstrate its applicability for low power real-time applications.", "keywords": ["Efficient inference", "Hardware-efficient model architectures", "Quantization"], "authorids": ["ICLR.cc/2019/Conference/Paper1413/Authors"], "authors": ["Anonymous"], "TL;DR": "Combine noise injection, gradual quantization and activation clamping learning to achieve state-of-the-art 3,4 and 5 bit quantization", "pdf": "/pdf/bc126879f95f7966ea0d5ca2b80884b653ea28f9.pdf", "paperhash": "anonymous|nice_noise_injection_and_clamping_estimation_for_neural_network_quantization", "_bibtex": "@inproceedings{    \nanonymous2019nice:,    \ntitle={NICE: noise injection and clamping estimation for neural network quantization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyfyN30qt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byx1VnR9K7", "original": "rJe5tfC5KQ", "number": 1412, "cdate": 1538087974850, "ddate": null, "tcdate": 1538087974850, "tmdate": 1538156097898, "tddate": null, "forum": "Byx1VnR9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Trajectory VAE for multi-modal imitation", "abstract": "We address the problem of imitating multi-modal expert demonstrations in sequential decision making problems. In many practical applications, for example video games, behavioural demonstrations are readily available that contain multi-modal structure not captured by typical existing imitation learning approaches. For example, differences in the observed players' behaviours may be representative of different underlying playstyles.\n\n In this paper, we use a generative model to capture different emergent playstyles in an unsupervised manner, enabling the imitation of a diverse range of distinct behaviours. We utilise a variational autoencoder to learn an embedding of the different types of expert demonstrations on the trajectory level, and jointly learn a latent representation with a policy. In experiments on a range of 2D continuous control problems representative of Minecraft environments, we empirically demonstrate that our model can capture a multi-modal structured latent space from the demonstrated behavioural trajectories. ", "keywords": ["imitation learning", "latent variable model", "variational autoencoder", "diverse behaviour"], "authorids": ["ICLR.cc/2019/Conference/Paper1412/Authors"], "authors": ["Anonymous"], "TL;DR": "A trajectory-VAE method for imitating multi-modal expert demonstrations in sequential decision making problems.", "pdf": "/pdf/52c9267181e391cc67d809146013480f00272fa9.pdf", "paperhash": "anonymous|trajectory_vae_for_multimodal_imitation", "_bibtex": "@inproceedings{    \nanonymous2019trajectory,    \ntitle={Trajectory VAE for multi-modal imitation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byx1VnR9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklJV3A9Ym", "original": "HyxxU7o9K7", "number": 1411, "cdate": 1538087974687, "ddate": null, "tcdate": 1538087974687, "tmdate": 1538156097690, "tddate": null, "forum": "HklJV3A9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Approximation capability of neural networks on sets of probability measures and tree-structured data", "abstract": "This paper extends the proof of density of neural networks in the space of continuous (or even measurable) functions on Euclidean spaces to functions on compact sets of probability measures.\nBy doing so the work parallels a more then a decade old results on mean-map embedding of probability measures in reproducing kernel Hilbert spaces.  \nThe work has wide practical consequences for multi-instance learning, where it theoretically justifies some recently proposed constructions.\nThe result is then extended to Cartesian products, yielding universal approximation theorem for tree-structured domains, which naturally occur in data-exchange formats like JSON, XML, YAML, AVRO, and ProtoBuffer. This has important practical implications, as it enables to automatically create an architecture of neural networks for processing structured data (AutoML paradigms), as demonstrated by an accompanied library for JSON format.", "keywords": ["multi-instance learning", "hierarchical models", "universal approximation theorem"], "authorids": ["ICLR.cc/2019/Conference/Paper1411/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper extends the proof of density of neural networks in the space of continuous (or even measurable) functions on Euclidean spaces to functions on compact sets of probability measures. ", "pdf": "/pdf/3367b7bea6c06087eb81ba185c9c6321e8a57e6b.pdf", "paperhash": "anonymous|approximation_capability_of_neural_networks_on_sets_of_probability_measures_and_treestructured_data", "_bibtex": "@inproceedings{    \nanonymous2019approximation,    \ntitle={Approximation capability of neural networks on sets of probability measures and tree-structured data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklJV3A9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sy4lojC9tm", "original": "rkeBXKc5Y7", "number": 593, "cdate": 1538087832261, "ddate": null, "tcdate": 1538087832261, "tmdate": 1538156097486, "tddate": null, "forum": "Sy4lojC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dataset Distillation", "abstract": "Model distillation aims to distill the knowledge of a complex model into a simpler one.  In this paper, we consider an alternative formulation called {\\em dataset distillation}: we keep the model fixed and instead attempt to distill the knowledge from a large training dataset into a small one.  The idea is to {\\em synthesize} a small number of data points that do not need to come from the correct data distribution, but will, when given to the learning algorithm as training data, approximate the model trained on the original data.  For example, we show that it is possible to compress $60,000$ MNIST training images into just $10$ synthetic {\\em distilled images} (one per class) and achieve close to original performance with only a few steps of gradient descent, given a particular fixed network initialization. Apart from being an interesting new way to think about distillation, this approach could potentially open up several applications, such as fast domain adaptation and effective data poisoning attacks.", "keywords": ["knowledge distillation", "deep learning", "few-shot learning", "adversarial attack"], "authorids": ["ICLR.cc/2019/Conference/Paper593/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose to distill a large dataset into a small set of synthetic data , so networks can achieve close to original performance when trained on these data.", "pdf": "/pdf/0f14b5e1fcbbf2463daf694d84b4735217786848.pdf", "paperhash": "anonymous|dataset_distillation", "_bibtex": "@inproceedings{    \nanonymous2019dataset,    \ntitle={Dataset Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sy4lojC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeZisA5t7", "original": "ByxKtPnqtm", "number": 595, "cdate": 1538087832609, "ddate": null, "tcdate": 1538087832609, "tmdate": 1538156097277, "tddate": null, "forum": "SkeZisA5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Estimators Show Information Compression in Deep Neural Networks", "abstract": "To improve how neural networks function it is crucial to understand their learning process. The information bottleneck theory of deep learning proposes that neural networks achieve good generalization by compressing their representations to disregard information that is not relevant for the task. However, empirical evidence for this theory is conflicting, as compression was only observed when the networks used a saturating activation functions. In contrast, networks with non-saturating activation functions achieved comparable levels of task performance but did not show compression. In this paper we developed a more robust mutual information estimation technique, that adapts to hidden activity of neural networks and produces more sensitive measurements of activations from all functions, especially unbounded functions. Using these adaptive estimation techniques, we explored compression in networks with a range of different activation functions. With two improved methods of estimation, firstly, we show that saturation of the activation function is not required for compression, and the amount of compression varies between different activation functions. We also found that there is a large amount of variation in compression between different network initializations. Secondary, we see that L2 regularization leads to significantly increased compression, while preventing overfitting. Finally, we show that only compression of the last layer is positively correlated with generalization.", "keywords": ["deep neural networks", "mutual information", "information bottleneck", "noise", "L2 regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper595/Authors"], "authors": ["Anonymous"], "TL;DR": "We developed robust mutual information estimates for DNNs and used them to observe compression in networks with non-saturating activation functions", "pdf": "/pdf/5ff4e373a98369addf746c741fbefecdf27cb37e.pdf", "paperhash": "anonymous|adaptive_estimators_show_information_compression_in_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Estimators Show Information Compression in Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeZisA5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkx-ii05FQ", "original": "Sklwp0LYFQ", "number": 596, "cdate": 1538087832786, "ddate": null, "tcdate": 1538087832786, "tmdate": 1538156097066, "tddate": null, "forum": "Hkx-ii05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Cakewalk Method", "abstract": "Combinatorial optimization is a common theme in computer science. While in general such problems are NP-Hard, from a practical point of view, locally optimal solutions can be useful. In some combinatorial problems however, it can be hard to define meaningful solution neighborhoods that connect large portions of the search space, thus hindering methods that search this space directly. We suggest to circumvent such cases by utilizing a policy gradient algorithm that transforms the problem to the continuous domain, and to optimize a new surrogate objective that renders the former as generic stochastic optimizer. This is achieved by producing a surrogate objective whose distribution is fixed and predetermined, thus removing the need to fine-tune various hyper-parameters in a case by case manner. Since we are interested in methods which can successfully recover locally optimal solutions, we use the problem of finding locally maximal cliques as a challenging experimental benchmark, and we report results on a large dataset of graphs that is designed to test clique finding algorithms. Notably, we show in this benchmark that fixing the distribution of the surrogate is key to consistently recovering locally optimal solutions, and that our surrogate objective leads to an algorithm that outperforms other methods we have tested in a number of measures.", "keywords": ["policy gradient", "combinatorial optimization", "blackbox optimization", "stochastic optimization", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper596/Authors"], "authors": ["Anonymous"], "TL;DR": "A new policy gradient algorithm designed to approach black-box combinatorial optimization problems. The algorithm relies only on function evaluations, and returns locally optimal solutions with high probability.", "pdf": "/pdf/a68e76c371a928110cc84722bc72bf5c614c337b.pdf", "paperhash": "anonymous|the_cakewalk_method", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Cakewalk Method},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkx-ii05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skf-oo0qt7", "original": "S1eIdp4KtQ", "number": 597, "cdate": 1538087832960, "ddate": null, "tcdate": 1538087832960, "tmdate": 1538156096852, "tddate": null, "forum": "Skf-oo0qt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Generalization Bounds of a Family of Recurrent Neural Networks", "abstract": "Recurrent Neural Networks (RNNs) have been widely applied to sequential data analysis. Due to their complicated modeling structures, however, the theory behind is still largely missing. To connect theory and practice, we study the generalization properties of vanilla RNNs as well as their variants, including Minimal Gated Unit (MGU) and Long Short Term Memory (LSTM) RNNs. Specifically, our theory is established under the PAC-Learning framework. The generalization bound is presented in terms of the spectral norms of the weight matrices and the total number of parameters. We also establish refined generalization bounds with additional norm assumptions, and draw a comparison among these bounds. We remark: (1) Our generalization bound for vanilla RNNs is significantly tighter than the best of existing results; (2) We are not aware of any other generalization bounds for MGU and LSTM in the exiting literature; (3) We demonstrate the advantages of these variants in generalization.", "keywords": ["Recurrent Neural Networks", "MGU", "LSTM", "Generalization Bound", "PAC-Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper597/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b8aabd4616cf0bfdd1235c33231cbcd000e22857.pdf", "paperhash": "anonymous|on_generalization_bounds_of_a_family_of_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Generalization Bounds of a Family of Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skf-oo0qt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1fbosCcYm", "original": "rJlRapo9tQ", "number": 598, "cdate": 1538087833132, "ddate": null, "tcdate": 1538087833132, "tmdate": 1538156096649, "tddate": null, "forum": "B1fbosCcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Biologically Inspired Visual Working Memory for Deep Networks", "abstract": "The ability to look multiple times through a series of pose-adjusted glimpses is fundamental to human vision. This critical faculty allows us to understand highly complex visual scenes. Short term memory plays an integral role in aggregating the information obtained from these glimpses and informing our interpretation of the scene. Computational models have attempted to address glimpsing and visual attention but have failed to incorporate the notion of memory. We introduce a novel, biologically inspired visual working memory architecture that we term the Hebb-Rosenblatt memory. We subsequently introduce a fully differentiable Short Term Attentive Working Memory model (STAWM) which uses transformational attention to learn a memory over each image it sees. The state of our Hebb-Rosenblatt memory is embedded in STAWM as the weights space of a layer. By projecting different queries through this layer we can obtain goal-oriented latent representations for tasks including classification and visual reconstruction. Our model obtains highly competitive classification performance on MNIST and CIFAR-10. As demonstrated through the CelebA dataset, to perform reconstruction the model learns to make a sequence of updates to a canvas which constitute a parts-based representation. Classification with the self supervised representation obtained from MNIST is shown to be in line with the state of the art models (none of which use a visual attention mechanism). Finally, we show that STAWM can be trained under the dual constraints of classification and reconstruction to provide an interpretable visual sketchpad which helps open the `black-box' of deep learning.", "keywords": ["memory", "visual attention", "image classification", "image reconstruction", "latent representations"], "authorids": ["ICLR.cc/2019/Conference/Paper598/Authors"], "authors": ["Anonymous"], "TL;DR": "A biologically inspired working memory that can be integrated in recurrent visual attention models for state of the art performance", "pdf": "/pdf/3e9a1d743a78dbce20c1829e9125e94c2c034a43.pdf", "paperhash": "anonymous|a_biologically_inspired_visual_working_memory_for_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Biologically Inspired Visual Working Memory for Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1fbosCcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1VWjiRcKX", "original": "SyglADn9tQ", "number": 599, "cdate": 1538087833304, "ddate": null, "tcdate": 1538087833304, "tmdate": 1538156096448, "tddate": null, "forum": "S1VWjiRcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal Successor Features Approximators", "abstract": "The ability of a reinforcement learning (RL) agent to learn about many reward functions at the same time has many potential benefits, such as the decomposition of complex tasks into simpler ones, the exchange of information between tasks, and the reuse of skills. We focus on one aspect in particular, namely the ability to generalise to unseen tasks. Parametric generalisation relies on the interpolation power of a function approximator that is given the task description as input; one of its most common form are universal value function approximators (UVFAs). Another way to generalise to new tasks is to exploit structure in the RL problem itself. Generalised policy improvement (GPI) combines solutions of previous tasks into a policy for the unseen task; this relies on instantaneous policy evaluation of old policies under the new reward function, which is made possible through successor features (SFs). Our proposed \\emph{universal successor features approximators} (USFAs) combine the advantages of all of these, namely the scalability of UVFAs, the instant inference of SFs, and the strong generalisation of GPI. We discuss the challenges involved in training a USFA, its generalisation properties and demonstrate its practical benefits and transfer abilities on a large-scale domain in which the agent has to navigate in a first-person perspective three-dimensional environment. ", "keywords": ["reinforcement learning", "zero-shot transfer", "successor features", "universal value functions", "general value functions"], "authorids": ["ICLR.cc/2019/Conference/Paper599/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/88b2ac0ced180f1e2c53dc3847c1cb03af6a5f7e.pdf", "paperhash": "anonymous|universal_successor_features_approximators", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Successor Features Approximators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1VWjiRcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bklfsi0cKm", "original": "Syev-zKvKQ", "number": 601, "cdate": 1538087833655, "ddate": null, "tcdate": 1538087833655, "tmdate": 1538156096037, "tddate": null, "forum": "Bklfsi0cKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Convolutional Networks as shallow Gaussian Processes", "abstract": "We show that the output of a (residual) CNN with an appropriate prior over the weights and biases is a GP in the limit of infinitely many convolutional filters, extending similar results for dense networks. For a CNN, the equivalent kernel can be computed exactly and, unlike \"deep kernels\", has very few parameters: only the hyperparameters of the original CNN. Further, we show that this kernel has two properties that allow it to be computed efficiently; the cost of evaluating the kernel for a pair of images is similar to a single forward pass through the original CNN with only one filter per layer. The kernel equivalent to a 32-layer ResNet obtains 0.84% classification error on MNIST, a new record for GP with a comparable number of parameters.", "keywords": ["Gaussian process", "CNN", "ResNet", "Bayesian"], "authorids": ["ICLR.cc/2019/Conference/Paper601/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that CNNs and ResNets with appropriate priors on the parameters are Gaussian processes in the limit of infinitely many convolutional filters.", "pdf": "/pdf/c6e23da309f003aee1c4be242af8ef457730a26d.pdf", "paperhash": "anonymous|deep_convolutional_networks_as_shallow_gaussian_processes", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Convolutional Networks as shallow Gaussian Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bklfsi0cKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxfjjA5Km", "original": "SJldhTuYFX", "number": 602, "cdate": 1538087833839, "ddate": null, "tcdate": 1538087833839, "tmdate": 1538156095830, "tddate": null, "forum": "rkxfjjA5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection", "abstract": "A new statistical procedure (Cande\u0300s,2018) has provided a way to identify important factors using any supervised learning method controlling for FDR. This line of research has shown great potential to expand the horizon of machine learning methods beyond the task of prediction, to serve the broader need for scientific researches for interpretable findings. However, the lack of a practical and flexible method to generate knockoffs remains the major obstacle for wide application of  Model-X procedure. This paper fills in the gap by proposing a model-free knockoff generator which approximates the correlation structure between features through latent variable representation. We demonstrate our proposed method can achieve FDR control and better power than two existing methods in various simulated settings and a real data example for finding mutations associated with drug resistance in HIV-1 patients.\n\n", "keywords": ["Model-X Knockoff Generator", "model-free FDR control", "variable selection"], "authorids": ["ICLR.cc/2019/Conference/Paper602/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper provide model free method for generating Knockoffs, which is critical step in Model-X procedure to choose important variables with any supervised learning method under rigorous FDR control.", "pdf": "/pdf/1cb8952b0610a5fa1a5bd327fc33b331e4f1825b.pdf", "paperhash": "anonymous|autoencoding_knockoff_generator_for_fdr_controlled_variable_selection", "_bibtex": "@inproceedings{    \nanonymous2019auto-encoding,    \ntitle={Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxfjjA5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklMjsRqY7", "original": "S1lWNM39FX", "number": 603, "cdate": 1538087834026, "ddate": null, "tcdate": 1538087834026, "tmdate": 1538156095625, "tddate": null, "forum": "BklMjsRqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Accumulation Bit-Width Scaling For Ultra-Low Precision Training Of Deep Networks", "abstract": "Efforts to reduce the numerical precision of computations in deep learning training have yielded systems that aggressively quantize weights and activations, yet employ wide high-precision accumulators for partial sums in inner-product operations to preserve the quality of convergence. The absence of any framework to analyze the precision requirements of partial sum accumulations results in conservative design choices. This imposes an upper-bound on the reduction of complexity of multiply-accumulate units. We present a statistical approach to analyze the impact of reduced accumulation precision on deep learning training. Observing that a bad choice for accumulation precision results in loss of information that manifests itself as a reduction in variance in an ensemble of partial sums, we derive a set of equations that relate this variance to the length of accumulation and the minimum number of bits needed for accumulation. We apply our analysis to three benchmark networks: CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet AlexNet. In each case, with accumulation precision set in accordance with our proposed equations, the networks successfully converge to the single precision floating-point baseline. We also show that reducing accumulation precision further degrades the quality of the trained network, proving that our equations produce tight bounds. Overall this analysis enables precise tailoring of computation hardware to the application, yielding area- and power-optimal systems.", "keywords": ["reduced precision floating-point", "partial sum accumulation bit-width", "deep learning", "training"], "authorids": ["ICLR.cc/2019/Conference/Paper603/Authors"], "authors": ["Anonymous"], "TL;DR": "We present an analytical framework to determine accumulation bit-width requirements in all three deep learning training GEMMs and verify the validity and tightness of our method via benchmarking experiments.", "pdf": "/pdf/5ef8a0c338bae21ed79d633c45b39c0d538b196f.pdf", "paperhash": "anonymous|accumulation_bitwidth_scaling_for_ultralow_precision_training_of_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019accumulation,    \ntitle={Accumulation Bit-Width Scaling For Ultra-Low Precision Training Of Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklMjsRqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgfjjC9Ym", "original": "HkgSSB35KX", "number": 604, "cdate": 1538087834204, "ddate": null, "tcdate": 1538087834204, "tmdate": 1538156095422, "tddate": null, "forum": "rJgfjjC9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Backprop with Approximate Activations for Memory-efficient Network Training", "abstract": "With innovations in architecture design, deeper and wider neural network models deliver improved performance on a diverse variety of tasks. But the increased memory footprint of these models presents a challenge during training, when all intermediate layer activations need to be stored for back-propagation. Limited GPU memory forces practitioners to make sub-optimal choices: either train inefficiently with smaller batches of examples; or limit the architecture to have lower depth and width, and fewer layers at higher spatial resolutions. This work introduces an approximation strategy that significantly reduces a network's memory footprint during training, but has negligible effect on training performance and computational expense. During the forward pass, we replace activations with lower-precision approximations immediately after they have been used by subsequent layers, thus freeing up memory. The approximate activations are then used during the backward pass. This approach limits the accumulation of errors across the forward and backward pass---because the forward computation across the network still happens at full precision, and the approximation has a limited effect when computing gradients to a layer's input. Experiments, on CIFAR and ImageNet, show that using our approach with 8- and even 4-bit fixed-point approximations of 32-bit floating-point activations has only a minor effect on training and validation performance, while affording significant savings in memory usage.", "keywords": ["Back-propagation", "Memory Efficient Training", "Approximate Gradients", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper604/Authors"], "authors": ["Anonymous"], "TL;DR": "An algorithm to reduce the amount of memory required for training deep networks, based on an approximation strategy.", "pdf": "/pdf/c87e6aa248b9dfed0b44a3d51f4f55125b5897fe.pdf", "paperhash": "anonymous|backprop_with_approximate_activations_for_memoryefficient_network_training", "_bibtex": "@inproceedings{    \nanonymous2019backprop,    \ntitle={Backprop with Approximate Activations for Memory-efficient Network Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgfjjC9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxMjoRcYm", "original": "rkx8POn5tm", "number": 605, "cdate": 1538087834372, "ddate": null, "tcdate": 1538087834372, "tmdate": 1538156095222, "tddate": null, "forum": "ryxMjoRcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Logically-Constrained Neural Fitted Q-iteration", "abstract": "This paper proposes a method for efficient training of the Q-function for continuous-state Markov Decision Processes (MDP), such that the traces of the resulting policies satisfy a Linear Temporal Logic (LTL) property. The logical property is converted into a limit deterministic Buchi automaton with which a synchronized product MDP is constructed. The control policy is then synthesized by a reinforcement learning algorithm assuming that no prior knowledge is available from the MDP. The proposed method is evaluated in a numerical study to test the quality of the generated control policy and is compared against conventional methods for policy synthesis such as MDP abstraction (Voronoi quantizer) and approximate dynamic programming (fitted value iteration). ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper605/Authors"], "authors": ["Anonymous"], "TL;DR": "As safety is becoming a critical notion in machine learning we believe that this work can act as a foundation for a number of research directions such as safety-aware learning algorithms.", "pdf": "/pdf/cbe9ffb9c5d99d7ede9f4ea9c3bf37f9d08bcc81.pdf", "paperhash": "anonymous|logicallyconstrained_neural_fitted_qiteration", "_bibtex": "@inproceedings{    \nanonymous2019logically-constrained,    \ntitle={Logically-Constrained Neural Fitted Q-iteration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxMjoRcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryemosC9tm", "original": "SyeOOOncFm", "number": 606, "cdate": 1538087834547, "ddate": null, "tcdate": 1538087834547, "tmdate": 1538156095008, "tddate": null, "forum": "ryemosC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Representation-Constrained Autoencoders and an Application to Wireless Positioning", "abstract": "In a number of practical applications that rely on dimensionality reduction, the dataset or measurement process provides valuable side information that can be incorporated when learning low-dimensional embeddings. We propose the inclusion of pairwise representation constraints into autoencoders (AEs) with the goal of promoting application-specific structure. We use synthetic results to show that only a small amount of AE representation constraints are required to substantially improve the local and global neighborhood preserving properties of the learned embeddings. To demonstrate the efficacy of our approach and to illustrate a practical application that naturally provides such representation constraints, we focus on wireless positioning using a recently proposed channel charting framework. We show that representation-constrained AEs recover the global geometry of the learned low-dimensional representations, which enables channel charting to perform approximate positioning without access to global navigation satellite systems or supervised learning methods that rely on extensive measurement campaigns. ", "keywords": ["Autoencoder", "dimensionality reduction", "wireless positioning", "channel charting", "localization"], "authorids": ["ICLR.cc/2019/Conference/Paper606/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose to impose representation constraints to autoencoders in order to localize wireless transmitters in space from their channel state information. ", "pdf": "/pdf/975713b528af3c1f545f5a6dc7548a4280cb502d.pdf", "paperhash": "anonymous|representationconstrained_autoencoders_and_an_application_to_wireless_positioning", "_bibtex": "@inproceedings{    \nanonymous2019representation-constrained,    \ntitle={Representation-Constrained Autoencoders and an Application to Wireless Positioning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryemosC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgXsjA5tQ", "original": "SyxvLWq5K7", "number": 607, "cdate": 1538087834729, "ddate": null, "tcdate": 1538087834729, "tmdate": 1538156094792, "tddate": null, "forum": "HJgXsjA5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the loss landscape of a class of deep neural networks with no bad local valleys", "abstract": "We identify a class of over-parameterized deep neural networks with standard activation functions and cross-entropy loss which provably have no bad local valley, in the sense that from any point in parameter space there exists a continuous path on which the cross-entropy loss is non-increasing and gets arbitrarily close to zero. This implies that these networks have no sub-optimal strict local minima.", "keywords": ["loss landscape", "local minima", "deep neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper607/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fb768423077cb20c450f3b8139b184a1e0ffe109.pdf", "paperhash": "anonymous|on_the_loss_landscape_of_a_class_of_deep_neural_networks_with_no_bad_local_valleys", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the loss landscape of a class of deep neural networks with no bad local valleys},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgXsjA5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1M7soActX", "original": "rJgDwPu5YQ", "number": 608, "cdate": 1538087834903, "ddate": null, "tcdate": 1538087834903, "tmdate": 1538156094588, "tddate": null, "forum": "H1M7soActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects", "abstract": "Understanding the behavior of  stochastic gradient descent (SGD) in the context of deep neural networks has raised lots of concerns recently. Along this line, we theoretically study a general form of gradient based optimization dynamics with unbiased noise, which unifies SGD and standard Langevin dynamics. Through investigating this general optimization dynamics, we analyze the behavior of SGD on escaping from minima and its regularization effects. A novel indicator is derived to characterize the efficiency of escaping from minima through measuring the alignment of noise covariance and the curvature of loss function. Based on this indicator, two conditions are established to show which type of noise structure is superior to isotropic noise in term of escaping efficiency. We further show that the anisotropic noise in SGD satisfies the two conditions, and thus helps to  escape from sharp and poor minima effectively, towards more stable and flat minima that typically generalize well. We verify our understanding through comparing\nthis anisotropic diffusion with full gradient descent plus isotropic diffusion (i.e. Langevin dynamics) and other types of position-dependent noise.", "keywords": ["Stochastic gradient descent", "anisotropic noise", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper608/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide theoretical and empirical analysis on the role of anisotropic noise introduced by stochastic gradient on escaping from minima.", "pdf": "/pdf/9bf0c38e3b6e894e55304589933458a2d48e7419.pdf", "paperhash": "anonymous|the_anisotropic_noise_in_stochastic_gradient_descent_its_behavior_of_escaping_from_minima_and_regularization_effects", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1M7soActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryf7ioRqFX", "original": "SylUa_35tQ", "number": 609, "cdate": 1538087835079, "ddate": null, "tcdate": 1538087835079, "tmdate": 1538156094375, "tddate": null, "forum": "ryf7ioRqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "h-detach: Modifying the LSTM Gradient Towards Better Optimization", "abstract": "Recurrent neural networks are known for their notorious exploding and vanishing gradient problem (EVGP). This problem becomes more evident in tasks where the information needed to correctly solve them exist over long time scales, because EVGP prevents important gradient components from being back-propagated adequately over a large number of steps. We introduce a simple stochastic algorithm h-detach that is specific to LSTM optimization and targeted towards addressing this problem. Specifically, we show that when the LSTM weights are large, the gradient components through the linear path (cell state) in the LSTM computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies (which we show empirically), their suppression can prevent the LSTM from capturing them. Our algorithm prevents the gradients flowing through this path from getting suppressed, thus allowing the LSTM to capture such dependencies better. We show significant convergence and generalization improvements using our algorithm on various benchmark datasets.", "keywords": ["LSTM", "Optimization", "Long term dependencies", "Back-propagation through time."], "authorids": ["ICLR.cc/2019/Conference/Paper609/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple algorithm to improve optimization and handling of long term dependencies in LSTM.", "pdf": "/pdf/01af7265a6e4c3a740e2f810ee927c266c30ad37.pdf", "paperhash": "anonymous|hdetach_modifying_the_lstm_gradient_towards_better_optimization", "_bibtex": "@inproceedings{    \nanonymous2019h-detach:,    \ntitle={h-detach: Modifying the LSTM Gradient Towards Better Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryf7ioRqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rk4Qso0cKm", "original": "HJgGbfk5tQ", "number": 610, "cdate": 1538087835260, "ddate": null, "tcdate": 1538087835260, "tmdate": 1538156094172, "tddate": null, "forum": "rk4Qso0cKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network", "abstract": "We present a new algorithm to train a robust neural network against adversarial attacks. \nOur algorithm is motivated by the following two ideas. First, although recent work has demonstrated that fusing randomness can improve the robustness of neural networks (Liu 2017), we noticed that adding noise blindly to all the layers is not the optimal way to incorporate randomness. \nInstead, we model randomness under the framework of Bayesian Neural Network (BNN) to formally learn the posterior distribution of models in a scalable way. Second, we formulate the mini-max problem in BNN to learn the best model distribution under adversarial attacks, leading to an adversarial-trained Bayesian neural net. Experiment results demonstrate that the proposed algorithm achieves state-of-the-art performance under strong attacks. On CIFAR-10 with VGG network, our model leads to 14% accuracy improvement compared with adversarial training (Madry 2017) and random self-ensemble (Liu, 2017) under PGD attack with 0.035 distortion, and the gap becomes even larger on a subset of ImageNet.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper610/Authors"], "authors": ["Anonymous"], "TL;DR": "We design an adversarial training method to Bayesian neural networks, showing a much stronger defense to white-box adversarial attacks", "pdf": "/pdf/3d4e423ca8a5589a846392c62cd8411e47d2d07a.pdf", "paperhash": "anonymous|advbnn_improved_adversarial_defense_through_robust_bayesian_neural_network", "_bibtex": "@inproceedings{    \nanonymous2019adv-bnn:,    \ntitle={Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rk4Qso0cKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJVmjjR9FX", "original": "Hke3nJsY_7", "number": 611, "cdate": 1538087835438, "ddate": null, "tcdate": 1538087835438, "tmdate": 1538156093966, "tddate": null, "forum": "SJVmjjR9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Bayesian Phylogenetic Inference", "abstract": "Bayesian phylogenetic inference is currently done via Markov chain Monte Carlo with simple mechanisms for proposing new states, which hinders exploration efficiency and often requires long runs to deliver accurate posterior estimates. In this paper we present an alternative approach: a variational framework for Bayesian phylogenetic analysis. We approximate the true posterior using an expressive graphical model for tree distributions, called a subsplit Bayesian network, together with appropriate branch length distributions. We train the variational approximation via stochastic gradient ascent and adopt multi-sample based gradient estimators for different latent variables separately to handle the composite latent space of phylogenetic models. We show that our structured variational approximations are flexible enough to provide comparable posterior estimation to MCMC, while requiring less computation due to a more efficient tree exploration mechanism enabled by variational inference. Moreover, the variational approximations can be readily used for further statistical analysis such as marginal likelihood estimation for model comparison via importance sampling. Experiments on both synthetic data and real data Bayesian phylogenetic inference problems demonstrate the effectiveness and efficiency of our methods.", "keywords": ["Bayesian phylogenetic inference", "Variational inference", "Subsplit Bayesian networks"], "authorids": ["ICLR.cc/2019/Conference/Paper611/Authors"], "authors": ["Anonymous"], "TL;DR": "The first variational Bayes formulation of phylogenetic inference, a challenging inference problem over structures with intertwined discrete and continuous components", "pdf": "/pdf/c8d3f2dac5a707879f9b1014e137a22b8ca1e4a2.pdf", "paperhash": "anonymous|variational_bayesian_phylogenetic_inference", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Bayesian Phylogenetic Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJVmjjR9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlEojAqFm", "original": "BkeNuaeYFQ", "number": 612, "cdate": 1538087835613, "ddate": null, "tcdate": 1538087835613, "tmdate": 1538156093754, "tddate": null, "forum": "rJlEojAqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Relational Forward Models for Multi-Agent Learning", "abstract": "The behavioral dynamics of multi-agent systems have a rich and orderly structure, which can be leveraged to understand these systems, and to improve how artificial agents learn to operate in them. Here we introduce Relational Forward Models (RFM) for multi-agent learning, networks that can learn to make accurate predictions of agents' future behavior in multi-agent environments. Because these models operate on the discrete entities and relations present in the environment, they produce interpretable intermediate representations which offer insights into what drives agents' behavior, and what events mediate the intensity and valence of social interactions. Furthermore, we show that embedding RFM modules inside agents results in faster learning systems compared to non-augmented baselines. \nAs more and more of the autonomous systems we develop and interact with become multi-agent in nature, developing richer analysis tools for characterizing how and why agents make decisions is increasingly necessary. Moreover, developing artificial agents that quickly and safely learn to coordinate with one another, and with humans in shared environments, is crucial.", "keywords": ["multi-agent reinforcement learning", "relational reasoning", "forward models"], "authorids": ["ICLR.cc/2019/Conference/Paper612/Authors"], "authors": ["Anonymous"], "TL;DR": "Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents.", "pdf": "/pdf/8940890d623b8495374e35bfb8d0533e1848ca27.pdf", "paperhash": "anonymous|relational_forward_models_for_multiagent_learning", "_bibtex": "@inproceedings{    \nanonymous2019relational,    \ntitle={Relational Forward Models for Multi-Agent Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlEojAqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgVisRqtX", "original": "HkeMAO2qt7", "number": 613, "cdate": 1538087835791, "ddate": null, "tcdate": 1538087835791, "tmdate": 1538156093545, "tddate": null, "forum": "HJgVisRqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SEGEN: SAMPLE-ENSEMBLE GENETIC EVOLUTIONARY NETWORK MODEL", "abstract": "Deep learning, a rebranding of deep neural network research works, has achieved a remarkable success in recent years. With multiple hidden layers, deep learning models aim at computing the hierarchical feature representations of the observational data. Meanwhile, due to its severe disadvantages in data consumption, computational resources, parameter tuning costs and the lack of result explainability, deep learning has also suffered from lots of criticism. In this paper, we will introduce a new representation learning model, namely \u201cSample-Ensemble Genetic Evolutionary Network\u201d (SEGEN), which can serve as an alternative approach to deep learning models. Instead of building one single deep model, based on a set of sampled sub-instances, SEGEN adopts a genetic-evolutionary learning strategy to build a group of unit models generations by generations. The unit models incorporated in SEGEN can be either traditional machine learning models or the recent deep learning models with a much \u201cnarrower\u201d and \u201cshallower\u201d architecture. The learning results of each instance at the final generation will be effectively combined from each unit model via diffusive propagation and ensemble learning strategies. From the computational perspective, SEGEN requires far less data, fewer computational resources and parameter tuning efforts, but has sound theoretic interpretability of the learning process and results. Extensive experiments have been done on several different real-world benchmark datasets, and the experimental results obtained by SEGEN have demonstrated its advantages over the state-of-the-art representation learning models.", "keywords": ["Genetic Evolutionary Network", "Deep Learning", "Genetic Algorithm", "Ensemble Learning", "Representation Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper613/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a new representation learning model, namely \u201cSample-Ensemble Genetic Evolutionary Network\u201d (SEGEN), which can serve as an alternative approach to deep learning models.", "pdf": "/pdf/72acae32af5730c669efa51298f7d276b3dbc41f.pdf", "paperhash": "anonymous|segen_sampleensemble_genetic_evolutionary_network_model", "_bibtex": "@inproceedings{    \nanonymous2019segen:,    \ntitle={SEGEN: SAMPLE-ENSEMBLE GENETIC EVOLUTIONARY NETWORK MODEL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgVisRqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgEjiRqYX", "original": "SkeW1cicKm", "number": 614, "cdate": 1538087835981, "ddate": null, "tcdate": 1538087835981, "tmdate": 1538156093339, "tddate": null, "forum": "BJgEjiRqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Case for Object Compositionality in Deep Generative Models of Images", "abstract": "Deep generative models seek to recover the process with which the observed data was generated. They may be used to synthesize new samples or to subsequently extract representations. Successful approaches in the domain of images are driven by several core inductive biases. However, a bias to account for the compositional way in which humans structure a visual scene in terms of objects has frequently been overlooked. In this work we propose to structure the generator of a GAN to consider objects and their relations explicitly, and generate images by means of composition. This provides a way to efficiently learn a more accurate generative model of real-world images, and serves as an initial step towards learning corresponding object representations. We evaluate our approach on several multi-object image datasets, and find that the generator learns to identify and disentangle information corresponding to different objects at a representational level. A human study reveals that the resulting generative model is better at generating images that are more faithful to the reference distribution.", "keywords": ["Objects", "Compositionality", "Generative Models", "GAN", "Unsupervised Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper614/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose to structure the generator of a GAN to consider objects and their relations explicitly, and generate images by means of composition", "pdf": "/pdf/f81142574e181abd9de705e70891a6f48d107e8f.pdf", "paperhash": "anonymous|a_case_for_object_compositionality_in_deep_generative_models_of_images", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Case for Object Compositionality in Deep Generative Models of Images},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgEjiRqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygNooCqY7", "original": "rJx6ypU5KQ", "number": 615, "cdate": 1538087836166, "ddate": null, "tcdate": 1538087836166, "tmdate": 1538156093132, "tddate": null, "forum": "SygNooCqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Noise-Tempered Generative Adversarial Networks", "abstract": "We present a novel method to stabilize the training of generative adversarial networks. The training stability is often undermined by the limited and low-dimensional support of the probability density function of the data samples. To address this problem we propose to simultaneously train the generative adversarial networks against different additive noise models, including the noise-free case. The benefits of this approach are that: 1) The case with noise added to both real and generated samples extends the support of the probability density function of the data, while not compromising the exact matching of the original data distribution, and 2) The noise-free case allows the exact matching of the original data distribution. We demonstrate our approach with both fixed additive noise and with learned noise models. We show that our approach results in a stable and well-behaved training of even the original minimax GAN formulation. Moreover, our technique can be incorporated in most modern GAN formulations and leads to a consistent improvement on several common datasets.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper615/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a2ffdb9d36b5f4255844f9b8eeabd48b517c40ef.pdf", "paperhash": "anonymous|noisetempered_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019noise-tempered,    \ntitle={Noise-Tempered Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygNooCqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeVsiAcYm", "original": "B1lwW6yqFQ", "number": 616, "cdate": 1538087836337, "ddate": null, "tcdate": 1538087836337, "tmdate": 1538156092925, "tddate": null, "forum": "SkeVsiAcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative predecessor models for sample-efficient imitation learning", "abstract": "We propose Generative Predecessor Models for Imitation Learning (GPRIL), a novel imitation learning algorithm that matches the state-action distribution to the distribution observed in expert demonstrations, using generative models to reason probabilistically about alternative histories of demonstrated states. We show that this approach allows an agent to learn robust policies using only a small number of expert demonstrations and self-supervised interactions with the environment. We derive this approach from first principles and compare it empirically to a state-of-the-art imitation learning method, showing that it outperforms or matches its performance on two simulated robot manipulation tasks and demonstrate significantly higher sample efficiency by applying the algorithm on a real robot.", "keywords": ["Imitation Learning", "Generative Models", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper616/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1f62e2d91f351ae3d2591098b322ab3315d0f0da.pdf", "paperhash": "anonymous|generative_predecessor_models_for_sampleefficient_imitation_learning", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative predecessor models for sample-efficient imitation learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeVsiAcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkeSiiA5Fm", "original": "HyeNTdj5tQ", "number": 617, "cdate": 1538087836519, "ddate": null, "tcdate": 1538087836519, "tmdate": 1538156092710, "tddate": null, "forum": "rkeSiiA5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution", "abstract": "The ground-breaking performance obtained by deep convolutional neural networks (CNNs) for image processing tasks is inspiring research efforts attempting to extend it for 3D geometric tasks. One of the main challenge in applying CNNs to 3D shape analysis is how to define a natural convolution operator on non-euclidean surfaces. In this paper, we present a method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere. A cascade set of geodesic disk filters rotate on the 2-sphere and collect multi-level spherical patterns to extract non-trivial features for various 3D shape analysis tasks.  We demonstrate theoretically and experimentally that our proposed method has the possibility to bridge the gap between 2D images and 3D shapes with the desired rotation equivariance/invariance, and its effectiveness is evaluated in applications of non-rigid/ rigid shape classification and shape retrieval.", "keywords": ["Spherical Convolution", "Geometric deep learning", "3D shape analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper617/Authors"], "authors": ["Anonymous"], "TL;DR": "A method for applying deep learning to 3D surfaces using their spherical descriptors and alt-az anisotropic convolution on 2-sphere.", "pdf": "/pdf/8bd9f368d4d3dced449df7d2de2270e7d3a24456.pdf", "paperhash": "anonymous|deep_learning_3d_shapes_using_altaz_anisotropic_2sphere_convolution", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Learning 3D Shapes Using Alt-az Anisotropic 2-Sphere Convolution},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeSiiA5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxHii09KQ", "original": "BygMMIt9t7", "number": 618, "cdate": 1538087836697, "ddate": null, "tcdate": 1538087836697, "tmdate": 1538156092498, "tddate": null, "forum": "ryxHii09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "In Your Pace: Learning the Right Example at the Right Time", "abstract": "Training neural networks is traditionally done by sequentially providing random mini-batches sampled uniformly from the entire dataset. In our work, we show that sampling mini-batches non-uniformly can both enhance the speed of learning and improve the final accuracy of the trained network. Specifically, we decompose the problem using the principles of curriculum learning: first, we sort the data by some difficulty measure; second, we sample mini-batches with a gradually increasing level of difficulty. We focus on CNNs trained on image recognition. Initially, we define the difficulty of a training image using transfer learning from some competitive \"teacher\" network trained on the Imagenet database, showing improvement in learning speed and final performance for both small and competitive networks, using the CIFAR-10 and the CIFAR-100 datasets. We then suggest a bootstrap alternative to evaluate the difficulty of points using the same network without relying on a \"teacher\" network, thus increasing the applicability of our suggested method. We compare this approach to a related version of Self-Paced Learning, showing that our method benefits learning while SPL impairs it.", "keywords": ["Curriculum Learning", "Transfer Learning", "Self-Paced Learning", "Image Recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper618/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide a formal definition of curriculum learning for deep neural networks, empirically showing how it can improve learning performance without additional human supervision and in a problem-free manner.", "pdf": "/pdf/1d6fa6ba65f595050d00b53bf8a47edf53fec844.pdf", "paperhash": "anonymous|in_your_pace_learning_the_right_example_at_the_right_time", "_bibtex": "@inproceedings{    \nanonymous2019in,    \ntitle={In Your Pace: Learning the Right Example at the Right Time},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxHii09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gHjoRqYQ", "original": "rkgYkHu9YQ", "number": 619, "cdate": 1538087836891, "ddate": null, "tcdate": 1538087836891, "tmdate": 1538156092287, "tddate": null, "forum": "B1gHjoRqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Efficient and Margin-Approaching Zero-Confidence Adversarial Attack", "abstract": "There are two major paradigms of white-box adversarial attacks that attempt to impose input perturbations.  The first paradigm, called the fix-perturbation attack, crafts adversarial samples within a given perturbation level.  The second paradigm, called the zero-confidence attack, finds the smallest perturbation needed to cause misclassification, also known as the margin of an input feature.  While the former paradigm is well-resolved, the latter is not.  Existing zero-confidence attacks either introduce significant approximation errors, or are too time-consuming.  We therefore propose MarginAttack, a zero-confidence attack framework that is able to compute the margin with improved accuracy and efficiency.  Our experiments show that MarginAttack is able to compute a smaller margin than the state-of-the-art zero-confidence attacks, and matches the state-of-the-art fix-perturbation attacks.  In addition, it runs significantly faster than the Carlini-Wagner attack, currently the most accurate zero-confidence attack algorithm.", "keywords": ["adversarial attack", "zero-confidence attack"], "authorids": ["ICLR.cc/2019/Conference/Paper619/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces MarginAttack, a stronger and faster zero-confidence adversarial attack.", "pdf": "/pdf/314981c3fbefb5652b34535e82efe8f2258bcfee.pdf", "paperhash": "anonymous|an_efficient_and_marginapproaching_zeroconfidence_adversarial_attack", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Efficient and Margin-Approaching Zero-Confidence Adversarial Attack},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gHjoRqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxHsjRqFQ", "original": "r1e-inoqF7", "number": 620, "cdate": 1538087837075, "ddate": null, "tcdate": 1538087837075, "tmdate": 1538156092084, "tddate": null, "forum": "rJxHsjRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hyperbolic Attention Networks", "abstract": "Recent approaches have successfully demonstrated the benefits of learning the parameters of shallow networks in hyperbolic space. We extend this line of work by imposing hyperbolic geometry on the embeddings used to compute the ubiquitous attention mechanisms for different neural networks architectures. By only changing the geometry of embedding of object representations, we can use the embedding space more efficiently without increasing the number of parameters of the model. Mainly as the number of objects grows exponentially for any semantic distance from the query, hyperbolic geometry  --as opposed to Euclidean geometry-- can encode those objects without having any interference. Our method shows improvements in generalization on neural machine translation on WMT'14 (English to German), learning on graphs (both on synthetic and real-world graph tasks) and visual question answering (CLEVR) tasks while keeping the neural representations compact.", "keywords": ["Hyperbolic Geometry", "Attention Methods", "Reasoning on Graphs", "Relation Learning", "Scale Free Graphs", "Transformers", "Power Law"], "authorids": ["ICLR.cc/2019/Conference/Paper620/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose to incorporate inductive biases and operations coming from hyperbolic geometry to improve the attention mechanism of the neural networks.", "pdf": "/pdf/4580b1ae4769e548fcd92ffe02f9d749505e52e1.pdf", "paperhash": "anonymous|hyperbolic_attention_networks", "_bibtex": "@inproceedings{    \nanonymous2019hyperbolic,    \ntitle={Hyperbolic Attention Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxHsjRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ersoRqtm", "original": "BkgYV4h5YX", "number": 621, "cdate": 1538087837262, "ddate": null, "tcdate": 1538087837262, "tmdate": 1538156091881, "tddate": null, "forum": "H1ersoRqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Structured Neural Summarization", "abstract": "Summarization of long sequences into a concise statement is a core problem in natural language processing, requiring non-trivial understanding of the input. Based on the promising results of graph neural networks on highly structured data, we develop a framework to extend existing sequence encoders with a graph component that can reason about long-distance relationships in weakly structured data such as text. In an extensive evaluation, we show that the resulting hybrid sequence-graph models outperform both pure sequence models as well as pure graph models on a range of summarization tasks.", "keywords": ["Summarization", "Graphs", "Source Code"], "authorids": ["ICLR.cc/2019/Conference/Paper621/Authors"], "authors": ["Anonymous"], "TL;DR": "One simple trick to improve sequence models: Compose them with a graph model", "pdf": "/pdf/b136623b7fb7ba2272cf95b85c854fb4e245efec.pdf", "paperhash": "anonymous|structured_neural_summarization", "_bibtex": "@inproceedings{    \nanonymous2019structured,    \ntitle={Structured Neural Summarization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ersoRqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xBioR5KX", "original": "rygbLZewtm", "number": 622, "cdate": 1538087837439, "ddate": null, "tcdate": 1538087837439, "tmdate": 1538156091672, "tddate": null, "forum": "S1xBioR5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization", "abstract": "Modern deep neural networks are highly overparameterized, and often of huge sizes. A number of post-training model compression techniques, such as distillation, pruning and quantization, can reduce the size of network parameters by a substantial fraction with little loss in performance. However, training a small network of the post-compression size de novo typically fails to reach the same level of accuracy achieved by compression of a large network, leading to a widely-held belief that gross overparameterization is essential to effective learning. In this work, we argue that this is not necessarily true.  We describe a dynamic sparse reparameterization technique that closed the performance gap between a model compressed by pruning and a model of the post-compression size trained de novo. We applied our method to training deep residual networks and showed that it outperformed existing static reparameterization techniques, yielding the best accuracy for a given parameter budget for training. Compared to other dynamic reparameterization methods that reallocate non-zero parameters during training, our approach broke free from a few key limitations and achieved much better performance at lower computational cost. Our method is not only of practical value for training under stringent memory constraints, but also potentially informative to theoretical understanding of generalization properties of overparameterized deep neural networks.  \n", "keywords": ["sparse", "reparameterization", "overparameterization", "convolutional neural network", "training", "compression", "pruning"], "authorids": ["ICLR.cc/2019/Conference/Paper622/Authors"], "authors": ["Anonymous"], "TL;DR": "We describe a dynamic sparse reparameterization technique that allow training of a small sparse network to generalize on par with, or better than, a full-sized dense model compressed to the same size.  ", "pdf": "/pdf/49cd6c44b5a414f8c5535a3f863a55eb6ce509c4.pdf", "paperhash": "anonymous|parameter_efficient_training_of_deep_convolutional_neural_networks_by_dynamic_sparse_reparameterization", "_bibtex": "@inproceedings{    \nanonymous2019parameter,    \ntitle={Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xBioR5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xLsjAqtX", "original": "Sygz4Ih5FX", "number": 623, "cdate": 1538087837680, "ddate": null, "tcdate": 1538087837680, "tmdate": 1538156091419, "tddate": null, "forum": "H1xLsjAqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Robust Text Classifier on Test-Time Budgets", "abstract": "In this paper, we design a generic framework for learning a robust text classification model that achieves accuracy comparable to standard full models under test-time\nbudget constraints. We take a different approach from existing methods and learn to dynamically delete a large fraction of unimportant words by a low-complexity selector such that the high-complexity classifier only needs to process a small fraction of important words. In addition, we propose a new data aggregation method to train the classifier, allowing it to make accurate predictions even on fragmented sequence of words. Our end-to-end method achieves state-of-the-art performance while its computational complexity scales linearly with the small fraction of important words in the whole corpus. Besides, a single deep neural network classifier trained by our framework can be dynamically tuned to different budget levels at inference time.", "keywords": ["Data Aggregation", "Budget Learning", "Speed  Up", "Faster Inference", "Robust Classifier"], "authorids": ["ICLR.cc/2019/Conference/Paper623/Authors"], "authors": ["Anonymous"], "TL;DR": "Modular framework for document classification and data aggregation technique for making the framework robust to various distortion, and noise and focus only on the important words. ", "pdf": "/pdf/28ed4fdd0e03e6a6964bc29ce68b2c644a8aa4ff.pdf", "paperhash": "anonymous|robust_text_classifier_on_testtime_budgets", "_bibtex": "@inproceedings{    \nanonymous2019robust,    \ntitle={Robust Text Classifier on Test-Time Budgets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xLsjAqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1l8iiA9tQ", "original": "r1xm69dqKQ", "number": 624, "cdate": 1538087837857, "ddate": null, "tcdate": 1538087837857, "tmdate": 1538156091212, "tddate": null, "forum": "B1l8iiA9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Backdrop: Stochastic Backpropagation", "abstract": "We introduce backdrop, a flexible and simple-to-implement method, intuitively described as dropout acting only along the backpropagation pipeline. Backdrop is implemented via one or more masking layers which are inserted at specific points along the network. Each backdrop masking layer acts as the identity in the forward pass, but randomly masks parts of the backward gradient propagation.  Intuitively, inserting a backdrop layer after any  convolutional layer leads to stochastic  gradients corresponding to features of that scale.  Therefore, backdrop is well suited for problems in which the data have a multi-scale, hierarchical structure. Backdrop can also be applied to problems with non-decomposable loss functions where standard SGD methods are not well suited. We perform a number of experiments and demonstrate that backdrop leads to significant improvements in generalization.", "keywords": ["stochastic optimization", "multi-scale data analysis", "non-decomposable loss", "generalization", "one-shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper624/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce backdrop, intuitively described as dropout acting on the backpropagation pipeline and find significant improvements in generalization for problems with non-decomposable losses and problems with multi-scale, hierarchical data structure.", "pdf": "/pdf/83dfc0524fa50888ad55198adbd0377e3f184130.pdf", "paperhash": "anonymous|backdrop_stochastic_backpropagation", "_bibtex": "@inproceedings{    \nanonymous2019backdrop:,    \ntitle={Backdrop: Stochastic Backpropagation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l8iiA9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gUsoR9YX", "original": "SJluewrKYX", "number": 625, "cdate": 1538087838044, "ddate": null, "tcdate": 1538087838044, "tmdate": 1538156091005, "tddate": null, "forum": "S1gUsoR9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multilingual Neural Machine Translation with Knowledge Distillation", "abstract": "Multilingual machine translation, which translates multiple languages with a single model, has attracted much attention due to its efficiency of offline training and online serving. However, traditional multilingual translation usually yields inferior accuracy compared with the counterpart using individual models for each language pair, due to language diversity and model capacity limitations. In this paper, we propose a distillation-based approach to boost the accuracy of multilingual machine translation. Specifically, individual models are first trained and regarded as teachers, and then the multilingual model is trained to fit the training data and match the outputs of individual models simultaneously through knowledge distillation. Experiments on IWSLT, WMT and Ted talk translation datasets demonstrate the effectiveness of our method. Particularly, we show that one model is enough to handle multiple languages (up to 44 languages in our experiment), with comparable or even better accuracy than individual models.", "keywords": ["NMT", "Multilingual NMT", "Knowledge Distillation"], "authorids": ["ICLR.cc/2019/Conference/Paper625/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed a knowledge distillation based method to boost the accuracy of multilingual neural machine translation.", "pdf": "/pdf/0d043f50aded196d6ba6666876676ceef3575520.pdf", "paperhash": "anonymous|multilingual_neural_machine_translation_with_knowledge_distillation", "_bibtex": "@inproceedings{    \nanonymous2019multilingual,    \ntitle={Multilingual Neural Machine Translation with Knowledge Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gUsoR9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkg8jjC9KQ", "original": "rklZBDq9FX", "number": 626, "cdate": 1538087838226, "ddate": null, "tcdate": 1538087838226, "tmdate": 1538156090796, "tddate": null, "forum": "Bkg8jjC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimistic mirror descent in saddle-point problems: Going the extra(-gradient) mile", "abstract": "Owing to their connection with generative adversarial networks (GANs), saddle-point problems have recently attracted considerable interest in machine learning and beyond. By necessity, most theoretical guarantees revolve around convex-concave (or even linear) problems; however, making theoretical inroads towards efficient GAN training depends crucially on moving beyond this classic framework. To make piecemeal progress along these lines, we analyze the behavior of mirror descent (MD) in a class of non-monotone problems whose solutions coincide with those of a naturally associated variational inequality \u2013 a property which we call coherence. We first show that ordinary, \u201cvanilla\u201d MD converges under a strict version of this condition, but not otherwise; in particular, it may fail to converge even in bilinear models with a unique solution. We then show that this deficiency is mitigated by optimism: by taking an \u201cextra-gradient\u201d step, optimistic mirror descent (OMD) converges in all coherent problems. Our analysis generalizes and extends the results of Daskalakis et al. [2018] for optimistic gradient descent (OGD) in bilinear problems, and makes concrete headway for provable convergence beyond convex-concave games. We also provide stochastic analogues of these results, and we validate our analysis by numerical experiments in a wide array of GAN models (including Gaussian mixture models, and the CelebA and CIFAR-10 datasets).", "keywords": ["Mirror descent", "extra-gradient", "generative adversarial networks", "saddle-point problems"], "authorids": ["ICLR.cc/2019/Conference/Paper626/Authors"], "authors": ["Anonymous"], "TL;DR": "We show how the inclusion of an extra-gradient step in first-order GAN training methods can improve stability and lead to improved convergence results.", "pdf": "/pdf/75df41a037df40feb73bacc1de9e2e3ee2393315.pdf", "paperhash": "anonymous|optimistic_mirror_descent_in_saddlepoint_problems_going_the_extragradient_mile", "_bibtex": "@inproceedings{    \nanonymous2019optimistic,    \ntitle={Optimistic mirror descent in saddle-point problems: Going the extra(-gradient) mile},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg8jjC9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkG8sjR5Km", "original": "SJxCd9n9Y7", "number": 627, "cdate": 1538087838405, "ddate": null, "tcdate": 1538087838405, "tmdate": 1538156090582, "tddate": null, "forum": "BkG8sjR5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Emergent Coordination Through Competition", "abstract": "We study the emergence of cooperative behaviors in reinforcement learning agents by introducing a challenging competitive multi-agent soccer environment with continuous simulated physics. We demonstrate that decentralized, population-based training with co-play can lead to a progression in agents' behaviors: from random, to simple ball chasing, and finally showing evidence of cooperation. Our study highlights several of the challenges encountered in large scale multi-agent training in continuous control. In particular, we demonstrate that the automatic optimization of simple shaping rewards, not themselves conducive to co-operative behavior, can lead to long-horizon team behavior. We further apply an evaluation scheme, grounded by game theoretic principals, that can assess agent performance in the absence of pre-defined evaluation tasks or human baselines.", "keywords": ["Multi-agent learning", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper627/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a new MuJoCo soccer environment for continuous multi-agent reinforcement learning research, and show that population-based training of independent reinforcement learners can learn cooperative behaviors", "pdf": "/pdf/3234ab605fb82608e18f8f9d735afca083c0cb51.pdf", "paperhash": "anonymous|emergent_coordination_through_competition", "_bibtex": "@inproceedings{    \nanonymous2019emergent,    \ntitle={Emergent Coordination Through Competition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkG8sjR5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxDjjCqtQ", "original": "Bkl20q3qtm", "number": 628, "cdate": 1538087838586, "ddate": null, "tcdate": 1538087838586, "tmdate": 1538156090372, "tddate": null, "forum": "ryxDjjCqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deconfounding Reinforcement Learning", "abstract": "In this paper, we propose a general formulation to cope with a family of reinforcement learning tasks in which confounder (i.e., a factor affecting both actions and rewards) exists in dynamic environments. Based on the proposed approach, we extend two representatives of reinforcement learning algorithms: Q-learning and Actor-Critic Methods, to their deconfounding variants. Due to lack of datasets in this direction, a benchmark is developed for deconfounding reinforcement learning algorithms by revising OpenAI Gym and MNIST. We demonstrate that the proposed algorithms are superior to traditional reinforcement learning algorithms in confounding environments. To the best of our knowledge, this is the first time that confounders are taken into consideration for addressing full reinforcement learning problems.", "keywords": ["confounder", "causal inference", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper628/Authors"], "authors": ["Anonymous"], "TL;DR": "This is the first attempt to build a bridge between confounding and the full reinforcement learning problem.", "pdf": "/pdf/78aa211cc4293eb2428a192e2f7c187861f4c8a2.pdf", "paperhash": "anonymous|deconfounding_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019deconfounding,    \ntitle={Deconfounding Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxDjjCqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeDojRcYQ", "original": "r1xmilPBKQ", "number": 629, "cdate": 1538087838758, "ddate": null, "tcdate": 1538087838758, "tmdate": 1538156090163, "tddate": null, "forum": "ByeDojRcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "COLLABORATIVE MULTIAGENT REINFORCEMENT LEARNING  IN HOMOGENEOUS SWARMS", "abstract": "A deep reinforcement learning solution is developed for a collaborative multiagent system. Individual agents choose actions in response to the state of the environment, their own state, and possibly partial information about the state of other agents. Actions are chosen to maximize a collaborative long term discounted reward that encompasses the individual rewards collected by each agent. The paper focuses on developing a scalable approach that applies to large swarms of homogeneous agents. This is accomplished by forcing the policies of all agents to be the same resulting in a constrained formulation in which the experiences of each agent inform the learning process of the whole team, thereby enhancing the sample efficiency of the learning process. A projected coordinate policy gradient descent algorithm is derived to solve the constrained reinforcement learning problem. Experimental evaluations in collaborative navigation, a multi-predator-multi-prey game, and a multiagent survival game show marked improvements relative to methods that do not exploit the policy equivalence that naturally arises in homogeneous swarms.", "keywords": ["Reinforcement Learning", "Multi Agent", "policy gradient"], "authorids": ["ICLR.cc/2019/Conference/Paper629/Authors"], "authors": ["Anonymous"], "TL;DR": "Novel policy gradient for multiagent systems via distributed learning. ", "pdf": "/pdf/94cb941dfda2901eb8ef525105baa41ea87accdb.pdf", "paperhash": "anonymous|collaborative_multiagent_reinforcement_learning_in_homogeneous_swarms", "_bibtex": "@inproceedings{    \nanonymous2019collaborative,    \ntitle={COLLABORATIVE MULTIAGENT REINFORCEMENT LEARNING  IN HOMOGENEOUS SWARMS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeDojRcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1fDssA5Y7", "original": "HJxdQ9icFQ", "number": 630, "cdate": 1538087838961, "ddate": null, "tcdate": 1538087838961, "tmdate": 1538156089956, "tddate": null, "forum": "S1fDssA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond", "abstract": "In this paper, we adopt distributionally robust optimization (DRO) in hope to achieve a better generalization in deep learning tasks. We establish the generalization guarantees and analyze the localized Rademacher complexity for DRO, and conduct experiments to show that DRO obtains a better performance. We reveal the profound connection between SGD and DRO, i.e., selecting a batch can be viewed as choosing a distribution over the training set. From this perspective, we prove that SGD is prone to escape from bad stationary points and small batch SGD outperforms large batch SGD. We give an upper bound for the robust loss when SGD converges and keeps stable. We propose a novel Weighted SGD (WSGD) algorithm framework, which assigns high-variance weights to the data of the current batch. We devise a practical implement of WSGD that can directly optimize the robust loss. We test our algorithm on CIFAR-10 and CIFAR-100, and WSGD achieves significant improvements over the conventional SGD.", "keywords": ["distributionally robust optimization", "deep learning", "SGD", "learning theory"], "authorids": ["ICLR.cc/2019/Conference/Paper630/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f3364a6e26de561af37e33105834b838de13e386.pdf", "paperhash": "anonymous|distributionally_robust_optimization_leads_to_better_generalization_on_sgd_and_beyond", "_bibtex": "@inproceedings{    \nanonymous2019distributionally,    \ntitle={Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1fDssA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryfDoiR5Ym", "original": "ByeWKin5K7", "number": 631, "cdate": 1538087839146, "ddate": null, "tcdate": 1538087839146, "tmdate": 1538156089737, "tddate": null, "forum": "ryfDoiR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fatty and Skinny: A Joint Training Method of Watermark Encoder and Decoder", "abstract": "Watermarks have been used for various purposes. Recently, researchers started to look into using them for deep neural networks. Some works try to hide attack triggers on their adversarial samples when attacking neural networks and others want to watermark neural networks to prove their ownership against plagiarism. Implanting a backdoor watermark module into a neural network is getting more attention from the community. In this paper, we present a general purpose encoder-decoder joint training method, inspired by generative adversarial networks (GANs). Unlike GANs, however, our encoder and decoder neural networks cooperate to find the best watermarking scheme given data samples. In other words, we do not design any new watermarking strategy but our proposed two neural networks will find the best suited method on their own. After being trained, the decoder can be implanted into other neural networks to attack or protect them (see Appendix for their use cases and real implementations). To this end, the decoder should be very tiny in order not to incur any overhead when attached to other neural networks but at the same time provide very high decoding success rates, which is very challenging. Our joint training method successfully solves the problem and in our experiments maintain almost 100\\% encoding-decoding success rates for multiple datasets with very little modifications on data samples to hide watermarks. We also present several real-world use cases in Appendix.", "keywords": ["Adversarial Machine Learning", "Watermarking", "Generative Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper631/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel watermark encoder-decoder neural networks. They perform a cooperative game to define their own watermarking scheme. People do not need to design watermarking methods any more.", "pdf": "/pdf/599b84fb70332752b375b408dd50c91869f727e9.pdf", "paperhash": "anonymous|fatty_and_skinny_a_joint_training_method_of_watermark_encoder_and_decoder", "_bibtex": "@inproceedings{    \nanonymous2019fatty,    \ntitle={Fatty and Skinny: A Joint Training Method of Watermark Encoder and Decoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryfDoiR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkNDsiC9KQ", "original": "H1lm8tCKYm", "number": 632, "cdate": 1538087839326, "ddate": null, "tcdate": 1538087839326, "tmdate": 1538156089530, "tddate": null, "forum": "HkNDsiC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Unsupervised Learning Rules", "abstract": "A major goal of unsupervised learning is to discover data representations that are useful for subsequent tasks, without access to supervised labels during training. Typically, this goal is approached by minimizing a surrogate objective, such as the negative log likelihood of a generative model, with the hope that representations useful for subsequent tasks will arise incidentally. In this work, we propose instead to directly target a later desired task by meta-learning an unsupervised learning rule, which leads to representations useful for that task. Here, our desired task (meta-objective) is the performance of the representation on semi-supervised classification, and we meta-learn an algorithm -- an unsupervised weight update rule -- that produces representations that perform well under this meta-objective.  Additionally, we constrain our unsupervised update rule to a be a biologically-motivated, neuron-local function, which enables it to generalize to novel neural network architectures. We show that the meta-learned update rule produces useful features and sometimes outperforms existing unsupervised learning techniques. We further show that the meta-learned unsupervised update rule generalizes to train networks with different widths, depths, and nonlinearities. It also generalizes to train on data with randomly permuted input dimensions and even generalizes from image datasets to a text task.", "keywords": ["Meta-learning", "unsupervised learning", "representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper632/Authors"], "authors": ["Anonymous"], "TL;DR": "We learn an unsupervised learning algorithm that produces useful representations from a set of supervised tasks. At test-time, we apply this algorithm to new tasks without any supervision and show performance comparable to a VAE.", "pdf": "/pdf/a6a8b6fc5f578a1c5f456b5792ccd68d8652284c.pdf", "paperhash": "anonymous|learning_unsupervised_learning_rules", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Unsupervised Learning Rules},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkNDsiC9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyldojC9t7", "original": "HJlC5oncYQ", "number": 633, "cdate": 1538087839561, "ddate": null, "tcdate": 1538087839561, "tmdate": 1538156089319, "tddate": null, "forum": "HyldojC9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "D2KE: From Distance to Kernel and Embedding via Random Features For Structured Inputs", "abstract": "We present a new methodology that constructs a family of \\emph{positive definite kernels} from any given dissimilarity measure on structured inputs whose elements are either real-valued time series or discrete structures such as strings, histograms, and graphs. \nOur approach, which we call D2KE (from Distance to Kernel and Embedding), draws from the literature of Random Features.\nHowever, instead of deriving random feature maps from a user-defined kernel to approximate kernel machines, we build a kernel from a random feature map, that we specify given the distance measure. \nWe further propose use of a finite number of random objects to produce a random feature embedding of each instance.\nWe provide a theoretical analysis showing that D2KE enjoys better generalizability than universal Nearest-Neighbor estimates. \nOn one hand, D2KE subsumes the widely-used \\emph{representative-set method} as a special case, and relates to the well-known \\emph{distance substitution kernel} in a limiting case. \nOn the other hand, D2KE generalizes existing \\emph{Random Features methods} applicable only to vector input representations to complex structured inputs of variable sizes. \nWe conduct classification experiments over such disparate domains as time series, strings, and histograms (for texts and images), for which our proposed framework compares favorably to existing distance-based learning methods in terms of both testing accuracy and computational time.", "keywords": ["Distance Kernel", "Embeddings", "Random Features", "Structured Inputs"], "authorids": ["ICLR.cc/2019/Conference/Paper633/Authors"], "authors": ["Anonymous"], "TL;DR": "From Distance to Kernel and Embedding via Random Features For Structured Inputs", "pdf": "/pdf/feda529a5de3ef84a817cc087bb9eaf77aaddca9.pdf", "paperhash": "anonymous|d2ke_from_distance_to_kernel_and_embedding_via_random_features_for_structured_inputs", "_bibtex": "@inproceedings{    \nanonymous2019d2ke:,    \ntitle={D2KE: From Distance to Kernel and Embedding via Random Features For Structured Inputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyldojC9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1e_ssC5F7", "original": "rklcE4nctQ", "number": 634, "cdate": 1538087839738, "ddate": null, "tcdate": 1538087839738, "tmdate": 1538156089115, "tddate": null, "forum": "S1e_ssC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hyper-Regularization: An Adaptive Choice for the Learning Rate in Gradient Descent", "abstract": "We present a novel approach for adaptively selecting the learning rate in gradient descent methods.  Specifically, we impose a regularization term on the learning rate via a generalized distance, and cast the joint updating process of the parameter and the learning rate into a maxmin problem. Some existing schemes such as AdaGrad (diagonal version) and WNGrad can be rederived from our approach. Based on our approach, the updating rules for the learning rate do not rely on the smoothness constant of optimization problems and are robust to the initial learning rate. We theoretically analyze our approach in full batch and online learning settings, which achieves comparable performances with other first-order gradient-based algorithms in terms of accuracy as well as convergence rate.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper634/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c669a3cf07fa4538741f35d0158a0c1c3453966d.pdf", "paperhash": "anonymous|hyperregularization_an_adaptive_choice_for_the_learning_rate_in_gradient_descent", "_bibtex": "@inproceedings{    \nanonymous2019hyper-regularization:,    \ntitle={Hyper-Regularization: An Adaptive Choice for the Learning Rate in Gradient Descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1e_ssC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxusjRctQ", "original": "rkgxsDccYQ", "number": 635, "cdate": 1538087839916, "ddate": null, "tcdate": 1538087839916, "tmdate": 1538156088902, "tddate": null, "forum": "rkxusjRctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning models for visual 3D localization with implicit mapping", "abstract": "We consider learning based methods for visual localization that do not require the construction of explicit maps in the form of point clouds or voxels. The goal is to learn an implicit representation of the environment at a higher, more abstract level, for instance that of objects. We propose to use a generative approach based on Generative Query Networks (GQNs, Eslami et al. 2018), asking the following questions: 1) Can GQN capture more complex scenes than those it was originally demonstrated on? 2) Can GQN be used for localization in those scenes? To study this approach we consider procedurally generated Minecraft worlds, for which we can generate images of complex 3D scenes along with camera pose coordinates. We first show that GQNs, enhanced with a novel attention mechanism can capture the structure of 3D scenes in Minecraft, as evidenced by their samples. We then apply the models to the localization problem, comparing the results to a discriminative baseline, and comparing the ways each approach captures the task uncertainty. ", "keywords": ["generative learning", "generative models", "generative query networks", "camera re-localization"], "authorids": ["ICLR.cc/2019/Conference/Paper635/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a generative approach based on Generative Query Networks + attention for localization with implicit mapping, and compare to a discriminative baseline with a similar architecture.", "pdf": "/pdf/942b54ce0e34a778b1b7dde80741a4e746235c32.pdf", "paperhash": "anonymous|learning_models_for_visual_3d_localization_with_implicit_mapping", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning models for visual 3D localization with implicit mapping},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxusjRctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxOoiAcYX", "original": "rJgBCqn5Km", "number": 636, "cdate": 1538087840103, "ddate": null, "tcdate": 1538087840103, "tmdate": 1538156088693, "tddate": null, "forum": "HkxOoiAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Estimating Information Flow in DNNs", "abstract": "We study the evolution of internal representations during deep neural network (DNN) training, aiming to demystify the compression aspect of the information bottleneck theory. The theory suggests that DNN training comprises a rapid fitting phase followed by a slower compression phase, in which the mutual information I(X;T) between the input X and internal representations T decreases. Several papers observe compression of estimated mutual information on different DNN models, but the true I(X;T) over these networks is provably either constant (discrete X) or infinite (continuous X). This work explains the discrepancy between theory and experiments, and clarifies what was actually measured by these past works. To this end, we introduce an auxiliary (noisy) DNN framework for which I(X;T) is a meaningful quantity that depends on the network's parameters. This noisy framework is shown to be a good proxy for the original (deterministic) DNN both in terms of performance and the learned representations. We then develop a rigorous estimator for I(X;T) in noisy DNNs and observe compression in various models. By relating I(X;T) in the noisy DNN to an information-theoretic communication problem, we show that compression is driven by the progressive clustering of hidden representations of inputs from the same class. Several methods to directly monitor clustering of hidden representations, both in noisy and deterministic DNNs, are used to show that meaningful clusters form in the T space. Finally, we return to the estimator of I(X;T) employed in past works, and demonstrate that while it fails to capture the true (vacuous) mutual information, it does serve as a measure for clustering. This clarifies the past observations of compression and isolates the geometric clustering of hidden representations as the true phenomenon of interest.", "keywords": ["information theory", "representation learning", "deep learning", "differential entropy estimation"], "authorids": ["ICLR.cc/2019/Conference/Paper636/Authors"], "authors": ["Anonymous"], "TL;DR": "Deterministic deep neural networks do not discard information, but they do cluster their inputs.", "pdf": "/pdf/b464fe0c5a7dc9708734452dcd4e16e8a479cd48.pdf", "paperhash": "anonymous|estimating_information_flow_in_dnns", "_bibtex": "@inproceedings{    \nanonymous2019estimating,    \ntitle={Estimating Information Flow in DNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxOoiAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyfdsjA9FX", "original": "S1lxkb8qFQ", "number": 637, "cdate": 1538087840280, "ddate": null, "tcdate": 1538087840280, "tmdate": 1538156088485, "tddate": null, "forum": "SyfdsjA9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Live Face De-Identification in Video", "abstract": "We propose a method for face de-identification that enables fully automatic video modification at high frame rates. The goal is to maximally decorrelate the identity, while having the perception (pose, illumination and expression) fixed. We achieve this by a novel feed forward encoder-decoder network architecture that is conditioned on the high-level representation of a person's facial image. The network is global, in the sense that it does not need to be retrained for a given video or for a given identity, and it creates natural-looking image sequences with little distortion in time. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper637/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4cc351e70bad5204562e2b310718dcebdb286b42.pdf", "paperhash": "anonymous|live_face_deidentification_in_video", "_bibtex": "@inproceedings{    \nanonymous2019live,    \ntitle={Live Face De-Identification in Video},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyfdsjA9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJeOioA9Y7", "original": "rkggZhjFFX", "number": 638, "cdate": 1538087840459, "ddate": null, "tcdate": 1538087840459, "tmdate": 1538156088280, "tddate": null, "forum": "BJeOioA9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Knowledge Flow: Improve Upon Your Teachers", "abstract": "A zoo of deep nets is available these days for almost any given task, and it is increasingly unclear which net to start with when addressing a new task, or which net to use as an initialization for fine-tuning a new model. To address this issue, in this paper, we develop knowledge flow which moves \u2018knowledge\u2019 from multiple deep nets, referred to as teachers, to a new deep net model, called the student. The structure of the teachers and the student can differ arbitrarily and they can be trained on entirely different tasks with different output spaces too. Upon training with knowledge flow the student is independent of the teachers. We demonstrate our approach on a variety of supervised and reinforcement learning tasks, outperforming fine-tuning and other \u2018knowledge exchange\u2019 methods.\n\n", "keywords": ["Transfer Learning", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper638/Authors"], "authors": ["Anonymous"], "TL;DR": "\u2018Knowledge Flow\u2019 trains a deep net (student) by injecting information from multiple nets (teachers). The student is independent upon training and performs very well on learned tasks irrespective of the setting (reinforcement or supervised learning).", "pdf": "/pdf/d0cee001ca105b4a7b7f957058a07b409945125f.pdf", "paperhash": "anonymous|knowledge_flow_improve_upon_your_teachers", "_bibtex": "@inproceedings{    \nanonymous2019knowledge,    \ntitle={Knowledge Flow: Improve Upon Your Teachers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeOioA9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SylKoo0cKm", "original": "S1gWp3hctQ", "number": 639, "cdate": 1538087840638, "ddate": null, "tcdate": 1538087840638, "tmdate": 1538156088076, "tddate": null, "forum": "SylKoo0cKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How Important is a Neuron", "abstract": "The problem of attributing a deep network\u2019s prediction to its input/base features is\nwell-studied (cf. Simonyan et al. (2013)). We introduce the notion of conductance\nto extend the notion of attribution to understanding the importance of hidden units.\nInformally, the conductance of a hidden unit of a deep network is the flow of attribution\nvia this hidden unit. We can use conductance to understand the importance of\na hidden unit to the prediction for a specific input, or over a set of inputs. We justify\nconductance in multiple ways via a qualitative comparison with other methods,\nvia some axiomatic results, and via an empirical evaluation based on a feature\nselection task. The empirical evaluations are done using the Inception network\nover ImageNet data, and a convolutinal network over text data. In both cases, we\ndemonstrate the effectiveness of conductance in identifying interesting insights\nabout the internal workings of these networks.", "keywords": ["attribution", "saliency", "influence"], "authorids": ["ICLR.cc/2019/Conference/Paper639/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cfd6ca4c1ba4465b2de4216a17b7a76170171971.pdf", "paperhash": "anonymous|how_important_is_a_neuron", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How Important is a Neuron},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SylKoo0cKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyxtso0qtX", "original": "Hygm0zn9K7", "number": 640, "cdate": 1538087840806, "ddate": null, "tcdate": 1538087840806, "tmdate": 1538156087865, "tddate": null, "forum": "Hyxtso0qtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Exploration Strategy for Self-Supervised Imitation Learning", "abstract": "We present an adversarial exploration strategy, a simple yet effective imitation learning scheme that incentivizes exploration of an environment without any extrinsic reward or human demonstration. Our framework consists of a deep reinforcement learning (DRL) agent and an inverse dynamics model contesting with each other. The former collects training samples for the latter, and its objective is to maximize the error of the latter. The latter is trained with samples collected by the former, and generates rewards for the former when it fails to predict the actual action taken by the former. In such a competitive setting, the DRL agent learns to generate samples that the inverse dynamics model fails to predict correctly, and the inverse dynamics model learns to adapt to the challenging samples. We further propose a reward structure that ensures the DRL agent collects only moderately hard samples and not overly hard ones that prevent the inverse model from imitating effectively. We evaluate the effectiveness of our method on several OpenAI gym robotic arm and hand manipulation tasks against a number of baseline models. Experimental results show that our method is comparable to that directly trained with expert demonstrations, and superior to the other baselines even without any human priors.", "keywords": ["adversarial exploration", "self-supervised", "imitation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper640/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple yet effective imitation learning scheme that incentivizes exploration of an environment without any extrinsic reward or human demonstration.", "pdf": "/pdf/0d0b41430698c4a2d4db0e12ca39937e19757b0f.pdf", "paperhash": "anonymous|adversarial_exploration_strategy_for_selfsupervised_imitation_learning", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Exploration Strategy for Self-Supervised Imitation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyxtso0qtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGtjjR5t7", "original": "rygnn53ct7", "number": 641, "cdate": 1538087840984, "ddate": null, "tcdate": 1538087840984, "tmdate": 1538156087656, "tddate": null, "forum": "SkGtjjR5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Drive by Observing the Best and Synthesizing the Worst", "abstract": "Our goal is to train a policy for autonomous driving via imitation learning that is robust enough to drive a real vehicle. We find that standard behavior cloning is insufficient for handling complex driving scenarios, even when we leverage a perception system for preprocessing the input and a controller for executing the output on the car: 30 million examples are still not enough. We propose exposing the learner to synthesized data in the form of perturbations to the expert's driving, which creates interesting situations such as collisions and/or going off the road. Rather than purely imitating all data, we augment the imitation loss with additional losses that penalize undesirable events and encourage progress -- the perturbations then provide an important signal for these losses and lead to robustness of the learned model. We show that the model can handle complex situations in simulation, and present ablation experiments that emphasize the importance of each of our proposed changes and show that the model is responding to the appropriate causal factors. Finally, we demonstrate the model driving a car in the real world ( https://sites.google.com/view/learn-to-drive ).", "keywords": ["Imitation Learning", "End-to-End Driving", "Learning to drive", "Autonomous Driving"], "authorids": ["ICLR.cc/2019/Conference/Paper641/Authors"], "authors": ["Anonymous"], "TL;DR": "This work explores how far we can take (supervised) imitation learning for the task of driving a car.", "pdf": "/pdf/3b6bbfbea9997938bf3e98a23aa86ceba180defb.pdf", "paperhash": "anonymous|learning_to_drive_by_observing_the_best_and_synthesizing_the_worst", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Drive by Observing the Best and Synthesizing the Worst},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGtjjR5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyztsoC5Y7", "original": "SygH8F55Y7", "number": 642, "cdate": 1538087841160, "ddate": null, "tcdate": 1538087841160, "tmdate": 1538156087447, "tddate": null, "forum": "HyztsoC5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning", "abstract": "Although reinforcement learning methods can achieve impressive results in simulation, the real world presents two major challenges: generating samples is exceedingly expensive, and unexpected perturbations or unseen situations cause proficient but specialized policies to fail at test time. Given that it is impractical to train separate policies to accommodate all situations the agent may see in the real world, this work proposes to learn how to quickly and effectively adapt online to new tasks. To enable sample-efficient learning, we consider learning online adaptation in the context of model-based reinforcement learning. Our approach uses meta-learning to train a dynamics model prior such that, when combined with recent data, this prior can be rapidly adapted to the local context. Our experiments demonstrate online adaptation for continuous control tasks on both simulated and real-world agents. We first show simulated agents adapting their behavior online to novel terrains, crippled body parts, and highly-dynamic environments. We also illustrate the importance of incorporating online adaptation into autonomous agents that operate in the real world by applying our method to a real dynamic legged millirobot: We demonstrate the agent's learned ability to quickly adapt online to a missing leg, adjust to novel terrains and slopes, account for miscalibration or errors in pose estimation, and compensate for pulling payloads.", "keywords": ["meta-learning", "reinforcement learning", "meta reinforcement learning", "online adaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper642/Authors"], "authors": ["Anonymous"], "TL;DR": "A model-based meta-RL algorithm that enables a real robot to adapt online in dynamic environments", "pdf": "/pdf/377e94eccdf32212b158678175f2fe7cbaccfa00.pdf", "paperhash": "anonymous|learning_to_adapt_in_dynamic_realworld_environments_through_metareinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyztsoC5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyEtjoCqFX", "original": "rJeV_T2qFX", "number": 643, "cdate": 1538087841332, "ddate": null, "tcdate": 1538087841332, "tmdate": 1538156087225, "tddate": null, "forum": "HyEtjoCqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Soft Q-Learning with Mutual-Information Regularization", "abstract": "We propose a reinforcement learning (RL) algorithm that uses mutual-information regularization to optimize the prior action distribution for better performance and exploration. Entropy-based regularization has previously been shown to improve both exploration and robustness in challenging sequential decision-making tasks. It does so by encouraging policies to put probability mass on all actions. However, entropy regularization might be undesirable when actions have significantly different importance. In this paper, we propose a theoretically motivated framework that dynamically weights the importance of actions by using the mutual-information. In particular, we express the RL problem as an inference problem where the prior probability distribution over actions is subject to optimization. We show that the prior optimization introduces a mutual-information regularizer in the RL objective. This regularizer encourages the policy to be close to a non-uniform distribution that assigns higher probability mass to more important actions. We empirically demonstrate that our method significantly improves over entropy regularization methods, attaining state-of-the-art performance. ", "keywords": ["reinforcement learning", "regularization", "entropy", "mutual information"], "authorids": ["ICLR.cc/2019/Conference/Paper643/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2cb1b7e210f5e74a26dd808b40eaefad8dc4686a.pdf", "paperhash": "anonymous|soft_qlearning_with_mutualinformation_regularization", "_bibtex": "@inproceedings{    \nanonymous2019soft,    \ntitle={Soft Q-Learning with Mutual-Information Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyEtjoCqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkEYojRqtm", "original": "ryeKct1NF7", "number": 644, "cdate": 1538087841502, "ddate": null, "tcdate": 1538087841502, "tmdate": 1538156087016, "tddate": null, "forum": "SkEYojRqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Representation Degeneration Problem in Training Natural Language Generation Models", "abstract": "We study an interesting problem in training neural network-based models for natural language generation tasks, which we call the \\emph{representation degeneration problem}. We observe that when we train a model in natural language generation tasks through likelihood maximization with weight tying trick, especially with big training dataset, most of the learnt word embeddings tend to degenerate and be distributed into a narrow cone, which largely limits the representation power of word embeddings. We analyze the conditions and causes of this problem and propose a novel regularization method to address it. Experiments on language modeling and machine translation show that our method can largely mitigate the representation degeneration problem and achieve better performance than baseline algorithms.", "keywords": ["Natural Language Processing", "Representation Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper644/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b0b8331bd8c900388c553e3f69a2dcc9e43d2ea8.pdf", "paperhash": "anonymous|representation_degeneration_problem_in_training_natural_language_generation_models", "_bibtex": "@inproceedings{    \nanonymous2019representation,    \ntitle={Representation Degeneration Problem in Training Natural Language Generation Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkEYojRqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxciiC9tm", "original": "ryg-tz6wtX", "number": 645, "cdate": 1538087841680, "ddate": null, "tcdate": 1538087841680, "tmdate": 1538156086809, "tddate": null, "forum": "rkxciiC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NADPEx: An on-policy temporally consistent exploration method for deep reinforcement learning", "abstract": "Reinforcement learning agents need exploratory behaviors to escape from local optima. These behaviors may include both immediate dithering perturbation and temporally consistent exploration. To achieve these, a stochastic policy model that is inherently consistent through a period of time is in desire, especially for tasks with either sparse rewards or long term information. In this work, we introduce a novel on-policy temporally consistent exploration strategy - Neural Adaptive Dropout Policy Exploration (NADPEx) - for deep reinforcement learning agents. Modeled as a global random variable for conditional distribution, dropout is incorporated to reinforcement learning policies, equipping them with inherent temporal consistency, even when the reward signals are sparse. Two factors, gradients' alignment with the objective and KL constraint in policy space, are discussed to guarantee NADPEx policy's stable improvement. Our experiments demonstrate that NADPEx solves tasks with sparse reward while naive exploration and parameter noise fail. It yields as well or even faster convergence in the standard mujoco benchmark for continuous control. ", "keywords": ["Reinforcement learning", "exploration"], "authorids": ["ICLR.cc/2019/Conference/Paper645/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8e04c01ba8982ba3ab21368c9f723a922e91c805.pdf", "paperhash": "anonymous|nadpex_an_onpolicy_temporally_consistent_exploration_method_for_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019nadpex:,    \ntitle={NADPEx: An on-policy temporally consistent exploration method for deep reinforcement learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxciiC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1x9siCcYQ", "original": "HJlxp4GOKQ", "number": 646, "cdate": 1538087841860, "ddate": null, "tcdate": 1538087841860, "tmdate": 1538156086598, "tddate": null, "forum": "B1x9siCcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SENSE: SEMANTICALLY ENHANCED NODE SEQUENCE EMBEDDING", "abstract": "Effectively capturing graph node sequences in the form of vector embeddings is critical to many applications. We achieve this by (i) first learning vector embeddings of single graph nodes and (ii) then composing them to compactly represent node sequences. Specifically, we propose SENSE-S (Semantically Enhanced Node Sequence Embedding - for Single nodes), a skip-gram based novel embedding mechanism, for single graph nodes that co-learns graph structure as well as their textual descriptions. We demonstrate that SENSE-S vectors increase the accuracy of multi-label classification tasks by up to 50% and link-prediction tasks by up to 78% under a variety of scenarios using real datasets. Based on SENSE-S, we next propose generic SENSE to compute composite vectors that represent a sequence of nodes, where preserving the node order is important. We prove that this approach is efficient in embedding node sequences, and our experiments on real data confirm its high accuracy in node order decoding.", "keywords": ["Semantic", "Graph", "Sequence", "Embeddings"], "authorids": ["ICLR.cc/2019/Conference/Paper646/Authors"], "authors": ["Anonymous"], "TL;DR": "Node sequence embedding mechanism that captures both graph and text properties.", "pdf": "/pdf/3d35625b9e546baba169b51a8395454d1afc206c.pdf", "paperhash": "anonymous|sense_semantically_enhanced_node_sequence_embedding", "_bibtex": "@inproceedings{    \nanonymous2019sense:,    \ntitle={SENSE: SEMANTICALLY ENHANCED NODE SEQUENCE EMBEDDING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1x9siCcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJGciiR5Y7", "original": "rJxTYpVtKm", "number": 647, "cdate": 1538087842041, "ddate": null, "tcdate": 1538087842041, "tmdate": 1538156086393, "tddate": null, "forum": "HJGciiR5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["ICLR.cc/2019/Conference/Paper647/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/adeeb93eb9f15aa1f63f606edfc1e158160d33f4.pdf", "paperhash": "anonymous|latent_convolutional_models", "_bibtex": "@inproceedings{    \nanonymous2019latent,    \ntitle={Latent Convolutional Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJGciiR5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylqooRqK7", "original": "r1x_4XTwtX", "number": 648, "cdate": 1538087842221, "ddate": null, "tcdate": 1538087842221, "tmdate": 1538156086187, "tddate": null, "forum": "rylqooRqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SNAS: stochastic neural architecture search", "abstract": "We propose Stochastic Neural Architecture Search (SNAS), an economical end-to-end solution to Neural Architecture Search (NAS) that trains neural operation parameters and architecture distribution parameters in same round of back-propagation, while maintaining the completeness and differentiablity of the NAS pipeline. In this work, NAS is modeled as an optimization problem on parameters of a joint distribution for the search space in a cell. To leverage the gradient information in generic differentiable loss for architecture search, a novel search gradient is proposed. We prove that this search gradient optimizes the same objective as reinforcement-learning-based NAS, but assigns credits to structural decisions more efficiently. This credit assignment is further augmented with locally decomposable reward to enforce a resource-efficient constraint. In experiments on CIFAR-10, SNAS takes less epochs to find a cell architecture with state-of-the-art accuracy than non-differentiable evolution-based and reinforcement-learning-based NAS, which is also transferable to ImageNet. It is also shown that child networks of SNAS can maintain the validation accuracy in searching, with which attention-based NAS requires parameter retraining to compete, exhibiting potentials to stride towards efficient NAS on big datasets.", "keywords": ["Neural Architecture Search"], "authorids": ["ICLR.cc/2019/Conference/Paper648/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/06014d674a4b5d12aee2c6ff4c98bf0dfa64d2f5.pdf", "paperhash": "anonymous|snas_stochastic_neural_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019snas:,    \ntitle={SNAS: stochastic neural architecture search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylqooRqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eqjiCctX", "original": "S1lNW255K7", "number": 649, "cdate": 1538087842400, "ddate": null, "tcdate": 1538087842400, "tmdate": 1538156085979, "tddate": null, "forum": "H1eqjiCctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding Composition of Word Embeddings via Tensor Decomposition", "abstract": "Word embedding is a powerful tool in natural language processing. In this paper we consider the problem of word embedding composition \\--- given vector representations of two words, compute a vector for the entire phrase. We give a generative model that can capture specific syntactic relations between words. Under our model, we prove that the correlations between three words (measured by their PMI) form a tensor that has an approximate low rank Tucker decomposition. The result of the Tucker decomposition gives the word embeddings as well as a core tensor, which can be used to produce better compositions of the word embeddings. We also complement our theoretical results with experiments that verify our assumptions, and demonstrate the effectiveness of the new composition method.", "keywords": ["word embeddings", "semantic composition", "tensor decomposition"], "authorids": ["ICLR.cc/2019/Conference/Paper649/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a generative model for compositional word embeddings that captures syntactic relations, and provide empirical verification and evaluation.", "pdf": "/pdf/e034cd83a05cf384afba10ae20fdef24020aef42.pdf", "paperhash": "anonymous|understanding_composition_of_word_embeddings_via_tensor_decomposition", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding Composition of Word Embeddings via Tensor Decomposition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eqjiCctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgosiRcKm", "original": "HylXU3jqK7", "number": 650, "cdate": 1538087842577, "ddate": null, "tcdate": 1538087842577, "tmdate": 1538156085771, "tddate": null, "forum": "BkgosiRcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation", "abstract": "Modeling sequential data has become more and more important in practice. Some applications are autonomous driving, virtual sensors and weather forecasting. To model such systems so called recurrent models are frequently used. In this paper we introduce several new Deep Recurrent Gaussian Process (DRGP) models based on the Sparse Spectrum Gaussian Process (SSGP) and the improved version called Variational Sparse Spectrum Gaussian Process (VSSGP). We follow the recurrent structure given by an existing DRGP based on a specific variational sparse Nystr\u00f6m approximation, the recurrent Gaussian Process (RGP). Therefore, we also variationally integrate out the input-space and hence can propagate uncertainty through the GP layers. Further, we combine the (V)SS approximations with a well known inducing-input regularization framework. This case naturally collapses to a tractable expression by calculating the integrals. For the simple extension of the (V)SS approximation an optimal variational distribution exists. Training is realized through optimizing the variational lower bounds. We improve over current state of the art methods in prediction accuracy for experimental data-sets used for their evaluation and introduce a new data-set for engine control, named Emission.", "keywords": ["Deep Gaussian Process Model", "Recurrent Model", "State-Space Model", "Nonlinear system identification", "Dynamical modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper650/Authors"], "authors": ["Anonymous"], "TL;DR": "Modeling time-series with several Gaussian Processes in a row via a specific Variational Sparse Spectrum Approximation", "pdf": "/pdf/0d8eb42cbf4c70aa29856f9af70fcb0f660e4043.pdf", "paperhash": "anonymous|deep_recurrent_gaussian_process_with_variational_sparse_spectrum_approximation", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgosiRcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxssoA5KX", "original": "Syg4yMjKtX", "number": 651, "cdate": 1538087842751, "ddate": null, "tcdate": 1538087842751, "tmdate": 1538156085558, "tddate": null, "forum": "BJxssoA5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces", "abstract": "We introduce an approach to model surface properties governing bounces in everyday scenes. Our model learns end-to-end, starting from sensor inputs, to predict post-bounce trajectories and infer two underlying physical properties that govern bouncing - restitution and effective collision normals. Our model, Bounce and Learn, comprises two modules -- a Physics Inference Module (PIM) and a Visual Inference Module (VIM). VIM learns to infer physical parameters for locations in a scene given a single still image, while PIM learns to model physical interactions for the prediction task given physical parameters and observed pre-collision 3D trajectories.  To achieve our results, we introduce the Bounce Dataset comprising 5K RGB-D videos of bouncing trajectories of a foam ball to probe surfaces of varying shapes and materials in everyday scenes including homes and offices. Our proposed model learns from our collected dataset of real-world bounces and is bootstrapped with additional information from simple physics simulations. We show qualitative and quantitative results on our newly collected dataset and outline open challenges for learning to model real-world bounces.", "keywords": ["intuitive physics", "visual prediction", "surface normal", "restitution", "bounces"], "authorids": ["ICLR.cc/2019/Conference/Paper651/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/55432638b95e0353c1cdd0d496a350367db96f0f.pdf", "paperhash": "anonymous|bounce_and_learn_modeling_scene_dynamics_with_realworld_bounces", "_bibtex": "@inproceedings{    \nanonymous2019bounce,    \ntitle={Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxssoA5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyGjjsC5tQ", "original": "Hygo2bK9F7", "number": 652, "cdate": 1538087842923, "ddate": null, "tcdate": 1538087842923, "tmdate": 1538156085345, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually games which optimise multiple, interdependent objectives in parallel -- from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in such games, accounting for the fact that the 'environment' includes agents adapting to one another's updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm which exploits this dynamic response and encourages cooperation in settings like the Iterated Prisoner's Dilemma. Although experimentally successful, we show that LOLA can exhibit 'arrogant' behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all differentiable games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead locally converges and avoids strict saddles in all differentiable games, the strongest results in the field so far. SOS inherits these desirable guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ICLR.cc/2019/Conference/Paper652/Authors"], "authors": ["Anonymous"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/6a7463a2eb8af62f778e7ff83c47c734c2f3ec19.pdf", "paperhash": "anonymous|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{    \nanonymous2019stable,    \ntitle={Stable Opponent Shaping in Differentiable Games},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyGjjsC5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMsiiRctX", "original": "rJemI029YQ", "number": 653, "cdate": 1538087843107, "ddate": null, "tcdate": 1538087843107, "tmdate": 1538156085132, "tddate": null, "forum": "HJMsiiRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Program Induction for Intuitive Physics Game Play", "abstract": "Recent findings suggest that humans deploy cognitive mechanism of physics simulation engines to simulate the physics of objects. We propose a framework for bots to deploy similar tools for interacting with intuitive physics environments. The framework employs a physics simulation in a probabilistic way to infer about moves performed by an agent in a setting governed by Newtonian laws of motion. However, methods of probabilistic programs can be slow in such setting due to their need to generate many samples. We complement the model with a model-free approach to aid the sampling procedures in becoming more efficient through learning from experience during game playing. We present an approach where a myriad of model-free approaches (a convolutional neural network in our model) and model-based approaches (probabilistic physics simulation) is able to achieve what neither could alone. This way the model outperforms an all model-free or all model-based approach. We discuss a case study showing empirical results of the performance of the model on the game of Flappy Bird. ", "keywords": ["intuitive physics", "probabilistic programming", "computational cognitive science", "probabilistic models"], "authorids": ["ICLR.cc/2019/Conference/Paper653/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper describes a method imitating human cognition about the physical world to play games in environments of physical interactions.", "pdf": "/pdf/87ca0450501814923dcf14163f714a155e41a727.pdf", "paperhash": "anonymous|probabilistic_program_induction_for_intuitive_physics_game_play", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Program Induction for Intuitive Physics Game Play},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMsiiRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJEjjoR9K7", "original": "r1xAGY55Km", "number": 654, "cdate": 1538087843292, "ddate": null, "tcdate": 1538087843292, "tmdate": 1538156084919, "tddate": null, "forum": "rJEjjoR9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Robust Representations by Projecting Superficial Statistics Out", "abstract": "Despite impressive performance as evaluated on i.i.d. holdout data, deep neural networks depend heavily on superficial statistics of the training data and are liable to break under distribution shift. For example, subtle changes to the background or texture of an image can break a seemingly powerful classifier. Building on previous work on domain generalization,\nwe hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training. We refer to this setting as unguided domain generalization. This setting is challenging because the model may extract many distribution-specific (superficial) signals together with distribution-agnostic (semantic) signals. \nTo overcome this challenge, we incorporate the gray-level co-occurrence matrix (GLCM) to extract patterns that our prior knowledge suggests are superficial. Then we introduce two techniques for improving our networks' out-of-sample performance. The first method is built on the reverse gradient method for tuning the model to be invariant to GLCM representation. The second method is built on the independence introduced by projecting the model's representation onto the subspace orthogonal to GLCM representation's. We test our method on a battery of standard domain generalization data sets and achieve comparable or better performance as compared to other domain generalization methods that explicitly require the distribution identification information.", "keywords": ["domain generalization", "robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper654/Authors"], "authors": ["Anonymous"], "TL;DR": "Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training.", "pdf": "/pdf/d57b050e8915e9b6922e2127c06fd134ff4c9efd.pdf", "paperhash": "anonymous|learning_robust_representations_by_projecting_superficial_statistics_out", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Robust Representations by Projecting Superficial Statistics Out},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJEjjoR9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkljioCcFQ", "original": "BkgqzBYctm", "number": 655, "cdate": 1538087843464, "ddate": null, "tcdate": 1538087843464, "tmdate": 1538156084702, "tddate": null, "forum": "HkljioCcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MARGINALIZED AVERAGE ATTENTIONAL NETWORK FOR WEAKLY-SUPERVISED LEARNING", "abstract": "In weakly-supervised temporal action localization, previous works suffer from overestimating the most salient regions and fail to locate dense and integral regions for each entire action. To alleviate this issue, we propose a marginalized average attentional network (MAAN) to suppress the dominant response of the most salient regions in a principled manner. The MAAN employs a novel marginalized average aggregation (MAA) module and learns a set of latent discriminative probabilities in an end-to-end fashion. MAA samples the subsets from the video snippet features based on the latent discriminative probabilities and takes the expectation over all the subset features. Theoretically, we prove that the learned latent discriminative probabilities reduce the difference of responses between the most salient regions and the others, and thus MAAN generates better class activation sequences to identify more dense and integral action regions in the videos. Moreover, we propose a fast algorithm to reduce the complexity of constructing MAA from $O(2^T)$ to $O(T^2)$. Extensive experiments on two large-scale video datasets show that our MAAN achieves superior performance on weakly-supervised temporal action localization task. \n\n\n", "keywords": ["feature aggregation", "weakly supervised learning", "temporal action localization"], "authorids": ["ICLR.cc/2019/Conference/Paper655/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel marginalized average attentional network for weakly-supervised temporal action localization ", "pdf": "/pdf/40e01ba428b98b2264d0c9f5529d505a07d97baa.pdf", "paperhash": "anonymous|marginalized_average_attentional_network_for_weaklysupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019marginalized,    \ntitle={MARGINALIZED AVERAGE ATTENTIONAL NETWORK FOR WEAKLY-SUPERVISED LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkljioCcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkgnii09Ym", "original": "H1lOZVN5KX", "number": 656, "cdate": 1538087843642, "ddate": null, "tcdate": 1538087843642, "tmdate": 1538156084490, "tddate": null, "forum": "Hkgnii09Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Set Transformer", "abstract": "Many machine learning tasks such as multiple instance learning, 3D shape recognition and few-shot image classification are defined on sets of instances. Since solutions to such problems do not depend on the permutation of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, specifically designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating increased performance compared to recent methods for set-structured data.", "keywords": ["attention", "meta-learning", "set-input neural networks", "permutation invariant modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper656/Authors"], "authors": ["Anonymous"], "TL;DR": "Attention-based neural network to process set-structured data", "pdf": "/pdf/01de1a1f83deada8811a11b5e3f3b9575481f8af.pdf", "paperhash": "anonymous|set_transformer", "_bibtex": "@inproceedings{    \nanonymous2019set,    \ntitle={Set Transformer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkgnii09Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hylnis0qKX", "original": "B1e-lucqKm", "number": 657, "cdate": 1538087843832, "ddate": null, "tcdate": 1538087843832, "tmdate": 1538156084281, "tddate": null, "forum": "Hylnis0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Task-GAN for Improved GAN based Image Restoration", "abstract": "Deep Learning (DL) algorithms based on Generative Adversarial Network (GAN) have demonstrated great potentials in computer vision tasks such as image restoration. Despite the rapid development of image restoration algorithms using DL and GANs, image restoration for specific scenarios, such as medical image enhancement and super-resolved identity recognition, are still facing challenges. How to ensure visually realistic restoration while avoiding hallucination or mode- collapse? How to make sure the visually plausible results do not contain hallucinated features jeopardizing downstream tasks such as pathology identification and subject identification?\nHere we propose to resolve these challenges by coupling the GAN based image restoration framework with another task-specific network. With medical imaging restoration as an example, the proposed model conducts additional pathology recognition/classification task to ensure the preservation of detailed structures that are important to this task. Validated on multiple medical datasets, we demonstrate the proposed method leads to improved deep learning based image restoration while preserving the detailed structure and diagnostic features. Additionally, the trained task network show potentials to achieve super-human level performance in identifying pathology and diagnosis.\nFurther validation on super-resolved identity recognition tasks also show that the proposed method can be generalized for diverse image restoration tasks.", "keywords": ["Task-GAN: Improving Generative Adversarial Network for Image Restoration"], "authorids": ["ICLR.cc/2019/Conference/Paper657/Authors"], "authors": ["Anonymous"], "TL;DR": "Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features.", "pdf": "/pdf/ed29a570e5bd56040ba4f2170981bb81ec1ab790.pdf", "paperhash": "anonymous|taskgan_for_improved_gan_based_image_restoration", "_bibtex": "@inproceedings{    \nanonymous2019task-gan,    \ntitle={Task-GAN for Improved GAN based Image Restoration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hylnis0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxhijAcY7", "original": "r1l5M7q9KX", "number": 658, "cdate": 1538087844014, "ddate": null, "tcdate": 1538087844014, "tmdate": 1538156084074, "tddate": null, "forum": "BJxhijAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "signSGD with Majority Vote is Communication Efficient and Byzantine Fault Tolerant", "abstract": "Training neural networks on large datasets can be accelerated by distributing the workload over a network of machines. As datasets grow ever larger, networks of hundreds or thousands of machines become economically viable. The time cost of communicating gradients limits the effectiveness of using such large machine counts, as may the increased chance of network faults. We explore a particularly simple algorithm for robust, communication-efficient learning---signSGD. Workers transmit only the sign of their gradient vector to a server, and the overall update is decided by a majority vote. This algorithm uses 32x less communication per iteration than full-precision, distributed SGD. Under natural conditions verified by experiment, we prove that signSGD converges in the large and mini-batch settings, establishing convergence for a parameter regime of Adam as a byproduct. We model adversaries as those workers who may compute a stochastic gradient estimate and manipulate it, but may not coordinate with other adversaries. Aggregating sign gradients by majority vote means that no individual worker has too much power. We prove that unlike SGD, majority vote is robust when up to 50% of workers behave adversarially. On the practical side, we built our distributed training system in Pytorch. Benchmarking against the state of the art collective communications library (NCCL), our framework---with the parameter server housed entirely on one machine---led to a 25% reduction in time for training resnet50 on Imagenet when using 15 AWS p3.2xlarge machines.", "keywords": ["large-scale learning", "distributed systems", "communication efficiency", "convergence rate analysis", "robust optimisation"], "authorids": ["ICLR.cc/2019/Conference/Paper658/Authors"], "authors": ["Anonymous"], "TL;DR": "Workers send gradient signs to the server, and the update is decided by majority vote. We show that this algorithm is convergent, communication efficient and adversarially robust, both in theory and in practice.", "pdf": "/pdf/e6cbd48aad71e5d69a0b0871c25fb29b7be043b5.pdf", "paperhash": "anonymous|signsgd_with_majority_vote_is_communication_efficient_and_byzantine_fault_tolerant", "_bibtex": "@inproceedings{    \nanonymous2019signsgd,    \ntitle={signSGD with Majority Vote is Communication Efficient and Byzantine Fault Tolerant},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxhijAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lnjo05Km", "original": "ryelH1T5FX", "number": 659, "cdate": 1538087844199, "ddate": null, "tcdate": 1538087844199, "tmdate": 1538156083858, "tddate": null, "forum": "B1lnjo05Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Spectral Regularization For Neural Network Interpretability", "abstract": "Deep neural networks can learn meaningful representations of data. However, these representations are hard to interpret. For example, visualizing a latent layer is generally only possible for at most three dimensions. Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer. Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions. To do so, we propose a class of regularizations we call \\textit{Graph Spectral Regularizations} that impose graph-structure on latent layers. This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters. This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data. First, we show a synthetic example that the graph-structured layer can reveal topological features of the data. Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets. Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation. In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations. Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.", "keywords": ["autoencoder", "interpretable", "graph signal processing", "graph spectrum", "graph filter", "capsule"], "authorids": ["ICLR.cc/2019/Conference/Paper659/Authors"], "authors": ["Anonymous"], "TL;DR": "Imposing graph structure on neural network layers for improved visual interpretability.", "pdf": "/pdf/23d53b1f9c8e989b383cce7c6a9eff44a4f24c8d.pdf", "paperhash": "anonymous|graph_spectral_regularization_for_neural_network_interpretability", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Spectral Regularization For Neural Network Interpretability},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lnjo05Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJe2so0qF7", "original": "r1lngq5qK7", "number": 660, "cdate": 1538087844393, "ddate": null, "tcdate": 1538087844393, "tmdate": 1538156083653, "tddate": null, "forum": "SJe2so0qF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning data-derived privacy preserving representations from information metrics", "abstract": "It is clear that users should own and control their data and privacy. Utility providers are also becoming more interested in guaranteeing data privacy. Therefore, users and providers can and should collaborate in privacy protecting challenges, and this paper addresses this new paradigm. We propose a framework where the user controls what characteristics of the data they wants to share (utility) and what they want to keep private (secret), without necessarily asking the utility provider to change its existing machine learning algorithms. We first analyze the space of privacy-preserving representations, and derive natural information-theoretic bounds on the utility-privacy trade-off when disclosing a sanitized version of the data X. We present explicit architectures to learn privacy-preserving representations that approach this bound in a data-driven fashion. We then describe important use-case scenarios where the utility providers are willing to collaborate, at least partially, with the sanitization process. In this setting, we limit the possible sanitization functions to space-preserving transformations, meaning the sanitation maps the data to the same space as the original data, and the utility provider can then use the exact same (existing) algorithm for the original and sanitized data, a novel critical attribute to help service providers to collaborate. We illustrate this framework and show how we can maintain utility while protecting secret information even in cases where the joint distribution of the data X and the utility and secret variables U and S are unknown; and where the difficulty of inferring the utility variable U is much higher than the task of inferring the secret variable S. This is done through the implementation of three use cases; subject-within-subject, where we tackle the problem of having an identity detector (from facial images) that works only on a consenting subset of users, an important application, for example, for mobile devices activated by face recognition, helping them to become private to the environment instead of always ``listening as they currently act; gender-and-subject, where we want to preserve facial verification (hard) while hiding the gender attribute (easy) for users who choose to do so; and emotion-and-gender, where we tackle the issue of hiding independent variables, as is the case of hiding gender while preserving emotion detection. ", "keywords": ["Machine learning", "privacy", "adversarial training", "information theory", "data-driven privacy"], "authorids": ["ICLR.cc/2019/Conference/Paper660/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning privacy-preserving transformations from data. A collaborative approach", "pdf": "/pdf/6383c6601bb94f809bf5beb351c657ef936ee228.pdf", "paperhash": "anonymous|learning_dataderived_privacy_preserving_representations_from_information_metrics", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning data-derived privacy preserving representations from information metrics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJe2so0qF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgToo0qFm", "original": "Syx_1y89Ym", "number": 661, "cdate": 1538087844573, "ddate": null, "tcdate": 1538087844573, "tmdate": 1538156083447, "tddate": null, "forum": "SkgToo0qFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transferrable End-to-End Learning for Protein Interface Prediction", "abstract": "While there has been an explosion in the number of experimentally determined, atomically detailed structures of proteins, how to represent these structures in a machine learning context remains an open research question.  In this work we demonstrate that representations learned from raw atomic coordinates can outperform hand-engineered structural features while displaying a much higher degree of transferrability.  To do so, we focus on a central problem in biology: predicting how proteins interact with one another\u2014that is, which surfaces of one protein bind to which surfaces of another protein.  We present Siamese Atomic Surfacelet Network (SASNet), the first end-to-end learning method for protein interface prediction.  Despite using only spatial coordinates and identities of atoms as inputs, SASNet outperforms state-of-the-art methods that rely on hand-engineered, high-level features.  These results are particularly striking because we train the method entirely on a significantly biased data set that does not account for the fact that proteins deform when binding to one another.  Demonstrating the first successful application of transfer learning to atomic-level data, our network maintains high performance, without retraining, when tested on real cases in which proteins do deform.", "keywords": ["transfer learning", "protein interface prediction", "deep learning", "structural biology"], "authorids": ["ICLR.cc/2019/Conference/Paper661/Authors"], "authors": ["Anonymous"], "TL;DR": "We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.", "pdf": "/pdf/a425c10a0a19bf0e08e3f83da0cdeb371a3d5f27.pdf", "paperhash": "anonymous|transferrable_endtoend_learning_for_protein_interface_prediction", "_bibtex": "@inproceedings{    \nanonymous2019transferrable,    \ntitle={Transferrable End-to-End Learning for Protein Interface Prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgToo0qFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1e6ij0cKQ", "original": "H1g3pscctm", "number": 662, "cdate": 1538087844749, "ddate": null, "tcdate": 1538087844749, "tmdate": 1538156083233, "tddate": null, "forum": "H1e6ij0cKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "EFFICIENT SEQUENCE LABELING WITH ACTOR-CRITIC TRAINING", "abstract": "Neural approaches to sequence labeling often use a Conditional Random Field (CRF) to model their output dependencies, while Recurrent Neural Networks (RNN) are used for the same purpose in other tasks. We set out to establish RNNs as an attractive alternative to CRFs for sequence labeling. To do so, we address one of the RNN\u2019s most prominent shortcomings, the fact that it is not exposed to its own errors with the maximum-likelihood training. We frame the prediction of the output sequence as a sequential decision-making process, where we train the network with an adjusted actor-critic algorithm (AC-RNN). We comprehensively compare this strategy with maximum-likelihood training for both RNNs and CRFs on three structured-output tasks. The proposed AC-RNN efficiently matches the performance of the CRF on NER and CCG tagging, and outperforms it on Machine Transliteration. We also show that our training strategy is significantly better than other techniques for addressing RNN\u2019s exposure bias, such as Scheduled Sampling, and Self-Critical policy training.\n", "keywords": ["Structured Prediction", "Reinforcement Learning", "NLP"], "authorids": ["ICLR.cc/2019/Conference/Paper662/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fdb32ddb4a126c40b5a21a39393cac0d57cd1a88.pdf", "paperhash": "anonymous|efficient_sequence_labeling_with_actorcritic_training", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={EFFICIENT SEQUENCE LABELING WITH ACTOR-CRITIC TRAINING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1e6ij0cKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJg6ssC5Y7", "original": "BygHOkvcFX", "number": 663, "cdate": 1538087844931, "ddate": null, "tcdate": 1538087844931, "tmdate": 1538156083027, "tddate": null, "forum": "rJg6ssC5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DeepOBS: A Deep Learning Optimizer Benchmark Suite", "abstract": "Because the choice and tuning of the optimizer affects the speed, and ultimately the performance of deep learning, there is significant past and recent research in this area. Yet, perhaps surprisingly, there is no generally agreed-upon protocol for the quantitative and reproducible evaluation of optimization strategies for deep learning. We suggest routines and benchmarks for stochastic optimization, with special focus on the unique aspects of deep learning, such as stochasticity, tunability and generalization. As the primary contribution, we present DeepOBS, a Python package of deep learning optimization benchmarks. The package addresses key challenges in the quantitative assessment of stochastic optimizers, and automates most steps of benchmarking. The library includes a wide and extensible set of ready-to-use realistic optimization problems, such as training Residual Networks for image classification on ImageNet or character-level language prediction models, as well as popular classics like MNIST and CIFAR-10. The package also provides realistic baseline results for the most popular optimizers on these test problems, ensuring a fair comparison to the competition when benchmarking new optimizers, and without having to run costly experiments. It comes with output back-ends that directly produce LaTeX code for inclusion in academic publications. It is written in TensorFlow and available open source.", "keywords": ["deep learning", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper663/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide a software package that drastically simplifies, automates, and improves the evaluation of deep learning optimizers.", "pdf": "/pdf/fdc7be4864c37b5a84588d1ce8ac6cc820b93b65.pdf", "paperhash": "anonymous|deepobs_a_deep_learning_optimizer_benchmark_suite", "_bibtex": "@inproceedings{    \nanonymous2019deepobs:,    \ntitle={DeepOBS: A Deep Learning Optimizer Benchmark Suite},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJg6ssC5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1epooR5FX", "original": "r1xFjyacYm", "number": 664, "cdate": 1538087845224, "ddate": null, "tcdate": 1538087845224, "tmdate": 1538156082810, "tddate": null, "forum": "B1epooR5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Predicted Variables in Programming", "abstract": "We present Predicted Variables, an approach to making machine learning a first class citizen in programming languages. \nThere is a growing divide in approaches to building systems: using human experts (e.g. programming) on the one hand, and using behavior learned from data (e.g. ML) on the other hand. PVars aim to make ML in programming as easy as `if' statements and with that hybridize ML with programming. We leverage the existing concept of variables and create a new type, a predicted variable. PVars are akin to native variables with one important distinction: PVars determine their value using ML when evaluated. We describe PVars and their interface, how they can be used in programming, and demonstrate the feasibility of our approach on three algorithmic problems: binary search, Quicksort, and caches.\nWe show experimentally that PVars are able to improve over the commonly used heuristics and lead to a better performance than the original algorithms.\nAs opposed to previous work applying ML to algorithmic problems, PVars have the advantage that they can be used within the existing frameworks and do not require the existing domain knowledge to be replaced. PVars allow for a seamless integration of ML into existing systems and algorithms.\nOur PVars implementation currently relies on standard Reinforcement Learning (RL) methods. To learn faster, PVars use the heuristic function, which they are replacing, as an initial function. We show that PVars quickly pick up the behavior of the initial function and then improve performance beyond that without ever performing substantially worse -- allowing for a safe deployment in critical applications.", "keywords": ["predicted variables", "machine learning", "programming", "computing systems", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper664/Authors"], "authors": ["Anonymous"], "TL;DR": "We present Predicted Variables, an approach to making machine learning a first class citizen in programming languages.", "pdf": "/pdf/2b7a10119a81cbd7797b0b2b429e459987c88c17.pdf", "paperhash": "anonymous|predicted_variables_in_programming", "_bibtex": "@inproceedings{    \nanonymous2019predicted,    \ntitle={Predicted Variables in Programming},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1epooR5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1g6osRcFQ", "original": "r1eqG9n9t7", "number": 665, "cdate": 1538087845411, "ddate": null, "tcdate": 1538087845411, "tmdate": 1538156082599, "tddate": null, "forum": "H1g6osRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Policy Transfer with Strategy Optimization", "abstract": "Computer simulation provides an automatic and safe way for training robotic control\npolicies to achieve complex tasks such as locomotion. However, a policy\ntrained in simulation usually does not transfer directly to the real hardware due\nto the differences between the two environments. Transfer learning using domain\nrandomization is a promising approach, but it usually assumes that the target environment\nis close to the distribution of the training environments, thus relying\nheavily on accurate system identification. In this paper, we present a different\napproach that leverages domain randomization for transferring control policies to\nunknown environments. The key idea that, instead of learning a single policy in\nthe simulation, we simultaneously learn a family of policies that exhibit different\nbehaviors. When tested in the target environment, we directly search for the best\npolicy in the family based on the task performance, without the need to identify\nthe dynamic parameters. We evaluate our method on five simulated robotic control\nproblems with different discrepancies in the training and testing environment\nand demonstrate that our method can overcome larger modeling errors compared\nto training a robust policy or an adaptive policy.", "keywords": ["transfer learning", "reinforcement learning", "modeling error", "strategy optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper665/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a policy transfer algorithm that can overcome large and challenging discrepancies in the system dynamics such as latency, actuator modeling error, etc.", "pdf": "/pdf/face04be758d75b372249d7fdccb6f7aa18e6606.pdf", "paperhash": "anonymous|policy_transfer_with_strategy_optimization", "_bibtex": "@inproceedings{    \nanonymous2019policy,    \ntitle={Policy Transfer with Strategy Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g6osRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJl0jiRqtX", "original": "rJlOO9j5FX", "number": 666, "cdate": 1538087845581, "ddate": null, "tcdate": 1538087845581, "tmdate": 1538156082392, "tddate": null, "forum": "HJl0jiRqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE", "abstract": "Making decisions requires information relevant to the task at hand. Many real-life decision-making situations allow acquiring further relevant information at a specific cost. For example, in assessing the health status of a patient we may decide to take additional measurements such as diagnostic tests or imaging scans before making a final assessment. More information that is relevant allows for better decisions but it may be costly to acquire all of this information.  How can we trade off the desire to make good decisions with the option to acquire further information at a cost? To this end, we propose a principled framework, named EDDI (Efficient Dynamic Discovery of high-value Information), based on the theory of Bayesian experimental design. In EDDI we propose a novel partial variational autoencoder (Partial VAE), to efficiently handle missing data over varying subsets of known information. EDDI combines this Partial VAE with an acquisition function that maximizes expected information gain on a set of target variables. EDDI is efficient and demonstrates that dynamic discovery of high-value information is possible; we show cost reduction at the same decision quality and improved decision quality at the same cost in benchmarks and in two health-care applications.. We believe there is great potential for realizing these gains in real-world decision support systems.", "keywords": ["active variable selection", "missing data", "amortized inference"], "authorids": ["ICLR.cc/2019/Conference/Paper666/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f4cfe253b6baf73e8daf5df313b14aff6868b67c.pdf", "paperhash": "anonymous|eddi_efficient_dynamic_discovery_of_highvalue_information_with_partial_vae", "_bibtex": "@inproceedings{    \nanonymous2019eddi:,    \ntitle={EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJl0jiRqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxAisC9FQ", "original": "r1xXyxT9YX", "number": 667, "cdate": 1538087845757, "ddate": null, "tcdate": 1538087845757, "tmdate": 1538156082185, "tddate": null, "forum": "HkxAisC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improved robustness to adversarial examples using Lipschitz regularization of the loss", "abstract": "Adversarial training  is an effective method for improving robustness to adversarial attacks.   We show that adversarial training using the Fast Signed Gradient Method  can be interpreted as a form of regularization.  We implemented a more effective form of adversarial training, which in turn can be interpreted as regularization of the loss in the  2-norm, $\\|\\nabla_x \\ell(x)\\|_2$.  We obtained further improvements to adversarial robustness, as well as provable robustness guarantees, by augmenting adversarial training with Lipschitz regularization. \n", "keywords": ["Adversarial training", "adversarial examples", "deep neural networks", "regularization", "Lipschitz constant"], "authorids": ["ICLR.cc/2019/Conference/Paper667/Authors"], "authors": ["Anonymous"], "TL;DR": "Improvements to adversarial robustness, as well as provable robustness guarantees, are obtained by augmenting adversarial training with a tractable Lipschitz regularization", "pdf": "/pdf/30f79347efa6efaff3a815937febc5f0790ea051.pdf", "paperhash": "anonymous|improved_robustness_to_adversarial_examples_using_lipschitz_regularization_of_the_loss", "_bibtex": "@inproceedings{    \nanonymous2019improved,    \ntitle={Improved robustness to adversarial examples using Lipschitz regularization of the loss},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxAisC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJG0ojCcFm", "original": "SJeehO29KX", "number": 668, "cdate": 1538087845928, "ddate": null, "tcdate": 1538087845928, "tmdate": 1538156081983, "tddate": null, "forum": "HJG0ojCcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Negotiating Team Formation Using Deep Reinforcement Learning", "abstract": "When autonomous agents interact in the same environment, they must often cooperate to achieve their goals. One way for agents to cooperate effectively is to form a team, make a binding agreement on a joint plan, and execute it. However, when agents are self-interested, the gains from team formation must be allocated appropriately to incentivize agreement. Various approaches for multi-agent negotiation have been proposed, but typically only work for particular negotiation protocols. More general methods usually require human input or domain-specific data, and so do not scale. To address this, we propose a framework for training agents to negotiate and form teams using deep reinforcement learning. Importantly, our method makes no assumptions about the specific negotiation protocol, and is instead completely experience driven. We evaluate our approach on both non-spatial and spatially extended team-formation negotiation environments, demonstrating that our agents beat hand-crafted bots and reach negotiation outcomes consistent with fair solutions predicted by cooperative game theory. Additionally, we investigate how the physical location of agents influences negotiation outcomes.", "keywords": ["Reinforcement Learning", "Negotiation", "Team Formation", "Cooperative Game Theory", "Shapley Value"], "authorids": ["ICLR.cc/2019/Conference/Paper668/Authors"], "authors": ["Anonymous"], "TL;DR": "Reinforcement learning can be used to train agents to negotiate team formation across many negotiation protocols", "pdf": "/pdf/345c9ba0a550c5b38a053a2963c78634b0e9a1d2.pdf", "paperhash": "anonymous|negotiating_team_formation_using_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019negotiating,    \ntitle={Negotiating Team Formation Using Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJG0ojCcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1GAsjC5Fm", "original": "S1xZjmxcY7", "number": 669, "cdate": 1538087846103, "ddate": null, "tcdate": 1538087846103, "tmdate": 1538156081784, "tddate": null, "forum": "r1GAsjC5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Self-Aware Visual-Textual Co-Grounded Navigation Agent", "abstract": "The Vision-and-Language Navigation (VLN) task entails an agent following navigational instruction in photo-realistic unknown environments. This challenging task demands that the agent be aware of which instruction was completed, which instruction is needed next, which way to go, and its navigation progress towards the goal. In this paper, we introduce a self-aware agent with two complementary components: (1) visual-textual co-grounding module to locate the instruction completed in the past, the instruction required for the next action, and the next moving direction from surrounding images and (2) progress monitor to ensure the grounded instruction correctly reflects the navigation progress. We test our self- aware agent on a standard benchmark and analyze our proposed approach through a series of ablation studies that elucidate the contributions of the primary components. Using our proposed method, we set the new state-of-art by a significant margin (8% absolute increase in success rate on the unseen test set).", "keywords": ["visual grounding", "textual grounding", "instruction-following", "navigation agent"], "authorids": ["ICLR.cc/2019/Conference/Paper669/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a self-aware agent for the Vision-and-Language Navigation task.", "pdf": "/pdf/80bb995109a79d7cc2943e42dd72ba9d9bff577e.pdf", "paperhash": "anonymous|selfaware_visualtextual_cogrounded_navigation_agent", "_bibtex": "@inproceedings{    \nanonymous2019self-aware,    \ntitle={Self-Aware Visual-Textual Co-Grounded Navigation Agent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GAsjC5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJx0sjC5FX", "original": "BJxwI2CtYm", "number": 670, "cdate": 1538087846274, "ddate": null, "tcdate": 1538087846274, "tmdate": 1538156081579, "tddate": null, "forum": "BJx0sjC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RNNs implicitly implement tensor-product representations", "abstract": "Recurrent neural networks (RNNs) can learn continuous vector representations of symbolic structures such as sequences and sentences; these representations often exhibit linear regularities (analogies). Such regularities motivate our hypothesis that RNNs implicitly compile symbolic structures into tensor product representations (TPRs; Smolensky, 1990), which additively combine tensor products of vectors for roles (e.g., sequence position) and vectors for fillers (e.g., a particular word). To test this hypothesis, we introduce Tensor Product Decomposition Networks (TPDNs), which use TPRs to approximate existing vector representations. We demonstrate using synthetic data that TPDNs can successfully approximate linear and tree-based RNN autoencoder representations; those representation exhibit highly interpretable compositional structure. We explore the settings that lead RNNs to induce such structure-sensitive representations. By contrast with these results, TPDN experiments with four standard sentence encoding models showed that those sentence encodings could be largely approximated using bag-of-words representations, with only marginal improvements from more sophisticated structures. We conclude that TPDNs provide a powerful method for interpreting vector representations, and that standard RNNs can induce compositional sequence representations that are remarkably well approximated by TPRs; at the same time, existing training tasks for sentence representation learning may not be sufficient for inducing robust structural properties.", "keywords": ["tensor-product representations", "compositionality", "neural network interpretability", "recurrent neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper670/Authors"], "authors": ["Anonymous"], "TL;DR": "RNNs implicitly implement tensor-product representations, a principled and interpretable method for representing symbolic structures in continuous space.", "pdf": "/pdf/6dc06be7caf6f1357dff89bcae1ecefe99cbde31.pdf", "paperhash": "anonymous|rnns_implicitly_implement_tensorproduct_representations", "_bibtex": "@inproceedings{    \nanonymous2019rnns,    \ntitle={RNNs implicitly implement tensor-product representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJx0sjC5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxCsj0qYX", "original": "S1l27H9KYm", "number": 671, "cdate": 1538087846454, "ddate": null, "tcdate": 1538087846454, "tmdate": 1538156081366, "tddate": null, "forum": "SJxCsj0qYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stackelberg GAN: Towards Provable Minimax Equilibrium via Multi-Generator Architectures", "abstract": "We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design. The discrepancy between the minimax and maximin objective values could serve as a proxy for the difficulties that the alternating gradient descent encounters in the optimization of GAN. In this work, we give new results on the benefits of multi-generator architecture of GANs. We show that the minimax gap shrinks to \\epsilon as the number of generators increases with rate O(1/\\epsilon). This improves over the best-known result of O(1/\\epsilon^2). At the core of our techniques is a novel application of Shapley-Folkman lemma to the generic minimax problem, where in the literature the technique was only known to work when the objective function is restricted to the Lagrangian function of a constraint optimization problem. Our proposed Stackelberg GAN performs well experimentally in both synthetic and real-world datasets, improving Frechet Inception Distance by 14.61% over the previous multi-generator GANs on the benchmark datasets.", "keywords": ["generative adversarial nets", "minimax duality gap", "equilibrium"], "authorids": ["ICLR.cc/2019/Conference/Paper671/Authors"], "authors": ["Anonymous"], "TL;DR": "We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design, with theoretical guarantees.", "pdf": "/pdf/a7f5a33bda4018efbf8de3b2243ffdebe1dbc4b5.pdf", "paperhash": "anonymous|stackelberg_gan_towards_provable_minimax_equilibrium_via_multigenerator_architectures", "_bibtex": "@inproceedings{    \nanonymous2019stackelberg,    \ntitle={Stackelberg GAN: Towards Provable Minimax Equilibrium via Multi-Generator Architectures},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxCsj0qYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1e13s05YX", "original": "HyxApcj5Ym", "number": 672, "cdate": 1538087846628, "ddate": null, "tcdate": 1538087846628, "tmdate": 1538156081161, "tddate": null, "forum": "r1e13s05YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural network gradient-based learning of black-box function interfaces", "abstract": "Deep neural networks work well at approximating complicated functions when provided with data and trained by gradient descent methods. At the same time, there is a vast amount of existing functions that programmatically solve different tasks in a precise manner eliminating the need for training. In many cases, it is possible to decompose a task to a series of functions, of which for some we may prefer to use a neural network to learn the functionality, while for others the preferred method would be to use existing black-box functions. We propose a method for end-to-end training of a base neural network that integrates calls to existing black-box functions. We do so by approximating the black-box functionality with a differentiable neural network in a way that drives the base network to comply with the black-box function interface during the end-to-end optimization process. At inference time, we replace the differentiable estimator with its external black-box non-differentiable counterpart such that the base network output matches the input arguments of the black-box function. Using this ``Estimate and Replace'' paradigm, we train a neural network, end to end, to compute the input to black-box functionality while eliminating the need for intermediate labels. We show that by leveraging the existing precise black-box function during inference, the integrated model generalizes better than a fully differentiable model, and learns more efficiently compared to RL-based methods.", "keywords": ["neural networks", "black box functions", "gradient descent"], "authorids": ["ICLR.cc/2019/Conference/Paper672/Authors"], "authors": ["Anonymous"], "TL;DR": "Training DNNs to interface w\\ black box functions w\\o intermediate labels by using an estimator sub-network that can be replaced with the black box after training", "pdf": "/pdf/ffaab71fb67ece2acc01d999e38943b7e6c662d8.pdf", "paperhash": "anonymous|neural_network_gradientbased_learning_of_blackbox_function_interfaces", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural network gradient-based learning of black-box function interfaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1e13s05YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJe1hsCcYQ", "original": "SyxQSepqYm", "number": 673, "cdate": 1538087846803, "ddate": null, "tcdate": 1538087846803, "tmdate": 1538156080950, "tddate": null, "forum": "BJe1hsCcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Lorentzian Distance Learning", "abstract": "This paper introduces an approach to learn representations based on the Lorentzian distance in hyperbolic geometry. Hyperbolic geometry is especially suited to hierarchically-structured datasets, which are prevalent in the real world. Current hyperbolic representation learning methods compare examples with the Poincar\\'e distance metric. They formulate the problem as minimizing the distance of each node in a hierarchy with its descendants while maximizing its distance with other nodes. This formulation produces node representations close to the centroid of their descendants. We exploit the fact that the centroid w.r.t the squared Lorentzian distance can be written in closed-form. We show that the Euclidean norm of such a centroid decreases as the curvature of the hyperbolic space decreases. This property makes it appropriate to represent hierarchies where parent nodes minimize the distances to their descendants and have smaller Euclidean norm than their children. Our approach obtains state-of-the-art results in retrieval and classification tasks on different datasets. ", "keywords": ["distance learning", "metric learning", "hyperbolic geometry", "hierarchy tree"], "authorids": ["ICLR.cc/2019/Conference/Paper673/Authors"], "authors": ["Anonymous"], "TL;DR": "A distance learning approach to learn hyperbolic representations", "pdf": "/pdf/2127c334cb5ef92ef554493baf2729cf9055e628.pdf", "paperhash": "anonymous|lorentzian_distance_learning", "_bibtex": "@inproceedings{    \nanonymous2019lorentzian,    \ntitle={Lorentzian Distance Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe1hsCcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1ey2sRcYQ", "original": "rkx81-I9KX", "number": 674, "cdate": 1538087847058, "ddate": null, "tcdate": 1538087847058, "tmdate": 1538156080744, "tddate": null, "forum": "S1ey2sRcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Direct Optimization through $\\arg \\max$  for  Discrete Variational Auto-Encoder", "abstract": "Reparameterization of variational auto-encoders is an effective method for reducing the variance of their gradient estimates. However, when the latent variables are discrete, a reparameterization is problematic due to discontinuities in the discrete space. In this work, we extend the direct loss minimization technique to discrete variational auto-encoders. We first reparameterize a discrete random variable using the $\\arg \\max$ function of the Gumbel-Max perturbation model. We then use direct optimization to propagate gradients through the non-differentiable $\\arg \\max$ using two perturbed $\\arg \\max$ operations.\n", "keywords": ["discrete variational auto encoders", "generative models", "perturbation models"], "authorids": ["ICLR.cc/2019/Conference/Paper674/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/80344032b86bf87135dd4d5ed870bef5fd3da396.pdf", "paperhash": "anonymous|direct_optimization_through_\\arg_\\max_for_discrete_variational_autoencoder", "_bibtex": "@inproceedings{    \nanonymous2019direct,    \ntitle={Direct Optimization through $\\arg \\max$  for  Discrete Variational Auto-Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1ey2sRcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1x1noAqKX", "original": "BJxFgmjcYQ", "number": 675, "cdate": 1538087847230, "ddate": null, "tcdate": 1538087847230, "tmdate": 1538156080539, "tddate": null, "forum": "H1x1noAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discriminative out-of-distribution detection for semantic segmentation", "abstract": "Most classification and segmentation datasets assume a closed-world scenario in which predictions are expressed as distribution over a predetermined set of visual classes. However, such assumption implies unavoidable and often unnoticeable failures in presence of out-of-distribution (OOD) input. These failures are bound to happen in most real-life applications since current visual ontologies are far from being comprehensive. We propose to address this issue by discriminative detection \nof OOD pixels in input data. Different from recent approaches, we avoid to bring any decisions by only observing the training dataset of the primary model trained to solve the desired computer vision task. Instead, we train a dedicated OOD model\nwhich discriminates the primary training set from a much larger \"background\" dataset which approximates the variety of the visual world. We perform our experiments on high resolution natural images in a dense prediction setup. We use several road driving datasets as our training distribution, while we approximate the background distribution with the ILSVRC dataset. We evaluate our approach on WildDash test, which is currently the only public test dataset with out-of-distribution images.\nThe obtained results show that the proposed approach succeeds to identify out-of-distribution pixels while outperforming previous work by a wide margin.", "keywords": ["out-of-distribution detection", "semantic segmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper675/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel approach for detecting out-of-distribution pixels in semantic segmentation.", "pdf": "/pdf/1d26a6365b0249baa002915cd2e4b846f41ef79f.pdf", "paperhash": "anonymous|discriminative_outofdistribution_detection_for_semantic_segmentation", "_bibtex": "@inproceedings{    \nanonymous2019discriminative,    \ntitle={Discriminative out-of-distribution detection for semantic segmentation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1x1noAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxknjC9KQ", "original": "ByesFn25FQ", "number": 676, "cdate": 1538087847409, "ddate": null, "tcdate": 1538087847409, "tmdate": 1538156080328, "tddate": null, "forum": "SyxknjC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Morph-Net: An Universal Function Approximator", "abstract": "Artificial neural networks are built on the basic operation of linear combination and non-linear activation function. Theoretically this structure can approximate any continuous function with three layer architecture. But in practice learning  the parameters of such network can be hard. Also the choice of activation function can greatly impact the performance of the network. In this paper we are proposing to replace the basic linear combination operation with non-linear operations that do away with the need of additional non-linear activation function. To this end we are proposing the use of elementary  morphological operations (dilation and erosion) as the basic operation in neurons. We show that these networks (Denoted as Morph-Net) with morphological operations can approximate any smooth function requiring less number of parameters than what is necessary for normal neural networks. The results show that our network perform favorably when compared with similar structured network. We have carried out our experiments on  MNIST, Fashion-MNIST, CIFAR10 and CIFAR100.", "keywords": ["Mathematical Morphology", "Deep Learning", "Activation Function", "Universal Aproximatimation."], "authorids": ["ICLR.cc/2019/Conference/Paper676/Authors"], "authors": ["Anonymous"], "TL;DR": "Using mophological operation (dilation and erosion) we have defined a class of network which can approximate any continious function. ", "pdf": "/pdf/1757347695d8fd5384262508b90bafbbb73af67e.pdf", "paperhash": "anonymous|morphnet_an_universal_function_approximator", "_bibtex": "@inproceedings{    \nanonymous2019morph-net:,    \ntitle={Morph-Net: An Universal Function Approximator},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxknjC9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkle3i09K7", "original": "Hyef-Tm9Km", "number": 677, "cdate": 1538087847580, "ddate": null, "tcdate": 1538087847580, "tmdate": 1538156080116, "tddate": null, "forum": "rkle3i09K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Robust Determinantal Generative Classifier for Noisy Labels and Adversarial Attacks", "abstract": "Large-scale datasets may contain significant proportions of noisy (incorrect) class labels, and it is well-known that modern deep neural networks poorly generalize from such noisy training datasets. In this paper, we propose a novel inference method, Deep Determinantal Generative Classifier (DDGC), which can obtain a more robust decision boundary under any softmax neural classifier pre-trained on noisy datasets. Our main idea is inducing a generative classifier on top of hidden feature spaces of the discriminative deep model. By estimating the parameters of generative classifier using the minimum covariance determinant estimator, we significantly improve the classification accuracy, with neither re-training of the deep model nor changing its architectures. In particular, we show that DDGC not only generalizes well from noisy labels, but also is robust against adversarial perturbations due to its large margin property. Finally, we propose the ensemble version of DDGC to improve its performance, by investigating the layer-wise characteristics of generative classifier. Our extensive experimental results demonstrate the superiority of DDGC given different learning models optimized by various training techniques to handle noisy labels or adversarial examples. For instance, we improve the test accuracy of DenseNet on CIFAR-10 datasets with 60% noisy labels from 53.34% to 74.72%. ", "keywords": ["Noisy Labels", "Adversarial Attacks", "Generative Models"], "authorids": ["ICLR.cc/2019/Conference/Paper677/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/014219c4bd68602948b4091334dc847cdf5b9c8a.pdf", "paperhash": "anonymous|robust_determinantal_generative_classifier_for_noisy_labels_and_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019robust,    \ntitle={Robust Determinantal Generative Classifier for Noisy Labels and Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkle3i09K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkxx3o0qFX", "original": "rJl9ZUr9K7", "number": 678, "cdate": 1538087847756, "ddate": null, "tcdate": 1538087847756, "tmdate": 1538156079903, "tddate": null, "forum": "Hkxx3o0qFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "High Resolution and Fast Face Completion via Progressively Attentive GANs", "abstract": "Face completion is a challenging task with the difficulty level increasing significantly with respect to high resolution, the complexity of \"holes\" and the controllable attributes of filled-in fragments. Our system addresses the challenges by learning a fully end-to-end framework that trains generative adversarial networks (GANs) progressively from low resolution to high resolution with conditional vectors encoding controllable attributes. We design a novel coarse-to-fine attentive module network architecture. Our model is encouraged to attend on finer details while the network is growing to a higher resolution, thus being capable of showing progressive attention to different frequency components in a coarse-to-fine way. We term the module Frequency-oriented Attentive Module (FAM). Our system can complete faces with large structural and appearance variations using a single feed-forward pass of computation with mean inference time of 0.54 seconds for images at 1024x1024 resolution. A pilot human study  shows our approach outperforms state-of-the-art face completion methods. The code will be released upon publication. ", "keywords": ["Face Completion", "progressive GANs", "Attribute Control", "Frequency-oriented Attention"], "authorids": ["ICLR.cc/2019/Conference/Paper678/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1b988167bd0e3e1fd0cc277c281cbc870ca8e46a.pdf", "paperhash": "anonymous|high_resolution_and_fast_face_completion_via_progressively_attentive_gans", "_bibtex": "@inproceedings{    \nanonymous2019high,    \ntitle={High Resolution and Fast Face Completion via Progressively Attentive GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkxx3o0qFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syfe2iR5FQ", "original": "BJloOD29Km", "number": 679, "cdate": 1538087847929, "ddate": null, "tcdate": 1538087847929, "tmdate": 1538156079686, "tddate": null, "forum": "Syfe2iR5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Parametrizing Fully Convolutional Nets with a Single High-Order Tensor", "abstract": "Recent findings indicate that over-parametrization, while crucial to the success of deep learning, also introduces large amounts of redundancy. Tensor methods have the potential to parametrize over-complete representations in a compact manner by leveraging this redundancy. In this paper, we propose fully parametrizing Convolutional Neural Networks (CNNs) with a single, low-rank tensor. Previous works on network tensorization haved focused on parametrizing individual layers (convolutional or fully connected) only, and perform the tensorization layer-by-layer disjointly. In contrast, we propose to jointly capture the full structure of a CNN by parametrizing it with a single, high-order tensor, the modes of which represent each of the architectural design parameters of the CNN (e.g. number of convolutional blocks, depth, number of stacks, input features, etc). This parametrization allows to regularize the whole network and drastically reduce the number of parameters by imposing a low-rank structure on that tensor. Further, our network is end-to-end trainable from scratch, which has been shown to be challenging in prior work. We study the case of networks with rich structure, namely Fully Convolutional CNNs, which we propose to parametrize them with a single 8-dimensional tensor. We show that our approach can achieve superior performance with small compression rates, and attain high compression rates with negligible drop in accuracy for the challenging task of human pose estimation.\n", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper679/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/44d45e772faed1f8bba36227a172d1265fc702dc.pdf", "paperhash": "anonymous|parametrizing_fully_convolutional_nets_with_a_single_highorder_tensor", "_bibtex": "@inproceedings{    \nanonymous2019parametrizing,    \ntitle={Parametrizing Fully Convolutional Nets with a Single High-Order Tensor},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syfe2iR5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMghjA9YX", "original": "rJgt6xp9tm", "number": 680, "cdate": 1538087848109, "ddate": null, "tcdate": 1538087848109, "tmdate": 1538156079477, "tddate": null, "forum": "HJMghjA9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Model Comparison for Semantic Grouping", "abstract": "We introduce a probabilistic framework for quantifying the semantic similarity between two groups of embeddings. We formulate this as a model comparison task in which we contrast a generative model that encodes similarity between the two groups versus one that does not. We illustrate how this framework can be used for the Semantic Text Similarity (STS) task using clear assumptions about how the embeddings of words are generated. We apply information criteria based model comparison to overcome the shortcomings of Bayesian model comparison, whilst still penalising model complexity. We achieve competitive results by applying the proposed framework with an appropriate choice of likelihood on the STS datasets.", "keywords": ["model comparison", "semantic similarity", "STS", "von Mises-Fisher", "information theoretic criteria"], "authorids": ["ICLR.cc/2019/Conference/Paper680/Authors"], "authors": ["Anonymous"], "TL;DR": "Competitive alternative to sentence embeddings in the task of semantic similarity using model comparison", "pdf": "/pdf/daf46808b6afda46d365ddd51059a86c5da4f9a1.pdf", "paperhash": "anonymous|model_comparison_for_semantic_grouping", "_bibtex": "@inproceedings{    \nanonymous2019model,    \ntitle={Model Comparison for Semantic Grouping},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMghjA9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkVe3iA9Ym", "original": "rJgR6gpqtm", "number": 681, "cdate": 1538087848283, "ddate": null, "tcdate": 1538087848283, "tmdate": 1538156079271, "tddate": null, "forum": "SkVe3iA9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Beyond Winning and Losing: Modeling Human Motivations and Behaviors with Vector-valued Inverse Reinforcement Learning", "abstract": "In recent years, reinforcement learning methods have been applied to model gameplay with great success, achieving super-human performance in various environments, such as Atari, Go and Poker.\nHowever, those studies mostly focus on winning the game and have largely ignored the rich and complex human motivations, which are essential for understanding the agents' diverse behavior.\nIn this paper, we present a multi-motivation behavior modeling which investigates the multifaceted human motivations and models the underlying value structure of the agents.\nOur approach extends inverse RL to the vectored-valued setting which imposes a much weaker assumption than previous studies.\nThe vectorized rewards incorporate Pareto optimality, which is a powerful tool to explain a wide range of behavior by its optimality.\nFor practical assessment, our algorithm is tested on the World of Warcraft Avatar History dataset spanning three years of the gameplay.\nOur experiments demonstrate the improvement over the scalarization-based methods on real-world problem settings.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper681/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/15b910986520b8476eace00b1b4f329d8102925e.pdf", "paperhash": "anonymous|beyond_winning_and_losing_modeling_human_motivations_and_behaviors_with_vectorvalued_inverse_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019beyond,    \ntitle={Beyond Winning and Losing: Modeling Human Motivations and Behaviors with Vector-valued Inverse Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkVe3iA9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyEl3o05Fm", "original": "BJeeReacFX", "number": 682, "cdate": 1538087848465, "ddate": null, "tcdate": 1538087848465, "tmdate": 1538156079065, "tddate": null, "forum": "HyEl3o05Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Adversarial Video Prediction", "abstract": "Being able to predict what may happen in the future requires an in-depth understanding of the physical and causal rules that govern the world. A model that is able to do so has a number of appealing applications, from robotic planning to representation learning. However, learning to predict raw future observations, such as frames in a video, is exceedingly challenging\u2014the ambiguous nature of the problem can cause a naively designed model to average together possible futures into a single, blurry prediction. Recently, this has been addressed by two distinct approaches: (a) latent variational variable models that explicitly model underlying stochasticity and (b) adversarially-trained models that aim to produce naturalistic images. However, a standard latent variable model can struggle to produce realistic results, and a standard adversarially-trained model underutilizes latent variables and fails to produce diverse predictions. We show that these distinct methods are in fact complementary. Combining the two produces predictions that look more realistic to human raters and better cover the range of possible futures. Our method outperforms prior works in these aspects.", "keywords": ["video prediction", "GANs", "variational autoencoder"], "authorids": ["ICLR.cc/2019/Conference/Paper682/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5947a1d2cdadeca7c01a28a66c8b9552d9c320de.pdf", "paperhash": "anonymous|stochastic_adversarial_video_prediction", "_bibtex": "@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Adversarial Video Prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyEl3o05Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1e-nj05FQ", "original": "rJgjMk69Fm", "number": 683, "cdate": 1538087848636, "ddate": null, "tcdate": 1538087848636, "tmdate": 1538156078855, "tddate": null, "forum": "r1e-nj05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Evolving intrinsic motivations for altruistic behavior", "abstract": "Multi-agent cooperation is an important feature of the natural world. Many tasks involve individual incentives that are misaligned with the common good, yet a wide range of organisms from bacteria to insects and humans are able to overcome their differences and collaborate. Therefore, the emergence of cooperative behavior amongst self-interested individuals is an important question for the fields of multi-agent reinforcement learning (MARL) and evolutionary theory. Here, we study a particular class of multi-agent problems called intertemporal social dilemmas (ISDs), where the conflict between the individual and the group is particularly sharp. By combining MARL with appropriately structured natural selection, we demonstrate that individual inductive biases for cooperation can be learned in a model-free way. To achieve this, we introduce an innovative modular architecture for deep reinforcement learning agents which supports multi-level selection. We present results in two challenging environments, and interpret these in the context of cultural and ecological evolution.", "keywords": ["evolution", "reinforcement learning", "intrinsic reward", "multi-agent", "social dilemmas", "cooperation"], "authorids": ["ICLR.cc/2019/Conference/Paper683/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a biologically-inspired modular evolutionary algorithm in which deep RL agents learn to cooperate in a difficult multi-agent social game, which could help to explain the evolution of altruism.", "pdf": "/pdf/4218358716b33f65f74f2082c53762c81038e96f.pdf", "paperhash": "anonymous|evolving_intrinsic_motivations_for_altruistic_behavior", "_bibtex": "@inproceedings{    \nanonymous2019evolving,    \ntitle={Evolving intrinsic motivations for altruistic behavior},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1e-nj05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgZ3oR9FX", "original": "Skle81P7FQ", "number": 684, "cdate": 1538087848817, "ddate": null, "tcdate": 1538087848817, "tmdate": 1538156078642, "tddate": null, "forum": "rkgZ3oR9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Refer to 3D Objects with Natural Language", "abstract": "Human world knowledge is both structured and flexible. When people see an object, they represent it not as a pixel array but as a meaningful arrangement of semantic parts. Moreover, when people refer to an object, they provide descriptions that are not merely true but also relevant in the current context. Here, we combine these two observations in order to learn fine-grained correspondences between language and contextually relevant geometric properties of 3D objects. To do this, we employed an interactive communication task with human participants to construct a large dataset containing natural utterances referring to 3D objects from ShapeNet in a wide variety of contexts. Using this dataset, we developed neural listener and speaker models with strong capacity for generalization. By performing targeted lesions of visual and linguistic input, we discovered that the neural listener depends heavily on part-related words and associates these words correctly with the corresponding geometric properties of objects, suggesting that it has learned task-relevant structure linking the two input modalities. We further show that a neural speaker that is `listener-aware' --- that plans its utterances according to how an imagined listener would interpret its words in context --- produces more discriminative referring expressions than an `listener-unaware' speaker, as measured by human performance in identifying the correct object.", "keywords": ["Referential Language", "3D Objects", "Part-Awareness", "Neural Speakers", "Neural Listeners"], "authorids": ["ICLR.cc/2019/Conference/Paper684/Authors"], "authors": ["Anonymous"], "TL;DR": "How to build neural-speakers/listeners that learn fine-grained characteristics of 3D objects, from referential language.", "pdf": "/pdf/e5b8e3028243983f16ddd69f526e89a974536558.pdf", "paperhash": "anonymous|learning_to_refer_to_3d_objects_with_natural_language", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Refer to 3D Objects with Natural Language},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgZ3oR9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByfbnsA9Km", "original": "H1egrKeqFX", "number": 685, "cdate": 1538087848992, "ddate": null, "tcdate": 1538087848992, "tmdate": 1538156078434, "tddate": null, "forum": "ByfbnsA9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cross-Entropy Loss Leads To Poor Margins", "abstract": "Neural networks could misclassify inputs that are slightly different from their training data, which indicates a small margin between their decision boundaries and the training dataset. In this work, we study the binary classification of linearly separable datasets and show that linear classifiers could also have decision boundaries that lie close to their training dataset if cross-entropy loss is used for training. In particular, we show that if the features of the training dataset lie in a low-dimensional affine subspace and the cross-entropy loss is minimized by using a gradient method, the margin between the training points and the decision boundary could be much smaller than the optimal value. This result is contrary to the conclusions of recent related works such as (Soudry et al., 2018), and we identify the reason for this contradiction. In order to improve the margin, we introduce differential training, which is a novel training paradigm that uses a loss function defined on pairs of points from each class. We show that the decision boundary of a linear classifier trained with differential training indeed achieves the maximum margin. The results reveal the use of cross-entropy loss as one of the hidden culprits of adversarial examples and introduces a new direction to make neural networks robust against them.", "keywords": ["Cross-entropy loss", "Binary classification", "Low-rank features", "Adversarial examples", "Differential training"], "authorids": ["ICLR.cc/2019/Conference/Paper685/Authors"], "authors": ["Anonymous"], "TL;DR": "We show minimizing the cross-entropy loss by using a gradient method could lead to a poor margin, and we introduce differential training to fix this.", "pdf": "/pdf/1cd0a92a7978cb85307012591191861fec499a81.pdf", "paperhash": "anonymous|crossentropy_loss_leads_to_poor_margins", "_bibtex": "@inproceedings{    \nanonymous2019cross-entropy,    \ntitle={Cross-Entropy Loss Leads To Poor Margins},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByfbnsA9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skz-3j05tm", "original": "Hyg3NchcYX", "number": 686, "cdate": 1538087849180, "ddate": null, "tcdate": 1538087849180, "tmdate": 1538156078220, "tddate": null, "forum": "Skz-3j05tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Convolutional Network with Sequential Attention For Goal-Oriented Dialogue Systems", "abstract": "Domain specific goal-oriented dialogue systems typically require modeling three types of inputs, viz., (i) the knowledge-base associated with the domain, (ii) the history of the conversation, which is a sequence of utterances and (iii) the current utterance for which the response needs to be generated. While modeling these inputs, current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation, semantic role labeling and document dating, we propose a memory augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base  and (ii) the dependency graph associated with an utterance to compute richer representations for words and entities. Further, we take cognizance of the fact that in certain situations, such as, when the conversation is in a code-mixed language, dependency parsers may not be available. We show that in such situations we could use the global word co-occurrence graph and use it to enrich the representations of utterances. We experiment with the modified DSTC2 dataset and its recently released code-mixed versions in four languages and show that our method outperforms existing state-of-the-art methods, using a wide range of evaluation metrics.", "keywords": ["Goal-oriented Dialogue Systems", "Graph Convolutional Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper686/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a Graph Convolutional Network based encoder-decoder model with sequential attention for goal-oriented dialogue systems.", "pdf": "/pdf/60c36aa1051298d04fc853fc0642e4d79c75823e.pdf", "paperhash": "anonymous|graph_convolutional_network_with_sequential_attention_for_goaloriented_dialogue_systems", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Convolutional Network with Sequential Attention For Goal-Oriented Dialogue Systems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skz-3j05tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyVbhi0cYX", "original": "BkxranO5Ym", "number": 687, "cdate": 1538087849354, "ddate": null, "tcdate": 1538087849354, "tmdate": 1538156078008, "tddate": null, "forum": "HyVbhi0cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Complexity of Training ReLU Neural Networks", "abstract": "In this paper, we explore some basic questions on complexity of training Neural networks with ReLU activation function. We show that it is NP-hard to train a two-hidden layer feedforward ReLU neural network. If dimension d of the data is fixed then we show that there exists a polynomial time algorithm for the same training problem. We also show that if sufficient over-parameterization is provided in the first hidden layer of ReLU neural network then there is a polynomial time algorithm which finds weights such that output of the over-parameterized ReLU neural network matches with the output of the given data.", "keywords": ["NP-hardness", "ReLU activation", "Two hidden layer networks"], "authorids": ["ICLR.cc/2019/Conference/Paper687/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/afb9678e8ebcb0eb37747b1fb9c4b7a722013705.pdf", "paperhash": "anonymous|complexity_of_training_relu_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019complexity,    \ntitle={Complexity of Training ReLU Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyVbhi0cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syez3j0cKX", "original": "HyerzhcctQ", "number": 688, "cdate": 1538087849543, "ddate": null, "tcdate": 1538087849543, "tmdate": 1538156077801, "tddate": null, "forum": "Syez3j0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dissecting an Adversarial framework for Information Retrieval", "abstract": "Recent advances in Generative Adversarial Networks facilitated by improvements to the framework and successful application to various problems has resulted in extensions to multiple domains. IRGAN attempts to leverage the framework for Information-Retrieval (IR), a task that can be described as modeling the correct conditional probability distribution p(d|q) over the documents (d), given the query (q). The work that proposes IRGAN claims that optimizing their minimax loss function will result in a generator which can learn the distribution, but their setup and baseline term steer the model away from an exact adversarial formulation, and this work attempts to point out certain inaccuracies in their formulation. Analyzing their loss curves gives insight into possible mistakes in the loss functions and better performance can be obtained by using the co-training like setup we propose, where two models are trained in a co-operative rather than an adversarial fashion.", "keywords": ["GAN", "Deep Learning", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper688/Authors"], "authors": ["Anonymous"], "TL;DR": "Points out problems in loss function used in IRGAN, a recently proposed GAN framework for Information Retrieval. Further, a model motivated by co-training is proposed, which achieves better performance.", "pdf": "/pdf/1084ea8db91c45db2477963bee635d3b8bc0dc81.pdf", "paperhash": "anonymous|dissecting_an_adversarial_framework_for_information_retrieval", "_bibtex": "@inproceedings{    \nanonymous2019dissecting,    \ntitle={Dissecting an Adversarial framework for Information Retrieval},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syez3j0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgzniCqY7", "original": "rJeEvj39Y7", "number": 689, "cdate": 1538087849716, "ddate": null, "tcdate": 1538087849716, "tmdate": 1538156077591, "tddate": null, "forum": "BkgzniCqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "STRUCTURED ADVERSARIAL ATTACK: TOWARDS GENERAL IMPLEMENTATION AND BETTER INTERPRETABILITY", "abstract": "When generating adversarial examples to attack deep neural networks (DNNs), Lp norm of the added perturbation is usually used to measure the similarity between original image and adversarial example. However, such adversarial attacks perturbing the raw input spaces may fail to capture structural information hidden in the input.   This work develops a more general attack model,  i.e., the structured attack (StrAttack),  which explores group sparsity in adversarial perturbation by sliding a mask through images aiming for extracting key spatial structures.  An ADMM (alternating direction method of multipliers)-based framework is proposed that can split the original problem into a sequence of analytically solvable subproblems and can be generalized to implement other attacking methods. Strong group sparsity is achieved in adversarial perturbations even with the same level of Lp-norm distortion (p\u2208 {1,2,\u221e}) as the state-of-the-art attacks. We demonstrate the effectiveness of StrAttack by extensive experimental results on MNIST, CIFAR-10 and ImageNet. We also show that StrAttack provides better interpretability (i.e., better correspondence with discriminative image regions) through adversarial saliency map (Paper-not et al., 2016b) and class activation map (Zhou et al., 2016).", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper689/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/18ce846a53d4e03ede27e2fa02dd9908b0074e59.pdf", "paperhash": "anonymous|structured_adversarial_attack_towards_general_implementation_and_better_interpretability", "_bibtex": "@inproceedings{    \nanonymous2019structured,    \ntitle={STRUCTURED ADVERSARIAL ATTACK: TOWARDS GENERAL IMPLEMENTATION AND BETTER INTERPRETABILITY},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgzniCqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1zz2i0cY7", "original": "S1x8hZacKX", "number": 690, "cdate": 1538087849896, "ddate": null, "tcdate": 1538087849896, "tmdate": 1538156077384, "tddate": null, "forum": "S1zz2i0cY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Integer Networks for Data Compression with Latent-Variable Models", "abstract": "We consider the problem of using variational latent-variable models for data compression. For such models to produce a compressed binary sequence, which is the universal data representation in a digital world, the latent representation needs to be subjected to entropy coding. Range coding as an entropy coding technique is optimal, but it can fail catastrophically if the computation of the prior differs even slightly between the sending and the receiving side. Unfortunately, this is a common scenario when floating point math is used and the sender and receiver operate on different hardware or software platforms, as numerical round-off is often platform dependent. We propose using integer networks as a universal solution to this problem, and demonstrate that they enable reliable cross-platform encoding and decoding of images using variational models.", "keywords": ["data compression", "variational models", "network quantization"], "authorids": ["ICLR.cc/2019/Conference/Paper690/Authors"], "authors": ["Anonymous"], "TL;DR": "We train variational models with quantized networks for computational determinism. This enables using them for cross-platform data compression.", "pdf": "/pdf/3546a7e8b3ef64701ac3f6d149e3a37ea04c87be.pdf", "paperhash": "anonymous|integer_networks_for_data_compression_with_latentvariable_models", "_bibtex": "@inproceedings{    \nanonymous2019integer,    \ntitle={Integer Networks for Data Compression with Latent-Variable Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1zz2i0cY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGfnoC5KQ", "original": "BJlypba9F7", "number": 691, "cdate": 1538087850066, "ddate": null, "tcdate": 1538087850066, "tmdate": 1538156077175, "tddate": null, "forum": "ryGfnoC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Kernel Recurrent Learning (KeRL)", "abstract": "We describe Kernel Recurrent Learning (KeRL), a reduced-rank, temporal eligibility-trace based approximation to backpropagation through time (BPTT) for training recurrent neural networks (RNNs) that gives competitive performance to BPTT on long time-dependence tasks. The approximation replaces the rank-4 credit assignment tensor by a reduced-rank product of a sensitivity weight and a temporal sensitivity kernel. In this structured approximation motivated by node perturbation, sensitivity weights and relevant time scales are learned by applying perturbations. The rule represents another step toward biologically plausible or neurally inspired ML, with relaxed architectural requirements (no symmetric return weights), a smaller memory demand (no unfolding and storage of states over time), and a shorter feedback time. ", "keywords": ["RNNs", "Biologically plausible learning rules", "Algorithm", "Neural Networks", "Supervised Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper691/Authors"], "authors": ["Anonymous"], "TL;DR": "A biologically plausible learning rule for training recurrent neural networks", "pdf": "/pdf/3f19e983fc2a11a6984f70c77a2f20915875d690.pdf", "paperhash": "anonymous|kernel_recurrent_learning_kerl", "_bibtex": "@inproceedings{    \nanonymous2019kernel,    \ntitle={Kernel Recurrent Learning (KeRL)},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGfnoC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgGhiR5KX", "original": "BylVql69YX", "number": 692, "cdate": 1538087850239, "ddate": null, "tcdate": 1538087850239, "tmdate": 1538156076965, "tddate": null, "forum": "BJgGhiR5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model", "abstract": "Neural language models have been shown to achieve an impressive level of performance on a number of language processing tasks. The majority of these models, however, are limited to producing predictions for only English texts due to limited amounts of labeled data available in other languages. One potential method for overcoming this issue is learning cross-lingual text representations that can be used to transfer the performance from training on English tasks to non-English tasks, despite little to no task-specific non-English data. In this paper, we explore a natural setup for learning cross-lingual sentence representations: the dual-encoder. We provide a comprehensive evaluation of our cross-lingual representations on a number of monolingual, cross-lingual, and zero-shot/few-shot learning tasks, and also give an analysis of different learned cross-lingual embedding spaces.", "keywords": ["sentence", "embeddings", "zero-shot", "multilingual", "multi-task"], "authorids": ["ICLR.cc/2019/Conference/Paper692/Authors"], "authors": ["Anonymous"], "TL;DR": "State-of-the-art zero-shot learning performance by using a translation task to bridge multi-task training across languages.", "pdf": "/pdf/f05abe6e218cdac4e31f09178e5c9f2d50b96745.pdf", "paperhash": "anonymous|learning_crosslingual_sentence_representations_via_a_multitask_dualencoder_model", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgGhiR5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkeGhoA5FX", "original": "r1eMkfaqt7", "number": 693, "cdate": 1538087850417, "ddate": null, "tcdate": 1538087850417, "tmdate": 1538156076758, "tddate": null, "forum": "HkeGhoA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Residual Non-local Attention Networks for Image Restoration", "abstract": "In this paper, we propose a residual non-local attention network for high-quality image restoration. Without considering the uneven distribution of information in the corrupted images, previous methods are restricted by local convolutional operation and equal treatment of spatial and channel-wise features. To address this issue, we design local and non-local attention blocks to extract features that capture the long-range dependencies between pixels and pay more attention to the challenging parts. Specifically, we design trunk branch and (non-)local mask branch in each (non-)local attention block. The trunk branch is used to extract hierarchical features. Local and non-local mask branches aim to adaptively rescale these hierarchical features with soft attentions. The local mask branch concentrates on more local structures with convolutional operations, while non-local attention considers more about long-range dependencies in the whole feature map. Furthermore, we propose residual local and non-local attention learning to train the very deep network, which further enhance the representation ability of the network. We demonstrate the effectiveness of our proposed method for various image restoration tasks, including image denoising, demosaicing, compression artifacts reduction, and super-resolution. Experiments show that our method achieves comparable or better results compared with recently leading methods. ", "keywords": ["Non-local network", "attention network", "image restoration", "residual learning"], "authorids": ["ICLR.cc/2019/Conference/Paper693/Authors"], "authors": ["Anonymous"], "TL;DR": "New state-of-the-art framework for image restoration", "pdf": "/pdf/50913062efd6a277cd27261f8f3d3f413921dcde.pdf", "paperhash": "anonymous|residual_nonlocal_attention_networks_for_image_restoration", "_bibtex": "@inproceedings{    \nanonymous2019residual,    \ntitle={Residual Non-local Attention Networks for Image Restoration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkeGhoA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxXhsAcFQ", "original": "rJeFsFNqFm", "number": 694, "cdate": 1538087850603, "ddate": null, "tcdate": 1538087850603, "tmdate": 1538156076552, "tddate": null, "forum": "SyxXhsAcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cohen Welling bases & SO(2)-Equivariant classifiers using Tensor nonlinearity.", "abstract": "In this paper we propose autoencoder architectures for learning a Cohen-Welling\n(CW)-basis for images and their rotations. We use the learned CW-basis to build\na rotation equivariant classifier to classify images. The autoencoder and classi-\nfier architectures use only tensor product nonlinearity. The model proposed by\nCohen & Welling (2014) uses ideas from group representation theory, and extracts\na basis exposing irreducible representations for images and their rotations. We\ngive several architectures to learn CW-bases including a novel coupling AE archi-\ntecture to learn a coupled CW-bases for images in different scales simultaneously.\nOur use of tensor product nonlinearity is inspired from recent work of Kondor\n(2018). Our classifier has very good accuracy and we use fewer parameters. Even\nwhen the sample complexity to learn a good CW-basis is low we learn classifiers\nwhich perform impressively. We show that a coupled CW-basis in one scale can\nbe deployed to classify images in a classifier trained and tested on images in a\ndifferent scale with only a marginal dip in performance.", "keywords": ["group representations", "group equivariant networks", "tensor product nonlinearity"], "authorids": ["ICLR.cc/2019/Conference/Paper694/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e1b4ed260e9c95c50d4803e27adc311507e0b2de.pdf", "paperhash": "anonymous|cohen_welling_bases_so2equivariant_classifiers_using_tensor_nonlinearity", "_bibtex": "@inproceedings{    \nanonymous2019cohen,    \ntitle={Cohen Welling bases & SO(2)-Equivariant classifiers using Tensor nonlinearity.},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxXhsAcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlmhs05tm", "original": "rkgm-MhcFX", "number": 695, "cdate": 1538087850779, "ddate": null, "tcdate": 1538087850779, "tmdate": 1538156076344, "tddate": null, "forum": "HJlmhs05tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "EnGAN: Latent Space MCMC and Maximum Entropy Generators for Energy-based Models", "abstract": "Unsupervised learning is about capturing dependencies between variables and is driven by the contrast between the probable vs improbable configurations of these variables, often either via a generative model which only samples probable ones or with an energy function (unnormalized log-density) which is low for probable ones and high for improbable ones. Here we consider learning both an energy function and  an efficient approximate sampling mechanism for the corresponding distribution. Whereas the critic (or discriminator) in generative adversarial networks (GANs) learns to separate data and generator samples, introducing an entropy maximization regularizer on the generator can turn the interpretation of the critic into an energy function, which separates the training distribution from everything else, and thus can be used for tasks like anomaly or novelty detection. \n\nThis paper is motivated by the older idea of sampling in latent space rather than data space because running a Monte-Carlo Markov Chain (MCMC) in latent space has been found to be easier and more efficient, and because a GAN-like generator can convert latent space samples to data space samples. For this purpose, we show how a Markov chain can be run in latent space whose samples can be mapped to data space, producing better samples. These samples are also used for the negative phase gradient required to estimate the log-likelihood gradient of the data space energy function. To maximize entropy at the output of the generator, we take advantage of recently introduced neural estimators of mutual information. We find that in addition to producing a useful scoring function for anomaly detection, the resulting approach produces sharp samples (like GANs) while covering the modes well, leading to high Inception and Fr\u00e9chet scores.\n", "keywords": ["Energy based model", "Generative models", "MCMC", "GANs"], "authorids": ["ICLR.cc/2019/Conference/Paper695/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduced entropy maximization to GANs, leading to a reinterpretation of the critic as an energy function.", "pdf": "/pdf/86b479e76d7f0ff8434b0f42cf479b3a45199884.pdf", "paperhash": "anonymous|engan_latent_space_mcmc_and_maximum_entropy_generators_for_energybased_models", "_bibtex": "@inproceedings{    \nanonymous2019engan:,    \ntitle={EnGAN: Latent Space MCMC and Maximum Entropy Generators for Energy-based Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlmhs05tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeQniAqK7", "original": "SJeKXzacK7", "number": 696, "cdate": 1538087850959, "ddate": null, "tcdate": 1538087850959, "tmdate": 1538156076139, "tddate": null, "forum": "SkeQniAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Combining Learned Representations for Combinatorial Optimization", "abstract": "We propose a new approach to combine Restricted Boltzmann Machines (RBMs) that can be used to solve combinatorial optimization problems. This allows synthesis of larger models from smaller RBMs that have been pretrained, thus effectively bypassing the problem of learning in large RBMs, and creating a system able to model a large, complex multi-modal space. We validate this approach by using learned representations to create ``invertible boolean logic'', where we can use Markov chain Monte Carlo (MCMC) approaches to find the solution to large scale combinatorial optimization problems. Using this method, we are able to solve 64 bit addition based problems, as well as factorize 16 bit numbers. We find that these combined representations can provide a more accurate result for the same sample size as compared to a fully trained model.  ", "keywords": ["Generative Models", "Restricted Boltzmann Machines", "Transfer Learning", "Compositional Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper696/Authors"], "authors": ["Anonymous"], "TL;DR": "We use combinations of RBMs to solve number factorization and combinatorial optimization problems.", "pdf": "/pdf/aceaf3473f220898148a4a2410d60f91ffab725e.pdf", "paperhash": "anonymous|combining_learned_representations_for_combinatorial_optimization", "_bibtex": "@inproceedings{    \nanonymous2019combining,    \ntitle={Combining Learned Representations for Combinatorial Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeQniAqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1l73iRqKm", "original": "ryehExocFQ", "number": 697, "cdate": 1538087851130, "ddate": null, "tcdate": 1538087851130, "tmdate": 1538156075933, "tddate": null, "forum": "r1l73iRqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Wizard of Wikipedia: Knowledge-Powered Conversational Agents", "abstract": "In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically \u201cgenerate and hope\u201d generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear  grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia.  We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.", "keywords": ["dialogue", "knowledge", "language", "conversation"], "authorids": ["ICLR.cc/2019/Conference/Paper697/Authors"], "authors": ["Anonymous"], "TL;DR": "We build knowledgeable conversational agents by conditioning on Wikipedia + a new supervised task.", "pdf": "/pdf/11a6b3325d021493edb62e7d4875d0506456cda2.pdf", "paperhash": "anonymous|wizard_of_wikipedia_knowledgepowered_conversational_agents", "_bibtex": "@inproceedings{    \nanonymous2019wizard,    \ntitle={Wizard of Wikipedia: Knowledge-Powered Conversational Agents},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1l73iRqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syx72jC9tm", "original": "SklUKGpcKX", "number": 698, "cdate": 1538087851315, "ddate": null, "tcdate": 1538087851315, "tmdate": 1538156075730, "tddate": null, "forum": "Syx72jC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Invariant and Equivariant Graph Networks", "abstract": "Invariant and equivariant networks have been successfully used for learning images, sets, point clouds, and graphs. A basic challenge in developing such networks is finding the maximal collection of invariant and equivariant \\emph{linear} layers. Although this question is answered for the first three examples (for popular transformations, at-least), a full characterization of invariant and equivariant linear layers for graphs is not known. \n\nIn this paper we provide such a characterization and show that the dimension of invariant and equivariant linear layers between edge-value graph data is $2$ and $15$, respectively. More generally, for graph data defined on $k$-tuples of nodes, the dimension is the $k$-th and $2k$-th Bell numbers. Orthogonal bases for the layers are computed, including generalization to multi-graph data. The constant number of basis elements and their characteristics allow successfully applying the networks to different size graphs. From the theoretical point of view, our results generalize and unify recent advancement in equivariant deep learning. \n\nApplying these new linear layers in a simple deep neural network framework is shown to achieve comparable results to state-of-the-art and to have better expressivity than previous invariant and equivariant bases.\n", "keywords": ["graph learning", "equivariance", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper698/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper provides a full characterization of invariant and equivariant linear layers for graph data.", "pdf": "/pdf/f729a03225fba959ae1ba9ac8e3b2cf281b0e497.pdf", "paperhash": "anonymous|invariant_and_equivariant_graph_networks", "_bibtex": "@inproceedings{    \nanonymous2019invariant,    \ntitle={Invariant and Equivariant Graph Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syx72jC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1e7hs05Km", "original": "rkgUUeXcFm", "number": 699, "cdate": 1538087851512, "ddate": null, "tcdate": 1538087851512, "tmdate": 1538156075520, "tddate": null, "forum": "B1e7hs05Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Exploration through Bayesian Deep Q-Networks", "abstract": "We propose Bayesian Deep Q-Networks (BDQN), a principled and a practical Deep Reinforcement Learning (DRL) algorithm for Markov decision processes (MDP). It combines Thompson sampling with deep-Q networks (DQN). Thompson sampling ensures more efficient exploration-exploitation tradeoff in high dimensions. It is typically carried out through posterior sampling over the model parameters, which makes it computationally expensive. To overcome this limitation, we directly incorporate uncertainty over the value (Q) function. Further, we only introduce randomness in the last layer (i.e. the output layer) of the DQN and use independent Gaussian priors on the weights. This allows us to efficiently carry out Thompson sampling through Gaussian sampling and Bayesian Linear Regression (BLR), which has fast closed-form updates. The rest of the layers of the Q network are trained through back propagation, as in a standard DQN. We apply our method to a wide range of Atari games in Arcade Learning Environments and compare BDQN to a powerful baseline: the double deep Q-network (DDQN). Since BDQN carries out more efficient exploration, it is able to reach higher rewards substantially faster: in less than 5M\u00b11M samples for almost half of the games to reach DDQN scores while a typical run of DDQN is 50-200M. We also establish theoretical guarantees for the special case when the feature representation is fixed and not learnt. We show that the Bayesian regret is bounded by O\udbff\udc12(d \\sqrt(N)) after N time steps for a d-dimensional feature map, and this bound is shown to be tight up-to logarithmic factors. To the best of our knowledge, this is the first Bayesian theoretical guarantee for Markov Decision Processes (MDP) beyond the tabula rasa setting.", "keywords": ["Deep RL", "Exploration Exploitation", "DQN", "Bayesian Regret", "Thompson Sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper699/Authors"], "authors": ["Anonymous"], "TL;DR": "Using Bayesian regression for the last layer of DQN, and do Thompson Sampling for exploration. With Bayesian Regret bound", "pdf": "/pdf/98a70027bac1d21f2c7d6f3f576ddd180e311af6.pdf", "paperhash": "anonymous|efficient_exploration_through_bayesian_deep_qnetworks", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Exploration through Bayesian Deep Q-Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e7hs05Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkl42iA5t7", "original": "H1g_KrhcKm", "number": 700, "cdate": 1538087851700, "ddate": null, "tcdate": 1538087851700, "tmdate": 1538156075315, "tddate": null, "forum": "rkl42iA5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES", "abstract": "Principal Filter Analysis (PFA) is an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprint. We propose two compression algorithms: the first allows a user to specify the proportion of the original spectral energy that should be preserved in each layer after compression, while the second is a heuristic that leads to a parameter-free approach that automatically selects the compression used at each layer. Both algorithms are evaluated against several architectures and datasets, and we show considerable compression rates without compromising accuracy, e.g., for VGG-16 on CIFAR-10 and CIFAR-100 PFA achieves a compression rate of 8x and 3x with an accuracy gain of 0.4% points and 1.4% points, respectively. In our tests we also demonstrate that networks compressed with PFA achieve an accuracy that is very close to the empirical upper bound for a given compression ratio. Finally, we show how PFA is an effective tool for simultaneous compression and domain adaptation.", "keywords": ["Artificial Intelligence", "Deep learning", "Machine learning", "Compression"], "authorids": ["ICLR.cc/2019/Conference/Paper700/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints.", "pdf": "/pdf/6cdf3cc87b5326e20d8c23dc0adc476214ca37ba.pdf", "paperhash": "anonymous|network_compression_using_correlation_analysis_of_layer_responses", "_bibtex": "@inproceedings{    \nanonymous2019network,    \ntitle={NETWORK COMPRESSION USING CORRELATION ANALYSIS OF LAYER RESPONSES},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl42iA5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlVhsA5KX", "original": "BylINMa5Ym", "number": 701, "cdate": 1538087851879, "ddate": null, "tcdate": 1538087851879, "tmdate": 1538156075107, "tddate": null, "forum": "BJlVhsA5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sequenced-Replacement Sampling for Deep Learning", "abstract": "We propose sequenced-replacement sampling (SRS) for training deep neural networks. The basic idea is to assign a fixed sequence index to each sample in the dataset. Once a mini-batch is randomly drawn in each training iteration, we refill the original dataset by successively adding samples according to their sequence index. Thus we carry out replacement sampling but in a batched and sequenced way. In a sense, SRS could be viewed as a way of performing \"mini-batch augmentation\". It is particularly useful for a task where we have a relatively small images-per-class such as CIFAR-100. Together with a longer period of initial large learning rate, it significantly improves the classification accuracy in CIFAR-100 over the current state-of-the-art results. Our experiments indicate that training deeper networks with SRS is less prone to over-fitting. In the best case, we achieve an error rate as low as 10.10%.", "keywords": ["deep neural networks", "stochastic gradient descent", "sequenced-replacement sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper701/Authors"], "authors": ["Anonymous"], "TL;DR": "Proposed a novel way (without adding new parameters) of training deep neural network in order to improve generalization, especially for the case where we have relatively small images-per-class.", "pdf": "/pdf/d5e0c948a797ea18533ba50e7c7f8e167e9b71f1.pdf", "paperhash": "anonymous|sequencedreplacement_sampling_for_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019sequenced-replacement,    \ntitle={Sequenced-Replacement Sampling for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlVhsA5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1fE3sAcYQ", "original": "H1gEt5qqYX", "number": 702, "cdate": 1538087852068, "ddate": null, "tcdate": 1538087852068, "tmdate": 1538156074900, "tddate": null, "forum": "r1fE3sAcYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Overcoming Neural Brainwashing", "abstract": "We identify a phenomenon, which we dub neural brainwashing, that occurs when sequentially training multiple deep networks with partially-shared parameters; the performance of previously-trained models degrades as one optimizes a subsequent one, due to the overwriting of shared parameters. To overcome this, we introduce a statistically-justified weight plasticity loss that regularizes the learning of a model's shared parameters according to their importance for the previous models, and demonstrate its effectiveness when training two models sequentially and for neural architecture search.", "keywords": ["brainwashing", "deep learning", "machine learning", "multi-model training", "neural architecture search"], "authorids": ["ICLR.cc/2019/Conference/Paper702/Authors"], "authors": ["Anonymous"], "TL;DR": "We identify a phenomenon, neural brainwashing, and introduce a statistically-justified weight plasticity loss to overcome this.", "pdf": "/pdf/57e5c30dd24af6f1ff4630bb5a265c1ee7956574.pdf", "paperhash": "anonymous|overcoming_neural_brainwashing", "_bibtex": "@inproceedings{    \nanonymous2019overcoming,    \ntitle={Overcoming Neural Brainwashing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1fE3sAcYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gNni0qtm", "original": "rkxe7XT5t7", "number": 703, "cdate": 1538087852238, "ddate": null, "tcdate": 1538087852238, "tmdate": 1538156074698, "tddate": null, "forum": "r1gNni0qtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generalized Tensor Models for Recurrent Neural Networks", "abstract": "Recurrent Neural Networks (RNNs) are very successful at solving challenging problems with sequential data. However, this observed efficiency is not yet entirely explained by theory. It is known that a certain class of multiplicative RNNs enjoys the property of depth efficiency --- a shallow network of exponentially large width is necessary to realize the same score function as computed by such an RNN. Such networks, however, are not very often applied to real life tasks. In this work, we attempt to reduce the gap between theory and practice by extending the theoretical analysis to RNNs which employ various nonlinearities, such as Rectified Linear Unit (ReLU), and show that they also benefit from properties of universality and depth efficiency. Our theoretical results are verified by a series of extensive computational experiments.", "keywords": ["expressive power", "recurrent neural networks", "Tensor-Train decomposition"], "authorids": ["ICLR.cc/2019/Conference/Paper703/Authors"], "authors": ["Anonymous"], "TL;DR": "Analysis of expressivity and generality of recurrent neural networks with ReLu nonlinearities using Tensor-Train decomposition.", "pdf": "/pdf/751f414ac71cc8be5eb34686bbfc2cdc58151a64.pdf", "paperhash": "anonymous|generalized_tensor_models_for_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019generalized,    \ntitle={Generalized Tensor Models for Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gNni0qtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lVniC5Y7", "original": "B1xgz165tm", "number": 704, "cdate": 1538087852416, "ddate": null, "tcdate": 1538087852416, "tmdate": 1538156074493, "tddate": null, "forum": "S1lVniC5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "From Nodes to Networks: Evolving Recurrent Neural Networks", "abstract": "Gated recurrent networks such as those composed of Long Short-Term Memory\n(LSTM) nodes have recently been used to improve state of the art in many sequential\nprocessing tasks such as speech recognition and machine translation. However,\nthe basic structure of the LSTM node is essentially the same as when it was\nfirst conceived 25 years ago. Recently, evolutionary and reinforcement learning\nmechanisms have been employed to create new variations of this structure. This\npaper proposes a new method, evolution of a tree-based encoding of the gated\nmemory nodes, and shows that it makes it possible to explore new variations more\neffectively than other methods. The method discovers nodes with multiple recurrent\npaths and multiple memory cells, which lead to significant improvement in the\nstandard language modeling benchmark task. Remarkably, this node did not perform\nwell in another task, music modeling, but it was possible to evolve a different\nnode that did, demonstrating that the approach discovers customized structure for\neach task. The paper also shows how the search process can be speeded up by\ntraining an LSTM network to estimate performance of candidate structures, and\nby encouraging exploration of novel solutions. Thus, evolutionary design of complex\nneural network structures promises to improve performance of deep learning\narchitectures beyond human ability to do so.", "keywords": ["Recurrent neural networks", "evolutionary algorithms", "genetic programming"], "authorids": ["ICLR.cc/2019/Conference/Paper704/Authors"], "authors": ["Anonymous"], "TL;DR": "Genetic programming to evolve new recurrent nodes for language and music. Uses a LSTM model to predict the performance of the recurrent node. ", "pdf": "/pdf/5fa938d04617bb6f945d2558a6b1a7a17bd9264a.pdf", "paperhash": "anonymous|from_nodes_to_networks_evolving_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019from,    \ntitle={From Nodes to Networks: Evolving Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lVniC5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eB3sRqtm", "original": "HyxsL8hcYX", "number": 705, "cdate": 1538087852589, "ddate": null, "tcdate": 1538087852589, "tmdate": 1538156074288, "tddate": null, "forum": "S1eB3sRqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploring Curvature Noise in Large-Batch Stochastic Optimization", "abstract": "Using stochastic gradient descent (SGD) with large batch-sizes to train deep neural networks is an increasingly popular technique. By doing so, one can improve parallelization by scaling to multiple workers (GPUs) and hence leading to significant reductions in training time. Unfortunately, a major drawback is the so-called generalization gap: large-batch training typically leads to a degradation in generalization performance of the model as compared to small-batch training. In this paper, we propose to correct this generalization gap by adding diagonal Fisher curvature noise to large-batch gradient updates. We provide a theoretical analysis of our method in the convex quadratic setting. Our empirical study with state-of-the-art deep learning models shows that our method not only improves the generalization performance in large-batch training but furthermore, does so in a way where the training convergence remains desirable and the training duration is not elongated. We additionally connect our method to recent works on loss surface landscape in the experimental section. ", "keywords": ["optimization", "large-batch training", "generalization", "noise covariance"], "authorids": ["ICLR.cc/2019/Conference/Paper705/Authors"], "authors": ["Anonymous"], "TL;DR": "Engineer large-batch training such that we retain fast training while achieving better generalization.", "pdf": "/pdf/d9e4a4b1841459c6f63f333204ad7214e3e95590.pdf", "paperhash": "anonymous|exploring_curvature_noise_in_largebatch_stochastic_optimization", "_bibtex": "@inproceedings{    \nanonymous2019exploring,    \ntitle={Exploring Curvature Noise in Large-Batch Stochastic Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eB3sRqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylBns0qtX", "original": "Bklq1Oh5KQ", "number": 706, "cdate": 1538087852763, "ddate": null, "tcdate": 1538087852763, "tmdate": 1538156074085, "tddate": null, "forum": "BylBns0qtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Learning Heteroscedastic Noise Models within Differentiable Bayes Filters", "abstract": "In many robotic applications, it is crucial to maintain a belief about the state of \na system, like the location of a robot or the pose of an object.\nThese state estimates serve as input for planning and decision making and \nprovide feedback during task execution. \nRecursive Bayesian Filtering algorithms address the state estimation problem,\nbut they require a model of the process dynamics and the sensory observations as well as \nnoise estimates that quantify the accuracy of these models. \nRecently, multiple works have demonstrated that the process and sensor models can be \nlearned by end-to-end training through differentiable versions of Recursive Filtering methods.\nHowever, even if the predictive models are known, finding suitable noise models \nremains challenging. Therefore, many practical applications rely on very simplistic noise \nmodels. \nOur hypothesis is that end-to-end training through differentiable Bayesian \nFilters enables us to learn more complex heteroscedastic noise models for\nthe system dynamics. We evaluate learning such models with different types of \nfiltering algorithms and on two different robotic tasks. Our experiments show that especially \nfor sampling-based filters like the Particle Filter, learning heteroscedastic noise \nmodels can drastically improve the tracking performance in comparison to using \nconstant noise models.", "keywords": ["bayesian filtering", "heteroscedastic noise", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper706/Authors"], "authors": ["Anonymous"], "TL;DR": "We evaluate learning heteroscedastic noise models within different Differentiable Bayes Filters", "pdf": "/pdf/3a6a24c2347f3673150e521e912579db67268429.pdf", "paperhash": "anonymous|on_learning_heteroscedastic_noise_models_within_differentiable_bayes_filters", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Learning Heteroscedastic Noise Models within Differentiable Bayes Filters},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylBns0qtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkGSniC9FQ", "original": "SkxgLg_cK7", "number": 707, "cdate": 1538087852938, "ddate": null, "tcdate": 1538087852938, "tmdate": 1538156073881, "tddate": null, "forum": "HkGSniC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Analysis of Composite Neural Network Performance from Function Composition Perspective", "abstract": "This work investigates the performance of a composite neural network, which is composed of pre-trained neural network models and non-instantiated neural network models, connected to form a rooted directed graph. A pre-trained neural network model is generally a well trained neural network model targeted for a specific function. The advantages of adopting such a pre-trained model in a composite neural network are two folds. One is to benefit from other's intelligence and diligence and the other is saving the efforts in data preparation and resources and time in training. However, the overall performance of composite neural network is still not clear. In this work, we prove that a composite neural network, with high probability, performs better than any of its pre-trained components under certain assumptions. In addition, if an extra pre-trained component is added to a composite network, with high probability the overall performance will be improved. In the empirical evaluations, distinctively different applications support the above findings.   ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper707/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fb153bc4c9425cda0123b2cac2567b7c64ec6643.pdf", "paperhash": "anonymous|an_analysis_of_composite_neural_network_performance_from_function_composition_perspective", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Analysis of Composite Neural Network Performance from Function Composition Perspective},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGSniC9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxH2o05FQ", "original": "BJlEqG99YQ", "number": 708, "cdate": 1538087853114, "ddate": null, "tcdate": 1538087853114, "tmdate": 1538156073668, "tddate": null, "forum": "HyxH2o05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Domain Adaptive Transfer Learning", "abstract": "Transfer learning is a widely used method to build high performing computer vision models. In this paper, we study the efficacy of transfer learning by examining how the choice of data impacts performance. We find that more pre-training data does not always help, and transfer performance depends on a judicious choice of pre-training data. These findings are important given the continued increase in dataset sizes. We further propose domain adaptive transfer learning, a simple and effective pre-training method using importance weights computed based on the target dataset. Our methods achieve state-of-the-art results on multiple fine-grained classification datasets and are well-suited for use in practice.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper708/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c99d57f55de88a6c1e3a3f6525526550c15e61e1.pdf", "paperhash": "anonymous|domain_adaptive_transfer_learning", "_bibtex": "@inproceedings{    \nanonymous2019domain,    \ntitle={Domain Adaptive Transfer Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxH2o05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bklr3j0cKX", "original": "BkeC4T8qKQ", "number": 709, "cdate": 1538087853286, "ddate": null, "tcdate": 1538087853286, "tmdate": 1538156073454, "tddate": null, "forum": "Bklr3j0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning deep representations by mutual information estimation and maximization", "abstract": "In this work, we perform unsupervised learning of representations by maximizing mutual information between an input and the output of a deep neural network encoder. Importantly, we show that structure matters: incorporating knowledge about locality of the input to the objective can greatly influence a representation's suitability for downstream tasks. We further control characteristics of the representation by matching to a prior distribution adversarially. Our method, which we call Deep InfoMax (DIM), outperforms a number of popular unsupervised learning methods and competes with fully-supervised learning on several classification tasks. DIM opens new avenues for unsupervised learning of representations and is an important step towards the flexible formulation of representation-learning objectives for specific end-goals.", "keywords": ["representation learning", "unsupervised learning", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper709/Authors"], "authors": ["Anonymous"], "TL;DR": "We learn deep representation by maximizing mutual information, leveraging structure in the objective, and are able to compute with fully supervised classifiers with comparable architectures", "pdf": "/pdf/6952f114dd049ae92c9aafe825897cadb1d133f8.pdf", "paperhash": "anonymous|learning_deep_representations_by_mutual_information_estimation_and_maximization", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning deep representations by mutual information estimation and maximization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bklr3j0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGH2oRcYX", "original": "H1xPKYqqF7", "number": 710, "cdate": 1538087853458, "ddate": null, "tcdate": 1538087853458, "tmdate": 1538156073227, "tddate": null, "forum": "SkGH2oRcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DEEP ADVERSARIAL FORWARD MODEL", "abstract": "Learning world dynamics has recently been investigated as a way to make reinforcement\nlearning (RL) algorithms to be more sample efficient and interpretable.\nIn this paper, we propose to capture an environment dynamics with a novel forward\nmodel that leverages recent works on adversarial learning and visual control. Such\na model estimates future observations conditioned on the current ones and other\ninput variables such as actions taken by an RL-agent. We focus on image generation\nwhich is a particularly challenging topic but our method can be adapted to\nother modalities. More precisely, our forward model is trained to produce realistic\nobservations of the future while a discriminator model is trained to distinguish\nbetween real images and the model\u2019s prediction of the future. This approach overcomes\nthe need to define an explicit loss function for the forward model which is currently\nused for solving such a class of problem. As a consequence, our learning protocol\ndoes not have to rely on an explicit distance such as Euclidean distance which\ntends to produce unsatisfactory predictions. To illustrate our method, empirical\nqualitative and quantitative results are presented on a real driving scenario, along\nwith qualitative results on Atari game Frostbite.", "keywords": ["forward model", "adversarial learning"], "authorids": ["ICLR.cc/2019/Conference/Paper710/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1a9692a0f310b0072e87e82f8724319ca006834e.pdf", "paperhash": "anonymous|deep_adversarial_forward_model", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={DEEP ADVERSARIAL FORWARD MODEL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGH2oRcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygInj05Fm", "original": "rJeiTQBqYm", "number": 711, "cdate": 1538087853632, "ddate": null, "tcdate": 1538087853632, "tmdate": 1538156073015, "tddate": null, "forum": "SygInj05Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Physiological Signal Embeddings (PHASE) via Interpretable Stacked Models", "abstract": "In health, machine learning is increasingly common, yet neural network embedding (representation) learning is arguably under-utilized for physiological signals.  This inadequacy stands out in stark contrast to more traditional computer science domains, such as computer vision (CV), and natural language processing (NLP).  For physiological signals, learning feature embeddings is a natural solution to data insufficiency caused by patient privacy concerns -- rather than share data, researchers may share informative embedding models (i.e., representation models), which map patient data to an output embedding.   Here, we present the PHASE (PHysiologicAl Signal Embeddings) framework, which consists of three components: i) learning neural network embeddings of physiological signals, ii) predicting outcomes based on the learned embedding, and iii) interpreting the prediction results by estimating feature attributions in the \"stacked\" models (i.e., feature embedding model followed by prediction model).  PHASE is novel in three ways: 1) To our knowledge, PHASE is the first instance of transferal of neural networks to create physiological signal embeddings. 2) We present a tractable method to obtain feature attributions through stacked models.  We prove that our stacked model attributions can approximate Shapley values -- attributions known to have desirable properties -- for arbitrary sets of models. 3) PHASE was extensively tested in a cross-hospital setting including publicly available data.  In our experiments, we show that PHASE significantly outperforms alternative embeddings -- such as raw, exponential moving average/variance, and autoencoder -- currently in use. Furthermore, we provide evidence that transferring neural network embedding/representation learners between distinct hospitals still yields performant embeddings.", "keywords": ["Representation learning", "transfer learning", "health", "machine learning", "physiological signals", "interpretation", "feature attributions", "shapley values", "univariate embeddings", "LSTMs", "XGB", "neural networks", "stacked models", "model pipelines", "interpretable stacked models"], "authorids": ["ICLR.cc/2019/Conference/Paper711/Authors"], "authors": ["Anonymous"], "TL;DR": "Physiological signal embeddings for prediction performance and hospital transference with a general Shapley value interpretability method for stacked models.", "pdf": "/pdf/8aeb5258e4fa20ac3e099d499e9ab62cda05e460.pdf", "paperhash": "anonymous|physiological_signal_embeddings_phase_via_interpretable_stacked_models", "_bibtex": "@inproceedings{    \nanonymous2019physiological,    \ntitle={Physiological Signal Embeddings (PHASE) via Interpretable Stacked Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygInj05Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJe8niAqKX", "original": "ByeM5UDcFX", "number": 712, "cdate": 1538087853814, "ddate": null, "tcdate": 1538087853814, "tmdate": 1538156072807, "tddate": null, "forum": "BJe8niAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Grounded Sentence Representations by Jointly Using Video and Text Information", "abstract": "Visual grounding of language is an active research field aiming at enriching text-based representations with visual information. In this paper, we propose a new way to leverage visual knowledge for sentence representations. Our approach transfers the structure of a visual representation space to the textual space by using two complementary sources of information: (1) the cluster information: the implicit knowledge that two sentences associated with the same visual content describe the same underlying reality and (2) the perceptual information contained within the structure of the visual space. We use a joint approach to encourage beneficial interactions during training between textual, perceptual, and cluster information. We demonstrate the quality of the learned representations on semantic relatedness, classification, and cross-modal retrieval tasks.", "keywords": ["multimodal", "sentence", "representation", "embedding", "grounding"], "authorids": ["ICLR.cc/2019/Conference/Paper712/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a joint model to incorporate visual knowledge in sentence representations", "pdf": "/pdf/53981a1ccee080ed45eb87db1054eb2586a73aef.pdf", "paperhash": "anonymous|learning_grounded_sentence_representations_by_jointly_using_video_and_text_information", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Grounded Sentence Representations by Jointly Using Video and Text Information},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe8niAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyeLno09Fm", "original": "r1efjSvtYQ", "number": 713, "cdate": 1538087853988, "ddate": null, "tcdate": 1538087853988, "tmdate": 1538156072597, "tddate": null, "forum": "SyeLno09Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Few-Shot Intent Inference via Meta-Inverse Reinforcement Learning", "abstract": "A significant challenge for the practical application of reinforcement learning toreal world problems is the need to specify an oracle reward function that correctly defines a task. Inverse reinforcement learning (IRL) seeks to avoid this challenge by instead inferring a reward function from expert behavior.  While appealing, it can be impractically expensive to collect datasets of demonstrations that cover the variation common in the real world (e.g. opening any type of door). Thus in practice, IRL must commonly be performed with only a limited set of demonstrations where it can be exceedingly difficult to unambiguously recover a reward function. In this work, we exploit the insight that demonstrations from other tasks can be used to constrain the set of possible reward functions by learning a \"prior\" that is specifically optimized for the ability to infer expressive reward functions from limited numbers of demonstrations.  We demonstrate that our method can efficiently recover rewards from images for novel tasks and provide intuition as to how our approach is analogous to learning a prior.", "keywords": ["Inverse Reinforcement Learning", "Meta-Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper713/Authors"], "authors": ["Anonymous"], "TL;DR": "The applicability of inverse reinforcement learning is often hampered by the expense of collecting expert demonstrations; this paper seeks to broaden its applicability by incorporating prior task information through meta-learning.", "pdf": "/pdf/1ad5fa3afb02a1642963e437cfdf552e2795d98b.pdf", "paperhash": "anonymous|fewshot_intent_inference_via_metainverse_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019few-shot,    \ntitle={Few-Shot Intent Inference via Meta-Inverse Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyeLno09Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SylU3jC5Y7", "original": "BkeorX6qYm", "number": 714, "cdate": 1538087854174, "ddate": null, "tcdate": 1538087854174, "tmdate": 1538156072394, "tddate": null, "forum": "SylU3jC5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ADAPTIVE NETWORK SPARSIFICATION VIA DEPENDENT VARIATIONAL BETA-BERNOULLI DROPOUT", "abstract": "While variational dropout approaches have been shown to be effective for network sparsification, they are still suboptimal in the sense that they set the dropout rate for each neuron without consideration of the input data. With such input-independent dropout, each neuron is evolved to be generic across inputs, which makes it difficult to sparsify networks without accuracy loss. To overcome this limitation, we propose adaptive variational dropout whose probabilities are drawn from sparsity-inducing beta-Bernoulli prior. It allows each neuron to be evolved either to be generic or specific for certain inputs, or dropped altogether. Such input-adaptive sparsity-inducing dropout allows the resulting network to tolerate larger degree of sparsity without losing its expressive power by removing redundancies among features. We validate our dependent variational beta-Bernoulli dropout on multiple public datasets, on which it obtains significantly more compact networks than baseline methods, with consistent accuracy improvements over the base networks.", "keywords": ["Bayesian deep learning", "network pruning"], "authorids": ["ICLR.cc/2019/Conference/Paper714/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel Bayesian network sparsification method that adaptively prunes networks according to inputs.", "pdf": "/pdf/0eec3327d4cf03e16ee96f686ddf1ae294c62ab3.pdf", "paperhash": "anonymous|adaptive_network_sparsification_via_dependent_variational_betabernoulli_dropout", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={ADAPTIVE NETWORK SPARSIFICATION VIA DEPENDENT VARIATIONAL BETA-BERNOULLI DROPOUT},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SylU3jC5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byx83s09Km", "original": "H1l9f-nctm", "number": 715, "cdate": 1538087854349, "ddate": null, "tcdate": 1538087854349, "tmdate": 1538156072190, "tddate": null, "forum": "Byx83s09Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Information-Directed Exploration for Deep Reinforcement Learning", "abstract": "Efficient exploration remains a major challenge for reinforcement learning. One reason is that the variability of the returns often depends on the current state and action, and is therefore heteroscedastic. Classical exploration strategies such as upper confidence bound algorithms and Thompson sampling fail to appropriately account for heteroscedasticity, even in the bandit setting. Motivated by recent findings that address this issue in bandits, we propose to use Information-Directed Sampling (IDS) for exploration in reinforcement learning. As our main contribution, we build on recent advances in distributional reinforcement learning and propose a novel, tractable approximation of IDS for deep Q-learning. The resulting exploration strategy explicitly accounts for both parametric uncertainty and heteroscedastic observation noise. We evaluate our method on Atari games and demonstrate a significant improvement over alternative approaches.", "keywords": ["reinforcement learning", "exploration", "information directed sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper715/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a practical extension of Information-Directed Sampling for Reinforcement Learning, which accounts for parametric uncertainty and heteroscedasticity in the return distribution for exploration.", "pdf": "/pdf/ddb940743bc8fe79be68d0bb6542e4c2c978a1eb.pdf", "paperhash": "anonymous|informationdirected_exploration_for_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019information-directed,    \ntitle={Information-Directed Exploration for Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byx83s09Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlDnoA5Y7", "original": "ryxs9IFcF7", "number": 716, "cdate": 1538087854520, "ddate": null, "tcdate": 1538087854520, "tmdate": 1538156071978, "tddate": null, "forum": "rJlDnoA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs", "abstract": "The Softmax function is used in the final layer of nearly all existing sequence-to-sequence models for language generation. However, it is usually the slowest layer to compute which limits the vocabulary size to a subset of most frequent types; and it has a large memory footprint. We propose a general technique for replacing the softmax layer with a continuous embedding layer. Our primary innovations are a novel probabilistic loss, and a training and inference procedure in which we generate a probability distribution over pre-trained word embeddings, instead of a multinomial distribution over the vocabulary obtained via softmax. We evaluate this new class of sequence-to-sequence models with continuous outputs on the task of neural machine translation. We show that our models obtain upto 2.5x speed-up in training time while performing on par with the state-of-the-art models in terms of translation quality. These models are capable of handling very large vocabularies without compromising on translation quality. They also produce more meaningful errors than in the softmax-based models, as these errors typically lie in a subspace of the vector space of the reference translations.", "keywords": ["Language Generation", "Regression", "Word Embeddings", "Machine Translation"], "authorids": ["ICLR.cc/2019/Conference/Paper716/Authors"], "authors": ["Anonymous"], "TL;DR": "Language generation using seq2seq models which produce word embeddings instead of a softmax based distribution over the vocabulary at each step enabling much faster training while maintaining generation quality", "pdf": "/pdf/1a9b2e5fbf5df399cd513f34b48f9f71cbfc7dd5.pdf", "paperhash": "anonymous|von_misesfisher_loss_for_training_sequence_to_sequence_models_with_continuous_outputs", "_bibtex": "@inproceedings{    \nanonymous2019von,    \ntitle={Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlDnoA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJePno0cYm", "original": "H1ll8Y2qKm", "number": 717, "cdate": 1538087854695, "ddate": null, "tcdate": 1538087854695, "tmdate": 1538156071779, "tddate": null, "forum": "HJePno0cYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transformer-XL: Language Modeling with Longer-Term Dependency", "abstract": "We propose a novel neural architecture, Transformer-XL, for modeling longer-term dependency. To address the limitation of fixed-length contexts, we introduce a notion of recurrence by reusing the representations from the history. Empirically, we show state-of-the-art (SoTA) results on both word-level and character-level language modeling datasets, including WikiText-103, One Billion Word, Penn Treebank, and enwiki8. Notably, we improve the SoTA result on WikiText-103 by 9 perplexity points down to 24, and achieve a 1.03 bpc on enwiki8 with 60+% fewer parameters than the previous SoTA. Performance improves when the attention length increases during evaluation, and our best model attends to up to 640 words and 3,800 characters. To quantify the effective length of dependency, we devise a new metric and show that on WikiText-103 Transformer-XL manages to model dependency of 900 words long on average, about 80% longer than recurrent networks and 450% longer than Transformer. Moreover, Transformer-XL is up to 1800+ times faster than vanilla Transformer during evaluation.", "keywords": ["Language Modeling", "Self-Attention"], "authorids": ["ICLR.cc/2019/Conference/Paper717/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0f149ba396a5c02e76a5fb7642bdbcb7a765cb72.pdf", "paperhash": "anonymous|transformerxl_language_modeling_with_longerterm_dependency", "_bibtex": "@inproceedings{    \nanonymous2019transformer-xl:,    \ntitle={Transformer-XL: Language Modeling with Longer-Term Dependency},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJePno0cYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklvnjRqY7", "original": "B1gjY429FQ", "number": 718, "cdate": 1538087854869, "ddate": null, "tcdate": 1538087854869, "tmdate": 1538156071573, "tddate": null, "forum": "rklvnjRqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A PRIVACY-PRESERVING IMAGE CLASSIFICATION FRAMEWORK WITH A LEARNABLE OBFUSCATOR", "abstract": "Real world images often contain large amounts of private / sensitive information that should be carefully protected without reducing their utilities. In this paper, we propose a privacy-preserving deep learning framework with a learnable ob- fuscator for the image classification task. Our framework consists of three mod- els: learnable obfuscator, classifier and reconstructor. The learnable obfuscator is used to remove the sensitive information in the images and extract the feature maps from them. The reconstructor plays the role as an attacker, which tries to recover the image from the feature maps extracted by the obfuscator. In order to best protect users\u2019 privacy in images, we design an adversarial training methodol- ogy for our framework to optimize the obfuscator. Through extensive evaluations on real world datasets, both the numerical metrics and the visualization results demonstrate that our framework is qualified to protect users\u2019 privacy and achieve a relatively high accuracy on the image classification task.", "keywords": ["privacy-preserving", "image classification", "adversarial training", "learnable obfuscator"], "authorids": ["ICLR.cc/2019/Conference/Paper718/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed a novel deep learning image classification framework that can both accurately classify images and protect users' privacy.", "pdf": "/pdf/752815624ec5f12edeeb071f79df32b66b302874.pdf", "paperhash": "anonymous|a_privacypreserving_image_classification_framework_with_a_learnable_obfuscator", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A PRIVACY-PRESERVING IMAGE CLASSIFICATION FRAMEWORK WITH A LEARNABLE OBFUSCATOR},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklvnjRqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkfPnoActQ", "original": "SJeTlEo5KQ", "number": 719, "cdate": 1538087855042, "ddate": null, "tcdate": 1538087855042, "tmdate": 1538156071369, "tddate": null, "forum": "BkfPnoActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards Consistent Performance on Atari using Expert Demonstrations", "abstract": "Despite significant advances in the field of deep Reinforcement Learning (RL), today's algorithms still fail to learn human-level policies consistently over a set of diverse tasks such as Atari 2600 games. We identify three key challenges that any algorithm needs to master in order to perform well on all games:  processing diverse reward distributions, reasoning over long time horizons, and exploring efficiently.  In this paper, we propose an algorithm that addresses each of these challenges and is able to learn human-level policies on nearly all Atari games. A new transformed Bellman operator allows our algorithm to process rewards of varying densities and scales; an auxiliary temporal consistency loss allows us to train stably using a discount factor of 0.999 (instead of 0.99) extending the effective planning horizon by an order of magnitude; and we ease the exploration problem by using human demonstrations that guide the agent towards rewarding states. When tested on a set of 42 Atari games, our algorithm exceeds the performance  of an average human on 40 games using a common set of hyper parameters.", "keywords": ["Reinforcement Learning", "Atari", "RL", "Demonstrations"], "authorids": ["ICLR.cc/2019/Conference/Paper719/Authors"], "authors": ["Anonymous"], "TL;DR": "Ape-X DQfD = Distributed (many actors + one learner + prioritized replay) DQN with demonstrations optimizing the unclipped 0.999-discounted return on Atari.", "pdf": "/pdf/be4b43074e9c1a938b1fe4964d97009503d49418.pdf", "paperhash": "anonymous|towards_consistent_performance_on_atari_using_expert_demonstrations", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Consistent Performance on Atari using Expert Demonstrations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkfPnoActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJGvns0qK7", "original": "H1lYWgv5KX", "number": 720, "cdate": 1538087855219, "ddate": null, "tcdate": 1538087855219, "tmdate": 1538156071159, "tddate": null, "forum": "SJGvns0qK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bayesian Policy Optimization for Model Uncertainty", "abstract": "Addressing uncertainty is critical for autonomous systems to robustly adapt to the real world. We formulate the problem of model uncertainty as a continuous Bayes-Adaptive Markov Decision Process (BAMDP), where an agent maintains a posterior distribution over the latent model parameters given a history of observations and maximizes its expected long-term reward with respect to this belief distribution. Our algorithm, Bayesian Policy Optimization, builds on recent policy optimization algorithms to learn a universal policy that navigates the exploration-exploitation trade-off to maximize the Bayesian value function. To address challenges from discretizing the continuous latent parameter space, we propose a policy network architecture that independently encodes the belief distribution from the observable state. Our method significantly outperforms algorithms that address model uncertainty without explicitly reasoning about belief distributions, and is competitive with state-of-the-art Partially Observable Markov Decision Process solvers.", "keywords": ["Bayes-Adaptive Markov Decision Process", "Model Uncertainty", "Bayes Policy Optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper720/Authors"], "authors": ["Anonymous"], "TL;DR": "We formulate model uncertainty in Reinforcement Learning as a continuous Bayes-Adaptive Markov Decision Process and present a method for practical and scalable Bayesian policy optimization.", "pdf": "/pdf/234c49ef436f92cdb4c909f52cb9e4faea5bf16c.pdf", "paperhash": "anonymous|bayesian_policy_optimization_for_model_uncertainty", "_bibtex": "@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Policy Optimization for Model Uncertainty},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJGvns0qK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyevnsCqtQ", "original": "Hklb_Kq9K7", "number": 721, "cdate": 1538087855389, "ddate": null, "tcdate": 1538087855389, "tmdate": 1538156070953, "tddate": null, "forum": "HyevnsCqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Integral Pruning on Activations and Weights for Efficient Neural Networks", "abstract": "With the rapidly scaling up of deep neural networks (DNNs), extensive research studies on network model compression such as weight pruning have been performed for efficient deployment. This work aims to advance the compression beyond the weights to the activations of DNNs. We propose the Integral Pruning (IP) technique which integrates the activation pruning with the weight pruning. Through the learning on the different importance of neuron responses and connections, the generated network, namely IPnet, balances the sparsity between activations and weights and therefore further improves execution efficiency. The feasibility and effectiveness of IPnet are thoroughly evaluated through various network models with different activation functions and on different datasets. With <0.5% disturbance on the testing accuracy, IPnet saves 71.1% ~ 96.35% of computation cost, compared to the original dense models with up to 5.8x and 10x reductions in activation and weight numbers, respectively. ", "keywords": ["activation pruning", "weight pruning", "computation cost reduction", "efficient DNNs"], "authorids": ["ICLR.cc/2019/Conference/Paper721/Authors"], "authors": ["Anonymous"], "TL;DR": "This work advances DNN compression beyond the weights to the activations by integrating the activation pruning with the weight pruning. ", "pdf": "/pdf/65da05c8d1598fa48f13c586a0e576acb5c88050.pdf", "paperhash": "anonymous|integral_pruning_on_activations_and_weights_for_efficient_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019integral,    \ntitle={Integral Pruning on Activations and Weights for Efficient Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyevnsCqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxd2oR9Y7", "original": "BklreE6ctQ", "number": 722, "cdate": 1538087855559, "ddate": null, "tcdate": 1538087855559, "tmdate": 1538156070751, "tddate": null, "forum": "rkxd2oR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Case for Full-Matrix Adaptive Regularization", "abstract": "Adaptive regularization methods pre-multiply a descent direction by a preconditioning matrix. Due to the large number of parameters of machine learning problems, full-matrix preconditioning methods are prohibitively expensive. We show how to modify full-matrix adaptive regularization in order to make it practical and effective. We also provide novel theoretical analysis\nfor adaptive regularization in non-convex optimization settings. The core of our algorithm, termed GGT, consists of efficient inverse computation of square roots of low-rank matrices. Our preliminary experiments underscore improved convergence rate of GGT across a variety of synthetic tasks and standard deep learning benchmarks.", "keywords": ["adaptive regularization", "non-convex optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper722/Authors"], "authors": ["Anonymous"], "TL;DR": "fast, truly scalable full-matrix AdaGrad/Adam, with theory for adaptive stochastic non-convex optimization", "pdf": "/pdf/91735a2c2f6dfcd6aaeb498c4341f000317ad755.pdf", "paperhash": "anonymous|the_case_for_fullmatrix_adaptive_regularization", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Case for Full-Matrix Adaptive Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxd2oR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1euhoAcKX", "original": "SyxKygTctQ", "number": 723, "cdate": 1538087855731, "ddate": null, "tcdate": 1538087855731, "tmdate": 1538156070547, "tddate": null, "forum": "B1euhoAcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DppNet: Approximating Determinantal Point Processes with Deep Networks", "abstract": "Determinantal Point Processes (DPPs) provide an elegant and versatile way to sample sets of items that balance the point-wise quality with the set-wise diversity of selected items. For this reason, they have gained prominence in many machine learning applications that rely on subset selection. However, sampling from a DPP over a ground set of size N is a costly operation, requiring in general an O(N^3) preprocessing cost and an O(Nk^3) sampling cost for subsets of size k. We approach this problem by introducing DppNets: generative deep models that produce DPP-like samples for arbitrary ground sets.  We develop an inhibitive attention mechanism based on transformer networks that captures a notion of dissimilarity between feature vectors.  We show theoretically that such an approximation is sensible as it maintains the guarantees of inhibition or dissimilarity that makes DPP so powerful and unique.  Empirically, we demonstrate that samples from our model receive high likelihood under the more expensive DPP alternative.", "keywords": ["dpp", "submodularity", "determinant"], "authorids": ["ICLR.cc/2019/Conference/Paper723/Authors"], "authors": ["Anonymous"], "TL;DR": "We approximate Determinantal Point Processes with neural nets; we justify our model theoretically and empirically.", "pdf": "/pdf/08f70925adfba583846458fc6bd58e585409cfa0.pdf", "paperhash": "anonymous|dppnet_approximating_determinantal_point_processes_with_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019dppnet:,    \ntitle={DppNet: Approximating Determinantal Point Processes with Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1euhoAcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJMO2iCct7", "original": "H1xOqj_FKQ", "number": 724, "cdate": 1538087855906, "ddate": null, "tcdate": 1538087855906, "tmdate": 1538156070340, "tddate": null, "forum": "SJMO2iCct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A NOVEL VARIATIONAL FAMILY FOR HIDDEN NON-LINEAR MARKOV MODELS", "abstract": "Latent variable models have been widely applied for the analysis and visualization of large datasets. In the case of sequential data, closed-form inference is possible when the transition and observation functions are linear. However, approximate inference techniques are usually necessary when dealing with nonlinear dynamics and observation functions. Here, we propose a novel variational inference frame- work for the explicit modeling of time series, Variational Inference for Nonlinear Dynamics (VIND), that is able to uncover nonlinear observation and transition functions from sequential data. The framework includes a structured approximate posterior, and an algorithm that relies on the fixed-point iteration method to find the best estimate for latent trajectories. We apply the method to several datasets and show that it is able to accurately infer the underlying dynamics of these systems, in some cases substantially outperforming state-of-the-art methods.", "keywords": ["variational inference", "time series", "nonlinear dynamics", "neuroscience"], "authorids": ["ICLR.cc/2019/Conference/Paper724/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new variational inference algorithm for time series and a novel variational family  endowed with nonlinear dynamics.", "pdf": "/pdf/7e72061f9d0326de6c5d76f760d6614f93af9a38.pdf", "paperhash": "anonymous|a_novel_variational_family_for_hidden_nonlinear_markov_models", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A NOVEL VARIATIONAL FAMILY FOR HIDDEN NON-LINEAR MARKOV MODELS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMO2iCct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByG_3s09KX", "original": "Byx_mn8cKQ", "number": 725, "cdate": 1538087856075, "ddate": null, "tcdate": 1538087856075, "tmdate": 1538156070131, "tddate": null, "forum": "ByG_3s09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dopamine: A Research Framework for Deep Reinforcement Learning", "abstract": "Deep reinforcement learning (deep RL) research has grown significantly in recent years. A number of software offerings now exist that provide stable, comprehensive implementations for benchmarking. At the same time, recent deep RL research\nhas become more diverse in its goals. In this paper we introduce Dopamine, a new research framework for deep RL that aims to support some of that diversity. Dopamine is open-source, TensorFlow-based, and provides compact yet reliable\nimplementations of some state-of-the-art deep RL agents. We complement this offering with a taxonomy of the different research objectives in deep RL research. While by no means exhaustive, our analysis highlights the heterogeneity of research\nin the field, and the value of frameworks such as ours.", "keywords": ["reinforcement learning", "software", "framework", "reproducibility"], "authorids": ["ICLR.cc/2019/Conference/Paper725/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper we introduce Dopamine, a new research framework for deep RL that is open-source, TensorFlow-based, and provides compact yet reliable implementations of some state-of-the-art deep RL agents.", "pdf": "/pdf/2350e7f4367c141be57d64c6b006719ae619d06b.pdf", "paperhash": "anonymous|dopamine_a_research_framework_for_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019dopamine:,    \ntitle={Dopamine: A Research Framework for Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByG_3s09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygunsAqYQ", "original": "r1x_Jrpqt7", "number": 726, "cdate": 1538087856254, "ddate": null, "tcdate": 1538087856254, "tmdate": 1538156069910, "tddate": null, "forum": "rygunsAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Implicit Maximum Likelihood Estimation", "abstract": "Implicit probabilistic models are models defined naturally in terms of a sampling procedure and often induces a likelihood function that cannot be expressed explicitly. We develop a simple method for estimating parameters in implicit models that does not require knowledge of the form of the likelihood function or any derived quantities, but can be shown to be equivalent to maximizing likelihood under some conditions. Our result holds in the non-asymptotic parametric setting, where both the capacity of the model and the number of data examples are finite. We also demonstrate encouraging experimental results. ", "keywords": ["likelihood-free inference", "implicit probabilistic models"], "authorids": ["ICLR.cc/2019/Conference/Paper726/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a new likelihood-free parameter estimation method that is equivalent to maximum likelihood under some conditions", "pdf": "/pdf/ae8aebd478202c1b544dca674b44118d7b6b4df3.pdf", "paperhash": "anonymous|implicit_maximum_likelihood_estimation", "_bibtex": "@inproceedings{    \nanonymous2019implicit,    \ntitle={Implicit Maximum Likelihood Estimation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygunsAqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJedho0qFX", "original": "H1xd8JF9FX", "number": 727, "cdate": 1538087856421, "ddate": null, "tcdate": 1538087856421, "tmdate": 1538156069707, "tddate": null, "forum": "HJedho0qFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks", "abstract": "As deep neural net architectures minimize loss, they build up information in a hierarchy of learned representations that ultimately serve their final goal.  Different architectures tackle this problem in slightly different ways, but all models aim to  create representational spaces that accumulate information through the depth of the network.  Here we build on previous work that indicated that two very different model classes trained on two very different tasks actually build knowledge representations that have similar underlying representations.  Namely, we compare word embeddings from SkipGram (trained to predict co-occurring words) to several CNN architectures (trained for image classification) in order to understand how this accumulation of knowledge behaves in CNNs.  We improve upon previous work by including 5 times more ImageNet classes in our experiments, and further expand the scope of the analyses to include a network trained on CIFAR-100.  We  characterize network behavior in pretrained models, and also during training, misclassification, and adversarial attack.  Our work illustrates the power of using one model to explore another, gives new insights for CNN models, and provides a framework for others to perform similar analyses when developing new architectures.", "keywords": ["Distributional Semantics", "word embeddings", "cnns", "interpretability"], "authorids": ["ICLR.cc/2019/Conference/Paper727/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple technique using word embeddings provides multiple insights into the function and performance of CNNs, both during and after training, and for misclassified and adversarial examples.", "pdf": "/pdf/87fe821bddead5d4fde633700a3fc89b33b52c29.pdf", "paperhash": "anonymous|using_word_embeddings_to_explore_the_learned_representations_of_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019using,    \ntitle={Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJedho0qFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xFhiC9Y7", "original": "rkeHxA5aOm", "number": 728, "cdate": 1538087856595, "ddate": null, "tcdate": 1538087856595, "tmdate": 1538156069497, "tddate": null, "forum": "B1xFhiC9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Domain Adaptation for Structured Output via Disentangled Patch Representations", "abstract": "Predicting structured outputs such as semantic segmentation relies on expensive per-pixel annotations to learn strong supervised models like convolutional neural networks. However, these models trained on one data domain may not generalize well to other domains unequipped with annotations for model finetuning. To avoid the labor-intensive process of annotation, we develop a domain adaptation method to adapt the source data to the unlabeled target domain. To this end, we propose to learn discriminative feature representations of patches based on label histograms in the source domain, through the construction of a disentangled space. With such representations as guidance, we then use an adversarial learning scheme to push the feature representations in target patches to the closer distributions in source ones. In addition, we show that our framework can integrate a global alignment process with the proposed patch-level alignment and achieve state-of-the-art performance on semantic segmentation. Extensive ablation studies and experiments are conducted on numerous benchmark datasets with various settings, such as synthetic-to-real and cross-city scenarios.", "keywords": ["Domain Adaptation", "Feature Representation Learning", "Semantic Segmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper728/Authors"], "authors": ["Anonymous"], "TL;DR": "A domain adaptation method for structured output via learning patch-level discriminative feature representations", "pdf": "/pdf/36a181969a1f4cc1dc50fbfcf4fe69011d9eda6e.pdf", "paperhash": "anonymous|domain_adaptation_for_structured_output_via_disentangled_patch_representations", "_bibtex": "@inproceedings{    \nanonymous2019domain,    \ntitle={Domain Adaptation for Structured Output via Disentangled Patch Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xFhiC9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eK3i09YQ", "original": "BJed6OecYm", "number": 729, "cdate": 1538087856767, "ddate": null, "tcdate": 1538087856767, "tmdate": 1538156069292, "tddate": null, "forum": "S1eK3i09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gradient Descent Provably Optimizes Over-parameterized Neural Networks", "abstract": "One of the mystery in the success of neural networks is randomly initialized first order methods like gradient descent can achieve zero training loss even though the objective function is non-convex and non-smooth. This paper demystifies this surprising phenomenon for two-layer fully connected ReLU activated neural networks. For an $m$ hidden node shallow neural network with ReLU activation and $n$ training data, we  show as long as $m$ is large enough and the data is non-degenerate, randomly initialized gradient descent converges a globally optimal solution at a linear convergence rate  for the quadratic loss function.\n\nOur analysis is based on the following observation: over-parameterization and random initialization jointly restrict every weight vector to be close to its initialization for all iterations, which allows us to exploit a strong convexity-like property to show that gradient descent converges at a global linear rate to the global optimum. We believe these insights are also useful in analyzing deep models and other first order methods.", "keywords": ["theory", "non-convex optimization", "overparameterization", "gradient descent"], "authorids": ["ICLR.cc/2019/Conference/Paper729/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove gradient descent achieves zero training loss with a linear rate on over-parameterized neural networks.", "pdf": "/pdf/74da60810e85ec67377b97546509e80fc2145515.pdf", "paperhash": "anonymous|gradient_descent_provably_optimizes_overparameterized_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019gradient,    \ntitle={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eK3i09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgK3oC5Fm", "original": "r1xTQsHqtm", "number": 730, "cdate": 1538087856949, "ddate": null, "tcdate": 1538087856949, "tmdate": 1538156069087, "tddate": null, "forum": "rkgK3oC5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bayesian Prediction of Future Street Scenes using Synthetic Likelihoods", "abstract": "For autonomous agents to successfully operate in the real world, the ability to anticipate future scene states is a key competence. In real-world scenarios, future states become increasingly uncertain and multi-modal, particularly on long time horizons. Dropout based Bayesian inference provides a computationally tractable, theoretically well grounded approach to learn different hypotheses/models to deal with uncertain futures and make predictions that correspond well to observations -- are well calibrated. However, it turns out that such approaches fall short to capture complex real-world scenes, even falling behind in accuracy when compared to the plain deterministic approaches. This is because the used log-likelihood estimate discourages diversity. In this work, we propose a novel Bayesian formulation for anticipating future scene states which leverages synthetic likelihoods that encourage the learning of diverse models to accurately capture the multi-modal nature of future scene states. We show that our approach achieves accurate state-of-the-art predictions and calibrated probabilities through extensive experiments for scene anticipation on Cityscapes dataset. Moreover, we show that our approach generalizes across diverse tasks such as digit generation and precipitation forecasting.", "keywords": ["bayesian inference", "segmentation", "anticipation", "multi-modality"], "authorids": ["ICLR.cc/2019/Conference/Paper730/Authors"], "authors": ["Anonymous"], "TL;DR": "Dropout based Bayesian inference is extended to deal with multi-modality and is evaluated on scene anticipation tasks.", "pdf": "/pdf/bcde25d49551e390f387b9126df6153fee6ed7c9.pdf", "paperhash": "anonymous|bayesian_prediction_of_future_street_scenes_using_synthetic_likelihoods", "_bibtex": "@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Prediction of Future Street Scenes using Synthetic Likelihoods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgK3oC5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeK3s0qKQ", "original": "rklCE_aUFX", "number": 731, "cdate": 1538087857129, "ddate": null, "tcdate": 1538087857129, "tmdate": 1538156068879, "tddate": null, "forum": "SkeK3s0qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Episodic Curiosity through Reachability", "abstract": "Rewards are sparse in the real world and most today's reinforcement learning algorithms struggle with such sparsity. One solution to this problem is to allow the agent to create rewards for itself --- thus making rewards dense and more suitable for learning. In particular, inspired by curious behaviour in animals, observing something novel could be rewarded with a bonus. Such bonus is summed up with the real task reward --- making it possible for RL algorithms to learn from the combined reward. We propose a new curiosity method which uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. Crucially, the comparison is done based on how many environment steps it takes to reach the current observation from those in memory --- which incorporates rich information about environment dynamics. This allows us to overcome the known \"couch-potato\" issues of prior work --- when the agent finds a way to instantly gratify itself by exploiting actions which lead to unpredictable consequences. We test our approach in visually rich 3D environments in ViZDoom and DMLab. In ViZDoom, our agent learns to successfully navigate to a distant goal at least 2 times faster than the state-of-the-art curiosity method ICM. In DMLab, our agent generalizes well to new procedurally generated levels of the game --- reaching the goal at least 2 times more frequently than ICM on test mazes with very sparse reward.", "keywords": ["deep learning", "reinforcement learning", "curiosity", "exploration", "episodic memory"], "authorids": ["ICLR.cc/2019/Conference/Paper731/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel model of curiosity based on episodic memory and the ideas of reachability which allows us to overcome the known \"couch-potato\" issues of prior work.", "pdf": "/pdf/1ee019011758def1de2ecbde41f9fae9adf7c83e.pdf", "paperhash": "anonymous|episodic_curiosity_through_reachability", "_bibtex": "@inproceedings{    \nanonymous2019episodic,    \ntitle={Episodic Curiosity through Reachability},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeK3s0qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syxt2jC5FX", "original": "rJeidVj9tX", "number": 732, "cdate": 1538087857307, "ddate": null, "tcdate": 1538087857307, "tmdate": 1538156068673, "tddate": null, "forum": "Syxt2jC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference", "abstract": "Nonlinearity is crucial to the performance of a deep (neural) network (DN).\nTo date there has been little progress understanding the menagerie of available  nonlinearities, but recently progress has been made on understanding the r\\^{o}le played by piecewise affine and convex nonlinearities like the ReLU and absolute value activation functions and max-pooling.\nIn particular, DN layers constructed from these operations can be interpreted as {\\em max-affine spline operators} (MASOs) that have an elegant link to vector quantization (VQ) and $K$-means.\nWhile this is good theoretical progress, the entire MASO approach is predicated on the requirement that the nonlinearities be piecewise affine and convex, which precludes important activation functions like the sigmoid, hyperbolic tangent, and softmax.\n{\\em This paper extends the MASO framework to these and an infinitely large class of new nonlinearities by linking deterministic MASOs with probabilistic Gaussian Mixture Models (GMMs).}\nWe show that, under a GMM, piecewise affine, convex nonlinearities like ReLU, absolute value, and max-pooling can be interpreted as solutions to certain natural ``hard'' VQ inference problems, while sigmoid, hyperbolic tangent, and softmax can be interpreted as solutions to corresponding ``soft'' VQ inference problems.\nWe further extend the framework by hybridizing the hard and soft VQ optimizations to create a $\\beta$-VQ inference that interpolates between hard, soft, and linear VQ inference.\nA prime example of a $\\beta$-VQ DN nonlinearity is the {\\em swish} nonlinearity, which offers state-of-the-art performance in a range of computer vision tasks but was developed ad hoc by experimentation.\nFinally, we validate with experiments an important assertion of our theory, namely that DN performance can be significantly improved by enforcing orthogonality in its linear filters.\n", "keywords": ["Spline", "Vector Quantization", "Inference", "Nonlinearities", "Deep Network"], "authorids": ["ICLR.cc/2019/Conference/Paper732/Authors"], "authors": ["Anonymous"], "TL;DR": "Reformulate deep networks nonlinearities from a vector quantization scope and bridge most known nonlinearities together.", "pdf": "/pdf/764421b2cca22b5d68a6760c6ee12f800811b87a.pdf", "paperhash": "anonymous|from_hard_to_soft_understanding_deep_network_nonlinearities_via_vector_quantization_and_statistical_inference", "_bibtex": "@inproceedings{    \nanonymous2019from,    \ntitle={From Hard to Soft: Understanding Deep Network Nonlinearities via Vector Quantization and Statistical Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syxt2jC5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1ethsR9Ym", "original": "B1eKGST9KX", "number": 733, "cdate": 1538087857486, "ddate": null, "tcdate": 1538087857486, "tmdate": 1538156068456, "tddate": null, "forum": "B1ethsR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Look Ma, No GANs! Image Transformation with ModifAE", "abstract": "Existing methods of image to image translation require multiple steps in the training or modification process, and suffer from either an inability to generalize, or long training times. These methods also focus on binary trait modification, ignoring continuous traits. To address these problems, we propose ModifAE: a novel standalone neural network, trained exclusively on an autoencoding task, that implicitly learns to make continuous trait image modifications. As a standalone image modification network, ModifAE requires fewer parameters and less time to train than existing models. We empirically show that ModifAE produces significantly more convincing and more consistent continuous face trait modifications than the previous state-of-the-art model.", "keywords": ["Computer Vision", "Deep Learning", "Autoencoder", "GAN", "Image Modification", "Social Traits", "Social Psychology"], "authorids": ["ICLR.cc/2019/Conference/Paper733/Authors"], "authors": ["Anonymous"], "TL;DR": "ModifAE is a standalone neural network, trained exclusively on an autoencoding task, that implicitly learns to make image modifications (without GANs).", "pdf": "/pdf/0e0aa9731c95e85abb8abc36e85bc1bc938ee415.pdf", "paperhash": "anonymous|look_ma_no_gans_image_transformation_with_modifae", "_bibtex": "@inproceedings{    \nanonymous2019look,    \ntitle={Look Ma, No GANs! Image Transformation with ModifAE},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1ethsR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xq3oR5tQ", "original": "SklW9Mo9FQ", "number": 734, "cdate": 1538087857652, "ddate": null, "tcdate": 1538087857652, "tmdate": 1538156068232, "tddate": null, "forum": "S1xq3oR5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The effects of neural resource constraints on early visual representations ", "abstract": "The visual system of vertebrates is organized in a hierarchical structure that processes visual information in successive stages. Neural representations vary drastically across the first stages of visual processing. At the output of the retina, receptive fields (RFs) exhibit a clear antagonistic center-surround structure, whereas in the primary visual cortex (V1), typical RFs are sharply tuned to a precise orientation. Moreover, there are striking differences in early visual representations across species. Specifically, the retinas of small vertebrates (e.g. salamander, mouse) perform sophisticated non-linear computations extracting features directly relevant to behavior. In contrast, the dominant retinal cell types in primates encode the visual scene quasi-linearly and respond to a much broader range of stimuli. There is currently no theory explaining these differences in representation across layers and across species. Here, using a deep convolutional neural network trained on image recognition as a model of the visual system, we show that such differences in representation emerge as a direct consequence of different neural resource constraints on the retinal and brain networks. Whereas previous studies of efficient coding invoked inconsistent sets of metabolic constraints to account for the differences in RF shapes found in the retina and V1, we find a unique model from which both geometries spontaneously emerge at the appropriate stages of visual processing. The key constraint of this model is a reduced number of neurons at the retinal output, a constraint consistent with the anatomy of the optic nerve. Furthermore, we find that retinal neurons in our model emerge as non-linear and lossy feature detectors for small brain networks, whereas they emerge as linear and faithful encoders of the visual scene for large brains. Our results thus reconcile the two seemingly incompatible views of the retina as either performing feature extraction or efficient compression of natural scenes, by suggesting that all vertebrates lie on a spectrum between these two objectives, depending on the neural resources allocated to their visual system.", "keywords": ["visual system", "convolutional neural networks", "efficient coding", "retina"], "authorids": ["ICLR.cc/2019/Conference/Paper734/Authors"], "authors": ["Anonymous"], "TL;DR": "We reproduced neural representations found in biological visual systems by simulating their neural resource constraints in a deep convolutional model.", "pdf": "/pdf/4718f54b056a92b252b73db26e227c3af17737c0.pdf", "paperhash": "anonymous|the_effects_of_neural_resource_constraints_on_early_visual_representations", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The effects of neural resource constraints on early visual representations },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xq3oR5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byx93sC9tm", "original": "BklfEractQ", "number": 735, "cdate": 1538087857832, "ddate": null, "tcdate": 1538087857832, "tmdate": 1538156068022, "tddate": null, "forum": "Byx93sC9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Ensemble Bayesian Active Learning : Adressing the Mode Collapse issue in Monte Carlo dropout via Ensembles", "abstract": "In image classification tasks, the ability of deep convolutional neural networks (CNNs) to deal with complex image data has proved to be unrivalled. Deep CNNs, however, require large amounts of labeled training data to reach their full potential. In specialised domains such as healthcare, labeled data can be difficult and expensive to obtain. One way to alleviate this problem is to rely on active learning, a learning technique that aims to reduce the amount of labelled data needed for a specific task while still delivering satisfactory performance.\nWe propose a new active learning strategy designed\nfor deep neural networks. This method improves upon the current state-of-the-art deep Bayesian active learning method, which suffers from the mode collapse problem. We correct for this deficiency by making use of the expressive power and statistical properties of model ensembles. Our proposed method manages to capture superior data uncertainty, which translates into improved classification performance. We demonstrate empirically that our ensemble method yields faster convergence of CNNs trained on the MNIST and CIFAR-10 \ndatasets.", "keywords": ["Active Learning", "Deep Learning", "Bayesian Neural Networks", "Bayesian Deep Learning", "Ensembles"], "authorids": ["ICLR.cc/2019/Conference/Paper735/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a method for Deep Bayesian Active Learning combining MC-Dropout with Ensemble Models", "pdf": "/pdf/9e88fa8e666198b5fce006cde973942d163c6c87.pdf", "paperhash": "anonymous|deep_ensemble_bayesian_active_learning_adressing_the_mode_collapse_issue_in_monte_carlo_dropout_via_ensembles", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Ensemble Bayesian Active Learning : Adressing the Mode Collapse issue in Monte Carlo dropout via Ensembles},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byx93sC9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skxqni09KX", "original": "rylyIBTcYQ", "number": 736, "cdate": 1538087858005, "ddate": null, "tcdate": 1538087858005, "tmdate": 1538156067811, "tddate": null, "forum": "Skxqni09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Online Bellman Residue Minimization via Saddle Point Optimization", "abstract": "We study the problem of Bellman residual minimization with nonlinear function approximation in general.  \n   Based on a nonconvex saddle point formulation of Bellman residual minimization via Fenchel duality, we propose an online first-order algorithm with two-timescale learning rates.  Using tools from stochastic approximation, we establish the convergence of our problem by approximating the dynamics of the iterates using two ordinary differential equations. Moreover, as a byproduct, we establish a finite-time convergence result under the assumption that the dual problem can be solved up to some error. Finally, numerical experiments are provided to back up our theory.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper736/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b11e23478a490f3d19b723cedde7cc270e256f4f.pdf", "paperhash": "anonymous|online_bellman_residue_minimization_via_saddle_point_optimization", "_bibtex": "@inproceedings{    \nanonymous2019online,    \ntitle={Online Bellman Residue Minimization via Saddle Point Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skxqni09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1fcnoR9K7", "original": "BJxZ1g3qFX", "number": 737, "cdate": 1538087858186, "ddate": null, "tcdate": 1538087858186, "tmdate": 1538156067606, "tddate": null, "forum": "S1fcnoR9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning with Random Learning Rates.", "abstract": "Hyperparameter tuning is a bothersome step in the training of deep learning mod- els. One of the most sensitive hyperparameters is the learning rate of the gradient descent. We present the All Learning Rates At Once (Alrao) optimization method for neural networks: each unit or feature in the network gets its own learning rate sampled from a random distribution spanning several orders of magnitude. This comes at practically no computational cost. Perhaps surprisingly, stochastic gra- dient descent (SGD) with Alrao performs close to SGD with an optimally tuned learning rate, for various architectures and problems. Alrao could save time when testing deep learning models: a range of models could be quickly assessed with Alrao, and the most promising models could then be trained more extensively. This text comes with a PyTorch implementation of the method, which can be plugged on an existing PyTorch model.", "keywords": ["step size", "stochastic gradient descent", "hyperparameter tuning"], "authorids": ["ICLR.cc/2019/Conference/Paper737/Authors"], "authors": ["Anonymous"], "TL;DR": "We test stochastic gradient descent with random per-feature learning rates in neural networks, and find performance comparable to using SGD with the optimal learning rate, alleviating the need for learning rate tuning.", "pdf": "/pdf/ba202047800b77d48688e51d26566a5fbbb1d72e.pdf", "paperhash": "anonymous|learning_with_random_learning_rates", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning with Random Learning Rates.},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1fcnoR9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkg93jC5YX", "original": "HylkBanqKX", "number": 738, "cdate": 1538087858357, "ddate": null, "tcdate": 1538087858357, "tmdate": 1538156067402, "tddate": null, "forum": "Bkg93jC5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BLISS in Non-Isometric Embedding Spaces", "abstract": "Recent work on bilingual lexicon induction (BLI) has frequently depended either on aligned bilingual lexicons or on distribution matching, often with an assumption about the isometry of the two spaces. We propose a technique to quantitatively estimate this assumption of the isometry between two embedding spaces and  empirically show that this assumption weakens as the languages in question become increasingly etymologically distant. We then propose Bilingual Lexicon Induction with Semi-Supervision (BLISS) --- a novel semi-supervised approach that relaxes the isometric assumption while leveraging both limited aligned bilingual lexicons and a larger set of unaligned word embeddings, as well as a novel hubness filtering technique. Our proposed method improves over strong baselines for 11 of 14 on the MUSE dataset, particularly for languages whose embedding spaces do not appear to be isometric. In addition, we also show that adding supervision stabilizes the learning procedure, and is effective even with minimal supervision.", "keywords": ["bilingual lexicon induction", "semi-supervised methods", "embeddings"], "authorids": ["ICLR.cc/2019/Conference/Paper738/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel method to test for isometry between word embedding spaces, and a semi-supervised method for learning better mappings between them", "pdf": "/pdf/a8c90af9560a01d0e43dceb00edb7645ef53aa0b.pdf", "paperhash": "anonymous|bliss_in_nonisometric_embedding_spaces", "_bibtex": "@inproceedings{    \nanonymous2019bliss,    \ntitle={BLISS in Non-Isometric Embedding Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg93jC5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxjnjA5KQ", "original": "HJgOOBTcFm", "number": 739, "cdate": 1538087858534, "ddate": null, "tcdate": 1538087858534, "tmdate": 1538156067190, "tddate": null, "forum": "rkxjnjA5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation", "abstract": "Deep Reinforcement Learning has managed to achieve state-of-the-art results in learning control policies directly from raw pixels. However, despite its remarkable success, it fails to generalize, a fundamental component required in a stable Artificial Intelligence system. Using the Atari game Breakout, we demonstrate the difficulty of a trained agent in adjusting to simple modifications in the raw image, ones that a human could adapt to trivially. In transfer learning, the goal is to use the knowledge gained from the source task to make the training of the target task faster and better. We show that using various forms of fine-tuning, a common method for transfer learning, is not effective for adapting to such small visual changes. In fact, it is often easier to re-train the agent from scratch than to fine-tune a trained agent. We suggest that in some cases transfer learning can be improved by adding a dedicated component whose goal is to learn to visually map between the known domain and the new one. Concretely, we use Unaligned Generative Adversarial Networks (GANs) to create a mapping function to translate images in the target task to corresponding images in the source task. These mapping functions allow us to transform between various variations of the Breakout game, as well as between different levels of a Nintendo game, Road Fighter. We show that learning this mapping is substantially more efficient than re-training. A visualization of a trained agent playing Breakout and Road Fighter, with and without the GAN transfer, can be seen in \\url{https://streamable.com/msgtm} and \\url{https://streamable.com/5e2ka}.", "keywords": ["Transfer Learning", "Reinforcement Learning", "Generative Adversarial Networks", "Video Games"], "authorids": ["ICLR.cc/2019/Conference/Paper739/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method of transferring knowledge between related RL tasks using visual mappings, and demonstrate its effectiveness on visual variants of the Atari Breakout game and different levels of Road Fighter, a Nintendo car driving game.", "pdf": "/pdf/6c5fe5421d3e7bbc404a0c035f0edb8a59d8d639.pdf", "paperhash": "anonymous|transfer_learning_for_related_reinforcement_learning_tasks_via_imagetoimage_translation", "_bibtex": "@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxjnjA5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lo3sC9KX", "original": "B1xK5SaqKm", "number": 740, "cdate": 1538087858708, "ddate": null, "tcdate": 1538087858708, "tmdate": 1538156066984, "tddate": null, "forum": "H1lo3sC9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Asynchronous SGD without gradient delay for efficient distributed training", "abstract": "Asynchronous distributed gradient descent algorithms for training of deep neural\nnetworks are usually considered as inefficient, mainly because of the Gradient delay\nproblem. In this paper, we propose a novel asynchronous distributed algorithm\nthat tackles this limitation by well-thought-out averaging of model updates, computed\nby workers. The algorithm allows computing gradients along the process\nof gradient merge, thus, reducing or even completely eliminating worker idle time\ndue to communication overhead, which is a pitfall of existing asynchronous methods.\nWe provide theoretical analysis of the proposed asynchronous algorithm,\nand show its regret bounds. According to our analysis, the crucial parameter for\nkeeping high convergence rate is the maximal discrepancy between local parameter\nvectors of any pair of workers. As long as it is kept relatively small, the\nconvergence rate of the algorithm is shown to be the same as the one of a sequential\nonline learning. Furthermore, in our algorithm, this discrepancy is bounded\nby an expression that involves the staleness parameter of the algorithm, and is\nindependent on the number of workers. This is the main differentiator between\nour approach and other solutions, such as Elastic Asynchronous SGD or Downpour\nSGD, in which that maximal discrepancy is bounded by an expression that\ndepends on the number of workers, due to gradient delay problem. To demonstrate\neffectiveness of our approach, we conduct a series of experiments on image\nclassification task on a cluster with 4 machines, equipped with a commodity communication\nswitch and with a single GPU card per machine. Our experiments\nshow a linear scaling on 4-machine cluster without sacrificing the test accuracy,\nwhile eliminating almost completely worker idle time. Since our method allows\nusing commodity communication switch, it paves a way for large scale distributed\ntraining performed on commodity clusters.", "keywords": ["SGD", "distributed asynchronous training", "deep learning", "optimisation"], "authorids": ["ICLR.cc/2019/Conference/Paper740/Authors"], "authors": ["Anonymous"], "TL;DR": "A method for an efficient asynchronous distributed training of deep learning models along with theoretical regret bounds.", "pdf": "/pdf/6e08f084d5f9d00fc434104ad52965caee3ec0f7.pdf", "paperhash": "anonymous|asynchronous_sgd_without_gradient_delay_for_efficient_distributed_training", "_bibtex": "@inproceedings{    \nanonymous2019asynchronous,    \ntitle={Asynchronous SGD without gradient delay for efficient distributed training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lo3sC9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkMjhjCqK7", "original": "S1lU6HpcFQ", "number": 741, "cdate": 1538087858889, "ddate": null, "tcdate": 1538087858889, "tmdate": 1538156066771, "tddate": null, "forum": "BkMjhjCqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BNN+: Improved Binary Network Training", "abstract": "Deep neural networks (DNN) are widely used in many applications.  However,their  deployment  on  edge  devices  has  been  difficult  because  they  are  resource hungry.   Binary  networks (BNN)  helps to  alleviate  the prohibitive  resource  requirements of DNN; where both activations and weights are limited to 1-bit.  We propose  an  improved  binary  training  method  (BNN+)  where  this  method  is  an improvement  to  the  popular  BNN  training  scheme,  and  helps  reduce  accuracy degradation compared to the full-precision counterpart.  Our method is based on linear  operations  that  are  easily  implementable  into  the  binary  training  frame-work and we show experimental results on CIFAR-10 obtaining an accuracy of 86.5%, on AlexNet and 91.6%with VGG network.  On ImageNet, our method also outperforms the traditional BNN and XNOR-net, by a margin of4% and 2% respectively", "keywords": ["Binary Network", "Binary Network Training", "Model Compression", "Binary", "Quantization"], "authorids": ["ICLR.cc/2019/Conference/Paper741/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper presents an improved training mechanism for obtaining binary networks with smaller accuracy drop compared to it's full precision ", "pdf": "/pdf/b20046136344b85011d11022cd762bc0494b6e40.pdf", "paperhash": "anonymous|bnn_improved_binary_network_training", "_bibtex": "@inproceedings{    \nanonymous2019bnn+:,    \ntitle={BNN+: Improved Binary Network Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMjhjCqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1esnoAqt7", "original": "ryevvqqYtX", "number": 742, "cdate": 1538087859062, "ddate": null, "tcdate": 1538087859062, "tmdate": 1538156066560, "tddate": null, "forum": "r1esnoAqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Morpho-MNIST: Quantitative Assessment and Diagnostics for Representation Learning", "abstract": "Revealing latent structure in data is an active field of research, having brought exciting new models such as variational autoencoders and generative adversarial networks, and is essential to push machine learning towards unsupervised knowledge discovery. However, a major challenge is the lack of suitable benchmarks for an objective and quantitative evaluation of learned representations. To address this issue we introduce Morpho-MNIST. We extend the popular MNIST dataset by adding a morphometric analysis enabling quantitative comparison of different models, identification of the roles of latent variables, and characterisation of sample diversity. We further propose a set of quantifiable perturbations to assess the performance of unsupervised and supervised methods on challenging tasks such as outlier detection and domain adaptation.", "keywords": ["quantitative evaluation", "diagnostics", "generative models", "representation learning", "morphometrics", "image perturbations"], "authorids": ["ICLR.cc/2019/Conference/Paper742/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces Morpho-MNIST, a collection of shape metrics and perturbations, in a step towards quantitative evaluation of representation learning in computer vision.", "pdf": "/pdf/78139c43f54784ba22944ddd4fdde0234d8d9aa8.pdf", "paperhash": "anonymous|morphomnist_quantitative_assessment_and_diagnostics_for_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019morpho-mnist:,    \ntitle={Morpho-MNIST: Quantitative Assessment and Diagnostics for Representation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1esnoAqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lohoCqY7", "original": "ryl98139tm", "number": 743, "cdate": 1538087859232, "ddate": null, "tcdate": 1538087859232, "tmdate": 1538156066350, "tddate": null, "forum": "r1lohoCqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["ICLR.cc/2019/Conference/Paper743/Authors"], "authors": ["Anonymous"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/089afcad235349d9c1e08566b03150b450f607c5.pdf", "paperhash": "anonymous|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{    \nanonymous2019learning-based,    \ntitle={Learning-Based Frequency Estimation Algorithms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lohoCqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJej3s09Km", "original": "HJx9AIjqt7", "number": 744, "cdate": 1538087859398, "ddate": null, "tcdate": 1538087859398, "tmdate": 1538156066146, "tddate": null, "forum": "HJej3s09Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the effect of the activation function on the distribution of hidden nodes in a deep network", "abstract": "We analyze the joint probability distribution on the lengths of the\nvectors of hidden variables in different layers of a fully connected\ndeep network, when the weights and biases are chosen randomly according to\nGaussian distributions, and the input is binary-valued.  We show\nthat, if the activation function satisfies a minimal set of\nassumptions, satisfied by all activation functions that we know that\nare used in practice, then, as the width of the network gets large,\nthe ``length process'' converges in probability to a length map\nthat is determined as a simple function of the variances of the\nrandom weights and biases, and the activation function.\n\nWe also show that this convergence may fail for activation functions \nthat violate our assumptions.", "keywords": ["theory", "length map", "initialization"], "authorids": ["ICLR.cc/2019/Conference/Paper744/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove that, for activation functions satisfying some conditions, as a deep network gets wide, the lengths of the vectors of hidden variables converge to a length map.", "pdf": "/pdf/7fb78879ecb9d621a1a1df79fbff9165bf7b8650.pdf", "paperhash": "anonymous|on_the_effect_of_the_activation_function_on_the_distribution_of_hidden_nodes_in_a_deep_network", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the effect of the activation function on the distribution of hidden nodes in a deep network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJej3s09Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJlh2jR9FX", "original": "rkeA2gTctX", "number": 745, "cdate": 1538087859568, "ddate": null, "tcdate": 1538087859568, "tmdate": 1538156065940, "tddate": null, "forum": "SJlh2jR9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning with Reflective Likelihoods", "abstract": "Machine learning systems have achieved state-of-the-art results in many domains. They are usually trained using the maximum likelihood principle. However maximum likelihood learning can lead to poor learned representations of high dimensional data. For example this is manifested in deep generative latent variable models where the latent variables and their associated observations are driven independent from each other. We identify a peculiarity in maximum likelihood learning that causes this problem of poor learned representations. We then propose a new learning criterion for better representation learning. The proposed criterion relies on simultaneously maximizing the likelihood of the data and minimizing what we term the reflective likelihood of the data. We study this new criterion both theoretically and empirically and show improved performance on image classification under imbalance and text modeling with deep generative latent variable models.", "keywords": ["new learning criterion", "penalized maximum likelihood", "posterior inference in deep generative models", "input forgetting issue", "latent variable collapse issue"], "authorids": ["ICLR.cc/2019/Conference/Paper745/Authors"], "authors": ["Anonymous"], "TL;DR": "We identify a peculiarity in maximum likelihood learning that causes input collapse and propose a new learning criterion for better representation learning.", "pdf": "/pdf/bbfe6229d5a7b4b44ee765b0543ca9aa767c6f66.pdf", "paperhash": "anonymous|learning_with_reflective_likelihoods", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning with Reflective Likelihoods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlh2jR9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hygn2o0qKX", "original": "BygjLWK9KX", "number": 746, "cdate": 1538087859734, "ddate": null, "tcdate": 1538087859734, "tmdate": 1538156065731, "tddate": null, "forum": "Hygn2o0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience", "abstract": "The ability of overparameterized deep networks to generalize well has been linked to the fact that stochastic gradient descent (SGD) finds solutions that lie in flat, wide minima in the training loss -- minima where the output of the network is resilient to small random noise added to its parameters. \nSo far this observation has been used to provide generalization guarantees only for neural networks whose parameters are either \\textit{stochastic} or \\textit{compressed}. In this work, we present a general PAC-Bayesian framework that leverages this observation to provide a bound on the original network learned -- a network that is deterministic and uncompressed.  What enables us to do this is a key novelty in our approach: our framework allows us to show that if on training data, the interactions between the weight matrices satisfy certain conditions that imply a wide training loss minimum, these conditions themselves {\\em generalize} to the interactions between the matrices on test data, thereby implying a wide test loss minimum. We then apply our general framework in a setup where we assume that the pre-activation values of the network are not too small (although we assume this only on the training data). In this setup, we provide a generalization guarantee for the original (deterministic, uncompressed) network, that does not scale with product of the spectral norms of the weight matrices -- a guarantee that would not have been possible with prior approaches.\n", "keywords": ["generalization", "PAC-Bayes", "SGD", "learning theory", "implicit regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper746/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide a PAC-Bayes based generalization guarantee for deep networks by generalizing noise-resilience of the network on the training data to the test data.", "pdf": "/pdf/5dc5d2ae92e46273b93d9d71a167bbfa13f71819.pdf", "paperhash": "anonymous|deterministic_pacbayesian_generalization_bounds_for_deep_networks_via_generalizing_noiseresilience", "_bibtex": "@inproceedings{    \nanonymous2019deterministic,    \ntitle={Deterministic PAC-Bayesian generalization bounds for deep networks via generalizing noise-resilience},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygn2o0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJl2niR9KQ", "original": "HJxED7A_YQ", "number": 747, "cdate": 1538087859915, "ddate": null, "tcdate": 1538087859915, "tmdate": 1538156065526, "tddate": null, "forum": "SJl2niR9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["ICLR.cc/2019/Conference/Paper747/Authors"], "authors": ["Anonymous"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/733a1e5b28bc4c34ca15e02792b9aa48512ad25a.pdf", "paperhash": "anonymous|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{    \nanonymous2019beyond,    \ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl2niR9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxh2j0qYm", "original": "HJgCOaw9t7", "number": 748, "cdate": 1538087860091, "ddate": null, "tcdate": 1538087860091, "tmdate": 1538156065314, "tddate": null, "forum": "BJxh2j0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dynamic Channel Pruning: Feature Boosting and Suppression", "abstract": "Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources. In this paper, we exploit the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolutional layers. In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs. We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification. Experiments show that FBS can accelerate VGG-16 by 5x and improve the speed of ResNet-18 by 2x, both with less than 0.6% top-5 accuracy loss.", "keywords": ["dynamic network", "faster CNNs", "channel pruning"], "authorids": ["ICLR.cc/2019/Conference/Paper748/Authors"], "authors": ["Anonymous"], "TL;DR": "We make convolutional layers run faster by dynamically boosting and suppressing channels in feature computation.", "pdf": "/pdf/bd7f45379cb965aba7818d625804ed531975d411.pdf", "paperhash": "anonymous|dynamic_channel_pruning_feature_boosting_and_suppression", "_bibtex": "@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Channel Pruning: Feature Boosting and Suppression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxh2j0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1x33sC9KQ", "original": "HJgR0CYqtm", "number": 749, "cdate": 1538087860259, "ddate": null, "tcdate": 1538087860259, "tmdate": 1538156065110, "tddate": null, "forum": "B1x33sC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ACIQ: Analytical Clipping for Integer Quantization of neural networks", "abstract": "We analyze the trade-off between quantization noise and clipping distortion in low precision networks. We identify the statistics of various tensors, and derive exact expressions for the mean-square-error degradation due to clipping. By optimizing these expressions, we show marked improvements over standard quantization schemes that normally avoid clipping. For example, just by choosing the accurate clipping values, more than 40\\% accuracy improvement is obtained for the quantization of VGG-16 to 4-bits of precision. Our results have many applications for the quantization of neural networks at both training and inference time. \n", "keywords": ["quantization", "reduced precision", "training", "inference", "activation"], "authorids": ["ICLR.cc/2019/Conference/Paper749/Authors"], "authors": ["Anonymous"], "TL;DR": "We analyze the trade-off between quantization noise and clipping distortion in low precision networks, and show marked improvements over standard quantization schemes that normally avoid clipping", "pdf": "/pdf/77ba17634f1de6edd6928f1a5c3d318eafd8ce84.pdf", "paperhash": "anonymous|aciq_analytical_clipping_for_integer_quantization_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019aciq:,    \ntitle={ACIQ: Analytical Clipping for Integer Quantization of neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1x33sC9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyfn2jCcKm", "original": "rJgOp0cUtm", "number": 750, "cdate": 1538087860423, "ddate": null, "tcdate": 1538087860423, "tmdate": 1538156064894, "tddate": null, "forum": "Hyfn2jCcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Solving the Rubik's Cube with Approximate Policy Iteration", "abstract": "Recently, Approximate Policy Iteration (API) algorithms have achieved super-human proficiency in two-player zero-sum games such as Go, Chess, and Shogi without human data. These API algorithms iterate between two policies: a slow policy (tree search), and a fast policy (a neural network). In these two-player games, a reward is always received at the end of the game. However, the Rubik\u2019s Cube has only a single solved state, and episodes are not guaranteed to terminate. This poses a major problem for these API algorithms since they rely on the reward received at the end of the game. We introduce Autodidactic Iteration: an API algorithm that overcomes the problem of sparse rewards by training on a distribution of states that allows the reward to propagate from the goal state to states farther away. Autodidactic Iteration is able to learn how to solve the Rubik\u2019s Cube and the 15-puzzle without relying on human data. Our algorithm is able to solve 100% of randomly scrambled cubes while achieving a median solve length of 30 moves \u2014 less than or equal to solvers that employ human domain knowledge", "keywords": ["reinforcement learning", "Rubik's Cube", "approximate policy iteration", "deep learning", "deep reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper750/Authors"], "authors": ["Anonymous"], "TL;DR": "We solve the Rubik's Cube with pure reinforcement learning", "pdf": "/pdf/7fb5c4ea695878917abb28fc29e667cf67bd0d87.pdf", "paperhash": "anonymous|solving_the_rubiks_cube_with_approximate_policy_iteration", "_bibtex": "@inproceedings{    \nanonymous2019solving,    \ntitle={Solving the Rubik's Cube with Approximate Policy Iteration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyfn2jCcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygp3iRcF7", "original": "S1xrZR3cKm", "number": 751, "cdate": 1538087860592, "ddate": null, "tcdate": 1538087860592, "tmdate": 1538156064688, "tddate": null, "forum": "rygp3iRcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Area Attention", "abstract": "Existing attention mechanisms, are mostly point-based in that a model is designed to attend to a single item in a collection of items (the memory). Intuitively, an area in the memory that may contain multiple items can be worth attending to as well. Although Softmax, which is typically used for computing attention alignments, assigns non-zero probability for every item in memory, it tends to converge to a single item and cannot efficiently attend to a group of items that matter. We propose area attention: a way to attend to an area of the memory, where each area contains a group of items that are either spatially adjacent when the memory has a 2-dimensional structure, such as images, or temporally adjacent for 1-dimensional memory, such as natural language sentences. Importantly, the size of an area, i.e., the number of items in an area, can vary depending on the learned coherence of the adjacent items. Using an area of items, instead of a single, we hope attention mechanisms can better capture the nature of the task. Area attention can work along multi-head attention for attending multiple areas in the memory. We evaluate area attention on two tasks: character-level neural machine translation and image captioning, and improve upon strong (state-of-the-art) baselines in both cases. In addition to proposing the novel concept of area attention, we contribute an efficient way for computing it by leveraging the technique of summed area tables.", "keywords": ["Deep Learning", "attentional mechanisms", "machine translation", "captioning"], "authorids": ["ICLR.cc/2019/Conference/Paper751/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper presents a novel approach for attentional mechanisms that can benefit a range of tasks such as machine translation and image captioning.", "pdf": "/pdf/9edb2cc9184edcd9f3d4da5aa47ff45d183b4738.pdf", "paperhash": "anonymous|area_attention", "_bibtex": "@inproceedings{    \nanonymous2019area,    \ntitle={Area Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygp3iRcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJx63jRqFm", "original": "rJlS6znFYm", "number": 752, "cdate": 1538087860766, "ddate": null, "tcdate": 1538087860766, "tmdate": 1538156064473, "tddate": null, "forum": "SJx63jRqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diversity is All You Need: Learning Skills without a Reward Function", "abstract": "Intelligent creatures can explore their environments and learn useful skills without supervision.\nIn this paper, we propose ``Diversity is All You Need''(DIAYN), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.", "keywords": ["reinforcement learning", "unsupervised learning", "skill discovery"], "authorids": ["ICLR.cc/2019/Conference/Paper752/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an algorithm for learning useful skills without a reward function, and show how these skills can be used to solve downstream tasks.", "pdf": "/pdf/903265bc2103aafd2b050824b8ce123d506a359a.pdf", "paperhash": "anonymous|diversity_is_all_you_need_learning_skills_without_a_reward_function", "_bibtex": "@inproceedings{    \nanonymous2019diversity,    \ntitle={Diversity is All You Need: Learning Skills without a Reward Function},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJx63jRqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylahsR9tX", "original": "rJx93M2qKQ", "number": 753, "cdate": 1538087860973, "ddate": null, "tcdate": 1538087860973, "tmdate": 1538156064262, "tddate": null, "forum": "BylahsR9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Low-Rank Matrix Factorization of LSTM as Effective Model Compression", "abstract": "Large-scale Long Short-Term Memory (LSTM) cells are often the building blocks of many state-of-the-art algorithms for tasks in Natural Language Processing (NLP). However, LSTMs are known to be computationally inefficient because the memory capacity of the models depends on the number of parameters, and the inherent recurrence that models the temporal dependency is not parallelizable. In this paper, we propose simple, but effective, low-rank matrix factorization (MF) algorithms to compress network parameters and significantly speed up LSTMs with almost no loss of performance (and sometimes even gain). To show the effectiveness of our method across different tasks, we examine two settings: 1) compressing core LSTM layers in Language Models, 2) compressing biLSTM layers of ELMo~\\citep{ELMo} and evaluate in three downstream NLP tasks (Sentiment Analysis, Textual Entailment, and Question Answering). The latter is particularly interesting as embeddings from large pre-trained biLSTM Language Models are often used as contextual word representations. Finally, we discover that matrix factorization performs better in general, additive recurrence is often more important than multiplicative recurrence, and we identify an interesting correlation between matrix norms and compression performance.\n\n", "keywords": ["NLP", "LSTM", "Compression", "Low Rank", "Norm Analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper753/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose simple, but effective, low-rank matrix factorization (MF) algorithms to speed up in running time, save memory, and improve the performance of LSTMs.", "pdf": "/pdf/48f989c43de9234ec6ff3e81bd6d5a8c97f034a8.pdf", "paperhash": "anonymous|lowrank_matrix_factorization_of_lstm_as_effective_model_compression", "_bibtex": "@inproceedings{    \nanonymous2019low-rank,    \ntitle={Low-Rank Matrix Factorization of LSTM as Effective Model Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylahsR9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJe62s09tX", "original": "HyxvNptqKX", "number": 754, "cdate": 1538087861147, "ddate": null, "tcdate": 1538087861147, "tmdate": 1538156064045, "tddate": null, "forum": "HJe62s09tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Hyper-alignment for Multilingual Word Embeddings", "abstract": "We consider the problem of aligning continuous word representations, learned in multiple languages, to a common space. It was recently shown that, in the case of two languages, it is possible to learn such a mapping without supervision. In this paper, we extend one of the proposed methods to the problem of aligning multiple languages to a common space. A simple solution to this problem is to independently map all languages to English. Unfortunately, this can degrade the alignments between languages different from English. We thus\tpropose\tto add constraints to ensure that the learned mappings can be composed, leading to better alignments. We evaluate our method on the problem of aligning word vectors in eleven languages, showing improvement in word translation requiring the composition of mappings.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper754/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c6cebdc5a6a5dd4bafb21b1aa3752de6ad9637b2.pdf", "paperhash": "anonymous|unsupervised_hyperalignment_for_multilingual_word_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Hyper-alignment for Multilingual Word Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJe62s09tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgT3jRct7", "original": "H1eEnu9ctQ", "number": 755, "cdate": 1538087861319, "ddate": null, "tcdate": 1538087861319, "tmdate": 1538156063838, "tddate": null, "forum": "rkgT3jRct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation", "abstract": "Answerer in Questioner's Mind (AQM) is an information-theoretic framework that has been recently proposed for task-oriented dialog systems. AQM benefits from asking a question that would maximize the information gain when it is asked. However, due to its intrinsic nature of explicitly calculating the information gain, AQM has a limitation when the solution space is very large. To address this, we propose AQM+ that can deal with a large-scale problem and ask a question that is more coherent to the current context of the dialog. We evaluate our method on GuessWhich, a challenging task-oriented visual dialog problem, where the number of candidate classes is near 10K. Our experimental results and ablation studies show that AQM+ outperforms the state-of-the-art models by a remarkable margin with a reasonable approximation. In particular, the proposed AQM+ reduces more than 60% of error as the dialog proceeds, while the comparative algorithms diminish the error by less than 6%. Based on our results, we argue that AQM+ is a general task-oriented dialog algorithm that can be applied for non-yes-or-no responses. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper755/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4d4fab6760aa92fb81abd676397358bf80f0cfaa.pdf", "paperhash": "anonymous|largescale_answerer_in_questioners_mind_for_visual_dialog_question_generation", "_bibtex": "@inproceedings{    \nanonymous2019large-scale,    \ntitle={Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgT3jRct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJg6nj09F7", "original": "SJgz8UoqKQ", "number": 756, "cdate": 1538087861490, "ddate": null, "tcdate": 1538087861490, "tmdate": 1538156063628, "tddate": null, "forum": "SJg6nj09F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NEURAL MALWARE CONTROL WITH DEEP REINFORCEMENT LEARNING", "abstract": "Antimalware products are a key component in detecting malware attacks, and their engines typically execute unknown programs in a sandbox prior to running them on the native operating system. Files cannot be scanned indefinitely so the engine employs heuristics to determine when to halt execution. Previous research has investigated analyzing the sequence of system calls generated during this emulation process to predict if an unknown file is malicious, but these models require the emulation to be stopped after executing a fixed number of events from the beginning of the file. Also, these classifiers are not accurate enough to halt emulation in the middle of the file on their own. In this paper, we propose a novel algorithm which overcomes this limitation and learns the best time to halt the file's execution based on deep reinforcement learning (DRL). Because the new DRL-based system continues to emulate the unknown file until it can make a confident decision to stop, it prevents attackers from avoiding detection by initiating malicious activity after a fixed number of system calls. Results show that the proposed malware execution control model automatically halts emulation for 91.3\\% of the files earlier than heuristics employed by the engine. Furthermore, classifying the files at that time improves the true positive rate by 61.5%, at a false positive rate of 1%, compared to a baseline classifier.", "keywords": ["malware", "execution", "control", "deep reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper756/Authors"], "authors": ["Anonymous"], "TL;DR": "A deep reinforcement learning-based system is proposed to control when to halt the emulation of an unknown file and to improve the detection rate of a deep malware classifier.", "pdf": "/pdf/76d48a687a17e35e453b3c635c407b84d2f35c44.pdf", "paperhash": "anonymous|neural_malware_control_with_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={NEURAL MALWARE CONTROL WITH DEEP REINFORCEMENT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJg6nj09F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gR2sC9FX", "original": "Byxz0brcFQ", "number": 757, "cdate": 1538087861660, "ddate": null, "tcdate": 1538087861660, "tmdate": 1538156063417, "tddate": null, "forum": "r1gR2sC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Spectral Bias of Neural Networks", "abstract": "Prior work has theoretically established neural networks as a class of highly expressive functions. Their ability to memorize even random input-output mapping with 100% accuracy can be seen as a practical implication of this aspect. In this work we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis to study neural networks, We show that deep ReLU networks are biased towards low frequency functions, meaning that, they cannot have local fluctuations without affecting their global behavior. Intuitively, this property is in line with the observation that over-parameterized networks find simple patterns that generalize across data samples. We also investigate how the shape of the data manifold affects this spectral bias by showing strong evidence that different manifold shapes induce significantly different learning curves for deep ReLU networks and present a theoretical understanding of this behavior. Finally, we study the robustness of parameters to develop the intuition that parameters of a network must work together to express high frequency functions. ", "keywords": ["deep learning theory", "fourier analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper757/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate ReLU networks in the Fourier domain and demonstrate peculiar behaviour.", "pdf": "/pdf/358e415247eeac0eb2f4d474a37c78b4d66d5259.pdf", "paperhash": "anonymous|on_the_spectral_bias_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Spectral Bias of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gR2sC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklAhi09Y7", "original": "SJeBxii5Km", "number": 758, "cdate": 1538087861838, "ddate": null, "tcdate": 1538087861838, "tmdate": 1538156063209, "tddate": null, "forum": "HklAhi09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Question Generation using a Scratchpad Encoder", "abstract": "In this paper we introduce the Scratchpad Encoder, a novel addition to the sequence to sequence (seq2seq) framework and explore its effectiveness in generating natural language questions from a given logical form. The Scratchpad encoder enables the decoder at each time step to modify all the encoder outputs, thus using the encoder as a \"scratchpad\" memory to keep track of what has been generated so far and to guide future generation. Experiments on a knowledge based question generation dataset show that our approach generates more fluent and expressive questions according to quantitative metrics and human judgments.", "keywords": ["Question Generation", "Natural Language Generation", "Scratchpad Encoder", "Sequence to Sequence"], "authorids": ["ICLR.cc/2019/Conference/Paper758/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper we introduce the Scratchpad Encoder, a novel addition to the sequence to sequence (seq2seq) framework and explore its effectiveness in generating natural language questions from a given logical form.", "pdf": "/pdf/9e75567c6486b39e73cba4acb9c64c21b6294314.pdf", "paperhash": "anonymous|question_generation_using_a_scratchpad_encoder", "_bibtex": "@inproceedings{    \nanonymous2019question,    \ntitle={Question Generation using a Scratchpad Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklAhi09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1fA3oActQ", "original": "SkeSfMstYX", "number": 759, "cdate": 1538087862013, "ddate": null, "tcdate": 1538087862013, "tmdate": 1538156062992, "tddate": null, "forum": "B1fA3oActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation", "abstract": "Sequence-to-Sequence  (Seq2Seq)  neural  models  have  become  popular  for  text generation problems,  e.g.   neural machine translation (NMT) (Bahdanau et al.,2014;  Britz  et  al.,  2017),  text  summarization  (Nallapati  et  al.,  2017;  Wang  &Ling, 2016), and image captioning (Venugopalan et al., 2015; Liu et al., 2017). Though sequential modeling has been shown to be effective, the dependency graph among words contains additional semantic information and thus can be utilized for sentence modeling. In this paper, we propose a Graph-Sequence-to-Sequence(GraphSeq2Seq) model to fuse the dependency graph among words into the traditional  Seq2Seq  framework.   For each sample,  the sub-graph  of each word is encoded to a graph representation, which is then utilized to sequential encoding. At last, a sequence decoder is leveraged for output generation. Since above model fuses different features by contacting them together to encode, we also propose a variant of our model that regards the graph representations as additional annotations in attention mechanism (Bahdanau et al., 2014) by separately encoding different features.  Experiments on several translation benchmarks show that our models can outperform existing state-of-the-art methods, demonstrating the effectiveness of the combination of Graph2Seq and Seq2Seq.", "keywords": ["Neural Machine Translation", "Natural Language Generation", "Graph Embedding", "LSTM"], "authorids": ["ICLR.cc/2019/Conference/Paper759/Authors"], "authors": ["Anonymous"], "TL;DR": "Graph-Sequence-to-Sequence for Neural Machine Translation", "pdf": "/pdf/df68b7fbbefec4cd8f9dc11c45c1d13153c5ba72.pdf", "paperhash": "anonymous|graphseq2seq_graphsequencetosequence_for_neural_machine_translation", "_bibtex": "@inproceedings{    \nanonymous2019graphseq2seq:,    \ntitle={GraphSeq2Seq: Graph-Sequence-to-Sequence for Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1fA3oActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzR2iRcK7", "original": "HyeUGb-5YX", "number": 760, "cdate": 1538087862186, "ddate": null, "tcdate": 1538087862186, "tmdate": 1538156062788, "tddate": null, "forum": "SJzR2iRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-class classification without multi-class labels", "abstract": "This work presents a new strategy for multi-class classification that requires no class-specific labels, but instead leverages pairwise similarity between examples, which is a weaker form of annotation. The proposed method, meta classification learning, optimizes a binary classifier for pairwise similarity prediction and through this process learns a multi-class classifier as a submodule. We formulate this approach, present a probabilistic graphical model for it, and derive a surprisingly simple loss function that can be used to learn neural network-based models. We then demonstrate that this same framework generalizes to the supervised, unsupervised cross-task, and semi-supervised settings. Our method is evaluated against state of the art in all three learning paradigms and shows a superior or comparable accuracy, providing evidence that learning multi-class classification without multi-class labels is a viable learning option.", "keywords": ["classification", "unsupervised learning", "semi-supervised learning", "problem reduction", "weak supervision", "cross-task", "learning", "deep learning", "neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper760/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/beedbd5c7d187a3b467a9ea0d2d813e0bd8623cd.pdf", "paperhash": "anonymous|multiclass_classification_without_multiclass_labels", "_bibtex": "@inproceedings{    \nanonymous2019multi-class,    \ntitle={Multi-class classification without multi-class labels},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzR2iRcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hy4R2oRqKQ", "original": "HJeip0L5tQ", "number": 761, "cdate": 1538087862359, "ddate": null, "tcdate": 1538087862359, "tmdate": 1538156062579, "tddate": null, "forum": "Hy4R2oRqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Canonical Correlation Analysis with Implicit Distributions", "abstract": "Canonical Correlation Analysis (CCA) is a ubiquitous technique that shows promising performance in multi-view learning problems. Due to the conjugacy of the prior and the likelihood, probabilistic CCA (PCCA) presents the posterior with an analytic solution, which provides probabilistic interpretation for classic linear CCA. As the multi-view data are usually complex in practice, nonlinear mappings are adopted to capture nonlinear dependency among the views. However, the interpretation provided in PCCA cannot be generalized to this nonlinear setting, as the distribution assumptions on the prior and the likelihood makes it restrictive to capture nonlinear dependency. To overcome this bottleneck, in this paper, we provide a novel perspective for CCA based on implicit distributions. Specifically, we present minimum Conditional Mutual Information (CMI) as a new criteria to capture nonlinear dependency for multi-view learning problem. To eliminate the explicit distribution requirement in direct estimation of CMI, we derive an objective whose minimization implicitly leads to the proposed criteria. Based on this objective, we present an implicit probabilistic formulation for CCA, named Implicit CCA (ICCA), which provides a flexible framework to design CCA extensions with implicit distributions. As an instantiation, we present adversarial CCA (ACCA), a nonlinear CCA variant which benefits from consistent encoding achieved by adversarial learning. Quantitative correlation analysis and superior performance on cross-view generation task demonstrate the superiority of the proposed ACCA.", "keywords": ["Canonical Correlation Analysis", "implicit probabilistic model", "cross-view structure output prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper761/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a theoretical study for CCA based on implicit distributions and proposes a generative nonlinear CCA variant which achieves consistent encoding for the multi-view input.", "pdf": "/pdf/5a52021160f96fffcc5a77f6b85baa696e8275e7.pdf", "paperhash": "anonymous|canonical_correlation_analysis_with_implicit_distributions", "_bibtex": "@inproceedings{    \nanonymous2019canonical,    \ntitle={Canonical Correlation Analysis with Implicit Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hy4R2oRqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeJ6iR9Km", "original": "SyePBgT9Y7", "number": 762, "cdate": 1538087862526, "ddate": null, "tcdate": 1538087862526, "tmdate": 1538156062377, "tddate": null, "forum": "SkeJ6iR9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Sparse Coding", "abstract": "Variationalauto-encoders(VAEs)offeratractableapproachwhenperformingapproximate inference in otherwise intractable generative models. However, standard VAEs often produce latent codes that are disperse and lack interpretability, thus making the resulting representations unsuitable for auxiliary tasks (e.g. classi\ufb01cation) and human interpretation. We address these issues by merging ideas fromvariationalauto-encodersandsparsecoding,andproposetoexplicitlymodel sparsity in the latent space of a VAE with a Spike and Slab prior distribution. We derive the variational lower bound using a discrete mixture recognition function thereby making approximate posterior inference as computational ef\ufb01cient as in the standard VAE case. With the new approach, we are able to infer truly sparse representations with generally intractable non-linear probabilistic models. We show that these sparse representations are advantageous over standard VAE representationsontwobenchmarkclassi\ufb01cationtasks(MNISTandFashion-MNIST) by demonstratingimproved classi\ufb01cation accuracy and signi\ufb01cantly increased robustness to the number of latent dimensions. Furthermore, we demonstrate qualitatively that the sparse elements capture subjectively understandable sources of variation.\n", "keywords": ["Variational Auto-Encoders", "Sparse Coding", "Variational Inference"], "authorids": ["ICLR.cc/2019/Conference/Paper762/Authors"], "authors": ["Anonymous"], "TL;DR": "We explore the intersection of VAEs and sparse coding.", "pdf": "/pdf/e2c058968ec0806e67571112bb77cf7714eeecb6.pdf", "paperhash": "anonymous|variational_sparse_coding", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Sparse Coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeJ6iR9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlk6iRqKX", "original": "H1gG02Jctm", "number": 763, "cdate": 1538087862694, "ddate": null, "tcdate": 1538087862694, "tmdate": 1538156062156, "tddate": null, "forum": "rJlk6iRqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach", "abstract": "We study the problem of attacking machine learning models in the hard-label black-box setting, where no model information is revealed except that the attacker can make queries to probe the corresponding hard-label decisions. This is a very challenging problem since the direct extension of state-of-the-art white-box attacks (e.g., C&W or PGD) to the hard-label black-box setting will require minimizing a non-continuous step function, which is combinatorial and cannot be solved by a gradient-based optimizer. The only two current approaches are based on random walk on the boundary (Brendel et al., 2017) and random trials to evaluate the loss function (Ilyas et al., 2018), which require lots of queries and lacks convergence guarantees. \nWe propose a novel way to formulate the hard-label black-box attack as a real-valued optimization problem which is usually continuous and can be solved by any zeroth order optimization algorithm. For example, using the Randomized Gradient-Free method (Nesterov & Spokoiny, 2017), we are able to bound the number of iterations needed for our algorithm to achieve stationary points under mild assumptions. We demonstrate that our proposed method outperforms the previous stochastic approaches to attacking convolutional neural networks on MNIST, CIFAR, and ImageNet datasets. More interestingly, we show that the proposed algorithm can also be used to attack other discrete and non-continuous machine learning models, such as Gradient Boosting Decision Trees (GBDT).", "keywords": ["Adversarial example", "Hard-label", "Black-box attack", "Query-efficient"], "authorids": ["ICLR.cc/2019/Conference/Paper763/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8e1aa47569975325dd4a7baa856c02050781a5d9.pdf", "paperhash": "anonymous|queryefficient_hardlabel_blackbox_attack_an_optimizationbased_approach", "_bibtex": "@inproceedings{    \nanonymous2019query-efficient,    \ntitle={Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlk6iRqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygypo0qtm", "original": "Bke46Ip5tX", "number": 764, "cdate": 1538087862865, "ddate": null, "tcdate": 1538087862865, "tmdate": 1538156061955, "tddate": null, "forum": "rygypo0qtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Show, Attend and Translate: Unsupervised Image Translation with Self-Regularization and Attention", "abstract": "Image translation between two domains is a class of problems aiming to learn mapping from an input image in the source domain to an output image in the target domain. It has been applied to numerous applications, such as data augmentation, domain adaptation, and unsupervised training. When paired training data is not accessible, image translation becomes an ill-posed problem. We constrain the problem with the assumption that the translated image needs to be perceptually similar to the original image and also appears to be drawn from the new domain, and propose a simple yet effective image translation model consisting of a single generator trained with a self-regularization term and an adversarial term. We further notice that existing image translation techniques are agnostic to the subjects of interest and often introduce unwanted changes or artifacts to the input. Thus we propose to add an attention module to predict an attention map to guide the image translation process. The module learns to attend to key parts of the image while keeping everything else unaltered, essentially avoiding undesired artifacts or changes. The predicted attention map also opens door to applications such as unsupervised segmentation and saliency detection. Extensive experiments and evaluations show that our model while being simpler, achieves significantly better performance than existing image translation methods.", "keywords": ["image translation", "domain adaptation", "saliency detection"], "authorids": ["ICLR.cc/2019/Conference/Paper764/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a simple generative model for unsupervised image translation and saliency detection.", "pdf": "/pdf/8315e848c1166780ef1573433719648fb55b113e.pdf", "paperhash": "anonymous|show_attend_and_translate_unsupervised_image_translation_with_selfregularization_and_attention", "_bibtex": "@inproceedings{    \nanonymous2019show,,    \ntitle={Show, Attend and Translate: Unsupervised Image Translation with Self-Regularization and Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygypo0qtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lyTjAqYX", "original": "rygr68TcYQ", "number": 765, "cdate": 1538087863040, "ddate": null, "tcdate": 1538087863040, "tmdate": 1538156061745, "tddate": null, "forum": "r1lyTjAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Recurrent Experience Replay in Distributed Reinforcement Learning", "abstract": "Building on the recent successes of distributed training of RL agents, in this paper we investigate the training of RNN-based RL agents from experience replay. We investigate the effects of parameter lag resulting in representational drift and recurrent state staleness and empirically derive an improved training strategy. Using a single network architecture and fixed set of hyper-parameters, the resulting agent, Recurrent Replay Distributed DQN, triples the previous state of the art on Atari-57, and surpasses the state of the art on DMLab-30. R2D2 is the first agent to exceed human-level performance in 52 of the 57 Atari games.", "keywords": ["RNN", "LSTM", "experience replay", "distributed training", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper765/Authors"], "authors": ["Anonymous"], "TL;DR": "Investigation on combining recurrent neural networks and experience replay leading to state-of-the-art agent on both Atari-57 and DMLab-30 using single set of hyper-parameters.", "pdf": "/pdf/6faf5a4e5478dd050ba3945f32858e03424882a5.pdf", "paperhash": "anonymous|recurrent_experience_replay_in_distributed_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019recurrent,    \ntitle={Recurrent Experience Replay in Distributed Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lyTjAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1My6sR9tX", "original": "HJgpW-wYFm", "number": 766, "cdate": 1538087863220, "ddate": null, "tcdate": 1538087863220, "tmdate": 1538156061536, "tddate": null, "forum": "r1My6sR9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Learning via Meta-Learning", "abstract": "A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that relatively simple mechanisms for task design, such as clustering unsupervised representations, lead to good performance on a variety of downstream tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the representation learned by four prior unsupervised learning methods.", "keywords": ["unsupervised learning", "meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper766/Authors"], "authors": ["Anonymous"], "TL;DR": "An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.", "pdf": "/pdf/4df8ecc232d68185e62b597c5cb12ac17da5d753.pdf", "paperhash": "anonymous|unsupervised_learning_via_metalearning", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Learning via Meta-Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1My6sR9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1GkToR5tm", "original": "B1e-3baFYQ", "number": 767, "cdate": 1538087863390, "ddate": null, "tcdate": 1538087863390, "tmdate": 1538156061335, "tddate": null, "forum": "S1GkToR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discriminator Rejection Sampling", "abstract": "We propose a rejection sampling scheme using the discriminator of a GAN to\napproximately correct errors in the GAN generator distribution. We show that\nunder quite strict assumptions, this will allow us to recover the data distribution\nexactly. We then examine where those strict assumptions break down and design a\npractical algorithm\u2014called Discriminator Rejection Sampling (DRS)\u2014that can be\nused on real data-sets. Finally, we demonstrate the efficacy of DRS on a mixture of\nGaussians and on the state of the art SAGAN model. On ImageNet, we train an\nimproved baseline that increases the best published Inception Score from 52.52 to\n62.36 and reduces the Frechet Inception Distance from 18.65 to 14.79. We then use\nDRS to further improve on this baseline, improving the Inception Score to 76.08\nand the FID to 13.75.", "keywords": ["GANs", "rejection sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper767/Authors"], "authors": ["Anonymous"], "TL;DR": "We use a GAN discriminator to perform an approximate rejection sampling scheme on the output of the GAN generator.", "pdf": "/pdf/246d43e164fbf3f1b71811e0da33c4b4cb1fa48c.pdf", "paperhash": "anonymous|discriminator_rejection_sampling", "_bibtex": "@inproceedings{    \nanonymous2019discriminator,    \ntitle={Discriminator Rejection Sampling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1GkToR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxepo0cFX", "original": "r1gtQhZ5tX", "number": 768, "cdate": 1538087863562, "ddate": null, "tcdate": 1538087863562, "tmdate": 1538156061128, "tddate": null, "forum": "ryxepo0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "AntisymmetricRNN: A dynamical System View on Recurrent Neural Networks", "abstract": "Recurrent neural networks have gained widespread use in modeling sequential data. Learning long-term dependencies using these models remains difficult though, due to exploding or vanishing gradients. In this paper, we draw connections between recurrent networks and ordinary differential equations. A special form of recurrent network called the AntisymmetricRNN is proposed under this theoretical framework, which is able to capture long-term dependencies thanks to the stability property of its underlying differential equation. In comparison to existing approaches for improving RNN trainability, which often incur significant computation overhead, AntisymmetricRNN achieves the same goal by design. We showcase the advantage of this new architecture through extensive simulations and experiments. AntisymmetricRNN exhibits much more predictable dynamics. It outperforms regular LSTM models on tasks requiring long-term memory, and matches the performance on tasks where short-term dependencies dominate despite being much simpler.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper768/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d0a56cd84a60ea140c66d70c9964b0095ca796b6.pdf", "paperhash": "anonymous|antisymmetricrnn_a_dynamical_system_view_on_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019antisymmetricrnn:,    \ntitle={AntisymmetricRNN: A dynamical System View on Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxepo0cFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJll6o09tm", "original": "r1lsWwTcKm", "number": 769, "cdate": 1538087863731, "ddate": null, "tcdate": 1538087863731, "tmdate": 1538156060923, "tddate": null, "forum": "BJll6o09tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Padam: Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks", "abstract": "Adaptive gradient methods, which adopt historical gradient information to automatically adjust the learning rate, despite the nice property of fast convergence, have been observed to generalize worse than stochastic gradient descent (SGD) with momentum in training deep neural networks. This leaves how to close the generalization gap of adaptive gradient methods an open problem. In this work, we show that adaptive gradient methods such as Adam, Amsgrad, are sometimes \"over adapted\". We design a new algorithm, called Partially adaptive momentum estimation method (Padam), which unifies the Adam/Amsgrad with SGD by introducing a partial adaptive parameter p, to achieve the best from both worlds. Experiments on standard benchmarks show that Padam can maintain fast convergence rate as Adam/Amsgrad while generalizing as well as SGD in training deep neural networks. These results would suggest practitioners pick up adaptive gradient methods once again for faster training of deep neural networks.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper769/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fdc7396dce84798c8e915cd4d6540cdbbe6ca027.pdf", "paperhash": "anonymous|padam_closing_the_generalization_gap_of_adaptive_gradient_methods_in_training_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019padam:,    \ntitle={Padam: Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJll6o09tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgxasA5Ym", "original": "BJlHtDh9t7", "number": 770, "cdate": 1538087863894, "ddate": null, "tcdate": 1538087863894, "tmdate": 1538156060719, "tddate": null, "forum": "HkgxasA5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors", "abstract": "Obtaining reliable uncertainty estimates of neural network predictions is a long standing challenge. Bayesian neural networks have been proposed as a solution, but it remains open how to specify the prior. In particular, the common practice of a standard normal prior in weight space imposes only weak regularities, causing the function posterior to possibly generalize in unforeseen ways on out-of-distribution inputs. We propose noise contrastive priors (NCPs). The key idea is to train the model to output high uncertainty for data points outside of the training distribution. NCPs do so using an input prior, which adds noise to the inputs of the current mini batch, and an output prior, which is a wide distribution given these inputs. NCPs are compatible with any model that represents predictive uncertainty, are easy to scale, and yield reliable uncertainty estimates throughout training. Empirically, we show that NCPs prevent overfitting outside of the training distribution and result in uncertainty estimates that are useful for active learning. We demonstrate the scalability of our method on the flight delays data set, where we significantly improve upon previously published results.", "keywords": ["uncertainty estimates", "out of distribution", "bayesian neural network", "neural network priors", "regression", "active learning"], "authorids": ["ICLR.cc/2019/Conference/Paper770/Authors"], "authors": ["Anonymous"], "TL;DR": "We train neural networks to be uncertain on noisy inputs to avoid overconfident predictions outside of the training distribution.", "pdf": "/pdf/eecb2f0a21e123859305b63439a7f91d92c488c3.pdf", "paperhash": "anonymous|reliable_uncertainty_estimates_in_deep_neural_networks_using_noise_contrastive_priors", "_bibtex": "@inproceedings{    \nanonymous2019reliable,    \ntitle={Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgxasA5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyllasActm", "original": "Bkewnls9t7", "number": 771, "cdate": 1538087864065, "ddate": null, "tcdate": 1538087864065, "tmdate": 1538156060514, "tddate": null, "forum": "HyllasActm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "End-to-End Learning of Video Compression Using Spatio-Temporal Autoencoders", "abstract": "Deep learning (DL) is having a revolutionary impact in image processing, with DL-based approaches now holding the state of the art in many tasks, including image compression. However, video compression has so far resisted the DL revolution, with the very few proposed approaches being based on complex and impractical architectures with multiple networks. This paper proposes what we believe is the first approach to end-to-end learning of a single network for video compression. We tackle the problem in a novel way, avoiding explicit motion estimation/prediction, by formalizing it as the rate-distortion optimization of a single spatio-temporal autoencoder; i.e., we jointly learn a latent-space projection transform and a synthesis transform for low bitrate video compression. The quantizer uses a rounding scheme, which is relaxed during training, and an entropy estimation technique to enforce an information bottleneck, inspired by recent advances in image compression. We compare the obtained video compression networks with standard widely-used codecs, showing better performance than the MPEG-4 standard, being competitive with H.264/AVC for low bitrates. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper771/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1f47583e0f12599fbd9242d5d3da8f404415e069.pdf", "paperhash": "anonymous|endtoend_learning_of_video_compression_using_spatiotemporal_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-End Learning of Video Compression Using Spatio-Temporal Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyllasActm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJMeTo09YQ", "original": "HyeDBwa5tm", "number": 773, "cdate": 1538087864407, "ddate": null, "tcdate": 1538087864407, "tmdate": 1538156060104, "tddate": null, "forum": "SJMeTo09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Guided Exploration in Deep Reinforcement Learning", "abstract": "This paper proposes a new method to drastically speed up deep reinforcement learning (deep RL) training for problems that have the property of \\textit{state-action permissibility} (SAP). Two types of permissibility are defined under SAP. The first type says that after an action $a_t$ is performed in a state $s_t$ and the agent reaches the new state $s_{t+1}$, the agent can decide whether the action $a_t$ is \\textit{permissible} or \\textit{not permissible} in state $s_t$. The second type says that even without performing the action $a_t$ in state $s_t$, the agent can already decide whether $a_t$ is permissible or not in $s_t$. An action is not permissible in a state if the action can never lead to an optimal solution and thus should not be tried. We incorporate the proposed SAP property into two state-of-the-art deep RL algorithms to guide their state-action exploration. Results show that the SAP guidance can markedly speed up training.", "keywords": ["deep reinforcement learning", "guided exploration", "RL training speed up"], "authorids": ["ICLR.cc/2019/Conference/Paper773/Authors"], "authors": ["Anonymous"], "TL;DR": "introduces a guided action exploration mechanism that drastically speed up RL training", "pdf": "/pdf/de283580add1c2cd56eec9fe22757b7165aea466.pdf", "paperhash": "anonymous|guided_exploration_in_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019guided,    \ntitle={Guided Exploration in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMeTo09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1g-TiC9FX", "original": "H1xiLwa5t7", "number": 774, "cdate": 1538087864579, "ddate": null, "tcdate": 1538087864579, "tmdate": 1538156059894, "tddate": null, "forum": "r1g-TiC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Collobrative Networks", "abstract": "This paper presents a conceptually general and modularized neural collaborative network (NCN), which overcomes the limitations of the traditional convolutional neural networks (CNNs) in several aspects. Firstly, our NCN can directly handle non-Euclidean data without any pre-processing (e.g., graph normalizations) by defining a simple yet basic unit named neuron array for feature representation. Secondly, our NCN is capable of achieving both rotational equivariance and invariance properties via a simple yet powerful neuron collaboration mechanism, which imposes a ``glocal'' operation to capture both global and local information among neuron arrays within each layer. Thirdly, compared to the state-of-the-art networks that using large CNN kernels, our NCN with considerably fewer parameters can also achieve their strengths in feature learning by only exploiting highly efficient 1x1 convolution operations. Extensive experimental analyses on learning feature representation, handling novel viewpoints, and handling non-euclidean data demonstrate that our NCN can not only achieve state-of-the-art performance but also overcome the limitation of the conventional CNNs. The source codes will be released to facilite future researches after the review period for ensuring the anonymity.", "keywords": ["deep learning", "neural architecture search", "collaboration representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper774/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/94a849acbbf154d794f5a2bbe73a3934288f743e.pdf", "paperhash": "anonymous|neural_collobrative_networks", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Collobrative Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g-TiC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eZ6sRcFm", "original": "BklVkvgGYQ", "number": 775, "cdate": 1538087864739, "ddate": null, "tcdate": 1538087864739, "tmdate": 1538156059685, "tddate": null, "forum": "H1eZ6sRcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Autoencoders for Text Modeling without Weakening the Decoder", "abstract": "Previous work (Bowman et al., 2015; Yang et al., 2017) has found difficulty developing generative models based on variational autoencoders (VAEs) for text. To address the problem of the decoder ignoring information from the encoder (posterior collapse), these previous models weaken the capacity of the decoder to force the model to use information from latent variables. However, this strategy is not ideal as it degrades the quality of generated text and increases hyper-parameters. In this paper, we propose a new VAE for text utilizing a multimodal prior distribution, a modified encoder, and multi-task learning. We show our model can generate well-conditioned sentences without weakening the capacity of the decoder. Also, the multimodal prior distribution improves the interpretability of acquired representations.", "keywords": ["variational autoencoders", "generative model", "deep neural network", "text modeling", "unsupervised learning", "multimodal"], "authorids": ["ICLR.cc/2019/Conference/Paper775/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a model of variational autoencoders for text modeling without weakening the decoder, which improves the quality of text generation and interpretability of acquired representations.", "pdf": "/pdf/ccdf57c5e7510564837e4345dbf4dc805eb446fd.pdf", "paperhash": "anonymous|variational_autoencoders_for_text_modeling_without_weakening_the_decoder", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Autoencoders for Text Modeling without Weakening the Decoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eZ6sRcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ebTsActm", "original": "rkeDcR55tm", "number": 776, "cdate": 1538087864964, "ddate": null, "tcdate": 1538087864964, "tmdate": 1538156059465, "tddate": null, "forum": "H1ebTsActm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality", "abstract": "Deep learning has shown high performances in various types of tasks from visual recognition to natural language processing,\nwhich indicates superior flexibility and adaptivity of deep learning.\nTo understand this phenomenon theoretically, we develop a new approximation and estimation error analysis of \ndeep learning with the ReLU activation for functions in a Besov space and its variant with mixed smoothness.\nThe Besov space is a considerably general function space including the Holder space and Sobolev space, and especially can capture spatial inhomogeneity of smoothness. Through the analysis in the Besov space,  it is shown that deep learning can achieve the minimax optimal rate and outperform any non-adaptive (linear) estimator such as kernel ridge regression,\nwhich shows that deep learning has higher adaptivity to the spatial inhomogeneity of the target function than other estimators such as linear ones. In addition to this, it is shown that deep learning can avoid the curse of dimensionality if the target function is in a mixed smooth Besov space. We also show that the dependency of the convergence rate on the dimensionality is tight due to its minimax optimality. These results support high adaptivity of deep learning and its superior ability as a feature extractor.\n", "keywords": ["deep learning theory", "approximation analysis", "generalization error analysis", "Besov space", "minimax optimality"], "authorids": ["ICLR.cc/2019/Conference/Paper776/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b4d68acbf559ac56418b0377c19b1ba1629b7ab2.pdf", "paperhash": "anonymous|adaptivity_of_deep_relu_network_for_learning_in_besov_and_mixed_smooth_besov_spaces_optimal_rate_and_curse_of_dimensionality", "_bibtex": "@inproceedings{    \nanonymous2019adaptivity,    \ntitle={Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ebTsActm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxbps09K7", "original": "H1xS1qrqY7", "number": 777, "cdate": 1538087865139, "ddate": null, "tcdate": 1538087865139, "tmdate": 1538156059259, "tddate": null, "forum": "SJxbps09K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Empirical observations on the instability of aligning word vector spaces with GANs", "abstract": "Unsupervised bilingual dictionary induction (UBDI) is useful for unsupervised machine translation and for cross-lingual transfer of models into low-resource languages. One approach to UBDI is to align word vector spaces in different languages using Generative adversarial networks (GANs) with linear generators, achieving state-of-the-art performance for several language pairs. For some pairs, however, GAN-based induction is unstable or completely fails to align the vector spaces. We focus on cases where linear transformations provably exist, but the performance of GAN-based UBDI depends heavily on the model initialization. We show that the instability depends on the shape and density of the vector sets, but not on noise; it is the result of local optima, but neither over-parameterization nor changing the batch size or the learning rate consistently reduces instability. Nevertheless, we can stabilize GAN-based UBDI through best-of-N model selection, based on an unsupervised stopping criterion. ", "keywords": ["natural language processing", "bilingual dictionary induction", "unsupervised learning", "generative adversarial networks"], "authorids": ["ICLR.cc/2019/Conference/Paper777/Authors"], "authors": ["Anonymous"], "TL;DR": "An empirical investigation of GAN-based alignment of word vector spaces, focusing on cases, where linear transformations provably exist, but training is unstable.", "pdf": "/pdf/c95badf04bce091af50e1d449fad519fea5ee36b.pdf", "paperhash": "anonymous|empirical_observations_on_the_instability_of_aligning_word_vector_spaces_with_gans", "_bibtex": "@inproceedings{    \nanonymous2019empirical,    \ntitle={Empirical observations on the instability of aligning word vector spaces with GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxbps09K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkfbpsAcF7", "original": "SJgw_Fh5Y7", "number": 778, "cdate": 1538087865314, "ddate": null, "tcdate": 1538087865314, "tmdate": 1538156059053, "tddate": null, "forum": "BkfbpsAcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Excessive Invariance Causes Adversarial Vulnerability", "abstract": "Despite their impressive performance, deep neural networks exhibit striking failures on out-of-distribution inputs. One core idea of adversarial example research is to reveal neural network errors under such distribution shift. We decompose these errors into two complementary sources: sensitivity and invariance. We show deep networks are not only too sensitive to task-irrelevant changes of their input, as is well-known from epsilon-adversarial examples, but are also too invariant to a wide range of task-relevant changes, thus making vast regions in input space vulnerable to adversarial attacks.\nAfter identifying this excessive invariance, we propose the usage of bijective deep networks to enable access to all variations. We introduce metameric sampling as an analytic attack for these networks, requiring no optimization, and show that it uncovers large subspaces of misclassified inputs. Then we apply these networks to MNIST and ImageNet and show that one can manipulate the class-specific content of almost any image without changing the hidden activations. Further, we extend the standard cross-entropy loss to strengthen the model against such manipulations via an information-theoretic analysis, providing the first approach tailored explicitly to overcome invariance-based vulnerability. We conclude by empirically illustrating its ability to control undesirable class-specific invariance, showing promise to overcome one major cause for adversarial examples.", "keywords": ["Generalization", "Adversarial Examples", "Invariance", "Information Theory", "Invertible Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper778/Authors"], "authors": ["Anonymous"], "TL;DR": "We show deep networks are not only too sensitive to task-irrelevant changes of their input, but also too invariant to a wide range of task-relevant changes, thus making vast regions in input space vulnerable to adversarial attacks.", "pdf": "/pdf/571bf083ee9d717e7835bcbd53dcdcf91dd7fa5c.pdf", "paperhash": "anonymous|excessive_invariance_causes_adversarial_vulnerability", "_bibtex": "@inproceedings{    \nanonymous2019excessive,    \ntitle={Excessive Invariance Causes Adversarial Vulnerability},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkfbpsAcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklbTjRcKX", "original": "B1lO7PF5Y7", "number": 779, "cdate": 1538087865490, "ddate": null, "tcdate": 1538087865490, "tmdate": 1538156058845, "tddate": null, "forum": "HklbTjRcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "What Information Does a ResNet Compress?", "abstract": "The information bottleneck principle (Shwartz-Ziv & Tishby, 2017) suggests that SGD-based training of deep neural networks results in optimally compressed hidden layers, from an information theoretic perspective. However, this claim was established on toy data. The goal of the work we present here is to test these claims in a realistic setting using a larger and deeper convolutional architecture, a ResNet model. We trained PixelCNN++ models as inverse representation decoders to measure the mutual information between hidden layers of a ResNet and input image data, when trained for (1) classification and (2) autoencoding. We find that two stages of learning happen for both training regimes, and that compression does occur, even for an autoencoder. Sampling images by conditioning on hidden layers\u2019 activations offers an intuitive visualisation to understand what a ResNets learns to forget.", "keywords": ["Deep Learning", "Information Bottleneck", "Residual Neural Networks", "Information Theory"], "authorids": ["ICLR.cc/2019/Conference/Paper779/Authors"], "authors": ["Anonymous"], "TL;DR": "The Information Bottleneck Principle applied to ResNets, using PixelCNN++ models to decode mutual information and conditionally generate images for information illustration", "pdf": "/pdf/ca92f44210da156162f49186dea72ffc2b5eb213.pdf", "paperhash": "anonymous|what_information_does_a_resnet_compress", "_bibtex": "@inproceedings{    \nanonymous2019what,    \ntitle={What Information Does a ResNet Compress?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklbTjRcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylzTiC5Km", "original": "SkeQga3cKX", "number": 780, "cdate": 1538087865657, "ddate": null, "tcdate": 1538087865657, "tmdate": 1538156058642, "tddate": null, "forum": "HylzTiC5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING", "abstract": "The unconditional generation of high fidelity images is a longstanding benchmark\nfor testing the performance of image decoders. Autoregressive image models\nhave been able to generate small images unconditionally, but the extension of\nthese methods to large images where fidelity can be more readily assessed has\nremained an open problem. Among the major challenges are the capacity to encode\nthe vast previous context and the sheer difficulty of learning a distribution that\npreserves both global semantic coherence and exactness of detail. To address the\nformer challenge, we propose the Subscale Pixel Network (SPN), a conditional\ndecoder architecture that generates an image as a sequence of image slices of equal\nsize. The SPN compactly captures image-wide spatial dependencies and requires a\nfraction of the memory and the computation. To address the latter challenge, we\npropose to use multidimensional upscaling to grow an image in both size and depth\nvia intermediate stages corresponding to distinct SPNs. We evaluate SPNs on the\nunconditional generation of CelebAHQ of size 256 and of ImageNet from size 32\nto 128. We achieve state-of-the-art likelihood results in multiple settings, set up\nnew benchmark results in previously unexplored settings and are able to generate\nvery high fidelity large scale samples on the basis of both datasets.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper780/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that autoregressive models can generate high fidelity images. ", "pdf": "/pdf/63d45b837d25bbb0b0548ad7a463e5c8a31ca798.pdf", "paperhash": "anonymous|generating_high_fidelity_images_with_subscale_pixel_networks_and_multidimensional_upscaling", "_bibtex": "@inproceedings{    \nanonymous2019generating,    \ntitle={GENERATING HIGH FIDELITY IMAGES WITH SUBSCALE PIXEL NETWORKS AND MULTIDIMENSIONAL UPSCALING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylzTiC5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gGpjActQ", "original": "Hke0bTt5t7", "number": 781, "cdate": 1538087865849, "ddate": null, "tcdate": 1538087865849, "tmdate": 1538156058436, "tddate": null, "forum": "r1gGpjActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hint-based Training for Non-Autoregressive Translation", "abstract": "Machine translation is an important real-world application, and neural network-based AutoRegressive Translation (ART) models have achieved very promising accuracy. Due to the unparallelizable nature of the autoregressive factorization, ART models have to generate tokens one by one during decoding and thus suffer from high inference latency. Recently, Non-AutoRegressive Translation (NART) models were proposed to reduce the inference time. However, they could only achieve inferior accuracy compared with ART models. To improve the accuracy of NART models, in this paper, we propose to leverage the hints from a well-trained ART model to train the NART model. We define two hints for the machine translation task: hints from hidden states and hints from word alignments, and use such hints to regularize the optimization of NART models. Experimental results show that the NART model trained with hints could achieve significantly better translation performance than previous NART models on several tasks. In particular, for the WMT14 En-De and De-En task, we obtain BLEU scores of 25.20 and 29.52 respectively, which largely outperforms the previous non-autoregressive baselines. It is even comparable to a strong LSTM-based ART model (24.60 on WMT14 En-De), but one order of magnitude faster in inference.", "keywords": ["Natural Language Processing", "Machine Translation", "Non-Autoregressive Model"], "authorids": ["ICLR.cc/2019/Conference/Paper781/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a training algorithm for non-autoregressive machine translation models, achieving comparable accuracy to strong autoregressive baselines, but one order of magnitude faster in inference.  ", "pdf": "/pdf/89e9b16b04ea6e8aa390d2175568bfc8f319f5c8.pdf", "paperhash": "anonymous|hintbased_training_for_nonautoregressive_translation", "_bibtex": "@inproceedings{    \nanonymous2019hint-based,    \ntitle={Hint-based Training for Non-Autoregressive Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gGpjActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkGG6s0qKQ", "original": "B1gqFCi9FX", "number": 782, "cdate": 1538087866017, "ddate": null, "tcdate": 1538087866017, "tmdate": 1538156058229, "tddate": null, "forum": "rkGG6s0qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The GAN Landscape: Losses, Architectures, Regularization, and Normalization", "abstract": "Generative adversarial networks (GANs) are a class of deep generative models which aim to learn a target distribution in an unsupervised fashion. While they were successfully applied to many problems, training a GAN is a notoriously challenging task and requires a significant amount of hyperparameter tuning, neural architecture engineering, and a non-trivial amount of ``tricks\". The success in many practical applications coupled with the lack of a measure to quantify the failure modes of GANs resulted in a plethora of proposed losses, regularization and normalization schemes, and neural architectures. In this work we take a sober view of the current state of GANs from a practical perspective. We reproduce the current state of the art and go beyond fairly exploring the GAN landscape. We discuss common pitfalls and reproducibility issues, open-source our code on Github, and provide pre-trained models on TensorFlow Hub.", "keywords": ["GANs", "empirical evaluation", "large-scale", "reproducibility"], "authorids": ["ICLR.cc/2019/Conference/Paper782/Authors"], "authors": ["Anonymous"], "TL;DR": "A sober view on the current state of GANs from a practical perspective", "pdf": "/pdf/66c6991c5ef7b65e1af7b2dfa50b6b54fe2a2aa4.pdf", "paperhash": "anonymous|the_gan_landscape_losses_architectures_regularization_and_normalization", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The GAN Landscape: Losses, Architectures, Regularization, and Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkGG6s0qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syfz6sC9tQ", "original": "H1gfLV9qtm", "number": 783, "cdate": 1538087866190, "ddate": null, "tcdate": 1538087866190, "tmdate": 1538156058027, "tddate": null, "forum": "Syfz6sC9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Feature Matching Networks", "abstract": "We propose a non-adversarial feature matching-based approach to train generative models. Our approach, Generative Feature Matching Networks (GFMN), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. We perform an extensive number of experiments with different challenging datasets, including Imagenet. Our experimental results demonstrate that,  due to the expressiveness of the features from pretrained Imagenet classifiers, \neven by just matching first order statistics, our approach can achieve state-of-the-art results for challenging benchmarks such as CIFAR10 and STL10.", "keywords": ["Generative Deep Neural Networks", "Feature Matching", "Maximum Mean Discrepancy", "Generative Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper783/Authors"], "authors": ["Anonymous"], "TL;DR": "A new non-adversarial feature matching-based approach to train generative models that achieves state-of-the-art results.", "pdf": "/pdf/4492afec72b6cf76f854f90c67d6491b22175803.pdf", "paperhash": "anonymous|generative_feature_matching_networks", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Feature Matching Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syfz6sC9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hk4fpoA5Km", "original": "r1g87_6cY7", "number": 784, "cdate": 1538087866363, "ddate": null, "tcdate": 1538087866363, "tmdate": 1538156057819, "tddate": null, "forum": "Hk4fpoA5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning", "abstract": "We identify two issues with the family of algorithms based on the Adversarial Imitation Learning framework. The first problem is implicit bias present in the reward functions used in these algorithms. While these biases might work well for some environments, they can also lead to sub-optimal behavior in others. Secondly, even though these algorithms can learn from few expert demonstrations, they require a prohibitively large number of interactions with the environment in order to imitate the expert for many real-world applications. In order to address these issues, we propose a new algorithm called Discriminator-Actor-Critic that uses off-policy Reinforcement Learning to reduce policy-environment interaction sample complexity by an average factor of 10. Furthermore, since our reward function is designed to be unbiased, we can apply our algorithm to many problems without making any task-specific adjustments. ", "keywords": ["deep learning", "reinforcement learning", "imitation learning", "adversarial learning"], "authorids": ["ICLR.cc/2019/Conference/Paper784/Authors"], "authors": ["Anonymous"], "TL;DR": "We address sample inefficiency and reward bias in adversarial imitation learning algorithms such as GAIL and AIRL.", "pdf": "/pdf/b2e4900628d22124abfe965529d4dd8c1bb31b3c.pdf", "paperhash": "anonymous|discriminatoractorcritic_addressing_sample_inefficiency_and_reward_bias_in_adversarial_imitation_learning", "_bibtex": "@inproceedings{    \nanonymous2019discriminator-actor-critic:,    \ntitle={Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hk4fpoA5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklXaoAcFX", "original": "Bke-DrdcYm", "number": 785, "cdate": 1538087866535, "ddate": null, "tcdate": 1538087866535, "tmdate": 1538156057607, "tddate": null, "forum": "rklXaoAcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Geomstats: a Python Package for Riemannian Geometry in Machine Learning", "abstract": "We introduce geomstats, a Python package for Riemannian modelization and optimization over manifolds such as hyperspheres, hyperbolic spaces, SPD matrices or Lie groups of transformations. Our contribution is threefold. First, geomstats allows the flexible modeling of many a machine learning problem through an efficient and extensively unit-tested implementations of these manifolds, as well as the set of useful Riemannian metrics, exponential and logarithm maps that we provide. Moreover, the wide choice of loss functions and our implementation of the corresponding gradients allow fast and easy optimization over manifolds. Finally, geomstats is the only package to provide a unified framework for Riemannian geometry, as the operations implemented in geomstats are available with different computing backends (numpy,tensorflow and keras), as well as with a GPU-enabled mode\u2013-thus considerably facilitating the application of Riemannian geometry in machine learning. In this paper, we present geomstats through a review of the utility and advantages of manifolds in machine learning, using the concrete examples that they span to show the efficiency and practicality of their implementation using our package", "keywords": ["Riemannian geometry", "Python package", "machine learning", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper785/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce geomstats, an efficient Python package for Riemannian modelization and optimization over manifolds compatible with both numpy and tensorflow .", "pdf": "/pdf/7f5dedfc65a39052a893b688fc8c1d8cae0cc84d.pdf", "paperhash": "anonymous|geomstats_a_python_package_for_riemannian_geometry_in_machine_learning", "_bibtex": "@inproceedings{    \nanonymous2019geomstats:,    \ntitle={Geomstats: a Python Package for Riemannian Geometry in Machine Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklXaoAcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeQToAqKQ", "original": "ryl-4uTcKX", "number": 786, "cdate": 1538087866701, "ddate": null, "tcdate": 1538087866701, "tmdate": 1538156057400, "tddate": null, "forum": "HJeQToAqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TherML: The Thermodynamics of Machine Learning", "abstract": "In this work we offer an information-theoretic framework for representation learning that connects with a wide class of existing objectives in machine learning. We develop a formal correspondence between this work and thermodynamics and discuss its implications.", "keywords": ["representation learning", "information theory", "information bottleneck", "thermodynamics", "predictive information"], "authorids": ["ICLR.cc/2019/Conference/Paper786/Authors"], "authors": ["Anonymous"], "TL;DR": "We offer a framework for representation learning that connects with a wide class of existing objectives and is analogous to thermodynamics.", "pdf": "/pdf/7cbd3e389d18abb3b90642dbd453925a05355a94.pdf", "paperhash": "anonymous|therml_the_thermodynamics_of_machine_learning", "_bibtex": "@inproceedings{    \nanonymous2019therml:,    \ntitle={TherML: The Thermodynamics of Machine Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeQToAqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklQas09tm", "original": "r1lF3DTqYm", "number": 787, "cdate": 1538087866870, "ddate": null, "tcdate": 1538087866870, "tmdate": 1538156057191, "tddate": null, "forum": "rklQas09tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Corresponded Rationales for Text Matching", "abstract": "The ability to predict matches between two sources of text has a number of applications including natural language inference (NLI) and question answering (QA). While flexible neural models have become effective tools in solving these tasks, they are rarely transparent in terms of the mechanism that mediates the prediction. In this paper, we propose a self-explaining architecture where the model is forced to highlight, in a dependent manner, how spans of one side of the input match corresponding segments of the other side in order to arrive at the overall decision. The text spans are regularized to be coherent and concise, and their correspondence is captured explicitly. The text spans -- rationales -- are learned entirely as latent mechanisms, guided only by the distal supervision from the end-to-end task. We evaluate our model on both NLI and QA using three publicly available datasets.  Experimental results demonstrate quantitatively and qualitatively that our method delivers interpretable justification of the prediction without sacrificing state-of-the-art performance. Our code and data split will be publicly available. ", "keywords": ["interpretability", "rationalization", "text matching", "dependent selection"], "authorids": ["ICLR.cc/2019/Conference/Paper787/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel self-explaining architecture to predict matches between two sequences of texts. Specifically, we introduce the notion of corresponded rationales and learn to extract them by the distal supervision from the downstream task.", "pdf": "/pdf/ba4a1950524915a205bcf2ce98056285e6f25352.pdf", "paperhash": "anonymous|learning_corresponded_rationales_for_text_matching", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Corresponded Rationales for Text Matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklQas09tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Ske7ToC5Km", "original": "Bke79QcFY7", "number": 788, "cdate": 1538087867044, "ddate": null, "tcdate": 1538087867044, "tmdate": 1538156056975, "tddate": null, "forum": "Ske7ToC5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph2Seq: Scalable Learning Dynamics for Graphs", "abstract": "Neural networks have been shown to be an effective tool for learning algorithms over graph-structured data. However, graph representation techniques---that convert graphs to real-valued vectors for use with neural networks---are still in their infancy. Recent works have proposed several approaches (e.g., graph convolutional networks), but these methods have difficulty scaling and generalizing to graphs with different sizes and shapes. We present Graph2Seq, a new technique that represents vertices of graphs as infinite time-series. By not limiting the representation to a fixed dimension, Graph2Seq scales naturally to graphs of arbitrary sizes and shapes. Graph2Seq is also reversible, allowing full recovery of the graph structure from the sequence. By analyzing a formal computational model for graph representation, we show that an unbounded sequence is necessary for scalability. Our experimental results with Graph2Seq show strong generalization and new state-of-the-art performance on a variety of graph combinatorial optimization problems.\n", "keywords": ["graph neural networks", "scalable representations", "combinatorial optimization", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper788/Authors"], "authors": ["Anonymous"], "TL;DR": "Today's neural networks for graphs do not generalize to graphs that are much bigger than the training graphs. We propose graph2seq, a method that represents vertices as time-series sequences instead of fixed-sized vectors for improved generalization.", "pdf": "/pdf/232a700753ee06156b48fc388058be6909c50b8d.pdf", "paperhash": "anonymous|graph2seq_scalable_learning_dynamics_for_graphs", "_bibtex": "@inproceedings{    \nanonymous2019graph2seq:,    \ntitle={Graph2Seq: Scalable Learning Dynamics for Graphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Ske7ToC5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1MQ6jCcK7", "original": "r1xdP5-5FQ", "number": 789, "cdate": 1538087867215, "ddate": null, "tcdate": 1538087867215, "tmdate": 1538156056764, "tddate": null, "forum": "S1MQ6jCcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ChoiceNet: Robust Learning by  Revealing Output Correlations", "abstract": "In this paper, we focus on the supervised learning problem with corrupt training data. We assume that the training dataset is generated from a mixture of a target distribution and other unknown distributions. We estimate the quality of each data by revealing the correlation between the generated distribution and the target distribution. To this end, we present a novel framework referred to here as ChoiceNet that can robustly infer the target distribution in the presence of inconsistent data. We demonstrate that the proposed framework is applicable to both classification and regression tasks. Particularly, ChoiceNet is evaluated in comprehensive experiments, where we show that it constantly outperforms existing baseline methods in the handling of noisy data in synthetic regression tasks as well as behavior cloning problems. In the classification tasks, we apply the proposed method to the MNIST and CIFAR-10 datasets and it shows superior performances in terms of robustness to different types of noisy labels.", "keywords": ["Robust Deep Learning", "weakly supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper789/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5993e2ecf296e21873371df4a9bf4450cc16c624.pdf", "paperhash": "anonymous|choicenet_robust_learning_by_revealing_output_correlations", "_bibtex": "@inproceedings{    \nanonymous2019choicenet:,    \ntitle={ChoiceNet: Robust Learning by  Revealing Output Correlations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1MQ6jCcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMXTsCqYQ", "original": "Syl0iSTqY7", "number": 790, "cdate": 1538087867387, "ddate": null, "tcdate": 1538087867387, "tmdate": 1538156056556, "tddate": null, "forum": "HJMXTsCqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Constrained Bayesian Optimization for Automatic Chemical Design", "abstract": "Automatic Chemical Design provides a framework for generating novel molecules with optimized molecular properties. The current model suffers from the pathology that it tends to produce invalid molecular structures. By reformulating the search procedure as a constrained Bayesian optimization problem, we showcase improvements in both the validity and quality of the generated molecules. We demonstrate that the model consistently produces novel molecules ranking above the 90th percentile of the distribution over training set scores across a range of objective functions. Importantly, our method suffers no degradation in the complexity or the diversity of the generated molecules.", "keywords": ["Bayesian Optimization", "Generative Models"], "authorids": ["ICLR.cc/2019/Conference/Paper790/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/46ca8dd5165cf6bcab2612a307a19c62ec0fb7d3.pdf", "paperhash": "anonymous|constrained_bayesian_optimization_for_automatic_chemical_design", "_bibtex": "@inproceedings{    \nanonymous2019constrained,    \ntitle={Constrained Bayesian Optimization for Automatic Chemical Design},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMXTsCqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklVTi09tm", "original": "rygovOaqYm", "number": 791, "cdate": 1538087867558, "ddate": null, "tcdate": 1538087867558, "tmdate": 1538156056351, "tddate": null, "forum": "HklVTi09tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Detecting Topological Defects in 2D Active Nematics Using Convolutional Neural Networks", "abstract": "Active matter consists of active agents which transform energy extracted from surroundings into momentum, producing a variety of collective phenomena. A model, synthetic active system composed of microtubule polymers driven by protein motors spontaneously forms a liquid-crystalline nematic phase. Extensile stress created by the protein motors precipitates continuous buckling and folding of the microtubules creating motile topological defects and turbulent fluid flows. Defect motion is determined by the rheological properties of the material; however, these remain largely unquantified. Measuring defects dynamics can yield fundamental insights into active nematics, a class of materials that include bacterial films and animal cells. Current methods for defect detection lack robustness and precision, and require fine-tuning for datasets with different visual quality.  In this study, we applied Deep Learning to train a defect detector to automatically analyze microscopy videos of the microtubule active nematic.  Experimental results indicate that our method is robust and accurate. It is expected to significantly increase the amount of video data that can be processed.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper791/Authors"], "authors": ["Anonymous"], "TL;DR": "An interesting application of CNN in soft condensed matter physics experiments.", "pdf": "/pdf/a83dc71342014a823407fa668d9ec598ea3b245e.pdf", "paperhash": "anonymous|detecting_topological_defects_in_2d_active_nematics_using_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Topological Defects in 2D Active Nematics Using Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklVTi09tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgEaj05t7", "original": "Hkxzpt9FYX", "number": 792, "cdate": 1538087867729, "ddate": null, "tcdate": 1538087867729, "tmdate": 1538156056139, "tddate": null, "forum": "SkgEaj05t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Relation Between the Sharpest Directions of DNN Loss and the SGD Step Length", "abstract": "Training of deep neural networks with Stochastic Gradient Descent (SGD) typically ends in regions of the weight space, where both the generalization properties and the flatness of the local loss curvature depend on the learning rate and the batch size.\nWe discover that a related phenomena happens in the early phase of training and study its consequences. Initially, SGD visits increasingly sharp regions of the loss surface, reaching a maximum sharpness determined by both the learning rate and the batch-size of SGD. At this early peak value, an SGD step is on average too large to minimize the loss along the directions corresponding to the largest eigenvalues of the Hessian (i.e. the sharpest directions). To query the importance of this phenomena for training, we study a variant of SGD using a reduced learning rate along the sharpest directions and show that it can improve training speed while finding both sharper and better--generalizing solution, compared to vanilla SGD. Overall, our results show that the SGD dynamics along the sharpest directions influence the regions of the weight space visited, the overall training speed, and generalization ability.", "keywords": ["optimization", "generalization", "theory of deep learning", "SGD", "hessian"], "authorids": ["ICLR.cc/2019/Conference/Paper792/Authors"], "authors": ["Anonymous"], "TL;DR": "SGD is steered early on in training towards a region in which its step is too large compared to curvature, which impacts the rest of training. ", "pdf": "/pdf/c11fabd33d72ad85df3e24782425df9f830e0f13.pdf", "paperhash": "anonymous|on_the_relation_between_the_sharpest_directions_of_dnn_loss_and_the_sgd_step_length", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Relation Between the Sharpest Directions of DNN Loss and the SGD Step Length},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgEaj05t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlNpoA5YQ", "original": "HyxfnZ0YYX", "number": 793, "cdate": 1538087867908, "ddate": null, "tcdate": 1538087867908, "tmdate": 1538156055931, "tddate": null, "forum": "HJlNpoA5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Laplacian in RL: Learning Representations with Efficient Approximations", "abstract": "The smallest eigenvectors of the graph Laplacian are well-known to provide a succinct representation of the geometry of a weighted graph. In reinforcement learning (RL), where the weighted graph may be interpreted as the state transition process induced by a behavior policy acting on the environment, approximating the eigenvectors of the Laplacian provides a promising approach to state representation learning. However, existing methods for performing this approximation are ill-suited in general RL settings for two main reasons:  First, they are computationally expensive, often requiring operations on large matrices. Second, these methods lack adequate justification beyond simple, tabular, finite-state settings. In this paper, we present a fully general and scalable method for approximating the eigenvectors of the Laplacian in a model-free RL context. We systematically evaluate our approach and empirically show that it generalizes beyond the tabular, finite-state setting. Even in tabular, finite-state settings, its ability to approximate the eigenvectors outperforms previous proposals. Finally, we show the potential benefits of using a Laplacian representation learned using our method in goal-achieving RL tasks, providing evidence that our technique can be used to significantly improve the performance of an RL agent.", "keywords": ["Laplacian", "reinforcement learning", "representation"], "authorids": ["ICLR.cc/2019/Conference/Paper793/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a scalable method to approximate the eigenvectors of the Laplacian in the reinforcement learning context and we show that the learned representations can improve the performance of an RL agent.", "pdf": "/pdf/61429ab2e36d138569755e6e4e5bb716f405a362.pdf", "paperhash": "anonymous|the_laplacian_in_rl_learning_representations_with_efficient_approximations", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Laplacian in RL: Learning Representations with Efficient Approximations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlNpoA5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylV6i09tX", "original": "ryezF_6cK7", "number": 794, "cdate": 1538087868085, "ddate": null, "tcdate": 1538087868085, "tmdate": 1538156055723, "tddate": null, "forum": "rylV6i09tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Interpreting Adversarial Robustness: A View from Decision Surface in Input Space", "abstract": "One popular hypothesis of neural network generalization is that the flat local minima of loss surface in parameter space leads to good generalization. However, we demonstrate that loss surface in parameter space has no obvious relationship with generalization, especially under adversarial settings. Through visualizing decision surfaces in both parameter space and input space, we instead show that the geometry property of decision surface in input space correlates well with the adversarial robustness. We then propose an adversarial robustness indicator, which can evaluate a neural network's intrinsic robustness property without testing its accuracy under adversarial attacks. Guided by it, we further propose our robust training method. Without involving adversarial training, our method could enhance network's intrinsic adversarial robustness against various adversarial attacks.", "keywords": ["Adversarial examples", "Robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper794/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/227a11efaf0ae5485c44dfdc71af0d332dc28aa4.pdf", "paperhash": "anonymous|interpreting_adversarial_robustness_a_view_from_decision_surface_in_input_space", "_bibtex": "@inproceedings{    \nanonymous2019interpreting,    \ntitle={Interpreting Adversarial Robustness: A View from Decision Surface in Input Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylV6i09tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xVTjCqKQ", "original": "BygfaEu9KX", "number": 795, "cdate": 1538087868260, "ddate": null, "tcdate": 1538087868260, "tmdate": 1538156055512, "tddate": null, "forum": "B1xVTjCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Data-Driven and Distributed Approach to Sparse Signal Representation and Recovery", "abstract": "In this paper, we focus on two challenges which offset the promise of sparse signal representation, sensing, and recovery. First, real-world signals can seldom be described as perfectly sparse vectors in a known basis, and traditionally used random measurement schemes are seldom optimal for sensing them. Second, existing signal recovery algorithms are usually not fast enough to make them applicable to real-time problems. In this paper, we address these two challenges by presenting a novel framework based on deep learning. For the first challenge, we cast the problem of finding informative measurements by using a maximum likelihood (ML) formulation and show how we can build a data-driven dimensionality reduction protocol for sensing signals using convolutional architectures. For the second challenge, we discuss and analyze a novel parallelization scheme and show it significantly speeds-up the signal recovery process. We demonstrate the significant improvement our method obtains over competing methods through a series of experiments. ", "keywords": ["Sparsity", "Compressive Sensing", "Convolutional Network"], "authorids": ["ICLR.cc/2019/Conference/Paper795/Authors"], "authors": ["Anonymous"], "TL;DR": "We use deep learning techniques to solve the sparse signal representation and recovery problem.", "pdf": "/pdf/649288828e160d5b74b01ab2eabc4b88b1eca5ce.pdf", "paperhash": "anonymous|a_datadriven_and_distributed_approach_to_sparse_signal_representation_and_recovery", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Data-Driven and Distributed Approach to Sparse Signal Representation and Recovery},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xVTjCqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByMVTsR5KQ", "original": "SJxRSDD5tX", "number": 796, "cdate": 1538087868440, "ddate": null, "tcdate": 1538087868440, "tmdate": 1538156055303, "tddate": null, "forum": "ByMVTsR5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Audio Synthesis", "abstract": "While Generative Adversarial Networks (GANs) have seen wide success at the problem of synthesizing realistic images, they have seen little application to audio generation. Unlike for images, a barrier to success is that the best discriminative representations for audio tend to be non-invertible, and thus cannot be used to synthesize listenable outputs. In this paper we introduce WaveGAN, a first attempt at applying GANs to unsupervised synthesis of raw-waveform audio. Our experiments demonstrate that WaveGAN can produce intelligible words from a small vocabulary of speech, and can also synthesize audio from other domains such as drums, bird vocalizations, and piano. Qualitatively, we find that human judges prefer the sound quality of generated examples from WaveGAN over those from a method which na\u00efvely apply GANs on image-like audio feature representations.", "keywords": ["audio", "waveform", "spectrogram", "GAN", "adversarial", "WaveGAN", "SpecGAN"], "authorids": ["ICLR.cc/2019/Conference/Paper796/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning to synthesize raw waveform audio with GANs", "pdf": "/pdf/3b101b1d110d9971efdd8150bc7a41fb695a5c4e.pdf", "paperhash": "anonymous|adversarial_audio_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Audio Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByMVTsR5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxraoRcF7", "original": "Syg19xKqFm", "number": 797, "cdate": 1538087868616, "ddate": null, "tcdate": 1538087868616, "tmdate": 1538156055051, "tddate": null, "forum": "rkxraoRcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Disentangled Representations with Reference-Based Variational Autoencoders", "abstract": "Learning disentangled representations from visual data, where high-level generative factors correspond to independent dimensions of feature vectors, is of importance for many computer vision tasks. Supervised approaches, however, require a significant annotation effort in order to label the factors of interest in a training set. To alleviate the annotation cost, we introduce a learning setting which we refer to as \"reference-based disentangling''. Given a pool of unlabelled images, the goal is to learn a representation where a set of target factors are disentangled from others. The only supervision comes from an auxiliary  \"reference set\" that contains  images where the factors of interest are constant. In order to address this problem, we propose reference-based variational autoencoders, a novel deep generative model designed to exploit the weak supervisory signal provided by the reference set. During training, we use the variational inference framework where adversarial learning is used to minimize the objective function. By addressing tasks such as feature learning, conditional image generation or attribute transfer, we validate the ability of the proposed model to learn disentangled representations from minimal supervision.\n\n", "keywords": ["Disentangled representations", "Variational Autoencoders", "Adversarial Learning", "Weakly-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper797/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/10d68a0732cfb71fba2c3b187c9759dfbaed9528.pdf", "paperhash": "anonymous|learning_disentangled_representations_with_referencebased_variational_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Disentangled Representations with Reference-Based Variational Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxraoRcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklHpjCqKm", "original": "HkxQ3ua9Y7", "number": 798, "cdate": 1538087868787, "ddate": null, "tcdate": 1538087868787, "tmdate": 1538156054786, "tddate": null, "forum": "BklHpjCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning", "abstract": "Deep learning has achieved astonishing results on many tasks with large amounts of data and generalization within the proximity of training data. For many important real-world applications, these requirements are unfeasible and additional prior knowledge on the task domain is required to overcome the resulting problems. In particular, learning physics models for model-based control requires robust extrapolation from fewer samples \u2013 often collected online in real-time \u2013 and model errors may lead to drastic damages of the system.\nDirectly incorporating physical insight has enabled us to obtain a novel deep model learning approach that extrapolates well while requiring fewer samples. As a first example, we propose Deep Lagrangian Networks (DeLaN) as a deep network structure upon which Lagrangian Mechanics have been imposed. DeLaN can learn the equations of motion of a mechanical system (i.e., system dynamics) with a deep network efficiently while ensuring physical plausibility.\nThe resulting DeLaN network performs very well at robot tracking control. The proposed method did not only outperform previous model learning approaches at learning speed but exhibits substantially improved and more robust extrapolation to novel trajectories and learns online in real-time.", "keywords": ["Deep Model Learning", "Robot Control"], "authorids": ["ICLR.cc/2019/Conference/Paper798/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces a physics prior for Deep Learning and applies the resulting network topology for model-based control.", "pdf": "/pdf/a336351586c6c73ed847a0513c44df903ee168eb.pdf", "paperhash": "anonymous|deep_lagrangian_networks_using_physics_as_model_prior_for_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklHpjCqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyMras0cFQ", "original": "r1esXOWqKX", "number": 799, "cdate": 1538087868960, "ddate": null, "tcdate": 1538087868960, "tmdate": 1538156054569, "tddate": null, "forum": "SyMras0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An adaptive homeostatic algorithm for the unsupervised learning of visual features", "abstract": "The formation of structure in the brain, that is, of the connection between cells within neural populations, is by large an unsupervised learning process: The emergence of this architecture is mostly self-organized. In the primary visual cortex of mammals, for example, one may observe during development the formation of cells selective to localized, oriented features. This leads to the development of a rough representation of contours of the retinal image in area V1. We modeled these mechanisms using sparse Hebbian learning algorithms. These algorithms alternate a coding step to encode the information with a learning step to find the proper encoder. A major difficulty faced by these algorithms is to deduce a good representation while knowing immature encoders, and to learn good encoders with a non-optimal representation. To address this problem, we propose here to introduce a new regulation process between learning and coding, called homeostasis. Our homeostasis is compatible with a neuro-mimetic architecture and allows for the fast emergence of localized filters sensitive to orientation. The key to this algorithm lies in a simple adaptation mechanism based on non-linear functions that reconciles the antagonistic processes that occur at the coding and learning time scales. We tested this unsupervised algorithm with this homeostasis rule for a range of existing unsupervised learning algorithms coupled with different neural coding algorithms. In addition, we propose a simplification of this optimal homeostasis rule by implementing a simple heuristic on the probability of activation of neurons. Compared to the optimal homeostasis rule, we show that this heuristic allows to implement a more rapid unsupervised learning algorithm while keeping a large part of its effectiveness. These results demonstrate the potential application of such a strategy in machine learning and we illustrate this with one result in a convolutional neural network.", "keywords": ["Sparse Coding", "Unsupervised Learning", "Natural Scene Statistics", "Biologically Plausible Deep Networks", "Visual Perception", "Computer Vision"], "authorids": ["ICLR.cc/2019/Conference/Paper799/Authors"], "authors": ["Anonymous"], "TL;DR": "Unsupervised learning is hard and depends on normalisation heuristics. Can we find another simpler approach?", "pdf": "/pdf/7d7739562074b2bc774227806dfe94bf74a41e7e.pdf", "paperhash": "anonymous|an_adaptive_homeostatic_algorithm_for_the_unsupervised_learning_of_visual_features", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An adaptive homeostatic algorithm for the unsupervised learning of visual features},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyMras0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMHpjC9Ym", "original": "Hkg4DXnYYQ", "number": 800, "cdate": 1538087869154, "ddate": null, "tcdate": 1538087869154, "tmdate": 1538156054366, "tddate": null, "forum": "HJMHpjC9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition", "abstract": "In this paper, we propose a novel Convolutional Neural Network (CNN) architecture for learning multi-scale feature representations with good tradeoffs between speed and accuracy. This is achieved by using a multi-branch network, which has different computational complexity at different branches with different resolutions. Through frequent merging of features from branches at distinct scales, our model obtains multi-scale features while using less computation. The proposed approach demonstrates improvement of model efficiency and performance on both object recognition and speech recognition tasks, using popular architectures including ResNet, ResNeXt and SEResNeXt. For object recognition, our approach reduces computation by 1/3 while improving accuracy significantly over 1% point than the baselines, and the computational savings can be higher up to 1/2 without compromising the accuracy.  Our model also surpasses state-of-the-art CNN acceleration approaches by a large margin in terms of accuracy and FLOPs. On the task of speech recognition, our proposed multi-scale CNNs save 30% FLOPs with slightly better word error rates, showing good generalization across domains.", "keywords": ["CNN", "multi-scale", "efficiency", "object recognition", "speech recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper800/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/eb85380796ee6dabfcfe438135483facb0c8e624.pdf", "paperhash": "anonymous|biglittle_net_an_efficient_multiscale_feature_representation_for_visual_and_speech_recognition", "_bibtex": "@inproceedings{    \nanonymous2019big-little,    \ntitle={Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMHpjC9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJNH6sAqY7", "original": "SkxI9Q4FKQ", "number": 801, "cdate": 1538087869333, "ddate": null, "tcdate": 1538087869333, "tmdate": 1538156054152, "tddate": null, "forum": "rJNH6sAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Computation and Generalization of Generative Adversarial Networks under Spectrum Control", "abstract": "Generative Adversarial Networks (GANs), though powerful, suffer from training instability. Several recent works (Brock et al., 2016; Miyato et al., 2018) suggest that controlling the spectra of weight matrices in the discriminator can significantly improve the training of GANs. Motivated by their discovery, we propose a new framework for training GANs, which allows more flexible spectrum control (e.g., making the weight matrices of the discriminator have slow singular value decays). Specifically, we propose a new reparameterization approach for the weight matrices of the discriminator in GANs, which allows us to directly manipulate the spectra of the weight matrices through various regularizers and constraints, without intensively computing singular value decompositions. Theoretically, we further show that the spectrum control improves the generalization ability of GANs. Our experiments on CIFAR-10, STL-10, and ImgaeNet datasets confirm that compared to other competitors, our proposed method is capable of generating images with better or equal quality by utilizing spectral normalization and encouraging the slow singular value decay.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper801/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f4d00fcb06838d40a608b453425f6c377fb234d3.pdf", "paperhash": "anonymous|on_computation_and_generalization_of_generative_adversarial_networks_under_spectrum_control", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Computation and Generalization of Generative Adversarial Networks under Spectrum Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJNH6sAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxBpoR5tm", "original": "HygoMYp9Km", "number": 802, "cdate": 1538087869512, "ddate": null, "tcdate": 1538087869512, "tmdate": 1538156053943, "tddate": null, "forum": "HyxBpoR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarially Robust Training through Structured Gradient Regularization", "abstract": "We propose a novel data-dependent structured gradient regularizer to increase the robustness of neural networks vis-a-vis adversarial perturbations. Our regularizer can be derived as a controlled approximation from first principles, leveraging the fundamental link between training with noise and regularization. It adds very little computational overhead during learning and is simple to implement generically in standard deep learning frameworks. Our experiments provide strong evidence that structured gradient regularization can act as an effective first line of defense against attacks based on long-range correlated signal corruptions.", "keywords": ["Adversarial Training", "Gradient Regularization", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper802/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel data-dependent structured gradient regularizer to increase the robustness of neural networks against adversarial perturbations.", "pdf": "/pdf/8454382d83397a557a905e87a4960eb55db75c0f.pdf", "paperhash": "anonymous|adversarially_robust_training_through_structured_gradient_regularization", "_bibtex": "@inproceedings{    \nanonymous2019adversarially,    \ntitle={Adversarially Robust Training through Structured Gradient Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxBpoR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeL6sCqK7", "original": "HkxZi6s9F7", "number": 803, "cdate": 1538087869682, "ddate": null, "tcdate": 1538087869682, "tmdate": 1538156053734, "tddate": null, "forum": "SkeL6sCqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "REPRESENTATION COMPRESSION AND GENERALIZATION IN DEEP NEURAL NETWORKS", "abstract": "Understanding the groundbreaking performance of Deep Neural Networks is one\nof the greatest challenges to the scientific community today. In this work, we\nintroduce an information theoretic viewpoint on the behavior of deep networks\noptimization processes and their generalization abilities. By studying the Information\nPlane, the plane of the mutual information between the input variable and\nthe desired label, for each hidden layer. Specifically, we show that the training of\nthe network is characterized by a rapid increase in the mutual information (MI)\nbetween the layers and the target label, followed by a longer decrease in the MI\nbetween the layers and the input variable. Further, we explicitly show that these\ntwo fundamental information-theoretic quantities correspond to the generalization\nerror of the network, as a result of introducing a new generalization bound that is\nexponential in the representation compression. The analysis focuses on typical\npatterns of large-scale problems. For this purpose, we introduce a novel analytic\nbound on the mutual information between consecutive layers in the network.\nAn important consequence of our analysis is a super-linear boost in training time\nwith the number of non-degenerate hidden layers, demonstrating the computational\nbenefit of the hidden layers.", "keywords": ["Deep neural network", "information theory", "training dynamics"], "authorids": ["ICLR.cc/2019/Conference/Paper803/Authors"], "authors": ["Anonymous"], "TL;DR": "Introduce an information theoretic viewpoint on the behavior of deep networks optimization processes and their generalization abilities", "pdf": "/pdf/2541a9bd3c70731b6c7cf6f89780578b33a17399.pdf", "paperhash": "anonymous|representation_compression_and_generalization_in_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019representation,    \ntitle={REPRESENTATION COMPRESSION AND GENERALIZATION IN DEEP NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeL6sCqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkeUasA5YQ", "original": "rylc_K25Fm", "number": 804, "cdate": 1538087869849, "ddate": null, "tcdate": 1538087869849, "tmdate": 1538156053525, "tddate": null, "forum": "BkeUasA5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LIT: Block-wise Intermediate Representation Training for Model Compression", "abstract": "Knowledge distillation (KD) is a popular method for reducing the computational over-\nhead of deep network inference, in which the output of a teacher model is used to train\na smaller, faster student model. Hint training (i.e., FitNets) extends KD by regressing a\nstudent model\u2019s intermediate representation to a teacher model\u2019s intermediate representa-\ntion. In this work, we introduce bLock-wise Intermediate representation Training (LIT),\na novel model compression technique that extends the use of intermediate represen-\ntations in deep network compression, outperforming KD and hint training. LIT has two\nkey ideas: 1) LIT trains a student of the same width (but shallower depth) as the teacher\nby directly comparing the intermediate representations, and 2) LIT uses the intermediate\nrepresentation from the previous block in the teacher model as an input to the current stu-\ndent block during training, avoiding unstable intermediate representations in the student\nnetwork. We show that LIT provides substantial reductions in network depth without\nloss in accuracy \u2014 for example, LIT can compress a ResNeXt-110 to a ResNeXt-20\n(5.5\u00d7) on CIFAR10 and a VDCNN-29 to a VDCNN-9 (3.2\u00d7) on Amazon Reviews\nwithout loss in accuracy, outperforming KD and hint training in network size at a given\naccuracy. We also show that applying LIT to identical student/teacher architectures\nincreases the accuracy of the student model above the teacher model, outperforming the\nrecently-proposed Born Again Networks procedure on ResNet, ResNeXt, and VDCNN.\nFinally, we show that LIT can effectively compress GAN generators, which are not\nsupported in the KD framework because GANs output pixels as opposed to probabilities.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper804/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4a12c06ef072bb79adccc7a016020e337b75d7fc.pdf", "paperhash": "anonymous|lit_blockwise_intermediate_representation_training_for_model_compression", "_bibtex": "@inproceedings{    \nanonymous2019lit:,    \ntitle={LIT: Block-wise Intermediate Representation Training for Model Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeUasA5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1fUpoR5FQ", "original": "S1etVYa5YQ", "number": 805, "cdate": 1538087870016, "ddate": null, "tcdate": 1538087870016, "tmdate": 1538156053311, "tddate": null, "forum": "S1fUpoR5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Quasi-hyperbolic momentum and Adam for deep learning", "abstract": "Momentum-based acceleration of stochastic gradient descent (SGD) is widely used in deep learning. We propose the quasi-hyperbolic momentum algorithm (QHM) as an extremely simple alteration of momentum SGD, averaging a plain SGD step with a momentum step. We describe numerous connections to and identities with other algorithms, and we characterize the set of two-state optimization algorithms that QHM can recover. Finally, we propose a QH variant of Adam called QHAdam, and we empirically demonstrate that our algorithms lead to significantly improved training in a variety of settings, including a new state-of-the-art result on WMT16 EN-DE. We hope that these empirical results, combined with the conceptual and practical simplicity of QHM and QHAdam, will spur interest from both practitioners and researchers. PyTorch code is immediately available.", "keywords": ["sgd", "momentum", "nesterov", "adam", "qhm", "qhadam", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper805/Authors"], "authors": ["Anonymous"], "TL;DR": "Mix plain SGD and momentum (or do something similar with Adam) for great profit.", "pdf": "/pdf/e07e4a8d42b8fdfa5d149e34d9dc346ccfaca88e.pdf", "paperhash": "anonymous|quasihyperbolic_momentum_and_adam_for_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019quasi-hyperbolic,    \ntitle={Quasi-hyperbolic momentum and Adam for deep learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1fUpoR5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJG8asRqKX", "original": "HygfP7BFKm", "number": 806, "cdate": 1538087870188, "ddate": null, "tcdate": 1538087870188, "tmdate": 1538156053104, "tddate": null, "forum": "rJG8asRqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Deep Learning Approach for Dynamic Survival Analysis with Competing Risks", "abstract": "Currently available survival analysis methods are limited in their ability to deal with complex, heterogeneous, and longitudinal data such as that available in primary care records, or in their ability to deal with multiple competing risks. This paper develops a novel deep learning architecture that flexibly incorporates the available longitudinal data comprising various repeated measurements (rather than only the last available measurements) in order to issue dynamically updated survival predictions for one or multiple competing risk(s). Unlike existing works in the survival analysis on the basis of longitudinal data, the proposed method learns the time-to-event distributions without specifying underlying stochastic assumptions of the longitudinal or the time-to-event processes. Thus, our method is able to learn associations between the longitudinal data and the various associated risks in a fully data-driven fashion. We demonstrate the power of our method by applying it to real-world longitudinal datasets and show a drastic improvement over state-of-the-art methods in discriminative performance. Furthermore, our analysis of the variable importance and dynamic survival predictions will yield a better understanding of the predicted risks which will result in more effective health care.", "keywords": ["dynamic survival analysis", "survival analysis", "longitudinal measurements", "competing risks"], "authorids": ["ICLR.cc/2019/Conference/Paper806/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/57e4cc6f251e37b6e225758d18cdd7b1a6329c5d.pdf", "paperhash": "anonymous|a_deep_learning_approach_for_dynamic_survival_analysis_with_competing_risks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Deep Learning Approach for Dynamic Survival Analysis with Competing Risks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJG8asRqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyVU6s05K7", "original": "HylI4dNFF7", "number": 807, "cdate": 1538087870354, "ddate": null, "tcdate": 1538087870354, "tmdate": 1538156052897, "tddate": null, "forum": "SyVU6s05K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Frank-Wolfe For Neural Network Optimization", "abstract": "Learning a deep neural network requires solving a challenging optimization problem: it is a high-dimensional, non-convex and non-smooth minimization problem with a large number of terms. The current practice in neural network optimization is to rely on the stochastic gradient descent (SGD) algorithm or its adaptive variants. However, SGD requires a hand-designed schedule for the learning rate. In addition, its adaptive variants tend to produce solutions that generalize less well on unseen data than SGD with a hand-designed schedule. We present an optimization method that offers the best of both worlds: our algorithm yields good generalization performance while requiring only one hyper-parameter. Our approach is based on a composite proximal framework, which exploits the compositional nature of deep neural networks and can leverage powerful convex optimization algorithms by design. Specifically, we employ the Frank-Wolfe (FW) algorithm for SVM, which computes an optimal step-size in closed-form at each time-step. We further show that the descent direction is given by a simple backward pass in the network, yielding the same computational cost per iteration as SGD. We customize the algorithm in two ways to further improve its performance. First, we use a descent direction that smoothes the loss function to better condition the problem. Second, we combine our proximal algorithm with Nesterov momentum to benefit from acceleration. We present experiments on the CIFAR and SNLI data sets, where we demonstrate the significant superiority of our method over Adam, Adagrad, as well as the recently proposed BPGrad and AMSGrad. Furthermore, we compare our algorithm to SGD with a hand-designed learning rate schedule, and show that it provides similar generalization while converging faster.", "keywords": ["optimization", "conditional gradient", "Frank-Wolfe"], "authorids": ["ICLR.cc/2019/Conference/Paper807/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3acce8fd45158372254aaf869b6b897346584553.pdf", "paperhash": "anonymous|deep_frankwolfe_for_neural_network_optimization", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Frank-Wolfe For Neural Network Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyVU6s05K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgDTiCctQ", "original": "ryg37biqKQ", "number": 808, "cdate": 1538087870524, "ddate": null, "tcdate": 1538087870524, "tmdate": 1538156052692, "tddate": null, "forum": "HkgDTiCctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Knowledge Distillation from Few Samples", "abstract": "Current knowledge distillation methods require full training data to distill knowledge from a large \"teacher\" network to a compact \"student\" network by matching certain statistics between \"teacher\" and \"student\" such as softmax outputs and feature responses. This is not only time-consuming but also inconsistent with human cognition in which children can learn knowledge from adults with few examples. This paper proposes a novel and simple method for knowledge distillation from few samples. Taking the assumption that both \"teacher\" and \"student\" have the same  feature map sizes at each corresponding block, we add a 1x1 conv-layer at the end of each block in the student network, and align the block-level outputs between \"teacher\" and \"student\" by estimating the parameters of the added layer with limited samples. We prove that the added layer can be absorbed into the previous conv-layer so that no extra parameters and computation are introduced. Experiments show that the proposed method can recover a student network's top-1 accuracy on ImageNet from 0.2% to 62.7% with just 1000 samples in a few minutes, and is effective on various ways for constructing student networks.", "keywords": ["knowledge distillation", "few-sample learning", "network compression"], "authorids": ["ICLR.cc/2019/Conference/Paper808/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes a novel and simple method for knowledge distillation from few samples.", "pdf": "/pdf/4c4f5633647df619ccb5b8f838e44f7429884463.pdf", "paperhash": "anonymous|knowledge_distillation_from_few_samples", "_bibtex": "@inproceedings{    \nanonymous2019knowledge,    \ntitle={Knowledge Distillation from Few Samples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgDTiCctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylDpoActX", "original": "rylxt_pctX", "number": 809, "cdate": 1538087870698, "ddate": null, "tcdate": 1538087870698, "tmdate": 1538156052485, "tddate": null, "forum": "HylDpoActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "N-Ary Quantization for CNN Model Compression and Inference Acceleration", "abstract": "The tremendous memory and computational complexity of Convolutional Neural Networks (CNNs) prevents the inference deployment on resource-constrained systems. As a result, recent research focused on CNN optimization techniques, in particular quantization, which allows weights and activations of layers to be represented with just a few bits while achieving impressive prediction performance. However, aggressive quantization techniques still fail to achieve full-precision prediction performance on state-of-the-art CNN architectures on large-scale classification tasks. In this work we propose a method for weight and activation quantization that is scalable in terms of quantization levels (n-ary representations) and easy to compute while maintaining the performance close to full-precision CNNs. Our weight quantization scheme is based on trainable scaling factors and a nested-means clustering strategy which is robust to weight updates and therefore exhibits good convergence properties. The flexibility of nested-means clustering enables exploration of various n-ary weight representations with the potential of high parameter compression. For activations, we propose a linear quantization strategy that takes the statistical properties of batch normalization into account. We demonstrate the effectiveness of our approach using state-of-the-art models on ImageNet.", "keywords": ["low-resource deep neural networks", "quantized weights", "weight-clustering", "resource efficient neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper809/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a quantization scheme for weights and activations of deep neural networks. This reduces the memory footprint substantially and accelerates inference.", "pdf": "/pdf/ba7811c9624d583c3ebc4811fccfa9de1c28783e.pdf", "paperhash": "anonymous|nary_quantization_for_cnn_model_compression_and_inference_acceleration", "_bibtex": "@inproceedings{    \nanonymous2019n-ary,    \ntitle={N-Ary Quantization for CNN Model Compression and Inference Acceleration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylDpoActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgPajAcY7", "original": "BJxRGKoqt7", "number": 810, "cdate": 1538087870870, "ddate": null, "tcdate": 1538087870870, "tmdate": 1538156052278, "tddate": null, "forum": "BkgPajAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "No Training Required: Exploring Random Encoders for Sentence Classification", "abstract": "We explore various methods for computing sentence representations from pre-trained word embeddings without any training, i.e., using nothing but random parameterizations. Our aim is to put sentence embeddings on more solid footing by 1) looking at how much modern sentence embeddings gain over random methods---as it turns out, surprisingly little; and by 2) providing the field with more appropriate baselines going forward---which are, as it turns out, quite strong. We also make important observations about proper experimental protocol for sentence classification evaluation, together with recommendations for future research.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper810/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5d9f338827f52c0f4c82ee3c024d571ab08aac3d.pdf", "paperhash": "anonymous|no_training_required_exploring_random_encoders_for_sentence_classification", "_bibtex": "@inproceedings{    \nanonymous2019no,    \ntitle={No Training Required: Exploring Random Encoders for Sentence Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgPajAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkMwpiR9Y7", "original": "SJgUcKT9FQ", "number": 811, "cdate": 1538087871038, "ddate": null, "tcdate": 1538087871038, "tmdate": 1538156052069, "tddate": null, "forum": "SkMwpiR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Measuring and regularizing networks in function space", "abstract": "To optimize a neural network one often thinks of optimizing its parameters, but it is ultimately a matter of optimizing the function that maps inputs to outputs. Since a change in the parameters might serve as a poor proxy for the change in the function, it is of some concern that primacy is given to parameters but that the correspondence has not been tested. Here, we show that it is simple and computationally feasible to calculate distances between functions in a $L^2$ Hilbert space. We examine how typical networks behave in this space, and compare how parameter $\\ell^2$ distances compare to function $L^2$ distances between various points of an optimization trajectory. We find that the two distances are nontrivially related. In particular, the $L^2/\\ell^2$ ratio decreases throughout optimization, reaching a steady value around when test error plateaus. We then investigate how the $L^2$ distance could be applied directly to optimization. We first propose that in multitask learning, one can avoid catastrophic forgetting by directly limiting how much the input/output function changes between tasks. Secondly, we propose a new learning rule that regularizes the distance a network can travel through $L^2$-space in any one update. This allows new examples to be learned in a way that minimally interferes with what has previously been learned. These applications demonstrate how one can measure and regularize function distances directly, without relying on parameters or local approximations like loss curvature.", "keywords": ["function space", "Hilbert space", "empirical characterization", "multitask learning", "catastrophic forgetting", "optimization", "natural gradient"], "authorids": ["ICLR.cc/2019/Conference/Paper811/Authors"], "authors": ["Anonymous"], "TL;DR": "It is cheap to measure distances in function space, and these distances aren't always proportional to the corresponding parameter distances.", "pdf": "/pdf/08973e7aaf2c9583d957f95bf2cf79cefbbb3192.pdf", "paperhash": "anonymous|measuring_and_regularizing_networks_in_function_space", "_bibtex": "@inproceedings{    \nanonymous2019measuring,    \ntitle={Measuring and regularizing networks in function space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkMwpiR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkfwpiA9KX", "original": "HJx5SVpqKQ", "number": 812, "cdate": 1538087871216, "ddate": null, "tcdate": 1538087871216, "tmdate": 1538156051862, "tddate": null, "forum": "HkfwpiA9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Automata Guided Skill Composition", "abstract": "Skills learned through (deep) reinforcement learning often generalizes poorly\nacross tasks and re-training is necessary when presented with a new task. We\npresent a framework that combines techniques in formal methods with reinforcement\nlearning (RL) that allows for the convenient specification of complex temporal\ndependent tasks with logical expressions and construction of new skills from existing\nones with no additional exploration. We provide theoretical results for our\ncomposition technique and evaluate on a simple grid world simulation as well as\na robotic manipulation task.", "keywords": ["Skill composition", "temporal logic", "finite state automata"], "authorids": ["ICLR.cc/2019/Conference/Paper812/Authors"], "authors": ["Anonymous"], "TL;DR": "A formal method's approach to skill composition in reinforcement learning tasks", "pdf": "/pdf/d7a31a66d437e2706ffb07410c83d65618b2a183.pdf", "paperhash": "anonymous|automata_guided_skill_composition", "_bibtex": "@inproceedings{    \nanonymous2019automata,    \ntitle={Automata Guided Skill Composition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkfwpiA9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJ4vTjRqtQ", "original": "HyxEUAetK7", "number": 813, "cdate": 1538087871385, "ddate": null, "tcdate": 1538087871385, "tmdate": 1538156051653, "tddate": null, "forum": "SJ4vTjRqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning To Plan", "abstract": "We introduce Learning To Plan (L2P), a novel architecture for deep reinforcement learning, that combines model-based and model-free aspects for online planning. Our architecture learns to dynamically construct plans using a learned state-transition model by selecting and traversing between simulated states and actions to maximize valuable information before acting. In contrast to model-free methods, model-based planning lets the agent efficiently test action hypotheses without performing costly trial-and-error in the environment. L2P learns to efficiently form plans by expanding a single action-conditional state transition at a time instead of exhaustively evaluating each action, reducing the required number of state-transitions during planning by up to 96%. We observe various emergent planning patterns used to solve environments, including classical search methods such as breadth-first and depth-first search. Learning To Plan shows improved data efficiency, performance, and generalization to new and unseen domains in comparison to several baselines.", "keywords": ["reinforcement learning", "planning", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper813/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fa70f4b2275f2b71487b345b26bb6a79c012f1d6.pdf", "paperhash": "anonymous|learning_to_plan", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning To Plan},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJ4vTjRqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gOpsCctm", "original": "SyeVDlV9KX", "number": 814, "cdate": 1538087871564, "ddate": null, "tcdate": 1538087871564, "tmdate": 1538156051436, "tddate": null, "forum": "S1gOpsCctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Finite State Representations of Recurrent Policy Networks", "abstract": "Recurrent neural networks (RNNs) are an effective representation of control policies for a wide range of reinforcement and imitation learning problems. RNN policies, however, are particularly difficult to explain, understand, and analyze due to their use of continuous-valued memory vectors and observation features. In this paper, we introduce a new technique, Quantized Bottleneck Insertion, to learn finite representations of these vectors and features. The result is a quantized representation of the RNN that can be analyzed to improve our understanding of memory use and general behavior. We present results of this approach on synthetic environments and six Atari games. The resulting finite representations are surprisingly small in some cases, using as few as 3 discrete memory states and 10 observations for a perfect Pong policy. We also show that these finite policy representations lead to improved interpretability. ", "keywords": ["recurrent neural networks", "finite state machine", "quantization", "interpretability", "autoencoder", "moore machine", "reinforcement learning", "imitation learning", "representation", "Atari", "Tomita"], "authorids": ["ICLR.cc/2019/Conference/Paper814/Authors"], "authors": ["Anonymous"], "TL;DR": "Extracting a finite state machine from a recurrent neural network via quantization for the purpose of interpretability with experiments on Atari.", "pdf": "/pdf/d2f66d5abaede80e3812673616f21fcc586deb61.pdf", "paperhash": "anonymous|learning_finite_state_representations_of_recurrent_policy_networks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Finite State Representations of Recurrent Policy Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gOpsCctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gupiC5KQ", "original": "SklanFpcFX", "number": 815, "cdate": 1538087871734, "ddate": null, "tcdate": 1538087871734, "tmdate": 1538156051219, "tddate": null, "forum": "H1gupiC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The wisdom of the crowd: reliable deep reinforcement learning through ensembles of Q-functions", "abstract": "Reinforcement learning agents learn by exploring the environment and then exploiting what they have learned.\nThis frees the human trainers from having to know the preferred action or intrinsic value of each encountered state.\nThe cost of this freedom is reinforcement learning is slower and more unstable than supervised learning.\nWe explore the possibility that ensemble methods can remedy these shortcomings and do so by investigating a novel technique which harnesses the wisdom of the crowds by bagging Q-function approximator estimates.\n\nOur results show that this proposed approach improves all three tasks and reinforcement learning approaches attempted.\nWe are able to demonstrate that this is a direct result of the increased stability of the action portion of the state-action-value function used by Q-learning to select actions and by policy gradient methods to train the policy.\n", "keywords": ["reinforcement learning", "ensembles", "deep learning", "neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper815/Authors"], "authors": ["Anonymous"], "TL;DR": "Examined how a simple ensemble approach can tackle the biggest challenges in Q-learning.", "pdf": "/pdf/c699a7a6b6f899b5f49955993f10032247bd556a.pdf", "paperhash": "anonymous|the_wisdom_of_the_crowd_reliable_deep_reinforcement_learning_through_ensembles_of_qfunctions", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The wisdom of the crowd: reliable deep reinforcement learning through ensembles of Q-functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gupiC5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxdpiA5Ym", "original": "Hkg7cQa9FX", "number": 816, "cdate": 1538087871902, "ddate": null, "tcdate": 1538087871902, "tmdate": 1538156051008, "tddate": null, "forum": "rkxdpiA5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diagnosing Language Inconsistency in Cross-Lingual Word Embeddings", "abstract": "Cross-lingual embeddings encode meaning of words from different languages into a shared low-dimensional space. However, despite numerous applications, evaluation of such embeddings is limited. We focus on diagnosing the problem of words segregated by languages in cross-lingual embeddings. In an ideal cross-lingual embedding, word similarity should be independent of language---i.e., words within a language should not be more similar to each other than to words in another language. One test of this is modularity, a network measurement that measures the strength of clusters in a graph. When we apply this measure to a nearest neighbor graph, imperfect cross-lingual embeddings are sorted into modular, distinct regions. The correlation of this measurement with accuracy on two downstream tasks demonstrates that modularity can serve as an intrinsic metric of embedding quality.", "keywords": ["cross-lingual embeddings", "evaluation", "graph-based metric", "modularity"], "authorids": ["ICLR.cc/2019/Conference/Paper816/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8533d615482f0001f80701b5ace49b74f658f60d.pdf", "paperhash": "anonymous|diagnosing_language_inconsistency_in_crosslingual_word_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019diagnosing,    \ntitle={Diagnosing Language Inconsistency in Cross-Lingual Word Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxdpiA5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJed6j0cKX", "original": "rJxtOGactm", "number": 817, "cdate": 1538087872073, "ddate": null, "tcdate": 1538087872073, "tmdate": 1538156050794, "tddate": null, "forum": "rJed6j0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Analyzing Inverse Problems with Invertible Neural Networks", "abstract": "For many applications, in particular in natural science, the task is to\ndetermine hidden system parameters from a set of measurements. Often,\nthe forward process from parameter- to measurement-space is well-defined,\nwhereas the inverse problem is ambiguous: multiple parameter sets can\nresult in the same measurement. To fully characterize this ambiguity, the full\nposterior parameter distribution, conditioned on an observed measurement,\nhas to be determined. We argue that a particular class of neural networks\nis well suited for this task \u2013 so-called Invertible Neural Networks (INNs).\nUnlike classical neural networks, which attempt to solve the ambiguous\ninverse problem directly, INNs focus on learning the forward process, using\nadditional latent output variables to capture the information otherwise\nlost. Due to invertibility, a model of the corresponding inverse process is\nlearned implicitly. Given a specific measurement and the distribution of\nthe latent variables, the inverse pass of the INN provides the full posterior\nover parameter space. We prove theoretically and verify experimentally, on\nartificial data and real-world problems from medicine and astrophysics, that\nINNs are a powerful analysis tool to find multi-modalities in parameter space,\nuncover parameter correlations, and identify unrecoverable parameters.", "keywords": ["Inverse problems", "Neural Networks", "Uncertainty", "Invertible Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper817/Authors"], "authors": ["Anonymous"], "TL;DR": "To analyze inverse problems with Invertible Neural Networks", "pdf": "/pdf/df4572b1bf25bb9b5ed706326b5e666e1be82c57.pdf", "paperhash": "anonymous|analyzing_inverse_problems_with_invertible_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019analyzing,    \ntitle={Analyzing Inverse Problems with Invertible Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJed6j0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyxu6oAqYX", "original": "HkxA1Ya9Km", "number": 818, "cdate": 1538087872246, "ddate": null, "tcdate": 1538087872246, "tmdate": 1538156050584, "tddate": null, "forum": "Hyxu6oAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Energy-Based Framework for Arbitrary Label Noise Correction", "abstract": "We propose an energy-based framework for correcting mislabelled training examples in the context of binary classification. While existing work addresses random and class-dependent label noise, we focus on feature dependent label noise, which is ubiquitous in real-world data and difficult to model. Two elements distinguish our approach from others: 1) instead of relying on the original feature space, we employ an autoencoder to learn a discriminative representation and 2) we introduce an energy-based formalism for the label correction problem. We prove that a discriminative representation can be learned by training a generative model using a loss function comprised of the difference of energies corresponding to each class. The learned energy value for each training instance is compared to the original training labels and contradictions between energy assignment and training label are used to correct labels. We validate our method across eight datasets, spanning synthetic and realistic settings, and demonstrate the technique's state-of-the-art label correction performance. Furthermore, we derive analytical expressions to show the effect of label noise on the gradients of empirical risk.", "keywords": ["label noise", "feature dependent noise", "label correction", "unsupervised machine learning", "semi-supervised machine learning"], "authorids": ["ICLR.cc/2019/Conference/Paper818/Authors"], "authors": ["Anonymous"], "TL;DR": "We show how to learn a discriminative representation using an energy based semi-supervised model and we show how to use it to correct input dependent label noise of various types on several datasets.", "pdf": "/pdf/0f95254a2101ea3fb42619f67a4bc61a01f13061.pdf", "paperhash": "anonymous|an_energybased_framework_for_arbitrary_label_noise_correction", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Energy-Based Framework for Arbitrary Label Noise Correction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyxu6oAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyMuaiAqY7", "original": "BygW-56qYQ", "number": 819, "cdate": 1538087872417, "ddate": null, "tcdate": 1538087872417, "tmdate": 1538156050375, "tddate": null, "forum": "HyMuaiAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deli-Fisher GAN: Stable and Efficient Image Generation With Structured Latent Generative Space", "abstract": "Generative Adversarial Networks (GANs) are powerful tools for realistic image generation. However, a major drawback of GANs is that they are especially hard to train, often requiring large amounts of data and long training time. In this paper we propose the Deli-Fisher GAN, a GAN that generates photo-realistic images by enforcing structure on the latent generative space using similar approaches in \\cite{deligan}. The structure of the latent space we consider in this paper is modeled as a mixture of Gaussians, whose parameters are learned in the training process. Furthermore, to improve stability and efficiency, we use the Fisher Integral Probability Metric as the divergence measure in our GAN model, instead of the Jensen-Shannon divergence. We show by experiments that the Deli-Fisher GAN performs better than DCGAN, WGAN, and the Fisher GAN as measured by inception score.", "keywords": ["Generative Adversarial Networks", "Structured Latent Space", "Stable Training"], "authorids": ["ICLR.cc/2019/Conference/Paper819/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes a new Generative Adversarial Network that is more stable, more efficient, and produces better images than those of status-quo ", "pdf": "/pdf/adabb9c4f4e6fb02b90e8fcbf3763efaa8a34b6d.pdf", "paperhash": "anonymous|delifisher_gan_stable_and_efficient_image_generation_with_structured_latent_generative_space", "_bibtex": "@inproceedings{    \nanonymous2019deli-fisher,    \ntitle={Deli-Fisher GAN: Stable and Efficient Image Generation With Structured Latent Generative Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMuaiAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygK6sA5tX", "original": "Bylh0Ss5tm", "number": 820, "cdate": 1538087872594, "ddate": null, "tcdate": 1538087872594, "tmdate": 1538156050167, "tddate": null, "forum": "SygK6sA5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Classification with Geometric Scattering", "abstract": "One of the most notable contributions of deep learning is the application of convolutional neural networks (ConvNets) to structured signal classification, and in particular image classification. Beyond their impressive performances in supervised learning, the structure of such networks inspired the development of deep filter banks referred to as scattering transforms. These transforms apply a cascade of wavelet transforms and complex modulus operators to extract features that are invariant to group operations and stable to deformations. Furthermore, ConvNets inspired recent advances in geometric deep learning, which aim to generalize these networks to graph data by applying notions from graph signal processing to learn deep graph filter cascades. We further advance these lines of research by proposing a geometric scattering transform using graph wavelets defined in terms of random walks on the graph. We demonstrate the utility of features extracted with this designed deep filter bank in graph classification, and show its competitive performance relative to other methods, including graph kernel methods and geometric deep learning ones, on both social and biochemistry data.", "keywords": ["geometric learning", "graph neural network", "graph classification", "scattering"], "authorids": ["ICLR.cc/2019/Conference/Paper820/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a new feed forward graph ConvNet based on generalizing the wavelet scattering transform of Mallat, and demonstrate its utility in graph classification tasks.", "pdf": "/pdf/f96595cc0672877d9af526782232563fe28e19fa.pdf", "paperhash": "anonymous|graph_classification_with_geometric_scattering", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Classification with Geometric Scattering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygK6sA5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgK6iA5KX", "original": "SJxgJXW5tX", "number": 821, "cdate": 1538087872768, "ddate": null, "tcdate": 1538087872768, "tmdate": 1538156049956, "tddate": null, "forum": "BJgK6iA5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "AutoLoss: Learning Discrete Schedule for Alternate Optimization", "abstract": "Many machine learning problems involve iteratively and alternately optimizing different task objectives with respect to different sets of parameters. Appropriately scheduling the optimization of a task objective or a set of parameters is usually crucial to the quality of convergence. In this paper, we present AutoLoss, a meta-learning framework that automatically learns and determines the optimization schedule. AutoLoss provides a generic way to represent and learn the discrete optimization schedule from metadata, allows for a dynamic and data-driven schedule in ML problems that involve alternating updates of different parameters or from different loss objectives.\n\nWe apply AutoLoss on four ML tasks: d-ary quadratic regression, classification using a multi-layer perceptron (MLP), image generation using GANs, and multi-task neural machine translation (NMT). We show that the AutoLoss controller is able to capture the distribution of better optimization schedules that result in higher quality of convergence on all four tasks. The trained AutoLoss controller is generalizable -- it can guide and improve the learning of a new task model with different specifications, or on different datasets.", "keywords": ["Meta Learning", "AutoML", "Optimization Schedule"], "authorids": ["ICLR.cc/2019/Conference/Paper821/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.", "pdf": "/pdf/1862afde0808b26572a07cc8613e7bbe7e5a269a.pdf", "paperhash": "anonymous|autoloss_learning_discrete_schedule_for_alternate_optimization", "_bibtex": "@inproceedings{    \nanonymous2019autoloss:,    \ntitle={AutoLoss: Learning Discrete Schedule for Alternate Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgK6iA5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJlt6oA9Fm", "original": "BJe55Pm5YX", "number": 822, "cdate": 1538087872942, "ddate": null, "tcdate": 1538087872942, "tmdate": 1538156049737, "tddate": null, "forum": "SJlt6oA9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Selective Convolutional Units: Improving CNNs via Channel Selectivity", "abstract": "Bottleneck structures with identity (e.g., residual) connection are now emerging popular paradigms for designing deep convolutional neural networks (CNN), for processing large-scale features efficiently. In this paper, we focus on the information-preserving nature of the bottleneck structures and utilize this to enable a convolutional layer to have a new functionality of channel-selectivity, i.e., focusing its computations on important channels. In particular, we propose Selective Convolutional Unit (SCU), an easy-to-use architectural unit that improves parameter efficiency of various modern CNNs with bottlenecks. During training, SCU gradually learns the channel-selectivity on-the-fly via the alternative usage of (a) pruning unimportant channels, and (b) rewiring the pruned parameters to important channels. The rewired parameters emphasize the target channel in a way that selectively enlarges the convolutional kernels corresponding to it. Our experimental results demonstrate that the SCU-based models without any post-processing generally achieve both model compression and accuracy improvement compared to the baselines, consistently for all tested architectures.", "keywords": ["convolutional neural networks", "channel-selectivity", "channel re-wiring", "bottleneck architectures", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper822/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new module that improves any ResNet-like architectures by enforcing \"channel selective\" behavior to convolutional layers", "pdf": "/pdf/a75205e2a4c52793066be593c3657d863fa9c552.pdf", "paperhash": "anonymous|selective_convolutional_units_improving_cnns_via_channel_selectivity", "_bibtex": "@inproceedings{    \nanonymous2019selective,    \ntitle={Selective Convolutional Units: Improving CNNs via Channel Selectivity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlt6oA9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxKajC5t7", "original": "B1eJAoXtFQ", "number": 823, "cdate": 1538087873111, "ddate": null, "tcdate": 1538087873111, "tmdate": 1538156049527, "tddate": null, "forum": "HJxKajC5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Self-Binarizing Networks", "abstract": "We present a method to train self-binarizing neural networks, that is, networks that evolve their weights and activations during training to become binary. To obtain similar binary networks, existing methods rely on the sign activation function. This function, however, has no gradients for non-zero values, which makes standard backpropagation impossible. To circumvent the difficulty of training a network relying on the sign activation function, these methods alternate between floating-point and binary representations of the network during training, which is sub-optimal and inefficient. We approach the binarization task by training on a unique representation involving a smooth activation function, which is iteratively sharpened during training until it becomes a binary representation equivalent to the sign activation function. Additionally, we introduce a new technique to perform binary batch normalization that simplifies the conventional batch normalization by transforming it into a simple comparison operation. This is unlike existing methods, which are forced to the retain the conventional floating-point-based batch normalization. Our binary networks, apart from displaying advantages of lower memory and computation as compared to conventional floating-point and binary networks, also show higher classification accuracy than existing state-of-the-art methods on multiple benchmark datasets.", "keywords": ["Binarization", "Convolutional Neural Networks", "Deep Learning", "Deep Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper823/Authors"], "authors": ["Anonymous"], "TL;DR": "A method to binarize both weights and activations of a deep neural network that is efficient in computation and memory usage and performs better than the state-of-the-art.", "pdf": "/pdf/826ba0af1a9860a3a83f7d562f9dbc0d4da8ab57.pdf", "paperhash": "anonymous|selfbinarizing_networks", "_bibtex": "@inproceedings{    \nanonymous2019self-binarizing,    \ntitle={Self-Binarizing Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxKajC5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJeY6sR9KX", "original": "rke6jAwtF7", "number": 824, "cdate": 1538087873290, "ddate": null, "tcdate": 1538087873290, "tmdate": 1538156049313, "tddate": null, "forum": "BJeY6sR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Aligning Artificial Neural Networks to the Brain yields Shallow Recurrent Architectures", "abstract": "Deep artificial neural networks with spatially repeated processing (a.k.a., deep convolutional ANNs) have been established as the best class of candidate models of visual processing in the primate ventral visual processing stream. Over the past five years, these ANNs have evolved from a simple feedforward eight-layer architecture in AlexNet to extremely deep and branching NASNet architectures, demonstrating increasingly better object categorization performance. Here we ask, as ANNs have continued to evolve in performance, are they also strong candidate models for the brain? To answer this question, we developed Brain-Score, a composite of neural and behavioral benchmarks that score any ANN on how brain-like it is, together with an online platform where ANNs can be submitted to receive a Brain-Score and their rank relative to other models. Deploying our framework on dozens of state-of-the-art ANNs, we found that ResNet and DenseNet families of models are the closest models from the Machine Learning community to primate ventral visual stream. Curiously, best current ImageNet models, such as PNASNet, were not the top-performing models on Brain-Score. Despite high scores, these deep models are often hard to map onto the brain's anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. To further map onto anatomy and validate our approach, we built CORnet-S: a neural network developed by using Brain-Score as a guide with the anatomical constraints of compactness and recurrence. Although a shallow model with four anatomically mapped areas with recurrent connectivity, CORnet-S is a top model on Brain-Score and outperforms similarly compact models on ImageNet.", "keywords": ["Computational Neuroscience", "Brain-Inspired", "Neural Networks", "Simplified Models", "Recurrent Neural Networks", "Computer Vision"], "authorids": ["ICLR.cc/2019/Conference/Paper824/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/99e2c1b628d1064ebfa247473cc0b491dbc515ef.pdf", "paperhash": "anonymous|aligning_artificial_neural_networks_to_the_brain_yields_shallow_recurrent_architectures", "_bibtex": "@inproceedings{    \nanonymous2019aligning,    \ntitle={Aligning Artificial Neural Networks to the Brain yields Shallow Recurrent Architectures},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeY6sR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJfFTjA5KQ", "original": "BJgMD039FX", "number": 825, "cdate": 1538087873467, "ddate": null, "tcdate": 1538087873467, "tmdate": 1538156049101, "tddate": null, "forum": "SJfFTjA5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unification of  Recurrent   Neural Network Architectures and Quantum Inspired Stable Design ", "abstract": "Various architectural advancements in the design of recurrent neural networks~(RNN) have been focusing on improving the empirical stability and representability by sacrificing the complexity of the architecture. However, more remains to be done to fully understand the fundamental trade-off between these conflicting requirements. Towards answering this question, we forsake the purely bottom-up approach of data-driven machine learning to understand, instead,  the physical origin and dynamical properties of existing RNN architectures.  This facilitates designing new RNNs with smaller complexity overhead and provable stability guarantee. First, we define a family of  deep recurrent neural networks,  $n$-$t$-ORNN, according to the order of nonlinearity $n$ and the range of temporal memory scale $t$ in their underlying dynamics embodied in the form of discretized ordinary differential equations. We show that most of the existing proposals of RNN architectures belong to different orders of $n$-$t$-ORNNs.    We then propose a new RNN ansatz, namely the Quantum-inspired  Universal computing  Neural Network~(QUNN), to leverage the reversibility, stability, and universality of quantum computation for stable and universal RNN.  QUNN   provides a complexity reduction in the number of training parameters from being polynomial in both data and correlation time to only linear in correlation time.  Compared to Long-Short-Term Memory (LSTM), QUNN of the same number of hidden layers facilitates higher nonlinearity and longer memory span with provable stability. Our work opens new directions in designing minimal RNNs based on additional knowledge about the dynamical nature of both the data and different training architectures.", "keywords": ["theory and analysis of RNNs architectures", "reversibe evolution", "stability of deep neural network", "learning representations of outputs or states", "quantum inspired embedding"], "authorids": ["ICLR.cc/2019/Conference/Paper825/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide theoretical proof of various recurrent neural network designs representable dynamics' nonlinearity and memory scale, and propose a new RNN ansatz inspired by quantum physics.", "pdf": "/pdf/5a26b67c5ba83aaf758ec469732814d4541556d1.pdf", "paperhash": "anonymous|unification_of_recurrent_neural_network_architectures_and_quantum_inspired_stable_design", "_bibtex": "@inproceedings{    \nanonymous2019unification,    \ntitle={Unification of  Recurrent   Neural Network Architectures and Quantum Inspired Stable Design },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfFTjA5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hklc6oAcFX", "original": "H1e4vFh5tX", "number": 826, "cdate": 1538087873654, "ddate": null, "tcdate": 1538087873654, "tmdate": 1538156048898, "tddate": null, "forum": "Hklc6oAcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Co-manifold learning with missing data", "abstract": " Representation learning is typically applied to only one mode of a data matrix, either its rows or columns. Yet in many applications, there is an underlying geometry to both the rows and the columns. We propose utilizing this coupled structure to perform co-manifold learning: uncovering the underlying geometry of both the rows and the columns of a given matrix, where we focus on a missing data setting. Our unsupervised approach consists of three components.  We first solve a family of optimization problems to estimate a complete matrix at multiple scales of smoothness. We then use this collection of smooth matrix estimates to compute pairwise distances on the rows and columns based on a new multi-scale metric that implicitly introduces a coupling between the rows and the columns.  Finally, we construct row and column representations from these multi-scale metrics.  We demonstrate that our approach outperforms competing methods in both data visualization and clustering.  ", "keywords": ["nonlinear dimensionality reduction", "missing data", "manifold learning", "co-clustering", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper826/Authors"], "authors": ["Anonymous"], "TL;DR": "Nonlinear representations of observations and features of a data matrix with missing entries and coupled geometries", "pdf": "/pdf/0e05f0174402db00e32dfec4533cc85d71de07fc.pdf", "paperhash": "anonymous|comanifold_learning_with_missing_data", "_bibtex": "@inproceedings{    \nanonymous2019co-manifold,    \ntitle={Co-manifold learning with missing data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hklc6oAcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlc6iA5YX", "original": "BkeX4Nw9YX", "number": 827, "cdate": 1538087873833, "ddate": null, "tcdate": 1538087873833, "tmdate": 1538156048692, "tddate": null, "forum": "BJlc6iA5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ACE: Artificial Checkerboard Enhancer to Induce and Evade Adversarial Attacks", "abstract": "The checkerboard phenomenon is one of the well-known visual artifacts in the computer vision field. The origins and solutions of checkerboard artifacts in the pixel space have been studied for a long time, but their effects on the gradient space have rarely been investigated. In this paper, we revisit the checkerboard artifacts in the gradient space which turn out to be the weak point of a network architecture. We explore image-agnostic property of gradient checkerboard artifacts and propose a simple yet effective defense method by utilizing the artifacts. We introduce our defense module, dubbed Artificial Checkerboard Enhancer (ACE), which induces adversarial attacks on designated pixels. This enables the model to deflect attacks by shifting only a single pixel in the image with a remarkable defense rate. We provide extensive experiments to support the effectiveness of our work for various attack scenarios using state-of-the-art attack methods. Furthermore, we show that ACE is even applicable to large-scale datasets including ImageNet dataset and can be easily transferred to various pretrained networks.", "keywords": ["Adversarial Examples", "Neural Network Security", "Deep Neural Network", "Checkerboard Artifact"], "authorids": ["ICLR.cc/2019/Conference/Paper827/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel aritificial checkerboard enhancer (ACE) module which guides attacks to a pre-specified pixel space and successfully defends it with a simple padding operation.", "pdf": "/pdf/0a044815727fef5d73d3f921c6b233499620845e.pdf", "paperhash": "anonymous|ace_artificial_checkerboard_enhancer_to_induce_and_evade_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019ace:,    \ntitle={ACE: Artificial Checkerboard Enhancer to Induce and Evade Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlc6iA5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkl5aoR5tm", "original": "SkedZEqcKX", "number": 828, "cdate": 1538087874000, "ddate": null, "tcdate": 1538087874000, "tmdate": 1538156048487, "tddate": null, "forum": "Hkl5aoR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Self Modulation for Generative Adversarial Networks", "abstract": "Training Generative Adversarial Networks (GANs) is notoriously challenging. We propose and study an architectural modification, self-modulation, which improves GAN performance across different data sets, architectures, losses, regularizers, and hyperparameter settings. Intuitively, self-modulation allows the intermediate feature maps of a generator to change as a function of the input noise vector. While reminiscent of other conditioning techniques, it requires no labeled data. In a large-scale empirical study we observe a relative decrease of 5%-35% in FID. Furthermore, all else being equal, adding this modification to the generator leads to improved performance in 124/144 (86%) of the studied settings. Self-modulation is a simple architectural change that requires no additional parameter tuning, which suggests that it can be applied readily to any GAN.", "keywords": ["unsupervised learning", "generative adversarial networks", "deep generative modelling"], "authorids": ["ICLR.cc/2019/Conference/Paper828/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. ", "pdf": "/pdf/181b90e18f809a4a325e432f60d6314f1b407a65.pdf", "paperhash": "anonymous|on_self_modulation_for_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Self Modulation for Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkl5aoR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzqpj09YQ", "original": "SyxAhGTcFm", "number": 829, "cdate": 1538087874175, "ddate": null, "tcdate": 1538087874175, "tmdate": 1538156048278, "tddate": null, "forum": "SJzqpj09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Spectral Inference Networks: Unifying Deep and Spectral Learning", "abstract": "We present Spectral Inference Networks, a framework for learning eigenfunctions of linear operators by stochastic optimization. Spectral Inference Networks generalize Slow Feature Analysis to generic symmetric operators, and are closely related to Variational Monte Carlo methods from computational physics. As such, they can be a powerful tool for unsupervised representation learning from video or graph-structured data. We cast training Spectral Inference Networks as a bilevel optimization problem, which allows for online learning of multiple eigenfunctions. We show results of training Spectral Inference Networks on problems in quantum mechanics and feature learning for videos on synthetic datasets. Our results demonstrate that Spectral Inference Networks accurately recover eigenfunctions of linear operators and can discover interpretable representations from video in a fully unsupervised manner.", "keywords": ["spectral learning", "unsupervised learning", "manifold learning", "dimensionality reduction"], "authorids": ["ICLR.cc/2019/Conference/Paper829/Authors"], "authors": ["Anonymous"], "TL;DR": "We show how to learn spectral decompositions of linear operators with deep learning, and use it for unsupervised learning without a generative model.", "pdf": "/pdf/3f810c4e2639cf662a748a92cd363640961e687a.pdf", "paperhash": "anonymous|spectral_inference_networks_unifying_deep_and_spectral_learning", "_bibtex": "@inproceedings{    \nanonymous2019spectral,    \ntitle={Spectral Inference Networks: Unifying Deep and Spectral Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzqpj09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkg5aoAqKm", "original": "Bye6Yq35YX", "number": 830, "cdate": 1538087874345, "ddate": null, "tcdate": 1538087874345, "tmdate": 1538156048067, "tddate": null, "forum": "Bkg5aoAqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fast Binary Functional Search on Graph", "abstract": "The large-scale search is an essential task in modern information systems. Numerous learning based models are proposed to capture semantic level similarity measures for searching or ranking. However, these measures are usually complicated and beyond metric distances. As Approximate Nearest Neighbor Search (ANNS) techniques have specifications on metric distances, efficient searching by advanced measures is still an open question. In this paper, we formulate large-scale search as a general task, Optimal Binary Functional Search (OBFS), which contains ANNS as special cases. We analyze existing OBFS methods' limitations and explain they are not applicable for complicated searching measures. We propose a flexible graph-based solution for OBFS, Search on L2 Graph (SL2G). SL2G approximates gradient decent in Euclidean space, with accessible conditions. Experiments demonstrate SL2G's efficiency in searching by advanced matching measures (i.e., Neural Network based measures).", "keywords": ["Binary Functional Search", "Large-scale Search", "Approximate Nearest Neighbor Search"], "authorids": ["ICLR.cc/2019/Conference/Paper830/Authors"], "authors": ["Anonymous"], "TL;DR": "Efficient Search by Neural Network based searching measures.", "pdf": "/pdf/b7f06788fb2a748faf143e0e0dab1c826e0d32f4.pdf", "paperhash": "anonymous|fast_binary_functional_search_on_graph", "_bibtex": "@inproceedings{    \nanonymous2019fast,    \ntitle={Fast Binary Functional Search on Graph},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg5aoAqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bke96sC5tm", "original": "BylyDcTcYm", "number": 831, "cdate": 1538087874510, "ddate": null, "tcdate": 1538087874510, "tmdate": 1538156047859, "tddate": null, "forum": "Bke96sC5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning", "abstract": "Model-based reinforcement learning (RL) methods can be broadly categorized as global model methods, which depend on learning models that provide sensible predictions in a wide range of states, or local model methods, which iteratively refit simple models that are used for policy improvement. While predicting future states that will result from the current actions is difficult, local model methods only attempt to understand system dynamics in the neighborhood of the current policy, making it possible to produce local improvements without ever learning to predict accurately far into the future. The main idea in this paper is that we can learn representations that make it easy to retrospectively infer simple dynamics given the data from the current policy, thus enabling local models to be used for policy learning in complex systems. We evaluate our approach against other model-based and model-free RL methods on a suite of robotics tasks, including manipulation tasks on a real Sawyer robotic arm directly from camera images.", "keywords": ["model-based reinforcement learning", "structured representation learning", "robotics"], "authorids": ["ICLR.cc/2019/Conference/Paper831/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/29031d74629b883626388899f6f0a678086506df.pdf", "paperhash": "anonymous|solar_deep_structured_representations_for_modelbased_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019solar:,    \ntitle={SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bke96sC5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1espiA9YQ", "original": "HJgwv_s5Y7", "number": 832, "cdate": 1538087874678, "ddate": null, "tcdate": 1538087874678, "tmdate": 1538156047643, "tddate": null, "forum": "r1espiA9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards More Theoretically-Grounded Particle Optimization Sampling for Deep Learning", "abstract": "Many deep-learning based methods such as Bayesian deep learning (DL) and deep reinforcement learning (RL) have heavily relied on the ability of a model being able to efficiently explore via Bayesian sampling. Particle-optimization sampling (POS) is a recently developed technique to generate high-quality samples from a target distribution by iteratively updating a set of interactive particles, with a representative algorithm the Stein variational gradient descent (SVGD). Though obtaining significant empirical success, the {\\em non-asymptotic} convergence behavior of SVGD remains unknown. In this paper, we generalize POS to a stochasticity setting by injecting random noise in particle updates, called stochastic particle-optimization sampling (SPOS). Notably, for the first time, we develop {\\em non-asymptotic convergence theory} for the SPOS framework, characterizing convergence of a sample approximation w.r.t.\\! the number of particles and iterations under both convex- and noncovex-energy-function settings. Interestingly, we provide theoretical understanding of a pitfall of SVGD that can be avoided in the proposed SPOS framework, {\\it i.e.}, particles tend to collapse to a local mode in SVGD under some particular conditions. Our theory is based on the analysis of nonlinear stochastic differential equations, which serves as an extension and a complementary development to the asymptotic convergence theory for SVGD such as (Liu, 2017). With such theoretical guarantees, SPOS can be safely and effectively applied on both Bayesian DL and deep RL tasks. Extensive results demonstrate the effectiveness of our proposed framework.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper832/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2e16c0caeecd6f0a70b31e2ba4dba6b90a54d84b.pdf", "paperhash": "anonymous|towards_more_theoreticallygrounded_particle_optimization_sampling_for_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards More Theoretically-Grounded Particle Optimization Sampling for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1espiA9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bylj6oC5K7", "original": "Ske5kV4cKX", "number": 833, "cdate": 1538087874860, "ddate": null, "tcdate": 1538087874860, "tmdate": 1538156047431, "tddate": null, "forum": "Bylj6oC5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Logit Regularization Methods for Adversarial Robustness", "abstract": "While great progress has been made at making neural networks effective across a wide range of tasks, many are surprisingly vulnerable to small, carefully chosen perturbations of their input, known as adversarial examples. In this paper, we advocate for and experimentally investigate the use of logit regularization techniques as an adversarial defense, which can be used in conjunction with other methods for creating adversarial robustness at little to no cost. We demonstrate that much of the effectiveness of one recent adversarial defense mechanism can be attributed to logit regularization and show how to improve its defense against both white-box and black-box attacks, in the process creating a stronger black-box attacks against PGD-based models.\n", "keywords": ["adversarial"], "authorids": ["ICLR.cc/2019/Conference/Paper833/Authors"], "authors": ["Anonymous"], "TL;DR": "Logit regularization methods help explain and improve state of the art adversarial defenses", "pdf": "/pdf/e9c2bf2cd826b46016825ad0131402099c694fd5.pdf", "paperhash": "anonymous|logit_regularization_methods_for_adversarial_robustness", "_bibtex": "@inproceedings{    \nanonymous2019logit,    \ntitle={Logit Regularization Methods for Adversarial Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bylj6oC5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJej6jR5Fm", "original": "rkxwdqp5tX", "number": 834, "cdate": 1538087875035, "ddate": null, "tcdate": 1538087875035, "tmdate": 1538156047220, "tddate": null, "forum": "HJej6jR5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning to Guide Segmentation", "abstract": "There are myriad kinds of segmentation, and ultimately the `\"right\" segmentation of a given scene is in the eye of the annotator. Standard approaches require large amounts of labeled data to learn just one particular kind of segmentation. As a first step towards relieving this annotation burden, we propose the problem of guided segmentation: given varying amounts of pixel-wise labels, segment unannotated pixels by propagating supervision locally (within an image) and non-locally (across images). We propose guided networks, which extract a latent task representation---guidance---from variable amounts and classes (categories, instances, etc.) of pixel supervision and optimize our architecture end-to-end for fast, accurate, and data-efficient segmentation by meta-learning. To span the few-shot and many-shot learning regimes, we examine guidance from as little as one pixel per concept to as much as 1000+ images, and compare to full gradient optimization at both extremes. To explore generalization, we analyze guidance as a bridge between different levels of supervision to segment classes as the union of instances. Our segmentor concentrates different amounts of supervision of different types of classes into an efficient latent representation, non-locally propagates this supervision across images, and can be updated quickly and cumulatively when given more supervision.", "keywords": ["meta-learning", "few-shot learning", "visual segmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper834/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a meta-learning approach for guiding visual segmentation tasks from varying amounts of supervision.", "pdf": "/pdf/3ac16d4d3a45c356c87356f19da22b72633ebd66.pdf", "paperhash": "anonymous|metalearning_to_guide_segmentation", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning to Guide Segmentation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJej6jR5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryGs6iA5Km", "original": "Hyg-Tz65t7", "number": 835, "cdate": 1538087875216, "ddate": null, "tcdate": 1538087875216, "tmdate": 1538156047009, "tddate": null, "forum": "ryGs6iA5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How Powerful are Graph Neural Networks?", "abstract": "Graph Neural Networks (GNNs) for representation learning of graphs broadly follow a neighborhood aggregation framework, where the representation vector of a node is computed by recursively aggregating and transforming feature vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs in capturing different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.", "keywords": ["graph neural networks", "theory", "deep learning", "representational power", "graph isomorphism", "deep multisets"], "authorids": ["ICLR.cc/2019/Conference/Paper835/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.", "pdf": "/pdf/acd1a73827c779cf7f0ea7c39da0f0d9c32aaa5d.pdf", "paperhash": "anonymous|how_powerful_are_graph_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How Powerful are Graph Neural Networks?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGs6iA5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xipsA5K7", "original": "S1xCQxO5Y7", "number": 836, "cdate": 1538087875382, "ddate": null, "tcdate": 1538087875382, "tmdate": 1538156046800, "tddate": null, "forum": "H1xipsA5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Two-layer Neural Networks with Symmetric Inputs", "abstract": "We give a new algorithm for learning a two-layer neural network under a very general class of input distributions. Assuming there is a ground-truth two-layer network \ny = A \\sigma(Wx) + \\xi,\nwhere A, W are weight matrices, \\xi represents noise, and the number of neurons in the hidden layer is no larger than the input or output,  our algorithm is guaranteed to recover the parameters A, W of the ground-truth network. The only requirement on the input x is that it is symmetric, which still allows highly complicated and structured input. \n\nOur algorithm is based on the method-of-moments framework and extends several results in tensor decompositions. We use spectral algorithms to avoid the complicated non-convex optimization in learning neural networks. Experiments show that our algorithm can robustly learn the ground-truth neural network with a small number of samples for many symmetric input distributions.", "keywords": ["Neural Network", "Optimization", "Symmetric Inputs", "Moment-of-moments"], "authorids": ["ICLR.cc/2019/Conference/Paper836/Authors"], "authors": ["Anonymous"], "TL;DR": "We give an algorithm for learning a two-layer neural network with symmetric input distribution. ", "pdf": "/pdf/ab33fd107eba22bdb51d89c615590553daf03c7e.pdf", "paperhash": "anonymous|learning_twolayer_neural_networks_with_symmetric_inputs", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Two-layer Neural Networks with Symmetric Inputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xipsA5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1x2aiRqFX", "original": "BkeMaOi5t7", "number": 837, "cdate": 1538087875546, "ddate": null, "tcdate": 1538087875546, "tmdate": 1538156046587, "tddate": null, "forum": "S1x2aiRqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Differentiable Expected BLEU for Text Generation", "abstract": "Neural text generation models such as recurrent networks are typically trained by maximizing data log-likelihood based on cross entropy. Such training objective shows a discrepancy from test criteria like the BLEU metric. Recent work optimizes expected BLEU under the model distribution using policy gradient, while such algorithm can suffer from high variance and become impractical. In this paper, we propose a new Differentiable Expected BLEU (DEBLEU) objective that permits direct optimization of neural generation models with gradient descent. We leverage the decomposability and sparsity of BLEU, and reformulate it with moderate approximations, making the evaluation of the objective and its gradient efficient, comparable to common cross-entropy loss. We further devise a simple training procedure with ground-truth masking and annealing for stable optimization. Experiments on neural machine translation and image captioning show our method significantly improves over both cross-entropy and policy gradient training.", "keywords": ["text generation", "BLEU", "differentiable", "gradient descent", "maximum likelihood learning", "policy gradient", "machine translation"], "authorids": ["ICLR.cc/2019/Conference/Paper837/Authors"], "authors": ["Anonymous"], "TL;DR": "A new differentiable expected BLEU objective that is end-to-end trainable with gradient descent for neural text generation models", "pdf": "/pdf/3f04f582cf9897abacd3f6adf8a61179dcb14c52.pdf", "paperhash": "anonymous|differentiable_expected_bleu_for_text_generation", "_bibtex": "@inproceedings{    \nanonymous2019differentiable,    \ntitle={Differentiable Expected BLEU for Text Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1x2aiRqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgnpiR9Y7", "original": "r1elfJzqF7", "number": 838, "cdate": 1538087875731, "ddate": null, "tcdate": 1538087875731, "tmdate": 1538156046382, "tddate": null, "forum": "HkgnpiR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Recycling the discriminator for improving the inference mapping of GAN", "abstract": "Generative adversarial networks (GANs) have achieved outstanding success in generating the high-quality data. Focusing on the generation process, existing GANs learn a unidirectional mapping from the latent vector to the data. Later, various studies point out that the latent space of GANs is semantically meaningful and can be utilized in advanced data analysis and manipulation. In order to analyze the real data in the latent space of GANs, it is necessary to investigate the inverse generation mapping from the data to the latent vector. To tackle this problem, the bidirectional generative models introduce an encoder to establish the inverse path of the generation process. Unfortunately, this effort leads to the degradation of generation quality because the imperfect generator rather interferes the encoder training and vice versa. \nIn this paper, we propose an effective algorithm to infer the latent vector based on existing unidirectional GANs by preserving their generation quality.\nIt is important to note that we focus on increasing the accuracy and efficiency of the inference mapping but not influencing the GAN performance (i.e., the quality or the diversity of the generated sample).\nFurthermore, utilizing the proposed inference mapping algorithm, we suggest a new metric for evaluating the GAN models by measuring the reconstruction error of unseen real data.\nThe experimental analysis demonstrates that the proposed algorithm achieves more accurate inference mapping than the existing method and provides the robust metric for evaluating GAN performance. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper838/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4565c705d620e8928226d545ab5423b812f5f05c.pdf", "paperhash": "anonymous|recycling_the_discriminator_for_improving_the_inference_mapping_of_gan", "_bibtex": "@inproceedings{    \nanonymous2019recycling,    \ntitle={Recycling the discriminator for improving the inference mapping of GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgnpiR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MhpiRqFm", "original": "BJgs6l99FQ", "number": 839, "cdate": 1538087875904, "ddate": null, "tcdate": 1538087875904, "tmdate": 1538156046151, "tddate": null, "forum": "B1MhpiRqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Boltzmann Weighting Done Right in Reinforcement Learning", "abstract": "The Boltzmann softmax operator can trade-off well between exploration and exploitation according to current estimation in an exponential weighting scheme, which is a promising way to address the exploration-exploitation dilemma in reinforcement learning. Unfortunately, the Boltzmann softmax operator is not a non-expansion, which may lead to unstable or even divergent learning behavior when used in estimating the value function. The convergence of value iteration is guaranteed in a restricted set of non-expansive operators and how to characterize the effect of such non-expansive operators in value iteration remains an open problem. In this paper, we propose a new technique to analyze the error bound of value iteration with the the Boltzmann softmax operator. We then propose the dynamic Boltzmann softmax(DBS) operator to enable the convergence to the optimal value function in value iteration. We also present convergence rate analysis of the algorithm. Using Q-learning as an application, we show that the DBS operator can be applied in a model-free reinforcement learning algorithm. Finally, we demonstrate the effectiveness of the DBS operator in a toy problem called GridWorld and a suite of Atari games. Experimental results show that outperforms DQN substantially in benchmark games. ", "keywords": ["Reinforcement Learning", "Boltzmann Softmax Operator", "Exploration-Exploitation Dilemma"], "authorids": ["ICLR.cc/2019/Conference/Paper839/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/29e7e036064114b61e1574b91a9ed0a5f28f2dd1.pdf", "paperhash": "anonymous|boltzmann_weighting_done_right_in_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019boltzmann,    \ntitle={Boltzmann Weighting Done Right in Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MhpiRqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJe3TsR5K7", "original": "ryxkdPtcKm", "number": 840, "cdate": 1538087876079, "ddate": null, "tcdate": 1538087876079, "tmdate": 1538156045936, "tddate": null, "forum": "HJe3TsR5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching", "abstract": "We study the joint distribution matching problem which aims at learning bidirectional mappings to match the joint distribution of two domains. This problem occurs in unsupervised image-to-image translation and video-to-video synthesis tasks, which, however, has two critical challenges: (i) it is difficult to exploit sufficient information from the joint distribution; (ii) how to theoretically and experimentally evaluate the generalization performance remains an open question. To address the above challenges, we propose a new optimization problem and design a novel Joint Wasserstein Auto-Encoders (JWAE) to minimize the Wasserstein distance of the joint distributions in two domains. We theoretically prove that the generalization ability of the proposed method can be guaranteed by minimizing the Wasserstein distance of joint distributions. To verify the generalization ability, we apply our method to unsupervised video-to-video synthesis by performing video frame interpolation and producing visually smooth videos in two domains, simultaneously. Both qualitative and quantitative comparisons demonstrate the superiority of our method over several state-of-the-arts.", "keywords": ["joint distribution matching", "video-to-video synthesis", "Wasserstein distance"], "authorids": ["ICLR.cc/2019/Conference/Paper840/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching", "pdf": "/pdf/44f17663f2e769ad85ad6a9f298813e265ed6685.pdf", "paperhash": "anonymous|learning_joint_wasserstein_autoencoders_for_joint_distribution_matching", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJe3TsR5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylhToC5YQ", "original": "SklUHxncFX", "number": 841, "cdate": 1538087876245, "ddate": null, "tcdate": 1538087876245, "tmdate": 1538156045734, "tddate": null, "forum": "rylhToC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Neural Multi-Document Abstractive Summarization", "abstract": "Abstractive summarization has been studied using neural sequence transduction methods with datasets of large, paired document-summary examples. However, such datasets are rare and the models trained from them do not generalize to other domains. Recently, some progress has been made in learning sequence-to-sequence mappings with only unpaired examples. In our work, we consider the setting where there are only documents and no summaries provided and propose an end-to-end, neural model architecture to perform unsupervised abstractive summarization. Our proposed model consists of an auto-encoder trained so that the mean of the representations of the input documents decodes to a reasonable summary. We consider variants of the proposed architecture and perform an ablation study to show the importance of specific components. We apply our model to the summarization of business and product reviews and show that the generated summaries are fluent, show relevancy in terms of word-overlap, representative of the average sentiment of the input documents, and are highly abstractive compared to baselines. The code to reproduce results is available at github.com/REDACTED.", "keywords": ["unsupervised learning", "abstractive summarization", "reviews", "text generation"], "authorids": ["ICLR.cc/2019/Conference/Paper841/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.", "pdf": "/pdf/4630a6d4b3bd013131d6e26194769de8c05ed784.pdf", "paperhash": "anonymous|unsupervised_neural_multidocument_abstractive_summarization", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Neural Multi-Document Abstractive Summarization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylhToC5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJl2ps0qKQ", "original": "HkeCV5pqF7", "number": 842, "cdate": 1538087876420, "ddate": null, "tcdate": 1538087876420, "tmdate": 1538156045528, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerer to answer compound questions. Our model consists of two components: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) a simple-question answerer that classifies the corresponding relation to answers. Experiments demonstrate that our model learns complex rules of compositionality as policy, which benefits a simple neural network to achieve state-of-the-art results on the most challenging research dataset. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["ICLR.cc/2019/Conference/Paper842/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a learning-to-decompose agent that helps a simple-question answerer to answer compound question over knowledge graph.", "pdf": "/pdf/91e8d02212378cb6963e832dacd0a39229ce2aad.pdf", "paperhash": "anonymous|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl2ps0qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJl6TjRcY7", "original": "Hyl_T8KcF7", "number": 843, "cdate": 1538087876585, "ddate": null, "tcdate": 1538087876585, "tmdate": 1538156045324, "tddate": null, "forum": "BJl6TjRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Probabilistic Motor Primitives for Humanoid Control", "abstract": "Transferring functional properties from one or multiple expert policies to a student policy is an important challenge in control. Expert robustness is of particular interest; we would like to not only transfer the expert behavior but also its ability to recover from perturbations.  With this in mind, we explore approaches for policy cloning and propose linear feedback policy cloning as a simple option for certain settings.  We show that it can be surprisingly straightforward to clone ex-pert policies for seemingly complex behaviors without the student requiring any environment interactions. We then propose a latent-variable architecture that bottlenecks a sensory-motor primitive space,  which,  again,  can be trained entirely offline to compress thousands of expert policies.  We show this resulting neural probabilistic motor primitive system produces robust one-shot imitation of whole-body humanoid behaviors.  In addition, we analyze the resulting latent space and demonstrate the ability to reuse this system. We encourage readers to view a supplementary video (https://youtu.be/44tPXdUCc-g ) summarizing our results.", "keywords": ["Motor Primitives", "Distillation", "Reinforcement Learning", "Continuous Control", "Humanoid Control", "Motion Capture", "One-Shot Imitation"], "authorids": ["ICLR.cc/2019/Conference/Paper843/Authors"], "authors": ["Anonymous"], "TL;DR": "Neural Probabilistic Motor Primitives compress motion capture tracking policies into one flexible model capable of one-shot imitation and reuse as a low-level controller.", "pdf": "/pdf/a83c14a721e29fbb4c676eab17e795b27adfdc15.pdf", "paperhash": "anonymous|neural_probabilistic_motor_primitives_for_humanoid_control", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Probabilistic Motor Primitives for Humanoid Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl6TjRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJeapjA5FX", "original": "HkxBgsacK7", "number": 844, "cdate": 1538087876762, "ddate": null, "tcdate": 1538087876762, "tmdate": 1538156045110, "tddate": null, "forum": "BJeapjA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GEOMETRIC AUGMENTATION FOR ROBUST NEURAL NETWORK CLASSIFIERS", "abstract": "We introduce a novel geometric perspective and unsupervised model augmentation framework for transforming traditional deep (convolutional) neural networks into adversarially robust classifiers. Class-conditional probability densities based on Bayesian nonparametric mixtures of factor analyzers (BNP-MFA) over the input space are used to design soft decision labels for feature to label isometry. Classconditional distributions over features are also learned using BNP-MFA to develop plug-in maximum a posterior (MAP) classifiers to replace the traditional multinomial logistic softmax classification layers. This novel unsupervised augmented framework, which we call geometrically robust networks (GRN), is applied to CIFAR-10, CIFAR-100, and to Radio-ML (a time series dataset for radio modulation recognition). We demonstrate the robustness of GRN models to adversarial attacks from fast gradient sign method, Carlini-Wagner, and projected gradient descent.", "keywords": ["Bayesian nonparametric", "robust", "deep neural network", "classifier", "unsupervised learning", "geometric"], "authorids": ["ICLR.cc/2019/Conference/Paper844/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a statistical-geometric unsupervised learning augmentation framework for deep neural networks to make them robust to adversarial attacks.", "pdf": "/pdf/2192f3eb60d60878d29534558e1494bd1ec29eec.pdf", "paperhash": "anonymous|geometric_augmentation_for_robust_neural_network_classifiers", "_bibtex": "@inproceedings{    \nanonymous2019geometric,    \ntitle={GEOMETRIC AUGMENTATION FOR ROBUST NEURAL NETWORK CLASSIFIERS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeapjA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgTTjA9tX", "original": "r1ejl6AKYQ", "number": 845, "cdate": 1538087876930, "ddate": null, "tcdate": 1538087876930, "tmdate": 1538156044704, "tddate": null, "forum": "rJgTTjA9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure", "abstract": "There has been a large amount of interest, both in the past and particularly recently, into the relative advantage of different families of universal function approximators, for instance neural networks, polynomials, rational functions, etc. However, current research has focused almost exclusively on understanding this problem in a worst case setting: e.g. characterizing the best L1 or L_{infty} approximation in a box (or sometimes, even under an adversarially constructed data distribution.) In this setting many classical tools from approximation theory can be effectively used.\n\nHowever, in typical applications we expect data to be high dimensional, but structured -- so, it would only be important to approximate the desired function well on the relevant part of its domain, e.g. a small manifold on which real input data actually lies. Moreover, even within this domain the desired quality of approximation may not be uniform; for instance in classification problems, the approximation needs to be more accurate near the decision boundary. These issues, to the best of our knowledge, have remain unexplored until now.\n\t\nWith this in mind, we analyze the performance of neural networks and polynomial kernels in a natural regression setting where the data enjoys sparse latent structure, and the labels depend in a simple way on the latent variables. We give an almost-tight theoretical analysis of the performance of both neural networks and polynomials for this problem, as well as verify our theory with simulations. Our results both involve new (complex-analytic) techniques, which may be of independent interest, and show substantial qualitative differences with what is known in the worst-case setting.", "keywords": ["theory", "representational power", "universal approximators", "polynomial kernels", "latent sparsity", "beyond worst case", "separation result"], "authorids": ["ICLR.cc/2019/Conference/Paper845/Authors"], "authors": ["Anonymous"], "TL;DR": "Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.", "pdf": "/pdf/7feceaed0bc654b643c4b5b607c360e1ce0f3215.pdf", "paperhash": "anonymous|the_comparative_power_of_relu_networks_and_polynomial_kernels_in_the_presence_of_sparse_latent_structure", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgTTjA9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyepTiR9FQ", "original": "S1xulja9YX", "number": 846, "cdate": 1538087877101, "ddate": null, "tcdate": 1538087877101, "tmdate": 1538156044494, "tddate": null, "forum": "SyepTiR9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention", "abstract": "A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry. However, these surface-centric properties also pose challenges on designing tools to recognize and synthesize point clouds. This work presents a novel autoregressive model, PointGrow, which generates realistic point cloud samples from scratch or conditioned from given semantic contexts. Our model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points. Since point cloud object shapes are typically encoded by long-range interpoint dependencies, we augment our model with dedicated self-attention modules to capture these relations. Extensive evaluation demonstrates that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to fidelity, diversity and semantic preservation. Further, conditional PointGrow learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside.", "keywords": ["point cloud generation", "autoregressive models", "self-attention"], "authorids": ["ICLR.cc/2019/Conference/Paper846/Authors"], "authors": ["Anonymous"], "TL;DR": "An autoregressive deep learning model for generating diverse point clouds.", "pdf": "/pdf/c9e3a37e38f9e26e022541f58fc54c96ea91602f.pdf", "paperhash": "anonymous|pointgrow_autoregressively_learned_point_cloud_generation_with_selfattention", "_bibtex": "@inproceedings{    \nanonymous2019pointgrow:,    \ntitle={PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyepTiR9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgTps0qtQ", "original": "Bklk-sTct7", "number": 847, "cdate": 1538087877275, "ddate": null, "tcdate": 1538087877275, "tmdate": 1538156044288, "tddate": null, "forum": "SJgTps0qtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploiting Environmental Variation to Improve Policy Robustness in  Reinforcement Learning", "abstract": "Conventional reinforcement learning rarely considers how the physical variations in the environment (eg. mass, drag, etc.) affect the policy learned by the agent. In this paper, we explore how changes in the environment affect  policy generalization. We observe experimentally that, for each task we considered, there exists an optimal environment setting that results in the most robust policy that generalizes well to future environments. We propose a novel method to exploit this observation to develop robust actor policies, by automatically developing a sampling curriculum over environment settings to use in training. Ours is a model-free approach and experiments demonstrate that the performance of our method is on par with the best policies found by an exhaustive grid search, while bearing a significantly lower computational cost.", "keywords": ["Reinforcement Learning", "Policy Robustness", "Policy generalization", "Automated Curriculum"], "authorids": ["ICLR.cc/2019/Conference/Paper847/Authors"], "authors": ["Anonymous"], "TL;DR": "By formulating the learning curriculum as a bandit problem, we present a principled approach to motivating policy robustness in continuous controls tasks.", "pdf": "/pdf/4eccff5dd6ccd2dd8a84b0e817db7733c56cdb1c.pdf", "paperhash": "anonymous|exploiting_environmental_variation_to_improve_policy_robustness_in_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019exploiting,    \ntitle={Exploiting Environmental Variation to Improve Policy Robustness in  Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgTps0qtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGT6sRcFX", "original": "B1x1Xta5KQ", "number": 848, "cdate": 1538087877444, "ddate": null, "tcdate": 1538087877444, "tmdate": 1538156044082, "tddate": null, "forum": "SkGT6sRcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Infinitely Deep Infinite-Width Networks", "abstract": "Infinite-width neural networks have been extensively used to study the theoretical properties underlying the extraordinary empirical success of standard, finite-width neural networks. Nevertheless, until now, infinite-width networks have been limited to at most two hidden layers. To address this shortcoming, we study the initialisation requirements of these networks and show that the main challenge for constructing them is defining the appropriate sampling distributions for the weights. Based on these observations, we propose a principled approach to weight initialisation that correctly accounts for the functional nature of the hidden layer activations and facilitates the construction of arbitrarily many infinite-width layers, thus enabling the construction of arbitrarily deep infinite-width networks. The main idea of our approach is to iteratively reparametrise the hidden-layer activations into appropriately defined reproducing kernel Hilbert spaces and use the canonical way of constructing probability distributions over these spaces for specifying the required weight distributions in a principled way. Furthermore, we examine the practical implications of this construction for standard, finite-width networks. In particular, we derive a novel weight initialisation scheme for standard, finite-width networks that takes into account the structure of the data and information about the task at hand. We demonstrate the effectiveness of this weight initialisation approach on the MNIST, CIFAR-10 and Year Prediction MSD datasets.", "keywords": ["Infinite-width networks", "initialisation", "kernel methods", "reproducing kernel Hilbert spaces", "Gaussian processes"], "authorids": ["ICLR.cc/2019/Conference/Paper848/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method for the construction of arbitrarily deep infinite-width networks, based on which we derive a novel weight initialisation scheme for finite-width networks and demonstrate its competitive performance.", "pdf": "/pdf/e99c6267511df6941bfe62d71a1549e15f3d9620.pdf", "paperhash": "anonymous|infinitely_deep_infinitewidth_networks", "_bibtex": "@inproceedings{    \nanonymous2019infinitely,    \ntitle={Infinitely Deep Infinite-Width Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGT6sRcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1g0piA9tQ", "original": "HJgyvUoqYm", "number": 849, "cdate": 1538087877629, "ddate": null, "tcdate": 1538087877629, "tmdate": 1538156043879, "tddate": null, "forum": "H1g0piA9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Evaluation Methodology for Attacks Against Confidence Thresholding Models", "abstract": "Current machine learning algorithms can be easily fooled by adversarial examples. One possible solution path is to make models that use confidence thresholding to avoid making mistakes. Such models refuse to make a prediction when they are not confident of their answer. We propose to evaluate such models in terms of tradeoff curves with the goal of high success rate on clean examples and low failure rate on adversarial examples. Existing untargeted attacks developed for models that do not use confidence thresholding tend to underestimate such models' vulnerability. We propose the MaxConfidence family of attacks, which are optimal in a variety of theoretical settings, including one realistic setting: attacks against linear models. Experiments show the attack attains good results in practice. We show that simple defenses are able to perform well on MNIST but not on CIFAR, contributing further to previous calls that MNIST should be retired as a benchmarking dataset for adversarial robustness research.  We release code for these evaluations as part of the cleverhans (Papernot et al 2018) library  (ICLR reviewers should be careful not to look at who contributed these features to cleverhans to avoid de-anonymizing this submission).", "keywords": ["adversarial examples"], "authorids": ["ICLR.cc/2019/Conference/Paper849/Authors"], "authors": ["Anonymous"], "TL;DR": "We present metrics and an optimal attack for evaluating models that defend against adversarial examples using confidence thresholding", "pdf": "/pdf/58ee81bbb9ab33424599a4a7ac6ff9642b54721a.pdf", "paperhash": "anonymous|evaluation_methodology_for_attacks_against_confidence_thresholding_models", "_bibtex": "@inproceedings{    \nanonymous2019evaluation,    \ntitle={Evaluation Methodology for Attacks Against Confidence Thresholding Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g0piA9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeRTsAcYm", "original": "ryg5G0OqYm", "number": 850, "cdate": 1538087877800, "ddate": null, "tcdate": 1538087877800, "tmdate": 1538156043665, "tddate": null, "forum": "SkeRTsAcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["ICLR.cc/2019/Conference/Paper850/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/da6374351fa9e59f7d0e1972cb0619c1930a9dd8.pdf", "paperhash": "anonymous|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{    \nanonymous2019phase-aware,    \ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeRTsAcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJfRpoA9YX", "original": "BJgoJPF9YX", "number": 851, "cdate": 1538087877965, "ddate": null, "tcdate": 1538087877965, "tmdate": 1538156043450, "tddate": null, "forum": "BJfRpoA9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Information Factorization", "abstract": "We propose a novel generative model architecture designed to learn representations for images that factor out a single attribute from the rest of the representation. A single object may have many attributes which when altered do not change the identity of the object itself. Consider the human face; the identity of a particular person is independent of whether or not they happen to be wearing glasses. The attribute of wearing glasses can be changed without changing the identity of the person. However, the ability to manipulate and alter image attributes without altering the object identity is not a trivial task. Here, we are interested in learning a representation of the image that separates the identity of an object (such as a human face) from an attribute (such as 'wearing glasses'). We demonstrate the success of our factorization approach by using the learned representation to synthesize the same face with and without a chosen attribute. We refer to this specific synthesis process as image attribute manipulation. We further demonstrate that our model achieves competitive scores, with state of the art, on a facial attribute classification task.", "keywords": ["disentangled representations", "factored representations", "generative adversarial networks", "variational auto encoders", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper851/Authors"], "authors": ["Anonymous"], "TL;DR": "Learn representations for images that factor out a single attribute.", "pdf": "/pdf/1f69d9d1a453fe728fc3e0470ffcb5c295173d25.pdf", "paperhash": "anonymous|adversarial_information_factorization", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Information Factorization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfRpoA9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyMRaoAqKX", "original": "HJeStoT5KQ", "number": 852, "cdate": 1538087878137, "ddate": null, "tcdate": 1538087878137, "tmdate": 1538156043245, "tddate": null, "forum": "HyMRaoAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Implicit Autoencoders", "abstract": "In this paper, we describe the \"implicit autoencoder\" (IAE), a generative autoencoder in which both the generative path and the recognition path are parametrized by implicit distributions. We use two generative adversarial networks to define the reconstruction and the regularization cost functions of the implicit autoencoder, and derive the learning rules based on maximum-likelihood learning. Using implicit distributions allows us to learn more expressive posterior and conditional likelihood distributions for the autoencoder. Learning an expressive conditional likelihood distribution enables the latent code to only capture the abstract and high-level information of the data, while the remaining information is captured by the implicit conditional likelihood distribution. For example, we show that implicit autoencoders can disentangle the global and local information, and perform deterministic or stochastic reconstructions of the images. We further show that implicit autoencoders can disentangle discrete underlying factors of variation from the continuous factors in an unsupervised fashion, and perform clustering and semi-supervised learning.", "keywords": ["Unsupervised Learning", "Generative Models", "Variational Inference", "Generative Adversarial Networks."], "authorids": ["ICLR.cc/2019/Conference/Paper852/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.", "pdf": "/pdf/da06659e17b1194be8568839f6f8229e6c483a3d.pdf", "paperhash": "anonymous|implicit_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019implicit,    \ntitle={Implicit Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMRaoAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkVRTj0cYQ", "original": "rJlLsXTqt7", "number": 853, "cdate": 1538087878309, "ddate": null, "tcdate": 1538087878309, "tmdate": 1538156043032, "tddate": null, "forum": "SkVRTj0cYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Differentially Private Federated Learning: A Client Level Perspective", "abstract": "Federated learning is a recent advance in privacy protection. \nIn this context, a trusted curator aggregates parameters optimized in decentralized fashion by multiple clients. The resulting model is then distributed back to all clients, ultimately converging to a joint representative model without explicitly having to share the data. \nHowever, the protocol is vulnerable to differential attacks, which could originate from any party contributing during federated optimization. In such an attack, a client's contribution during training and information about their data set is revealed through analyzing the distributed model. \nWe tackle this problem and propose an algorithm for client sided differential privacy preserving federated optimization. The aim is to hide clients' contributions during training, balancing the trade-off between privacy loss and model performance. \nEmpirical studies suggest that given a sufficiently large number of participating clients, our proposed procedure can maintain client-level differential privacy at only a minor cost in model performance. ", "keywords": ["Machine Learning", "Federated Learning", "Privacy", "Security", "Differential Privacy"], "authorids": ["ICLR.cc/2019/Conference/Paper853/Authors"], "authors": ["Anonymous"], "TL;DR": "Ensuring that models learned in federated fashion do not reveal a client's participation.", "pdf": "/pdf/b0820366c53400ca4be650c144b551219c0b5fe2.pdf", "paperhash": "anonymous|differentially_private_federated_learning_a_client_level_perspective", "_bibtex": "@inproceedings{    \nanonymous2019differentially,    \ntitle={Differentially Private Federated Learning: A Client Level Perspective},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkVRTj0cYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r14Aas09Y7", "original": "rJx2zoLuFm", "number": 854, "cdate": 1538087878485, "ddate": null, "tcdate": 1538087878485, "tmdate": 1538156042830, "tddate": null, "forum": "r14Aas09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "COCO-GAN: Conditional Coordinate Generative Adversarial Network", "abstract": "Recent advancements on Generative Adversarial Network (GAN) have inspired a wide range of works that generate synthetic images. However, the current processes have to generate an entire image at once, and therefore resolutions are limited by memory or computational constraints. In this work, we propose COnditional COordinate GAN (COCO-GAN), which generates a specific patch of an image conditioned on a spatial position rather than the entire image at a time. The generated patches are later combined together to form a globally coherent full-image. With this process, we show that the generated image can achieve competitive quality to state-of-the-arts and the generated patches are locally smooth between consecutive neighbors. One direct implication of the COCO-GAN is that it can be applied onto any coordinate systems including the cylindrical systems which makes it feasible for generating panorama images. The fact that the patch generation process is independent to each other inspires a wide range of new applications: firstly, \"Patch-Inspired Image Generation\" enables us to generate the entire image based on a single patch. Secondly, \"Partial-Scene Generation\" allows us to generate images within a customized target region. Finally, thanks to COCO-GAN's patch generation and massive parallelism, which enables combining patches for generating a full-image with higher resolution than state-of-the-arts.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper854/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/bf2303ebb30ce5efafa0b3af69b587e16c8ba8ef.pdf", "paperhash": "anonymous|cocogan_conditional_coordinate_generative_adversarial_network", "_bibtex": "@inproceedings{    \nanonymous2019coco-gan:,    \ntitle={COCO-GAN: Conditional Coordinate Generative Adversarial Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r14Aas09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxyAjRcFX", "original": "rygOhrv5Km", "number": 855, "cdate": 1538087878657, "ddate": null, "tcdate": 1538087878657, "tmdate": 1538156042624, "tddate": null, "forum": "HJxyAjRcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation", "abstract": "Recent advances in conditional image generation tasks, such as image-to-image translation and image inpainting, are largely contributed by the success of conditional GAN models, which are often optimized by the joint use of the GAN loss with the reconstruction loss. However, we show that this training recipe shared by almost all existing methods always leads to a suboptimal generator and has one critical side effect: lack of diversity in output samples. In order to accomplish both training stability and multimodal output generation, we propose novel training schemes with a new set of losses that simply replace the reconstruction loss, and thus applicable to any conditional generation tasks. We show this by performing thorough experiments on image-to-image translation, super-resolution, and image inpainting tasks with Cityscapes, and CelebA dataset. A quantitative evaluation also confirms that our methods achieve great diversity of outputs while retaining or even improving the quality of images.", "keywords": ["conditional GANs", "conditional image generation", "multimodal generation", "reconstruction loss", "maximum likelihood estimation", "moment matching"], "authorids": ["ICLR.cc/2019/Conference/Paper855/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove that the mode collapse in conditional GANs is largely attributed to a mismatch between reconstruction loss and GAN loss and introduce a set of novel loss functions as alternatives for reconstruction loss.", "pdf": "/pdf/2021a9991ef92be8a8000c861dbda15c49c62e4a.pdf", "paperhash": "anonymous|harmonizing_maximum_likelihood_with_gans_for_multimodal_conditional_generation", "_bibtex": "@inproceedings{    \nanonymous2019harmonizing,    \ntitle={Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxyAjRcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xJAsA5F7", "original": "rJlM0fFYKX", "number": 856, "cdate": 1538087878834, "ddate": null, "tcdate": 1538087878834, "tmdate": 1538156042419, "tddate": null, "forum": "B1xJAsA5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Multimodal Graph-to-Graph Translation for Molecule Optimization", "abstract": "We view molecule optimization as a graph-to-graph translation problem. The goal is to learn to map from one molecular graph to another with better properties based on an available corpus of paired molecules. Since molecules can be optimized in different ways, there are multiple viable translations for each input graph. A key challenge is therefore to model diverse translation outputs. Our primary contributions include a junction tree encoder-decoder for learning diverse graph translations along with a novel adversarial training method for aligning distributions of molecules. Diverse output distributions in our model are explicitly realized by low-dimensional latent vectors that modulate the translation process. We evaluate our model on multiple molecule optimization tasks and show that our model outperforms previous state-of-the-art baselines by a significant margin. \n", "keywords": ["graph-to-graph translation", "adversarial training"], "authorids": ["ICLR.cc/2019/Conference/Paper856/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a graph-to-graph encoder-decoder framework for learning diverse graph translations.", "pdf": "/pdf/c77f0698d8431fed2eb42a3c042a9ceccf35451e.pdf", "paperhash": "anonymous|learning_multimodal_graphtograph_translation_for_molecule_optimization", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Multimodal Graph-to-Graph Translation for Molecule Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xJAsA5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgyAoRqFQ", "original": "rkxjtqpctX", "number": 857, "cdate": 1538087879004, "ddate": null, "tcdate": 1538087879004, "tmdate": 1538156042210, "tddate": null, "forum": "HJgyAoRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "State-Denoised Recurrent Neural Networks", "abstract": "Recurrent neural networks (RNNs) are difficult to train on sequence processing tasks, not only because input noise may be amplified through feedback, but also because any inaccuracy in the weights has similar consequences as input noise. We describe a method for denoising the hidden state during training to achieve more robust representations thereby improving generalization performance. Attractor dynamics are incorporated into the hidden state to `clean up' representations at each step of a sequence. The attractor dynamics are trained through an auxillary denoising loss to recover previously experienced hidden states from noisy versions of those states. This state-denoised recurrent neural network (SDRNN) performs multiple steps of internal processing for each external sequence step. On a range of tasks, we show that the SDRNN outperforms a generic RNN as well as a variant of the SDRNN with attractor dynamics on the hidden state but without the auxillary loss. We argue that attractor dynamics---and corresponding connectivity constraints---are an essential component of the deep learning arsenal and should be invoked not only for recurrent networks but also for improving deep feedforward nets and intertask transfer.", "keywords": ["recurrent nets", "attractor nets", "denoising", "sequence processing"], "authorids": ["ICLR.cc/2019/Conference/Paper857/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a mechanism for denoising the internal state of an RNN to improve generalization performance.", "pdf": "/pdf/e739554c0f3d38f53d82206aafb0f5335ecb5305.pdf", "paperhash": "anonymous|statedenoised_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019state-denoised,    \ntitle={State-Denoised Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgyAoRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJe10iC5K7", "original": "r1xUnj69FQ", "number": 858, "cdate": 1538087879171, "ddate": null, "tcdate": 1538087879171, "tmdate": 1538156041999, "tddate": null, "forum": "rJe10iC5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Modeling Parts, Structure, and System Dynamics via Predictive Learning", "abstract": "Humans easily recognize object parts and their hierarchical structure by watching how they move; they can then predict how each part moves in the future. In this paper, we propose a novel formulation that simultaneously learns a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos in a self-supervised manner. Our Parts, Structure, and Dynamics (PSD) model learns to first recognize the object parts via a layered image representation; second, predict hierarchy via a structural descriptor that composes low-level concepts into a hierarchical structure; and third, model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that our PSD model works well on all three tasks: segmenting object parts, building their hierarchical structure, and capturing their motion distributions.", "keywords": ["Self-Supervised Learning", "Visual Prediction", "Hierarchical Models"], "authorids": ["ICLR.cc/2019/Conference/Paper858/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning object parts, hierarchical structure, and dynamics by watching how they move", "pdf": "/pdf/977b962d32ff4e6c3227fd82b1d74d33c0aba99b.pdf", "paperhash": "anonymous|modeling_parts_structure_and_system_dynamics_via_predictive_learning", "_bibtex": "@inproceedings{    \nanonymous2019modeling,    \ntitle={Modeling Parts, Structure, and System Dynamics via Predictive Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJe10iC5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gkAoA5FQ", "original": "ByemWlJOYm", "number": 859, "cdate": 1538087879347, "ddate": null, "tcdate": 1538087879347, "tmdate": 1538156041771, "tddate": null, "forum": "r1gkAoA5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A bird's eye view on coherence, and a worm's eye view on cohesion", "abstract": "Generating coherent and cohesive long-form texts is a challenging problem in natural language generation. Previous works relied on a large amount of human-generated texts to train language models, however, few attempted to explicitly model the desired linguistic properties of natural language text, such as coherence and cohesion. In this work, we train two expert discriminators for coherence and cohesion, respectively, to provide hierarchical feedback for text generation. We also propose a simple variant of policy gradient, called 'negative-critical sequence training', using margin rewards, in which the 'baseline' is constructed from randomly generated negative samples. We demonstrate the effectiveness of our approach through empirical studies, showing significant improvements over the strong baseline -- attention-based bidirectional MLE-trained neural language model -- in a number of automated metrics. The proposed discriminators can serve as baseline architectures to promote further research to better extract, encode, and transfer essential qualities from texts.", "keywords": ["text generation", "natural language processing", "neural language model"], "authorids": ["ICLR.cc/2019/Conference/Paper859/Authors"], "authors": ["Anonymous"], "TL;DR": "We encode linguistic properties, such as, coherence and cohesion, into expert discriminators and improve text generation.", "pdf": "/pdf/2a20cc6cd28e2d96ac0c0f37352d5b827afea198.pdf", "paperhash": "anonymous|a_birds_eye_view_on_coherence_and_a_worms_eye_view_on_cohesion", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A bird's eye view on coherence, and a worm's eye view on cohesion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gkAoA5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxkCj09Fm", "original": "rJeepspct7", "number": 860, "cdate": 1538087879513, "ddate": null, "tcdate": 1538087879513, "tmdate": 1538156041565, "tddate": null, "forum": "ByxkCj09Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DEEP HIERARCHICAL MODEL FOR HIERARCHICAL SELECTIVE CLASSIFICATION AND ZERO SHOT LEARNING", "abstract": "Object recognition in real-world image scenes is still an open problem. A large number of object classes with complex relationships between them makes the classification problem particularly challenging. Standard N-way discrete classifiers treat all classes as disconnected and unrelated, and therefore unable to learn from their semantic relationships. In this work, we present a hierarchical interclass relationship model, and train it using a newly proposed probability-based loss function. We show the model advantages deploying it in two scenarios. The first one, selective classification, deals with the problem of low-confidence classification,\nwherein a model is unable to make a successful exact classification.\nIn this case, our model returns a corresponding closest super-class. In the second scenario, the proposed method is used for the zero-shot learning problem. In this case, given a new input, the model returns its hierarchically related group, rather than generating a true unseen group. Extensive experiments with the two scenarios show that the proposed hierarchical model provides significantly better semantic generalization ability compared to a regular N-way classifier, and yields more accurate and meaningful super-class predictions.", "keywords": ["deep learning", "large-scale classificaion", "heirarchical classification", "zero-shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper860/Authors"], "authors": ["Anonymous"], "TL;DR": "propose a new heirarchical probability bases loss funcsion which yeilds a better semantic classifier. We show our model advantages on two applications.", "pdf": "/pdf/c3560cef4cdb6de08ec66ce030515886deaf23c2.pdf", "paperhash": "anonymous|deep_hierarchical_model_for_hierarchical_selective_classification_and_zero_shot_learning", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={DEEP HIERARCHICAL MODEL FOR HIERARCHICAL SELECTIVE CLASSIFICATION AND ZERO SHOT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxkCj09Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyexAiA5Fm", "original": "r1etI4s9YX", "number": 861, "cdate": 1538087879679, "ddate": null, "tcdate": 1538087879679, "tmdate": 1538156041350, "tddate": null, "forum": "HyexAiA5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Scalable Unbalanced Optimal Transport using Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) are an expressive class of neural generative models with tremendous success in modeling high-dimensional continuous measures. In this paper, we present a scalable method for unbalanced optimal transport (OT) based on the generative-adversarial framework. We formulate unbalanced OT as a problem of simultaneously learning a transport map and a scaling factor that push a source measure to a target measure in a cost-optimal manner, and propose a new algorithm based on stochastic alternating gradient updates, similar in practice to GANs. We also provide theoretical justification for this formulation, showing that it is closely related to an existing static formulation by Liero et al. (2018), and perform numerical experiments demonstrating how this methodology could be applied to population modeling. ", "keywords": ["unbalanced optimal transport", "generative adversarial networks", "population modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper861/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose new methodology for unbalanced optimal transport using generative adversarial networks.", "pdf": "/pdf/0cbc2a0742b25232d52d3e5aa2be1f3d30034daa.pdf", "paperhash": "anonymous|scalable_unbalanced_optimal_transport_using_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019scalable,    \ntitle={Scalable Unbalanced Optimal Transport using Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyexAiA5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lg0jAcYm", "original": "H1xy9x29F7", "number": 862, "cdate": 1538087879855, "ddate": null, "tcdate": 1538087879855, "tmdate": 1538156041139, "tddate": null, "forum": "S1lg0jAcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ARM: Augment-REINFORCE-Merge Gradient for Stochastic Binary Networks", "abstract": "To backpropagate the gradients through stochastic binary layers, we propose the augment-REINFORCE-merge (ARM) estimator that is unbiased and has low variance. Exploiting data augmentation, REINFORCE, and reparameterization, the ARM estimator achieves adaptive variance reduction for Monte Carlo integration by merging two expectations via common random numbers. The variance-reduction mechanism of the ARM estimator can also be attributed to antithetic sampling in an augmented space. Experimental results show the ARM estimator provides state-of-the-art performance in auto-encoding variational Bayes and maximum likelihood inference, for discrete latent variable models with one or multiple stochastic binary layers. Python code is available at https://github.com/ABC-anonymous-1.", "keywords": ["Antithetic sampling", "data augmentation", "deep discrete latent variable models", "variance reduction", "variational auto-encoder"], "authorids": ["ICLR.cc/2019/Conference/Paper862/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2d7c3c4f1bbc35e6fe66b5018deffc5af59f2583.pdf", "paperhash": "anonymous|arm_augmentreinforcemerge_gradient_for_stochastic_binary_networks", "_bibtex": "@inproceedings{    \nanonymous2019arm:,    \ntitle={ARM: Augment-REINFORCE-Merge Gradient for Stochastic Binary Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lg0jAcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxxCiRqYX", "original": "Skg-px6cYX", "number": 863, "cdate": 1538087880027, "ddate": null, "tcdate": 1538087880027, "tmdate": 1538156040929, "tddate": null, "forum": "ryxxCiRqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Layers as Stochastic Solvers", "abstract": "We provide a novel perspective on the forward pass through a block of layers in a deep network. In particular, we show that a forward pass through a standard dropout layer followed by a linear layer and a non-linear activation is equivalent to optimizing a convex optimization objective with a single iteration of a $\\tau$-nice Proximal Stochastic Gradient method. We further show that replacing standard Bernoulli dropout with additive dropout is equivalent to optimizing the same convex objective with a variance-reduced proximal method. By expressing both fully-connected and convolutional layers as special cases of a high-order tensor product, we unify the underlying convex optimization problem in the tensor setting and derive a formula for the Lipschitz constant $L$ used to determine the optimal step size of the above proximal methods. We conduct experiments with standard convolutional networks applied to the CIFAR-10 and CIFAR-100 datasets, and show that replacing a block of layers with multiple iterations of the corresponding solver, with step size set via $L$, consistently improves classification accuracy.", "keywords": ["deep networks", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper863/Authors"], "authors": ["Anonymous"], "TL;DR": "A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.", "pdf": "/pdf/092fb55b36fad28ae39167851f97198bf9dc3ffa.pdf", "paperhash": "anonymous|deep_layers_as_stochastic_solvers", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Layers as Stochastic Solvers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxxCiRqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJex0o05F7", "original": "rJl_NF85tQ", "number": 864, "cdate": 1538087880202, "ddate": null, "tcdate": 1538087880202, "tmdate": 1538156040724, "tddate": null, "forum": "HJex0o05F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Generalized Active Learning Approach for Unsupervised Anomaly Detection", "abstract": "This work presents a new approach to active anomaly detection. We show that a prior needs to be assumed on what the anomalies are, in order to have performance guarantees in unsupervised anomaly detection. We argue that active anomaly detection has, in practice, the same cost of unsupervised anomaly detection but with the possibility of much better results. To solve this problem, we present a new layer that can be attached to any deep learning model designed for unsupervised anomaly detection to transform it into an active anomaly detection method, presenting results on both synthetic and real anomaly detection datasets.", "keywords": ["Anomaly Detection", "Active  Learning", "Unsupervised Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper864/Authors"], "authors": ["Anonymous"], "TL;DR": "A new approach to active anomaly detection. We present a new layer that can be attached to any deep learning model designed for unsupervised anomaly detection to transform it into an active anomaly detection method.", "pdf": "/pdf/d52f3180d40fa2afc1c793f6837125228aa79f97.pdf", "paperhash": "anonymous|a_generalized_active_learning_approach_for_unsupervised_anomaly_detection", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Generalized Active Learning Approach for Unsupervised Anomaly Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJex0o05F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyMxAi05Km", "original": "BJg9JIhqYm", "number": 865, "cdate": 1538087880369, "ddate": null, "tcdate": 1538087880369, "tmdate": 1538156040517, "tddate": null, "forum": "HyMxAi05Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dual Learning: Theoretical Study and Algorithmic Extensions", "abstract": "Dual learning has been successfully applied in many machine learning applications, including machine translation, image-to-image  transformation, etc. The high-level idea of dual learning is very intuitive: if we map an x from one domain to another and then map it back, we should recover the original x. Although its effectiveness has been empirically verified, theoretical understanding of dual learning is still missing. In this paper, we conduct a theoretical study to understand why and when dual learning can improve a mapping function. Based on the theoretical discoveries, we extend dual learning by introducing more related mappings and propose highly symmetric frameworks, cycle dual learning and multipath dual learning, in both of which we can leverage the feedback signals from additional domains to improve the qualities of the mappings. We prove that both cycle dual learning and multipath dual learning can boost the performance of standard dual learning under mild conditions. Experiments on WMT 14 English\u2194German and MultiUN English\u2194French translations verify our theoretical findings on dual learning, and the results on the translations among English, French, and Spanish of MultiUN demonstrate the efficacy of cycle dual learning and multipath dual learning.", "keywords": ["machine translation", "dual learning"], "authorids": ["ICLR.cc/2019/Conference/Paper865/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f84de5d29f36270196d323a68d415f4b226d35b0.pdf", "paperhash": "anonymous|dual_learning_theoretical_study_and_algorithmic_extensions", "_bibtex": "@inproceedings{    \nanonymous2019dual,    \ntitle={Dual Learning: Theoretical Study and Algorithmic Extensions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMxAi05Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eZCjA9KX", "original": "HJxSr_FctX", "number": 866, "cdate": 1538087880546, "ddate": null, "tcdate": 1538087880546, "tmdate": 1538156040307, "tddate": null, "forum": "B1eZCjA9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles", "abstract": "We present a sequence-to-action parsing approach for the natural language to SQL task that incrementally fills the slots of a SQL query with feasible actions from a pre-defined inventory. To account for the fact that typically there are multiple correct SQL queries with the same or very similar semantics, we draw inspiration from syntactic parsing techniques and propose to train our sequence-to-action models with non-deterministic oracles. We evaluate our models on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the test set, a 2.1% absolute improvement over the models trained with traditional static oracles assuming a single correct target SQL query. When further combined with the execution-guided decoding strategy, our model sets a new state-of-the-art performance at an execution accuracy of 87.1%.", "keywords": ["semantic parsing", "non-deterministic oracles", "natural language to SQL", "incremental parsing", "sequence prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper866/Authors"], "authors": ["Anonymous"], "TL;DR": "We design incremental sequence-to-action parsers for text-to-SQL task and achieve SOTA results. We further improve by using non-deterministic oracles to allow multiple correct action sequences. ", "pdf": "/pdf/2ad29c4a27386931a85355b9abce5de773accb04.pdf", "paperhash": "anonymous|incsql_training_incremental_texttosql_parsers_with_nondeterministic_oracles", "_bibtex": "@inproceedings{    \nanonymous2019incsql:,    \ntitle={IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eZCjA9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eZRiC9YX", "original": "HJxg1PlgKQ", "number": 867, "cdate": 1538087880721, "ddate": null, "tcdate": 1538087880721, "tmdate": 1538156040094, "tddate": null, "forum": "B1eZRiC9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sufficient Conditions for Robustness to Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks", "abstract": "We prove, under two sufficient conditions, that idealised models can have no adversarial examples. We discuss which idealised models satisfy our conditions, and show that idealised Bayesian neural networks (BNNs) satisfy these. We continue by studying near-idealised BNNs using HMC inference, demonstrating the theoretical ideas in practice. We experiment with HMC on synthetic data derived from MNIST for which we know the ground-truth image density, showing that near-perfect epistemic uncertainty correlates to density under image manifold, and that adversarial images lie off the manifold in our setting. This suggests why MC dropout, which can be seen as performing approximate inference, has been observed to be an effective defence against adversarial examples in practice; We highlight failure-cases of non-idealised BNNs relying on dropout, suggesting a new attack for dropout models and a new defence as well. Lastly, we demonstrate the defence on a cats-vs-dogs image classification task with a VGG13 variant.", "keywords": ["Bayesian deep learning", "Bayesian neural networks", "adversarial examples"], "authorids": ["ICLR.cc/2019/Conference/Paper867/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove that idealised Bayesian neural networks can have no adversarial examples, and give empirical evidence with real-world BNNs.", "pdf": "/pdf/5f32fed6bf08335d741e0d2db8d94aaa32cc2244.pdf", "paperhash": "anonymous|sufficient_conditions_for_robustness_to_adversarial_examples_a_theoretical_and_empirical_study_with_bayesian_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019sufficient,    \ntitle={Sufficient Conditions for Robustness to Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eZRiC9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1GWAoRcKX", "original": "SylGY4p5FX", "number": 868, "cdate": 1538087880910, "ddate": null, "tcdate": 1538087880910, "tmdate": 1538156039889, "tddate": null, "forum": "H1GWAoRcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Teacher Student Network For Faster Video Classification", "abstract": "Over the past few years, various tasks involving videos such as classification, description, summarization and question answering have received a lot of attention. Current models for these tasks compute an encoding of the video by treating it as a sequence of images and going over every image in the sequence, which becomes computationally expensive for longer videos. In this paper, we focus on the task of video classification and aim to reduce the computational cost by using the idea of distillation. Specifically, we propose a Teacher-Student network wherein the teacher looks at all the frames in the video but the student looks at only a small fraction of the frames in the video. The idea is to then train the student to minimize  (i)  the difference between the final representation computed by the student and the teacher and/or (ii) the difference between the distributions predicted by the teacher and the student. This smaller student network which involves fewer computations but still learns to mimic the teacher can then be employed at inference time for video classification. We experiment with the YouTube-8M dataset and show  that the proposed student network can reduce the inference time by upto 30% with a negligent drop in the performance. ", "keywords": ["video classification", "efficient computation", "knowledge distillation", "teacher-student"], "authorids": ["ICLR.cc/2019/Conference/Paper868/Authors"], "authors": ["Anonymous"], "TL;DR": "Teacher-Student framework for efficient video classification using fewer frames ", "pdf": "/pdf/b2e92652dd0a0aac936aa2b618b6961e2a97032f.pdf", "paperhash": "anonymous|a_teacher_student_network_for_faster_video_classification", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Teacher Student Network For Faster Video Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1GWAoRcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJMZRsC9Y7", "original": "r1e2Bha5Km", "number": 869, "cdate": 1538087881085, "ddate": null, "tcdate": 1538087881085, "tmdate": 1538156039682, "tddate": null, "forum": "SJMZRsC9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING", "abstract": "This paper revisits the Random Walk model for sentence embedding in the context of non-extensive statistics. We propose a non-extensive algebra to compute the discourse vector. We argue that by doing so we are taking into account high non-linearity in the semantic space. Furthermore, we show that by considering a non-extensive algebra, the compounding effect of the vector length is mitigated. Overall, we show that the proposed model leads to good sentence embedding. We evaluate the embedding method on textual similarity tasks.", "keywords": ["sentence embedding", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper869/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d296c11ba5cab54f2a3104a4dc52d6c2150f96bd.pdf", "paperhash": "anonymous|a_nonlinear_theory_for_sentence_embedding", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMZRsC9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyNbRj09Y7", "original": "BylHzsT5FQ", "number": 870, "cdate": 1538087881255, "ddate": null, "tcdate": 1538087881255, "tmdate": 1538156039475, "tddate": null, "forum": "SyNbRj09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visual Imitation Learning with Recurrent Siamese Networks", "abstract": "People are incredibly skilled at imitating others by simply observing them. They achieve this even in the presence of significant morphological differences and capabilities. Further, people are able to do this from raw perceptions of the actions of others, without direct access to the abstracted demonstration actions and with only partial state information. People therefore solve a difficult problem of understanding the salient features of both observations of others and the relationship to their own state when learning to imitate specific tasks.\nHowever, we can attempt to reproduce a similar demonstration via trail and error and through this gain more understanding of the task space.\nTo reproduce this ability an agent would need to both learn how to recognize the differences between itself and some demonstration and at the same time learn to minimize the distance between its own performance and that of the demonstration.\nIn this paper we propose an approach using only visual information to learn a distance metric between agent behaviour and a given video demonstration.\nWe train an RNN-based siamese model to compute distances in space and time between motion clips while training an RL policy to minimize this distance.\nFurthermore, we examine a particularly challenging form of this problem where the agent must learn an imitation based task given a single demonstration.\nWe demonstrate our approach in the setting of deep learning based control for physical simulation of humanoid walking in both 2D with $10$ degrees of freedom (DoF) and 3D with $38$ DoF.", "keywords": ["Reinforcement Learning", "Imitation Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper870/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning a vision-based recurrent distance function to allow agents to imitate behaviours from noisy video data.", "pdf": "/pdf/41f0d0ef757216eed4d618f46ecc3c8b7857dc8c.pdf", "paperhash": "anonymous|visual_imitation_learning_with_recurrent_siamese_networks", "_bibtex": "@inproceedings{    \nanonymous2019visual,    \ntitle={Visual Imitation Learning with Recurrent Siamese Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyNbRj09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgW0oA9FX", "original": "Hyx6kDqqYX", "number": 871, "cdate": 1538087881448, "ddate": null, "tcdate": 1538087881448, "tmdate": 1538156039266, "tddate": null, "forum": "rkgW0oA9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and prematured early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper871/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3a7be09010d1c68ae0d25b9a88a883e8b10d9834.pdf", "paperhash": "anonymous|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph HyperNetworks for Neural Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgW0oA9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxzRsR9Y7", "original": "S1lsmBj5tm", "number": 872, "cdate": 1538087881639, "ddate": null, "tcdate": 1538087881639, "tmdate": 1538156039056, "tddate": null, "forum": "HyxzRsR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Self-Imitating Diverse Policies", "abstract": "The success of popular algorithms for deep reinforcement learning, such as policy-gradients and Q-learning, relies heavily on the availability of an informative reward signal at each timestep of the sequential decision-making process. When rewards are only sparsely available during an episode, or a rewarding feedback is provided only after episode termination, these algorithms perform sub-optimally due to the difficultly in credit assignment. Alternatively, trajectory-based policy optimization methods, such as cross-entropy method and evolution strategies, do not require per-timestep rewards, but have been found to suffer from high sample complexity by completing forgoing the temporal nature of the problem. Improving the efficiency of RL algorithms in real-world problems with sparse or episodic rewards is therefore a pressing need. In this work, we introduce a self-imitation learning algorithm that exploits and explores well in the sparse and episodic reward settings. We view each policy as a state-action visitation distribution and formulate policy optimization as a divergence minimization problem. We show that with Jensen-Shannon divergence, this divergence minimization problem can be reduced into a policy-gradient algorithm with shaped rewards learned from experience replays. Experimental results indicate that our algorithm works comparable to existing algorithms in environments with dense rewards, and significantly better in environments with sparse and episodic rewards. We then discuss limitations of self-imitation learning, and propose to solve them by using Stein variational policy gradient descent with the Jensen-Shannon kernel to learn multiple diverse policies. We demonstrate its effectiveness on a number of challenging tasks.", "keywords": ["Reinforcement-learning", "Imitation-learning", "Ensemble-training"], "authorids": ["ICLR.cc/2019/Conference/Paper872/Authors"], "authors": ["Anonymous"], "TL;DR": "Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.", "pdf": "/pdf/463cb67172293382d2bcc67b38d761f419e5fa70.pdf", "paperhash": "anonymous|learning_selfimitating_diverse_policies", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Self-Imitating Diverse Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxzRsR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygMAiRqK7", "original": "ryer3ml5t7", "number": 873, "cdate": 1538087881823, "ddate": null, "tcdate": 1538087881823, "tmdate": 1538156038853, "tddate": null, "forum": "BygMAiRqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs", "abstract": "Building on the success of deep learning, two modern approaches to learn a probability model of the observed data are Generative Adversarial Networks (GANs) and Variational AutoEncoders (VAEs). VAEs consider an explicit probability model for the data and compute a generative distribution by maximizing a variational lower-bound on the log-likelihood function. GANs, however, compute a generative model by minimizing a distance between observed and generated probability distributions without considering an explicit model for the observed data. The lack of having explicit probability models in GANs prohibits computation of sample likelihoods in their frameworks and limits their use in statistical inference problems. In this work, we show that an optimal transport GAN with the entropy regularization can be viewed as a generative model that maximizes a lower-bound on sample likelihoods, an approach that VAEs are based on. In particular, our proof constructs an explicit probability model for GANs that can be used to compute likelihood statistics within GAN\u2019s framework. Our numerical results on several datasets demonstrate consistent trends with the proposed theory.\n", "keywords": ["GAN", "VAE", "likelihood estimation", "statistical inference"], "authorids": ["ICLR.cc/2019/Conference/Paper873/Authors"], "authors": ["Anonymous"], "TL;DR": "A statistical approach to compute sample likelihoods in Generative Adversarial Networks", "pdf": "/pdf/c43f837351c77718ec14481117ec1016277a32be.pdf", "paperhash": "anonymous|entropic_gans_meet_vaes_a_statistical_approach_to_compute_sample_likelihoods_in_gans", "_bibtex": "@inproceedings{    \nanonymous2019entropic,    \ntitle={Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygMAiRqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gMCsAqY7", "original": "H1l3OTpYY7", "number": 874, "cdate": 1538087882016, "ddate": null, "tcdate": 1538087882016, "tmdate": 1538156038640, "tddate": null, "forum": "H1gMCsAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width multipliers, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models will be released.", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["ICLR.cc/2019/Conference/Paper874/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/768191e00d556b151589c980c372271282c72a29.pdf", "paperhash": "anonymous|slimmable_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019slimmable,    \ntitle={Slimmable Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gMCsAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlfAo09KX", "original": "SJec3AK5Fm", "number": 875, "cdate": 1538087882198, "ddate": null, "tcdate": 1538087882198, "tmdate": 1538156038436, "tddate": null, "forum": "HJlfAo09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross Entropy", "abstract": "We study model recovery for data classification, where the training labels are generated from a one-hidden-layer fully -connected neural network with sigmoid activations, and the goal is to recover the weight vectors of the neural network. We prove that under Gaussian inputs, the empirical risk function using cross entropy exhibits strong convexity and smoothness uniformly in a local neighborhood of the ground truth, as soon as the sample complexity is sufficiently large. This implies that if initialized in this neighborhood, which can be achieved via the tensor method, gradient descent converges linearly to a critical point that is provably close to the ground truth without requiring a fresh set of samples at each iteration. To the best of our knowledge, this is the first global convergence guarantee established for the empirical risk minimization using cross entropy via gradient descent for learning one-hidden-layer neural networks, at the near-optimal sample and computational complexity with respect to the network input dimension.", "keywords": ["cross entropy", "neural networks", "parameter recovery"], "authorids": ["ICLR.cc/2019/Conference/Paper875/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide the first theoretical analysis of guaranteed recovery of one-hidden-layer neural networks under cross entropy loss for classification problems.", "pdf": "/pdf/28df4734fd8a152b0297b6c078605ef964201dc3.pdf", "paperhash": "anonymous|guaranteed_recovery_of_onehiddenlayer_neural_networks_via_cross_entropy", "_bibtex": "@inproceedings{    \nanonymous2019guaranteed,    \ntitle={Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross Entropy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlfAo09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJGfCjA5FX", "original": "S1esrn69FX", "number": 876, "cdate": 1538087882367, "ddate": null, "tcdate": 1538087882367, "tmdate": 1538156038227, "tddate": null, "forum": "BJGfCjA5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PAIRWISE AUGMENTED GANS WITH ADVERSARIAL RECONSTRUCTION LOSS", "abstract": "We propose a novel autoencoding model called Pairwise Augmented GANs. We train a generator and an encoder jointly and in an adversarial manner. The generator network learns to sample realistic objects. In turn the encoder network at the same time in turn is trained to map the true data distribution to the prior in a latent space. To ensure good reconstructions we introduce an augmented adversarial reconstruction loss. Here we train a discriminator to distinguish two types of pairs: the object with its augmentation and the one with its reconstruction. We show that such adversarial loss compares objects based on the content rather than on the exact match. We experimentally demonstrate that our model generates samples and reconstructions of quality competitive with state-of-the-art on datasets MNIST, CIFAR10, CelebA and achieves good quantitative results on CIFAR10. ", "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Generative Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper876/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel autoencoding model with augmented adversarial reconstruction loss. We intoduce new metric for content-based assessment of reconstructions. ", "pdf": "/pdf/53cfa3a254e9e0492222136aff1cc7e08aaec29c.pdf", "paperhash": "anonymous|pairwise_augmented_gans_with_adversarial_reconstruction_loss", "_bibtex": "@inproceedings{    \nanonymous2019pairwise,    \ntitle={PAIRWISE AUGMENTED GANS WITH ADVERSARIAL RECONSTRUCTION LOSS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJGfCjA5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJeXCo0cYX", "original": "S1gFtMvqt7", "number": 877, "cdate": 1538087882537, "ddate": null, "tcdate": 1538087882537, "tmdate": 1538156038020, "tddate": null, "forum": "rJeXCo0cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop", "abstract": "Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons, but given the poor data efficiency of the current learning methods, this goal may require substantial research efforts. Here, we introduce the BabyAI research platform to support investigations towards including humans in the loop for grounded language learning. The BabyAI platform comprises an extensible suite of 19 levels of increasing difficulty. The levels gradually lead the agent towards acquiring a combinatorially rich synthetic language which is a proper subset of English. The platform also provides a heuristic expert agent for the purpose of simulating a human teacher. We report baseline results and estimate the amount of human involvement that would be required to train a neural network-based agent on some of the BabyAI levels. We put forward strong evidence that current deep learning methods are not yet sufficiently sample efficient when it comes to learning a language with compositional properties.", "keywords": ["language", "learning", "efficiency", "imitation learning", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper877/Authors"], "authors": ["Anonymous"], "TL;DR": "We present the BabyAI platform for studying data efficiency of language learning with a human in the loop", "pdf": "/pdf/bf4af01e2a614a830528cf59e8344cd0a3a1d40f.pdf", "paperhash": "anonymous|babyai_first_steps_towards_grounded_language_learning_with_a_human_in_the_loop", "_bibtex": "@inproceedings{    \nanonymous2019babyai:,    \ntitle={BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJeXCo0cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygmRoA9YQ", "original": "BylaDpzcFQ", "number": 878, "cdate": 1538087882715, "ddate": null, "tcdate": 1538087882715, "tmdate": 1538156037812, "tddate": null, "forum": "BygmRoA9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mixture of Pre-processing Experts Model for Noise Robust Deep Learning on Resource Constrained Platforms", "abstract": "Deep learning on an edge device requires energy efficient operation due to ever diminishing power budget. Intentional low quality data during the data acquisition for longer battery life, and natural noise from the low cost sensor degrade the quality of target output which hinders adoption of deep learning on an edge device. To overcome these problems,  we propose simple yet efficient mixture of pre-processing experts (MoPE) model to handle various image distortions including low resolution and noisy images.  We also propose to use adversarially trained auto encoder as a pre-processing expert for the noisy images.  We evaluate our proposed method for various machine learning tasks including object detection on MS-COCO 2014 dataset, multiple object tracking problem on MOT-Challenge dataset, and human activity recognition on UCF 101 dataset. Experimental results show that the proposed method achieves better detection, tracking and activity recognition accuracies under noise without sacrificing accuracies for the clean images. The overheads of our proposed MoPE are 0.67% and 0.17% in terms of memory and computation compared to the baseline object detection network.", "keywords": ["noise robust", "object detection"], "authorids": ["ICLR.cc/2019/Conference/Paper878/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/022230a0202c5e581793f5758069ca5636073409.pdf", "paperhash": "anonymous|mixture_of_preprocessing_experts_model_for_noise_robust_deep_learning_on_resource_constrained_platforms", "_bibtex": "@inproceedings{    \nanonymous2019mixture,    \ntitle={Mixture of Pre-processing Experts Model for Noise Robust Deep Learning on Resource Constrained Platforms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygmRoA9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkfQAiA9YX", "original": "H1l2DgOcFm", "number": 879, "cdate": 1538087882884, "ddate": null, "tcdate": 1538087882884, "tmdate": 1538156037605, "tddate": null, "forum": "SkfQAiA9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "In search of theoretically grounded pruning", "abstract": "Deep learning relies on resource-heavy linear algebra operations which can be prohibitively expensive when deploying to constrained embedded and mobile devices, or even when training large-scale networks. One way to reduce a neural network's resource requirements is to sparsify its weight matrices - a process often referred to as pruning. It is typically achieved by removing least important weights as measured by some salience criterion, with pruning by magnitude being the most popular option. This, however, often makes close to random judgments. In this paper we aim to closely investigate the concept of model weight importance, with a particular focus on the magnitude criterion and its most suitable substitute. To this end we identify a suitable Statistical framework and derive deep model parameter asymptotic theory to use with it. Thus, we derive a statistically-grounded pruning criterion which we compare with the magnitude pruning both qualitatively and quantitatively. We find this criterion to better capture parameter salience, by accounting for its estimation uncertainty. This results in improved performance and easier post-pruned re-training.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper879/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2dc2a07619bd7dbae1ec080e6e0e1f648afbafcd.pdf", "paperhash": "anonymous|in_search_of_theoretically_grounded_pruning", "_bibtex": "@inproceedings{    \nanonymous2019in,    \ntitle={In search of theoretically grounded pruning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkfQAiA9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyM7AiA5YX", "original": "HJgb2VkcK7", "number": 880, "cdate": 1538087883067, "ddate": null, "tcdate": 1538087883067, "tmdate": 1538156037400, "tddate": null, "forum": "HyM7AiA5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Complement Objective Training", "abstract": "Learning with a primary objective, such as softmax cross entropy for classification and sequence generation, has been the norm for training deep neural networks for years. Although being a widely-adopted approach, using cross entropy as the primary objective exploits mostly the information from the ground-truth class for maximizing data likelihood, and largely ignores information from the complement (incorrect) classes. We argue that, in addition to the primary objective, training also using a complement objective that leverages information from the complement classes can be effective in improving model performance. This motivates us to study a new training paradigm that maximizes the likelihood of the ground-truth class while neutralizing the probabilities of the complement classes. We conduct extensive experiments on multiple tasks ranging from computer vision to natural language understanding. The experimental results confirm that, compared to the conventional training with just one primary objective, training also with the complement objective further improves the performance of the state-of-the-art models across all tasks. In addition to the accuracy improvement, we also show that models trained with both primary and complement objectives are more robust to adversarial attacks.\n", "keywords": ["optimization", "entropy", "image recognition", "natural language understanding", "adversarial attacks", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper880/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.", "pdf": "/pdf/a5a7e0d36115d51b2b4afee6f53b96d24da83d9d.pdf", "paperhash": "anonymous|complement_objective_training", "_bibtex": "@inproceedings{    \nanonymous2019complement,    \ntitle={Complement Objective Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyM7AiA5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyNmRiCqtm", "original": "H1g5ihTcYm", "number": 881, "cdate": 1538087883242, "ddate": null, "tcdate": 1538087883242, "tmdate": 1538156037189, "tddate": null, "forum": "HyNmRiCqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CDeepEx: Contrastive Deep Explanations", "abstract": "We propose a method which can visually explain the classification decision of deep neural networks (DNNs). There are many proposed methods in machine learning and computer vision seeking to clarify the decision of machine learning black boxes, specifically DNNs.  All of these methods try to gain insight into why the network \"chose class A\" as an answer. Humans, when searching for explanations, ask two types of questions. The first question is, \"Why did you choose this answer?\" The second question asks, \"Why did you not choose answer B over A?\" The previously proposed methods are either not able to provide the latter directly or efficiently.\n\nWe introduce a method capable of answering the second question both directly and efficiently. In this work, we limit the inputs to be images. In general, the proposed method generates explanations in the input space of any model capable of efficient evaluation and gradient evaluation. We provide results, showing the superiority of this approach for gaining insight into the inner representation of machine learning models.", "keywords": ["Deep learning", "Explanation", "Network interpretation", "Contrastive explanation"], "authorids": ["ICLR.cc/2019/Conference/Paper881/Authors"], "authors": ["Anonymous"], "TL;DR": "A method to answer \"why not class B?\" for explaining deep networks", "pdf": "/pdf/1aadb277cd4bc6423d0eb1f8a5886508b53feb34.pdf", "paperhash": "anonymous|cdeepex_contrastive_deep_explanations", "_bibtex": "@inproceedings{    \nanonymous2019cdeepex:,    \ntitle={CDeepEx: Contrastive Deep Explanations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyNmRiCqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxXCi0qFX", "original": "BkeI1C5ctQ", "number": 882, "cdate": 1538087883410, "ddate": null, "tcdate": 1538087883410, "tmdate": 1538156036984, "tddate": null, "forum": "SkxXCi0qFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ProMP: Proximal Meta-Policy Search", "abstract": "Credit assignment in Meta-reinforcement learning (Meta-RL) is still poorly understood. Existing methods either neglect credit assignment to pre-adaptation behavior or implement it naively. This leads to poor sample-efficiency during meta-training as well as ineffective task identification strategies.\nThis paper provides a theoretical analysis of credit assignment in gradient-based Meta-RL. Building on the gained insights we develop a novel meta-learning algorithm that overcomes both the issue of poor credit assignment and previous difficulties in estimating meta-policy gradients. By controlling the statistical distance of both pre-adaptation and adapted policies during meta-policy search, the proposed algorithm endows efficient and stable meta-learning. Our approach leads to superior pre-adaptation policy behavior and consistently outperforms previous Meta-RL algorithms in sample-efficiency, wall-clock time, and asymptotic performance.", "keywords": ["Meta-Reinforcement Learning", "Meta-Learning", "Reinforcement-Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper882/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel and theoretically grounded meta-reinforcement learning algorithm", "pdf": "/pdf/78928953c05f5e5563196c1067bd5f3215c59929.pdf", "paperhash": "anonymous|promp_proximal_metapolicy_search", "_bibtex": "@inproceedings{    \nanonymous2019promp:,    \ntitle={ProMP: Proximal Meta-Policy Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxXCi0qFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gVRi0qFQ", "original": "BkxO02acYm", "number": 883, "cdate": 1538087883589, "ddate": null, "tcdate": 1538087883589, "tmdate": 1538156036779, "tddate": null, "forum": "B1gVRi0qFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Online abstraction with MDP homomorphisms for Deep Learning", "abstract": "Abstraction of Markov Decision Processes is a useful tool for solving complex problems, as it can ignore unimportant aspects of an environment, simplifying the process of learning an optimal policy. In this paper, we propose a new algorithm for finding abstract MDPs in environments with continuous state spaces. It is based on MDP homomorphisms, a structure-preserving mapping between MDPs. We demonstrate our algorithm's ability to learns abstractions from collected experience and show how to reuse the abstractions to guide exploration in new tasks the agent encounters. Our novel task transfer method beats a baseline based on a deep Q-network.", "keywords": ["reinforcement learning", "abstraction", "mdp homomorphism", "deep learning", "robotics"], "authorids": ["ICLR.cc/2019/Conference/Paper883/Authors"], "authors": ["Anonymous"], "TL;DR": "We create abstract models of environments from experience and use them to learn new tasks faster.", "pdf": "/pdf/03a3376e005459b1cb8bbdcd49c493c72b0acba7.pdf", "paperhash": "anonymous|online_abstraction_with_mdp_homomorphisms_for_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019online,    \ntitle={Online abstraction with MDP homomorphisms for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gVRi0qFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgVRiC9Km", "original": "H1x75JUqKQ", "number": 884, "cdate": 1538087883767, "ddate": null, "tcdate": 1538087883767, "tmdate": 1538156036574, "tddate": null, "forum": "SkgVRiC9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations", "abstract": "Deep networks have achieved impressive results across a variety of important tasks. However, a known weakness is a failure to perform well when evaluated on data which differ from the training distribution, even if these differences are very small, as is the case with adversarial examples.  We propose \\emph{Fortified Networks}, a simple transformation of existing networks, which \u201cfortifies\u201d the hidden layers in a deep network by identifying when the hidden states are off of the data manifold, and maps these hidden states back to parts of the data manifold where the network performs well. Our principal contribution is to show that fortifying these hidden states improves the robustness of deep networks and our experiments (i) demonstrate improved robustness to standard adversarial attacks in both black-box and white-box threat models; (ii) suggest that our improvements are not primarily due to the problem of deceptively good results due to degraded quality in the gradient signal (the gradient masking problem) and (iii) show the advantage of doing this fortification in the hidden layers instead of the input space.  We demonstrate improvements in adversarial robustness on three datasets (MNIST, Fashion MNIST, CIFAR10), across several attack parameters, both white-box and black-box settings, and the most widely studied attacks (FGSM, PGD, Carlini-Wagner).  We show that these improvements are achieved across a wide variety of hyperparameters.  ", "keywords": ["adversarial examples", "adversarial training", "autoencoders", "hidden state"], "authorids": ["ICLR.cc/2019/Conference/Paper884/Authors"], "authors": ["Anonymous"], "TL;DR": "Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  ", "pdf": "/pdf/96278b003cba15c10da0f905dd6adef7885c6ba4.pdf", "paperhash": "anonymous|fortified_networks_improving_the_robustness_of_deep_networks_by_modeling_the_manifold_of_hidden_representations", "_bibtex": "@inproceedings{    \nanonymous2019fortified,    \ntitle={Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgVRiC9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxNAjC5F7", "original": "BygSmgJ9Ym", "number": 885, "cdate": 1538087883942, "ddate": null, "tcdate": 1538087883942, "tmdate": 1538156036372, "tddate": null, "forum": "rJxNAjC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Hash Codes via Hamming Distance Targets", "abstract": "We present a powerful new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function.\nOur loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target.\nOur novel training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch.\nTo fully leverage the resulting hashes, we use multi-indexing.\nWe demonstrate that these techniques provide large improvements to a similarity search tasks.\nWe report the best results to date on competitive information retrieval tasks for Imagenet and SIFT 1M, improving recall from 73% to 84% and reducing query cost by a factor of 2-8, respectively.", "keywords": ["information retrieval", "learning to hash", "cbir"], "authorids": ["ICLR.cc/2019/Conference/Paper885/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a new loss function for training any differentiable model to hash that can vastly improve recall and lookup speed.", "pdf": "/pdf/d02a9d387f3c34f7aba0ac69ec265860632792c9.pdf", "paperhash": "anonymous|learning_hash_codes_via_hamming_distance_targets", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Hash Codes via Hamming Distance Targets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxNAjC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryzECoAcY7", "original": "rkeLkpaqKX", "number": 886, "cdate": 1538087884115, "ddate": null, "tcdate": 1538087884115, "tmdate": 1538156036158, "tddate": null, "forum": "ryzECoAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Reinforcement Learning with Limited Policies and Hindsight", "abstract": "We introduce a new hierarchical reinforcement learning framework that can accelerate\nlearning in tasks involving long time horizons and sparse rewards. Our\napproach improves sample efficiency by enabling agents to learn a hierarchy\nof short policies that operate at different time scales. The policy hierarchies\ncan support an arbitrary number of levels, and all policies within the hierarchy\nare trained in parallel and end-to-end. Our framework is the first hierarchical\nreinforcement learning approach that can learn hierarchies with more than\ntwo levels of policies in continuous tasks. We demonstrate experimentally in\nboth grid world and simulated robotics domains that our approach can significantly\nboost sample efficiency. A video illustrating our results is available at\nhttps://www.youtube.com/watch?v=i04QF7Yi50Y.", "keywords": ["Hierarchical Reinforcement Learning", "Reinforcement Learning", "Deep Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper886/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new hierarchical RL framework that can improve performance in tasks involving long time horizons and sparse rewards.", "pdf": "/pdf/72634f0f295a6efedf7ffeb7385e4934f9068d41.pdf", "paperhash": "anonymous|hierarchical_reinforcement_learning_with_limited_policies_and_hindsight", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Reinforcement Learning with Limited Policies and Hindsight},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryzECoAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyG4RiR5Ym", "original": "H1g51a6qYQ", "number": 887, "cdate": 1538087884281, "ddate": null, "tcdate": 1538087884281, "tmdate": 1538156035951, "tddate": null, "forum": "SyG4RiR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Distribution Learning for generalized time-to-event prediction", "abstract": "Predicting the time to the next event is an important task in various domains. \nHowever, due to censoring and irregularly sampled sequences, time-to-event prediction has resulted in limited success only for particular tasks, architectures and data. \nUsing recent advances in probabilistic programming and density networks, we make the case for a generalized parametric survival approach, sequentially predicting a distribution over the time to the next event. \nUnlike previous work, the proposed method can use asynchronously sampled features for censored, discrete, and multivariate data. \nFurthermore, it achieves good performance and near perfect calibration for probabilistic predictions without using rigid network-architectures, multitask approaches, complex learning schemes or non-trivial adaptations of cox-models. \nWe firmly establish that this can be achieved in the standard neural network framework by simply switching out the output layer and loss function.", "keywords": ["Deep Learning", "Survival Analysis", "Event prediction", "Time Series", "Probabilistic Programming", "Density Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper887/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a general solution to event prediction that has been there all along; Discrete Time Parametric Survival Analysis.", "pdf": "/pdf/70d59622126e6320d731d83362ff0896b7a5f448.pdf", "paperhash": "anonymous|neural_distribution_learning_for_generalized_timetoevent_prediction", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Distribution Learning for generalized time-to-event prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyG4RiR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1EERs09YQ", "original": "BJl_didwtm", "number": 888, "cdate": 1538087884451, "ddate": null, "tcdate": 1538087884451, "tmdate": 1538156035745, "tddate": null, "forum": "S1EERs09YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discovery of natural language concepts in individual units", "abstract": "Although deep convolutional networks have achieved improved performance in many natural language tasks, they have been treated as black boxes because they are difficult to interpret. Especially, little is known about how they represent language in their intermediate layers. In an attempt to understand the representations of deep convolutional networks trained on language tasks, we show that individual units are selectively responsive to specific morphemes, words, and phrases, rather than responding to arbitrary and uninterpretable patterns. In order to quantitatively analyze such intriguing phenomenon, we propose a concept alignment method based on how units respond to replicated text. We conduct analyses with different architectures on multiple datasets for classification and translation tasks and provide new insights into how deep models understand natural language.", "keywords": ["interpretability of deep neural networks", "natural language representation"], "authorids": ["ICLR.cc/2019/Conference/Paper888/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that individual units in CNN representations learned in NLP tasks are selectively responsive to natural language concepts.", "pdf": "/pdf/865b01f81e00b76e37c63fbbb5326bbd94a9bff3.pdf", "paperhash": "anonymous|discovery_of_natural_language_concepts_in_individual_units", "_bibtex": "@inproceedings{    \nanonymous2019discovery,    \ntitle={Discovery of natural language concepts in individual units},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1EERs09YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyerAiCqt7", "original": "rylSeaacYm", "number": 889, "cdate": 1538087884616, "ddate": null, "tcdate": 1538087884616, "tmdate": 1538156035539, "tddate": null, "forum": "SyerAiCqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling", "abstract": "This paper proposes a hierarchical Bayesian model for clustering sparse sequences.This is a mixture model and does not need the data to be represented by a Gaussian mixture and that gives significant modelling freedom.It also generates a very interpretable profile for the discovered latent groups.The data that was used for the work have been contributed by a restaurant loyalty program company. The data is a collection of sparse sequences where each entry of each sequence is the number of user visits of one week to some restaurant. This algorithm successfully clustered the data and calculated the expected user affiliation in each cluster.", "keywords": ["Hierarchical Bayesian Modeling", "Sparse sequence clustering", "Group profiling", "User group modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper889/Authors"], "authors": ["Anonymous"], "TL;DR": "Hierarchical Bayesian Modeling for Clustering Sparse Sequences ; user group modeling using behavioral data", "pdf": "/pdf/e225ca65da818ff565dc7fd35e03ce02f8043003.pdf", "paperhash": "anonymous|hierarchical_bayesian_modeling_for_clustering_sparse_sequences_in_the_context_of_group_profiling", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyerAiCqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lrAiA5Ym", "original": "B1xtTwa9KQ", "number": 890, "cdate": 1538087884784, "ddate": null, "tcdate": 1538087884784, "tmdate": 1538156035333, "tddate": null, "forum": "r1lrAiA5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity", "abstract": "The impressive lifelong learning in animal brains is primarily enabled by plastic changes in synaptic connectivity. Importantly, these changes are not passive, but are actively controlled by neuromodulation, which is itself under the control of the brain. The resulting self-modifying abilities of the brain play an important role in learning and adaptation, and are a major basis for biological reinforcement learning. Here we show for the first time that artificial neural networks with such neuromodulated plasticity can be trained with gradient descent. Extending previous work on differentiable Hebbian plasticity, we propose a differentiable formulation for the neuromodulation of plasticity. We show that neuromodulated plasticity improves the performance of neural networks on both reinforcement learning and supervised learning tasks. In one task, neuromodulated plastic LSTMs with millions of parameters outperform standard LSTMs on a benchmark language modeling task (controlling for the number of parameters). We conclude that differentiable neuromodulation of plasticity offers a powerful new framework for training neural networks.", "keywords": ["meta-learning", "reinforcement learning", "plasticity", "neuromodulation", "Hebbian learning", "recurrent neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper890/Authors"], "authors": ["Anonymous"], "TL;DR": "Neural networks can be trained to modify their own connectivity, improving their online learning performance on challenging tasks.", "pdf": "/pdf/f5ddac3575912659887f5c2d4209f491f5cf8b4f.pdf", "paperhash": "anonymous|backpropamine_training_selfmodifying_neural_networks_with_differentiable_neuromodulated_plasticity", "_bibtex": "@inproceedings{    \nanonymous2019backpropamine:,    \ntitle={Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lrAiA5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1erRoCqtX", "original": "BJeneLxqKQ", "number": 891, "cdate": 1538087884952, "ddate": null, "tcdate": 1538087884952, "tmdate": 1538156035121, "tddate": null, "forum": "r1erRoCqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LSH Microbatches for Stochastic Gradients:  Value in Rearrangement", "abstract": "   Metric embeddings are   immensely useful representations of associations between entities   (images, users, search queries, words, and more).  Embeddings are learned by  optimizing a loss objective of the general form of a sum over example associations. Typically, the optimization uses stochastic gradient updates over minibatches of examples that are arranged  independently at random. In this work, we propose the use of {\\em structured arrangements} through randomized {\\em microbatches} of examples that are more likely to include similar ones. We make a principled argument for the properties of our arrangements  that accelerate the training and present efficient algorithms to generate microbatches that respect the marginal  distribution of training examples.  Finally, we observe experimentally that our structured arrangements accelerate training by 3-20\\%. Structured arrangements emerge as a powerful and novel performance knob for SGD that is independent and complementary to other SGD  hyperparameters and thus is a candidate for wide deployment.", "keywords": ["Stochastic Gradient Descent", "Metric Embeddings", "Locality  Sensitive Hashing", "Microbatches", "Sample coordination"], "authorids": ["ICLR.cc/2019/Conference/Paper891/Authors"], "authors": ["Anonymous"], "TL;DR": "Accelerating SGD by arranging examples differently", "pdf": "/pdf/c1ea205f7792cf0a31ef31c7d5979b989a87864a.pdf", "paperhash": "anonymous|lsh_microbatches_for_stochastic_gradients_value_in_rearrangement", "_bibtex": "@inproceedings{    \nanonymous2019lsh,    \ntitle={LSH Microbatches for Stochastic Gradients:  Value in Rearrangement},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1erRoCqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlr0j0ctX", "original": "Sklbqh35FX", "number": 892, "cdate": 1538087885129, "ddate": null, "tcdate": 1538087885129, "tmdate": 1538156034912, "tddate": null, "forum": "BJlr0j0ctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?", "abstract": "Adversarial training is one of the strongest defenses against adversarial attacks, but it requires adversarial examples to be generated for every mini-batch during optimization.  The expense of producing these examples during training often precludes adversarial training from use on large and high-resolution image datasets.  In this study, we explore the mechanisms by which adversarial training improves classifier robustness, and show that these mechanisms can be effectively mimicked using simple regularization methods, including label smoothing and logit squeezing. Remarkably, using these simple regularization methods in combination with Gaussian noise injection, we are able to achieve strong adversarial robustness -- often exceeding that of adversarial training -- using no adversarial examples.", "keywords": ["adversarial machine learning", "machine learning security"], "authorids": ["ICLR.cc/2019/Conference/Paper892/Authors"], "authors": ["Anonymous"], "TL;DR": "Achieving strong adversarial robustness and exceeding adversarial training without training on adversarial examples", "pdf": "/pdf/db134cd1eac34f98b68a9f313aa344b159c0d270.pdf", "paperhash": "anonymous|label_smoothing_and_logit_squeezing_a_replacement_for_adversarial_training", "_bibtex": "@inproceedings{    \nanonymous2019label,    \ntitle={Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlr0j0ctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeB0sC9Fm", "original": "ByxkkZ39F7", "number": 893, "cdate": 1538087885300, "ddate": null, "tcdate": 1538087885300, "tmdate": 1538156034705, "tddate": null, "forum": "HJeB0sC9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Detecting Memorization in ReLU Networks", "abstract": "We propose a new notion of 'non-linearity' of a network layer with respect to an input batch that is based on its proximity to a linear system, which is reflected in the non-negative rank of the activation matrix.\nWe measure this non-linearity by applying non-negative factorization to the activation matrix.\nConsidering batches of similar samples, we find that high non-linearity in deep layers is indicative of memorization. Furthermore, by applying our approach layer-by-layer, we find that the mechanism for memorization consists of distinct phases. We perform experiments on fully-connected and convolutional neural networks trained on several image and audio datasets. Our results demonstrate that as an indicator for memorization, our technique can be used to perform early stopping.", "keywords": ["Memorization", "Generalization", "ReLU", "Non-negative matrix factorization"], "authorids": ["ICLR.cc/2019/Conference/Paper893/Authors"], "authors": ["Anonymous"], "TL;DR": "We use the non-negative rank of ReLU activation matrices as a complexity measure and show it (negatively) correlates with good generalization.", "pdf": "/pdf/5821f59dc5ee92460f4d733b6b5a0c136790fee2.pdf", "paperhash": "anonymous|detecting_memorization_in_relu_networks", "_bibtex": "@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Memorization in ReLU Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeB0sC9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1grRoR9tQ", "original": "Bkgzvl_tKX", "number": 894, "cdate": 1538087885466, "ddate": null, "tcdate": 1538087885466, "tmdate": 1538156034505, "tddate": null, "forum": "S1grRoR9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation", "abstract": "We propose a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables. Inspired by dropout, a popular tool for regularization and model ensemble, we assign sparse priors to the weights in deep neural networks (DNN) in order to achieve automatic ``dropout'' and avoid over-fitting. By alternatively sampling from posterior distribution through stochastic gradient Markov Chain Monte Carlo (SG-MCMC) and optimizing latent variables via stochastic approximation (SA), the trajectory of the target weights is proved to converge to the true posterior distribution conditioned on optimal latent variables. This ensures a stronger regularization on the over-fitted parameter space and more accurate uncertainty quantification on the decisive variables. Simulations from large-p-small-n regressions showcase the robustness of this method when applied to models with latent variables. Additionally, its application on the convolutional neural networks (CNN) leads to state-of-the-art performance on MNIST and Fashion MNIST datasets and improved resistance to adversarial attacks. ", "keywords": ["generalized stochastic approximation", "stochastic gradient Markov chain Monte Carlo", "adaptive algorithm", "EM algorithm", "convolutional neural networks", "Bayesian inference", "sparse prior", "spike and slab prior", "local trap"], "authorids": ["ICLR.cc/2019/Conference/Paper894/Authors"], "authors": ["Anonymous"], "TL;DR": "a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables", "pdf": "/pdf/966aae233aa4a48a5cea9b413188c6e070a72601.pdf", "paperhash": "anonymous|bayesian_deep_learning_via_stochastic_gradient_mcmc_with_a_stochastic_approximation_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1grRoR9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylIAsCqYm", "original": "BkldQ6a5Km", "number": 895, "cdate": 1538087885635, "ddate": null, "tcdate": 1538087885635, "tmdate": 1538156034297, "tddate": null, "forum": "rylIAsCqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A2BCD: Asynchronous Acceleration with Optimal Complexity", "abstract": "\tIn this paper, we propose the Asynchronous Accelerated Nonuniform Randomized Block Coordinate Descent algorithm (A2BCD). We prove A2BCD converges linearly to a solution of the convex minimization problem at the same rate as NU_ACDM, so long as the maximum delay is not too large. This is the first asynchronous Nesterov-accelerated algorithm that attains any provable speedup. Moreover, we then prove that these algorithms both have optimal complexity. Asynchronous algorithms complete much faster iterations, and A2BCD has optimal complexity. Hence we observe in experiments that A2BCD is the top-performing coordinate descent algorithm, converging up to 4-5x faster than NU_ACDM on some data sets in terms of wall-clock time. To motivate our theory and proof techniques, we also derive and analyze a continuous-time analog of our algorithm and prove it converges at the same rate.", "keywords": ["asynchronous", "optimization", "parallel", "accelerated", "complexity"], "authorids": ["ICLR.cc/2019/Conference/Paper895/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.", "pdf": "/pdf/f25155c8afbd21da2b3054ec55e0f403a58dd3c4.pdf", "paperhash": "anonymous|a2bcd_asynchronous_acceleration_with_optimal_complexity", "_bibtex": "@inproceedings{    \nanonymous2019a2bcd:,    \ntitle={A2BCD: Asynchronous Acceleration with Optimal Complexity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylIAsCqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJeUAj05tQ", "original": "HkgOEpp9Fm", "number": 896, "cdate": 1538087885816, "ddate": null, "tcdate": 1538087885816, "tmdate": 1538156034078, "tddate": null, "forum": "SJeUAj05tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DADAM: A consensus-based distributed adaptive gradient method for online optimization", "abstract": "Online and stochastic optimization methods such as SGD, ADAGRAD and ADAM are key algorithms in solving large-scale machine learning problems including deep learning. A number of schemes that are based on communications of nodes with a central server have been recently proposed in the literature to parallelize them. A bottleneck of such centralized algorithms lies on the high communication cost incurred by the central node. In this paper, we present a new consensus-based distributed adaptive moment estimation method (DADAM) for online optimization over a decentralized network that enables data parallelization, as well as decentralized computation. Such a framework note only can be extremely useful for learning agents with access to only local data in a communication constrained environment, but as shown in this work also outperform centralized adaptive algorithms such as ADAM for certain realistic classes of loss functions. We analyze the convergence properties of the proposed algorithm and provide a \\textit{dynamic regret} bound on the convergence rate of adaptive moment estimation methods in both stochastic and deterministic settings. Empirical results demonstrate that DADAM works well in practice and compares favorably to competing online optimization methods.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper896/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/bf78174116a6956ac5b266953645ee3bf0a8a26d.pdf", "paperhash": "anonymous|dadam_a_consensusbased_distributed_adaptive_gradient_method_for_online_optimization", "_bibtex": "@inproceedings{    \nanonymous2019dadam:,    \ntitle={DADAM: A consensus-based distributed adaptive gradient method for online optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJeUAj05tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklUAoAcY7", "original": "r1gsNT6ct7", "number": 897, "cdate": 1538087885988, "ddate": null, "tcdate": 1538087885988, "tmdate": 1538156033873, "tddate": null, "forum": "BklUAoAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Learning  of Sentence Representations Using Sequence Consistency", "abstract": "Computing universal distributed representations of sentences is a fundamental task in natural language processing. We propose a simple, yet surprisingly powerful unsupervised method to learn such representations by enforcing consistency constraints on sequences of tokens. We consider two classes of such constraints -- sequences that form a sentence and between two sequences that form a sentence when merged. We learn a sentence encoder by training it to distinguish between consistent and inconsistent examples. Extensive evaluation on several transfer learning and linguistic probing tasks shows improved performance over strong unsupervised and supervised baselines, substantially surpassing them in several cases. ", "keywords": ["sentence representation", "unsupervised learning", "LSTM"], "authorids": ["ICLR.cc/2019/Conference/Paper897/Authors"], "authors": ["Anonymous"], "TL;DR": "Good sentence encoders can be learned by training them to distinguish between consistent and inconsistent (pairs of) sequences that are generated in an unsupervised manner.", "pdf": "/pdf/859793322ccb5c22c25d3eef060054b2ac0135c4.pdf", "paperhash": "anonymous|unsupervised_learning_of_sentence_representations_using_sequence_consistency", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Learning  of Sentence Representations Using Sequence Consistency},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklUAoAcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1e8CsRctX", "original": "S1gnlDT5Y7", "number": 898, "cdate": 1538087886184, "ddate": null, "tcdate": 1538087886184, "tmdate": 1538156033659, "tddate": null, "forum": "B1e8CsRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Ensembles for Robust Anomaly Detection", "abstract": "Deep generative models are capable of learning probability distributions over large, high-dimensional datasets such as images, video and natural language. Generative models trained on samples from p(x) ought to assign low likelihoods to out-of-distribution (OoD) samples from q(x), making them suitable for anomaly detection applications. We show that in practice, likelihood models are themselves susceptible to OoD errors, and even assign large likelihoods to images from other natural datasets. To mitigate these issues, we propose Generative Ensembles, a model-independent technique for OoD detection that combines density-based anomaly detection with uncertainty estimation. Our method outperforms ODIN and VIB baselines on image datasets, and achieves comparable performance to a classification model on the Kaggle Credit Fraud dataset.", "keywords": ["Anomaly Detection", "Uncertainty", "Out-of-Distribution", "Generative Models"], "authorids": ["ICLR.cc/2019/Conference/Paper898/Authors"], "authors": ["Anonymous"], "TL;DR": "We use generative models to perform out-of-distribution detection, and improve their robustness with uncertainty estimation.", "pdf": "/pdf/014f9db90d72ed3ff854e4693291eb4756e669b3.pdf", "paperhash": "anonymous|generative_ensembles_for_robust_anomaly_detection", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Ensembles for Robust Anomaly Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e8CsRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJfUCoR5KX", "original": "rkxf5YPqYX", "number": 899, "cdate": 1538087886355, "ddate": null, "tcdate": 1538087886355, "tmdate": 1538156033455, "tddate": null, "forum": "rJfUCoR5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Systematic Study of Binary Neural Networks' Optimisation", "abstract": "Binary neural networks using the Straight-Through-Estimator (STE) have been shown to achieve state-of-the-art results, but their training process is not well-founded. This is due to the discrepancy between the evaluated function in the forward path, and the weight updates in the back-propagation, updates which do not correspond to gradients of the forward path. Efficient convergence and accuracy of binary models often rely on careful fine-tuning and various ad-hoc techniques. In this work, we empirically identify and study the effectiveness of the various ad-hoc techniques commonly used in the literature, providing best-practices for efficient training of binary models. We show that adapting learning rates using second moment methods is crucial for the successful use of the STE, and that other optimisers can easily get stuck in local minima. We also find that many of the commonly employed tricks are only effective towards the end of the training, with these methods making early stages of the training considerably slower. Our analysis disambiguates necessary from unnecessary ad-hoc techniques for training of binary neural networks, paving the way for future development of solid theoretical foundations for these. Our newly-found insights further lead to new procedures which make training of existing binary neural networks notably faster.", "keywords": ["binary neural networks", "quantized neural networks", "straight-through-estimator"], "authorids": ["ICLR.cc/2019/Conference/Paper899/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d5df7d63fdd9bd8833a4ddc9bf4069735f50a9c6.pdf", "paperhash": "anonymous|a_systematic_study_of_binary_neural_networks_optimisation", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Systematic Study of Binary Neural Networks' Optimisation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJfUCoR5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxwAo09KQ", "original": "H1ey6H0KY7", "number": 900, "cdate": 1538087886521, "ddate": null, "tcdate": 1538087886521, "tmdate": 1538156033246, "tddate": null, "forum": "HJxwAo09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper900/Authors"], "authors": ["Anonymous"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "anonymous|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@inproceedings{    \nanonymous2019learned,    \ntitle={Learned optimizers that outperform on wall-clock and validation loss},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxwAo09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lwRjR9YX", "original": "rkeAAJ0tFm", "number": 901, "cdate": 1538087886690, "ddate": null, "tcdate": 1538087886690, "tmdate": 1538156033037, "tddate": null, "forum": "S1lwRjR9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions", "abstract": "While momentum-based methods, in conjunction with the stochastic gradient descent, are widely used when training machine learning models, there is little theoretical understanding on the generalization error of such methods. In practice, the momentum parameter is often chosen in a heuristic fashion with little theoretical guidance. In this work, we use the framework of algorithmic stability to provide an upper-bound on the generalization error for the class of strongly convex loss functions, under mild technical assumptions. Our bound decays to zero inversely with the size of the training set, and increases as the momentum parameter is increased. We also develop an upper-bound on the expected true risk,  in terms of the number of training steps, the size of the training set, and the momentum parameter.", "keywords": ["Generalization Error", "Stochastic Gradient Descent", "Uniform Stability"], "authorids": ["ICLR.cc/2019/Conference/Paper901/Authors"], "authors": ["Anonymous"], "TL;DR": "Stochastic gradient method with momentum generalizes.", "pdf": "/pdf/62858886f6aa92813c508398ab739d72ac04e92b.pdf", "paperhash": "anonymous|stability_of_stochastic_gradient_method_with_momentum_for_strongly_convex_loss_functions", "_bibtex": "@inproceedings{    \nanonymous2019stability,    \ntitle={Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lwRjR9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJfvAoC9YQ", "original": "BkxV7iMctm", "number": 902, "cdate": 1538087886857, "ddate": null, "tcdate": 1538087886857, "tmdate": 1538156032828, "tddate": null, "forum": "BJfvAoC9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Feature Transformers: A Unified Representation Learning Framework for Lifelong Learning", "abstract": "Despite the recent advances in representation learning, lifelong learning continues\nto be one of the most challenging and unconquered problems. Catastrophic forgetting\nand data privacy constitute two of the important challenges for a successful\nlifelong learner. Further, existing techniques are designed to handle only specific\nmanifestations of lifelong learning, whereas a practical lifelong learner is expected\nto switch and adapt seamlessly to different scenarios. In this paper, we present a\nsingle, unified mathematical framework for handling the myriad variants of lifelong\nlearning, while alleviating these two challenges. We utilize an external memory\nto store only the features representing past data and learn richer and newer\nrepresentations incrementally through transformation neural networks - feature\ntransformers. We define, simulate and demonstrate exemplary performance on a\nrealistic lifelong experimental setting using the MNIST rotations dataset, paving\nthe way for practical lifelong learners. To illustrate the applicability of our method\nin data sensitive domains like healthcare, we study the pneumothorax classification\nproblem from X-ray images, achieving near gold standard performance.\nWe also benchmark our approach with a number of state-of-the art methods on\nMNIST rotations and iCIFAR100 datasets demonstrating superior performance.", "keywords": ["continual learning", "deep learning", "lifelong learning", "new task learning", "representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper902/Authors"], "authors": ["Anonymous"], "TL;DR": "Single generic mathematical framework for lifelong learning paradigms with data privacy", "pdf": "/pdf/d3be9720223e6c94973c2833be4f4ee03d7803ef.pdf", "paperhash": "anonymous|feature_transformers_a_unified_representation_learning_framework_for_lifelong_learning", "_bibtex": "@inproceedings{    \nanonymous2019feature,    \ntitle={Feature Transformers: A Unified Representation Learning Framework for Lifelong Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfvAoC9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hygv0sC5F7", "original": "S1xAXZq5YX", "number": 903, "cdate": 1538087887027, "ddate": null, "tcdate": 1538087887027, "tmdate": 1538156032624, "tddate": null, "forum": "Hygv0sC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?", "abstract": "We study the implicit bias of gradient descent methods in solving a binary classification problem over a linearly separable dataset. The classifier is described by a nonlinear ReLU model and the objective function adopts the exponential loss function. We first characterize the landscape of the loss function and show that there can exist spurious asymptotic local minima besides asymptotic global minima. We then show that gradient descent (GD) can converge to either a global or a local max-margin direction, or may diverge from the desired max-margin direction in a general context. For stochastic gradient descent (SGD), we show that it converges in expectation to either the global or the local max-margin direction if SGD converges. We further explore the implicit bias of these algorithms in learning a multi-neuron network under certain stationary conditions, and show that the learned classifier maximizes the margins of each sample pattern partition under the ReLU activation.", "keywords": ["gradient method", "max-margin", "ReLU model"], "authorids": ["ICLR.cc/2019/Conference/Paper903/Authors"], "authors": ["Anonymous"], "TL;DR": "We study the implicit bias of gradient methods in solving a binary classification problem with nonlinear ReLU models.", "pdf": "/pdf/f4b7688b3c9bea0e4a93a377dad1dccc965aab65.pdf", "paperhash": "anonymous|when_will_gradient_methods_converge_to_maxmargin_classifier_under_relu_models", "_bibtex": "@inproceedings{    \nanonymous2019when,    \ntitle={When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygv0sC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gDCiCqtQ", "original": "Skgcrnp5FQ", "number": 904, "cdate": 1538087887203, "ddate": null, "tcdate": 1538087887203, "tmdate": 1538156032414, "tddate": null, "forum": "S1gDCiCqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Representations in Model-Free Hierarchical Reinforcement Learning", "abstract": "Common approaches to Reinforcement Learning (RL) are seriously challenged by large-scale applications involving huge state spaces and sparse delayed reward feedback. Hierarchical Reinforcement Learning (HRL) methods attempt to address this scalability issue by learning action selection policies at multiple levels of temporal abstraction. Abstraction can be had by identifying a relatively small set of states that are likely to be useful as subgoals, in concert with the learning of corresponding skill policies to achieve those subgoals. Many approaches to subgoal discovery in HRL depend on the analysis of a model of the environment, but the need to learn such a model introduces its own problems of scale. Once subgoals are identified, skills may be learned through intrinsic motivation, introducing an internal reward signal marking subgoal attainment. In this paper, we present a novel model-free method for subgoal discovery using incremental unsupervised learning over a small memory of the most recent experiences of the agent. When combined with an intrinsic motivation learning mechanism, this method learns subgoals and skills together, based on experiences in the environment. Thus, we offer an original approach to HRL that does not require the acquisition of a model of the environment, suitable for large-scale applications. We demonstrate the efficiency of our method on two RL problems with sparse delayed feedback: a variant of the rooms environment and the ATARI 2600 game called Montezuma's Revenge.\n", "keywords": ["Reinforcement Learning", "Model-Free Hierarchical Reinforcement Learning", "Subgoal Discovery", "Unsupervised Learning", "Temporal Difference", "Temporal Abstraction", "Intrinsic Motivation", "Markov Decision Processes", "Deep Reinforcement Learning", "Optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper904/Authors"], "authors": ["Anonymous"], "TL;DR": "We offer an original approach to model-free deep hierarchical reinforcement learning, including unsupervised subgoal discovery and unified temporal abstraction and intrinsic motivation learning. ", "pdf": "/pdf/e4b525030cb6bdfaf77fc3492532d0ba948049a4.pdf", "paperhash": "anonymous|learning_representations_in_modelfree_hierarchical_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Representations in Model-Free Hierarchical Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gDCiCqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJePRoAct7", "original": "ryecpWtdYX", "number": 905, "cdate": 1538087887378, "ddate": null, "tcdate": 1538087887378, "tmdate": 1538156032200, "tddate": null, "forum": "HJePRoAct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph U-Net", "abstract": "We consider the problem of representation learning for graph data. Convolutional neural networks can naturally operate on images, but have significant challenges in dealing with graph data. Given images are special cases of graphs with nodes lie on 2D lattices, graph embedding tasks have a natural correspondence with image pixel-wise prediction tasks such as segmentation. While encoder-decoder architectures like U-Net have been successfully applied on many image pixel-wise prediction tasks, similar methods are lacking for graph data. This is due to the fact that pooling and up-sampling operations are not natural on graph data. To address these challenges, we propose novel graph pooling (gPool) and unpooling (gUnpool) operations in this work. The gPool layer adaptively selects some nodes to form a smaller graph based on their scalar projection values on a trainable projection vector. We further propose the gUnpool layer as the inverse operation of the gPool layer. The gUnpool layer restores the graph into its original structure using the position information of nodes selected in the corresponding gPool layer. Based on our proposed gPool and gUnpool layers, we develop an encoder-decoder model on graph, known as the graph U-Net. Our experimental results on node classification tasks demonstrate that our methods achieve consistently better performance than previous models.", "keywords": ["graph", "pooling", "unpooling", "U-Net"], "authorids": ["ICLR.cc/2019/Conference/Paper905/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose the graph U-Net based on our novel graph pooling and unpooling layer for network embedding.", "pdf": "/pdf/843dc5045adb7c9b7e0697e94707f9a91a51805b.pdf", "paperhash": "anonymous|graph_unet", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph U-Net},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJePRoAct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgd0iA9FQ", "original": "B1lbnopqFX", "number": 906, "cdate": 1538087887543, "ddate": null, "tcdate": 1538087887543, "tmdate": 1538156031983, "tddate": null, "forum": "rkgd0iA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Convergence Guarantees for RMSProp and ADAM in Non-Convex Optimization and an Empirical Comparison to Nesterov Acceleration", "abstract": "RMSProp and ADAM continue to be extremely popular algorithms for training neural nets but their theoretical convergence properties have remained unclear. Further, recent work has seemed to suggest that these algorithms have worse generalization properties when compared to carefully tuned stochastic gradient descent or its momentum variants. In this work, we make progress towards a deeper understanding of ADAM and RMSProp in two ways. First, we provide proofs that these adaptive gradient algorithms are guaranteed to reach criticality for smooth non-convex objectives, and we give bounds on the running time.\n\nNext we design experiments to empirically study the convergence and generalization properties of RMSProp and ADAM against Nesterov's Accelerated Gradient method on a variety of common autoencoder setups. Through these experiments we demonstrate the interesting sensitivity that ADAM has to its momentum parameter \\beta_1. We show that at very high values of the momentum parameter (\\beta_1 = 0.99) ADAM outperforms a carefully tuned NAG on most of our experiments, in terms of getting lower training and test losses. On the other hand, NAG can sometimes do better when ADAM's \\beta_1 is set to the most commonly used value: \\beta_1 = 0.9, indicating the importance of tuning the hyperparameters of ADAM to get better generalization performance.\n\nWe also report experiments on different autoencoders to demonstrate that NAG has better abilities in terms of reducing the gradient norms, and it also produces iterates which exhibit an increasing trend for the minimum eigenvalue of the Hessian of the loss function at the iterates. ", "keywords": ["adaptive gradient descent", "deeplearning", "ADAM", "RMSProp", "autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper906/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper we prove convergence to criticality of (stochastic and deterministic) RMSProp and deterministic ADAM for smooth non-convex objectives and we demonstrate an interesting beta_1 sensitivity for ADAM on autoencoders. ", "pdf": "/pdf/4b66a45f3f489d084fdb60acf19c7b2bd4a131b6.pdf", "paperhash": "anonymous|convergence_guarantees_for_rmsprop_and_adam_in_nonconvex_optimization_and_an_empirical_comparison_to_nesterov_acceleration", "_bibtex": "@inproceedings{    \nanonymous2019convergence,    \ntitle={Convergence Guarantees for RMSProp and ADAM in Non-Convex Optimization and an Empirical Comparison to Nesterov Acceleration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgd0iA9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxdAoCcYX", "original": "r1lwtgyqtQ", "number": 907, "cdate": 1538087887717, "ddate": null, "tcdate": 1538087887717, "tmdate": 1538156031767, "tddate": null, "forum": "HJxdAoCcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Characterizing Malicious Edges targeting on Graph Neural Networks", "abstract": "Deep neural networks on graph structured data have shown increasing success in various applications. However, due to recent studies about vulnerabilities of machine learning models, researchers are encouraged to explore the robustness of graph neural networks (GNNs). So far there are two work targeting to attack GNNs by adding/deleting edges to fool graph based classification tasks. Such attacks are challenging to be detected since the manipulation is very subtle compared with traditional graph attacks. In this paper we propose the first detection mechanism against these two proposed attacks. Given a perturbed graph, we propose a novel graph generation method together with link prediction as preprocessing to detect potential malicious edges. We also propose novel features which can be leveraged to perform outlier detection when the number of added malicious edges are large. Different detection components are proposed and tested, and we also evaluate the performance of final detection pipeline. Extensive experiments are conducted to show that the proposed detection mechanism can achieve AUC above 90% against the two attack strategies on both Cora and Citeseer datasets. We also provide in-depth analysis of different attack strategies and corresponding suitable detection methods. Our results shed light on several principles for detecting different types of attacks.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper907/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1251a91d41cdff7bbfa593ebcbb1d9d77907452c.pdf", "paperhash": "anonymous|characterizing_malicious_edges_targeting_on_graph_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019characterizing,    \ntitle={Characterizing Malicious Edges targeting on Graph Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxdAoCcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1luCsCqFm", "original": "SklJW9q9Fm", "number": 908, "cdate": 1538087887883, "ddate": null, "tcdate": 1538087887883, "tmdate": 1538156031562, "tddate": null, "forum": "r1luCsCqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating", "abstract": "Deep neural networks, which gain great success in a wide spectrum of applications, are often time, compute and storage hungry. Curriculum learning proposed to boost training of network by a syllabus from easy to hard. However, the relationship between data complexity and network training is unclear: why hard example harm the performance at beginning but helps at end. In this paper, we aim to investigate on this problem. Similar to internal covariate shift in network forward pass, the distribution changes in weight of top layers also affects training of preceding layers during the backward pass. We call this phenomenon inverse \"internal covariate shift\". Training hard examples aggravates the distribution shifting and damages the training. To address this problem, we introduce a curriculum loss that consists of two parts: a) an adaptive weight that mitigates large early punishment; b) an additional representation loss for low weighted samples. The intuition of the loss is very simple. We train top layers on \"good\" samples to reduce large shifting, and encourage \"bad\" samples to learn from \"good\" sample. In detail, the adaptive weight assigns small values to hard examples, reducing the influence of noisy gradients. On the other hand, the less-weighted hard sample receives the proposed representation loss. Low-weighted data gets nearly no training signal and can stuck in embedding space for a long time. The proposed representation loss aims to encourage their training. This is done by letting them learn a better representation from its superior neighbours but not participate in learning of top layers. In this way, the fluctuation of top layers is reduced and hard samples also received signals for training. We found in this paper that curriculum learning needs random sampling between tasks for better training. Our curriculum loss is easy to combine with existing stochastic algorithms like SGD. Experimental result shows an consistent improvement over several benchmark datasets.", "keywords": ["Curriculum Learning", "Internal Covariate Shift"], "authorids": ["ICLR.cc/2019/Conference/Paper908/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4ae687244ce452107e640d4936afefc3321e8a50.pdf", "paperhash": "anonymous|learn_from_neighbour_a_curriculum_that_train_low_weighted_samples_by_imitating", "_bibtex": "@inproceedings{    \nanonymous2019learn,    \ntitle={Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1luCsCqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyM_RsCqYm", "original": "Syg46pTcK7", "number": 909, "cdate": 1538087888059, "ddate": null, "tcdate": 1538087888059, "tmdate": 1538156031346, "tddate": null, "forum": "HyM_RsCqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling", "abstract": "This paper proposes a hierarchical Bayesian model for clustering sparse sequences.This is a mixture model and does not need the data to be represented by a Gaussian mixture and that gives significant modelling freedom.It also generates a very interpretable profile for the discovered latent groups.The data that was used for the work have been contributed by a restaurant loyalty program company. The data is a collection of sparse sequences where each entry of each sequence is the number of user visits of one week to some restaurant. This algorithm successfully clustered the data and calculated the expected user affiliation in each cluster.", "keywords": ["Hierarchical Bayesian Modeling", "Sparse Sequence Clustering", "User group Modeling", "group profile creation"], "authorids": ["ICLR.cc/2019/Conference/Paper909/Authors"], "authors": ["Anonymous"], "TL;DR": "Hierarchical Bayesian Modeling for Clustering Sparse Sequences; User group modeling", "pdf": "/pdf/65f67af1c54ee0e750ac1141ea450be6e2cdd40d.pdf", "paperhash": "anonymous|hierarchical_bayesian_modeling_for_clustering_sparse_sequences_in_the_context_of_group_profiling", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyM_RsCqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyzdRiR9Y7", "original": "SyeafOTqFm", "number": 910, "cdate": 1538087888236, "ddate": null, "tcdate": 1538087888236, "tmdate": 1538156031139, "tddate": null, "forum": "HyzdRiR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal Transformers", "abstract": "Recurrent neural networks (RNNs) sequentially process data by updating their state with each new data point, and have long been the de facto choice for sequence modeling tasks. However, their inherently sequential computation makes them slow to train. Feed-forward and convolutional architectures have recently been shown to achieve superior results on some sequence modeling tasks such as machine translation, with the added advantage that they concurrently process all inputs in the sequence, leading to easy parallelization and faster training times. Despite these successes, however, popular feed-forward sequence models like the Transformer fail to generalize in many simple tasks that recurrent models handle with ease, e.g. copying strings or even simple logical inference when the string or formula lengths exceed those observed at training time. We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues. UTs combine the parallelizability and global receptive field of feed-forward sequence models like the Transformer with the recurrent inductive bias of RNNs. We also add a dynamic per-position halting mechanism and find that it improves accuracy on several tasks. In contrast to the standard Transformer, under certain assumptions UTs can be shown to be Turing-complete. Our experiments show that UTs outperform standard Transformers on a wide range of algorithmic and language understanding tasks, including the challenging LAMBADA language modeling task where UTs achieve a new state of the art, and machine translation where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset.", "keywords": ["sequence-to-sequence", "rnn", "transformer", "machine translation", "language understanding", "learning to execute"], "authorids": ["ICLR.cc/2019/Conference/Paper910/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce the Universal Transformer, a self-attentive parallel-in-time recurrent sequence model that outperforms Transformers and LSTMs on a wide range of sequence-to-sequence tasks, including machine translation.", "pdf": "/pdf/f2985e6a75a285300197cb5e19f55128f1bd0309.pdf", "paperhash": "anonymous|universal_transformers", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Transformers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyzdRiR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyVuRiC5K7", "original": "r1gNKqKqK7", "number": 911, "cdate": 1538087888410, "ddate": null, "tcdate": 1538087888410, "tmdate": 1538156030929, "tddate": null, "forum": "SyVuRiC5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING", "abstract": "The goal of few-shot learning is to learn a classifier that generalizes well even when trained with a limited number of training instances per class. The recently introduced meta-learning approaches tackle this problem by learning a generic classifier across a large number of multiclass classification tasks and generalizing the model to a new task. Yet, even with such meta-learning, the low-data problem in the novel classification task still remains. In this paper, we propose Transductive Propagation Network (TPN), a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem. Specifically, we propose to learn to propagate labels from labeled instances to unlabeled test instances, by learning a graph construction module that exploits the manifold structure in the data. TPN jointly learns both the parameters of feature embedding and the graph construction in an end-to-end manner.  We validate TPN on multiple benchmark datasets, on which it largely outperforms existing few-shot learning approaches and achieves the state-of-the-art results. ", "keywords": ["few-shot learning", "meta-learning", "label propagation", "manifold learning"], "authorids": ["ICLR.cc/2019/Conference/Paper911/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem.", "pdf": "/pdf/660610b23322752adb258d886072234513fd8b67.pdf", "paperhash": "anonymous|learning_to_propagate_labels_transductive_propagation_network_for_fewshot_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyVuRiC5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlY0jA5F7", "original": "B1g7yV69tX", "number": 912, "cdate": 1538087888590, "ddate": null, "tcdate": 1538087888590, "tmdate": 1538156030723, "tddate": null, "forum": "HJlY0jA5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving Sample-based Evaluation for Generative Adversarial Networks", "abstract": "In this paper, we propose an improved quantitative evaluation framework for Generative Adversarial Networks (GANs) on generating domain-specific images, where we improve conventional evaluation methods on two levels: the feature representation and the evaluation metric. Unlike most existing evaluation frameworks which transfer the representation of ImageNet inception model to map images onto the feature space, our framework uses a specialized encoder to acquire fine-grained domain-specific representation. Moreover, for datasets with multiple classes, we propose Class-Aware Frechet Distance (CAFD), which employs a Gaussian mixture model on the feature space to better fit the multi-manifold feature distribution. Experiments and analysis on both the feature level and the image level were conducted to demonstrate improvements of our proposed framework over the recently proposed state-of-the-art FID method. To our best knowledge, we are the first to provide counter examples where FID gives inconsistent results with human judgments. It is shown in the experiments that our framework is able to overcome the shortness of FID and improves robustness. Code will be made available.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper912/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper improves existing sample-based evaluation for GANs and contains some insightful experiments.", "pdf": "/pdf/c0c84392e5674aac1bf1b37376733f470d291079.pdf", "paperhash": "anonymous|improving_samplebased_evaluation_for_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Sample-based Evaluation for Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlY0jA5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xtAjR5tX", "original": "ByxXipK5KQ", "number": 913, "cdate": 1538087888768, "ddate": null, "tcdate": 1538087888768, "tmdate": 1538156030513, "tddate": null, "forum": "S1xtAjR5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving Sequence-to-Sequence Learning via Optimal Transport", "abstract": "Sequence-to-sequence models are commonly trained via maximum likelihood estimation (MLE). However, standard MLE training considers a word-level objective, predicting the next word given the previous ground-truth partial sentence. This procedure focuses on modeling local syntactic patterns, and may fail to capture long-range semantic structure. We present a novel solution to alleviate these issues. Our approach imposes global sequence-level guidance via new supervision based on optimal transport, enabling the overall characterization and preservation of semantic features. We further show that this method can be understood as a Wasserstein gradient flow trying to match our model to the ground truth sequence distribution. Extensive experiments are conducted to validate the utility of the proposed approach, showing consistent improvements over a wide variety of NLP tasks, including machine translation, abstractive text summarization, and image captioning.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper913/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b29d2852affb3a98fcb536e9c8fd39af797df4e7.pdf", "paperhash": "anonymous|improving_sequencetosequence_learning_via_optimal_transport", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Sequence-to-Sequence Learning via Optimal Transport},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xtAjR5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1fF0iR9KX", "original": "H1lWyATqKX", "number": 914, "cdate": 1538087888942, "ddate": null, "tcdate": 1538087888942, "tmdate": 1538156030305, "tddate": null, "forum": "H1fF0iR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Geometry aware convolutional filters for omnidirectional images representation", "abstract": "Due to their wide field of view, omnidirectional cameras are frequently used by autonomous vehicles, drones and robots for navigation and other computer vision tasks. The images captured by such cameras, are often analyzed and classified with techniques designed for planar images that unfortunately fail to properly handle the native geometry of such images. That results in suboptimal performance, and lack of truly meaningful visual features. In this paper we aim at improving popular deep convolutional neural networks so that they can properly take into account the specific properties of omnidirectional data. In particular we propose an algorithm that adapts convolutional layers, which often serve as a core building block of a CNN, to the properties of omnidirectional images. Thus, our filters have a shape and size that adapts with the location on the omnidirectional image. We show that our method  achieves better results compared to existing deep neural network techniques for omnidirectional image classification. Finally we show that our method is not limited to spherical surfaces and is able to incorporate the knowledge about any kind of omnidirectional  geometry inside the deep learning network.\n", "keywords": ["omnidirectional images", "classification", "deep learning", "graph signal processing"], "authorids": ["ICLR.cc/2019/Conference/Paper914/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/820a99c44a2cb19d62bd02fc37f07a506225db67.pdf", "paperhash": "anonymous|geometry_aware_convolutional_filters_for_omnidirectional_images_representation", "_bibtex": "@inproceedings{    \nanonymous2019geometry,    \ntitle={Geometry aware convolutional filters for omnidirectional images representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1fF0iR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyeFAsRctQ", "original": "r1xxdIvLFQ", "number": 915, "cdate": 1538087889121, "ddate": null, "tcdate": 1538087889121, "tmdate": 1538156030099, "tddate": null, "forum": "HyeFAsRctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Verification of Non-Linear Specifications for Neural Networks", "abstract": "Prior work on neural network verification has focused on specifications that are linear functions of the output of the network, e.g., invariance of the classifier output under adversarial perturbations of the input. In this paper, we extend verification algorithms to be able to certify richer properties of neural networks. To do this we introduce the class of convex-relaxable specifications, which constitute nonlinear specifications that can be verified using a convex relaxation. We show that a number of important properties of interest can be modeled within this class, including conservation of energy in a learned dynamics model of a physical system; semantic consistency of a classifier's output labels under adversarial perturbations and bounding errors in a system that predicts the summation of handwritten digits. Our experimental evaluation shows that our method is able to effectively verify these specifications. Moreover, our evaluation exposes the failure modes in models which cannot be verified to satisfy these specifications. Thus, emphasizing the importance of training models not just to fit training data but also to be consistent with specifications.", "keywords": ["Verification", "Convex Optimization", "Adversarial Robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper915/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/49b4f01f62d66e3d170aecf1f85768e9820ab571.pdf", "paperhash": "anonymous|verification_of_nonlinear_specifications_for_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019verification,    \ntitle={Verification of Non-Linear Specifications for Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeFAsRctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeKCi0qYX", "original": "H1eqbtO5K7", "number": 916, "cdate": 1538087889297, "ddate": null, "tcdate": 1538087889297, "tmdate": 1538156029889, "tddate": null, "forum": "HJeKCi0qYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MILE: A Multi-Level Framework for Scalable Graph Embedding", "abstract": "Recently there has been a surge of interest in designing graph embedding methods. Few, if any, can scale to a large-sized graph with millions of nodes due to both computational complexity and memory requirements. In this paper, we relax this limitation by introducing the MultI-Level Embedding (MILE) framework \u2013 a generic methodology allowing contemporary graph embedding methods to scale to large graphs. MILE repeatedly coarsens the graph into smaller ones using a hybrid matching technique to maintain the backbone structure of the graph. It then applies existing embedding methods on the coarsest graph and refines the embeddings to the original graph through a novel graph convolution neural network that it learns. The proposed MILE framework is agnostic to the underlying graph embedding techniques and can be applied to many existing graph embedding methods without modifying them. We employ our framework on several popular graph embedding techniques and conduct embedding for real-world graphs. Experimental results on five large-scale datasets demonstrate that MILE significantly boosts the speed (order of magnitude) of graph embedding while also often generating embeddings of better quality for the task of node classification. MILE can comfortably scale to a graph with 9 million nodes and 40 million edges, on which existing methods run out of memory or take too long to compute on a modern workstation.", "keywords": ["Network Embedding", "Graph Convolutional Networks", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper916/Authors"], "authors": ["Anonymous"], "TL;DR": "A generic framework to scale existing graph embedding techniques to large graphs.", "pdf": "/pdf/d2c5d142e6ef127ef8d750958493d5f89b6cc3f7.pdf", "paperhash": "anonymous|mile_a_multilevel_framework_for_scalable_graph_embedding", "_bibtex": "@inproceedings{    \nanonymous2019mile:,    \ntitle={MILE: A Multi-Level Framework for Scalable Graph Embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeKCi0qYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lYRjC9F7", "original": "r1l2yRT9KX", "number": 917, "cdate": 1538087889476, "ddate": null, "tcdate": 1538087889476, "tmdate": 1538156029680, "tddate": null, "forum": "r1lYRjC9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset", "abstract": "Generating musical audio directly with neural networks is notoriously difficult because it requires coherently modeling structure at many different timescales. Fortunately, most music is also highly structured and can be represented as discrete note events played on musical instruments. Herein, we show that by using notes as an intermediate representation, we can train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure on timescales spanning six orders of magnitude (~0.1 ms to ~100 s). This large advance in the state of the art is enabled by our release of the new MAESTRO (MIDI and Audio Edited for Synchronous TRacks and Organization) dataset, composed of over 172 hours of virtuosic piano performances captured with fine alignment (~3 ms) between note labels and audio waveforms. The networks and the dataset together present a promising approach toward creating new expressive and interpretable neural models of music.", "keywords": ["music", "piano transcription", "transformer", "wavnet", "audio synthesis", "dataset", "midi"], "authorids": ["ICLR.cc/2019/Conference/Paper917/Authors"], "authors": ["Anonymous"], "TL;DR": "We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.", "pdf": "/pdf/18d62fe54d28d81bb4b423b686552b88d0643382.pdf", "paperhash": "anonymous|enabling_factorized_piano_music_modeling_and_generation_with_the_maestro_dataset", "_bibtex": "@inproceedings{    \nanonymous2019enabling,    \ntitle={Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lYRjC9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByecAoAqK7", "original": "rJxYDSacFm", "number": 918, "cdate": 1538087889645, "ddate": null, "tcdate": 1538087889645, "tmdate": 1538156029479, "tddate": null, "forum": "ByecAoAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Zero-shot Dual Machine Translation", "abstract": "Neural Machine Translation (NMT) systems rely on large amounts of parallel data.This is a major challenge for low-resource languages. Building on recent work onunsupervised and semi-supervised methods, we present an approach that combineszero-shot and dual learning. The latter relies on reinforcement learning, to exploitthe duality of the machine translation task, and requires only monolingual datafor the target language pair. Experiments on the UN corpus show that a zero-shotdual system, trained on English-French and English-Spanish, outperforms by largemargins a standard NMT system in zero-shot translation performance on Spanish-French (both directions). We also evaluate onnewstest2014. These experimentsshow that the zero-shot dual method outperforms the LSTM-based unsupervisedNMT system proposed in (Lample et al., 2018b), on the en\u2192fr task, while onthe fr\u2192en task it outperforms both the LSTM-based and the Transformers-basedunsupervised NMT systems.", "keywords": ["unsupervised", "machine translation", "dual learning", "zero-shot"], "authorids": ["ICLR.cc/2019/Conference/Paper918/Authors"], "authors": ["Anonymous"], "TL;DR": "A multilingual NMT model with reinforcement learning (dual learning) aiming to improve zero-shot translation directions.", "pdf": "/pdf/bccab057a76a9d26379a6f111b25349cd0618508.pdf", "paperhash": "anonymous|zeroshot_dual_machine_translation", "_bibtex": "@inproceedings{    \nanonymous2019zero-shot,    \ntitle={Zero-shot Dual Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByecAoAqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkeqCoA5tX", "original": "Byxs-Aa5Y7", "number": 919, "cdate": 1538087889808, "ddate": null, "tcdate": 1538087889808, "tmdate": 1538156029274, "tddate": null, "forum": "rkeqCoA5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LEARNING GENERATIVE MODELS FOR DEMIXING OF STRUCTURED SIGNALS FROM THEIR SUPERPOSITION USING GANS", "abstract": "Recently, Generative Adversarial Networks (GANs) have emerged as popular alternative for modeling complex high dimensional distributions. Most of the existing works implicitly assume that the clean samples from the target distribution are easily available. However, in many applications this assumption is violated. In this paper, we consider the problem of learning GANs under the observation setting when the samples from target distribution are given by superposition of two structured components. We propose two novel frameworks: denoising-GAN and demixing-GAN. The denoising-GAN assumes access to clean samples from the second component and try to learn the other distribution, whereas demixing-GAN learns the distribution of the components in the same time. Through of comprehensive numerical experiments, we demonstrate that proposed frameworks can generate clean samples from unknown distributions, and provide competitive performance in tasks such as denoising, demixing, and compressive sensing. ", "keywords": ["Generative Models", "GANs", "Denosing", "Demixing", "Structured Recovery"], "authorids": ["ICLR.cc/2019/Conference/Paper919/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/270ee3a226733f3db9069174acfd72382758d1cf.pdf", "paperhash": "anonymous|learning_generative_models_for_demixing_of_structured_signals_from_their_superposition_using_gans", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={LEARNING GENERATIVE MODELS FOR DEMIXING OF STRUCTURED SIGNALS FROM THEIR SUPERPOSITION USING GANS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeqCoA5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkl5CjC9Fm", "original": "B1l5SqacYX", "number": 920, "cdate": 1538087889978, "ddate": null, "tcdate": 1538087889978, "tmdate": 1538156029071, "tddate": null, "forum": "rkl5CjC9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dual Importance Weight GAN", "abstract": "Generative Adversarial Networks (GAN) are trained to generate a sample image of interest. To this end, generative network of GAN learns implicit distribution of true dataset from the classification samples with candidate generated samples. However, in real implementation of GAN, training the generative network with limited number of candidate samples guarantees to properly represent neither true distribution nor the distribution of generator outputs. In this paper, we propose dual importance weights for the candidate samples represented in the latent space of auto-encoder. The auto-encoder is pre-trained with real target dataset. Therefore, the latent space representation allows us to compare real distribution and the distribution of generated samples explicitly. Dual importance weights iteratively maximize the representation of generated samples for both distributions: current generator outputs and real dataset. Proposed generative model not only resolves mode collapse problem of GAN but also improves the convergence on target distribution. Experimental evaluation shows that the proposed network learns complete modes of target distribution more stable and faster than state of the art methods. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper920/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b412aa2d4ec85c8f7f738a2c0a96571ac67e0aec.pdf", "paperhash": "anonymous|dual_importance_weight_gan", "_bibtex": "@inproceedings{    \nanonymous2019dual,    \ntitle={Dual Importance Weight GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl5CjC9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgqCiRqKQ", "original": "SklJfA69tm", "number": 921, "cdate": 1538087890147, "ddate": null, "tcdate": 1538087890147, "tmdate": 1538156028855, "tddate": null, "forum": "rkgqCiRqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Inferring Reward Functions from Demonstrators with Unknown Biases", "abstract": "Our goal is to infer reward functions from demonstrations. In order to infer the correct reward function, we must account for the systematic ways in which the demonstrator is suboptimal. Prior work in inverse reinforcement learning can account for specific, known biases, but cannot handle demonstrators with unknown biases. In this work, we explore the idea of learning the demonstrator's planning algorithm (including their unknown biases), along with their reward function. What makes this challenging is that any demonstration could be explained either by positing a term in the reward function, or by positing a particular systematic bias. We explore what assumptions are sufficient for avoiding this impossibility result: either access to tasks with known rewards which enable estimating the planner separately, or that the demonstrator is sufficiently close to optimal that this can serve as a regularizer. In our exploration with synthetic models of human biases, we find that it is possible to adapt to different biases and perform better than assuming a fixed model of the demonstrator, such as Boltzmann rationality.", "keywords": ["Inverse reinforcement learning", "differentiable planning"], "authorids": ["ICLR.cc/2019/Conference/Paper921/Authors"], "authors": ["Anonymous"], "TL;DR": "When we infer preferences from behavior, we can try to improve accuracy by jointly learning a bias model and preferences, though this requires new assumptions to make progress.", "pdf": "/pdf/5386d88f6508dbd1c0e8d3b2bb767c7bdc61b798.pdf", "paperhash": "anonymous|inferring_reward_functions_from_demonstrators_with_unknown_biases", "_bibtex": "@inproceedings{    \nanonymous2019inferring,    \ntitle={Inferring Reward Functions from Demonstrators with Unknown Biases},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgqCiRqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryfcCo0ctQ", "original": "HklXNp29FQ", "number": 922, "cdate": 1538087890327, "ddate": null, "tcdate": 1538087890327, "tmdate": 1538156028644, "tddate": null, "forum": "ryfcCo0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective", "abstract": " We study reinforcement learning algorithms with nonlinear function approximation in the online setting. By formulating both the problems of value function estimation and policy learning as bilevel optimization problems, we propose online Q-learning and actor-critic algorithms for these two problems respectively.   Our algorithms are gradient-based methods and thus are computationally efficient. Moreover, by approximating the iterates using differential equations,   we establish convergence guarantees for the proposed algorithms. Thorough numerical experiments are conducted to back up our theory.", "keywords": ["reinforcement learning", "Deep Q-networks", "actor-critic algorithm", "ODE approximation"], "authorids": ["ICLR.cc/2019/Conference/Paper922/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b5090a93bdd9dbc5fb39e9816dc1ed3b3652c393.pdf", "paperhash": "anonymous|convergent_reinforcement_learning_with_function_approximation_a_bilevel_optimization_perspective", "_bibtex": "@inproceedings{    \nanonymous2019convergent,    \ntitle={Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryfcCo0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkMq0oRqFQ", "original": "B1gQV_8KKX", "number": 923, "cdate": 1538087890499, "ddate": null, "tcdate": 1538087890499, "tmdate": 1538156028435, "tddate": null, "forum": "BkMq0oRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Normalization Gradients are Least-squares Residuals", "abstract": "Batch Normalization (BN) and its variants have seen widespread adoption in the deep learning community because they improve the training of deep neural networks. Discussions of why this normalization works so well remain unsettled.  We make explicit the relationship between ordinary least squares and partial derivatives computed when back-propagating through BN. We recast the back-propagation of BN as a least squares fit, which zero-centers and decorrelates partial derivatives from normalized activations. This view, which we term {\\em gradient-least-squares}, is an extensible and arithmetically accurate description of BN. Our view offers a unified interpretation of BN and related work; we motivate, from a regression perspective, two improvements to BN, and evaluate on CIFAR-10.", "keywords": ["Deep Learning", "Normalization", "Least squares", "Gradient regression"], "authorids": ["ICLR.cc/2019/Conference/Paper923/Authors"], "authors": ["Anonymous"], "TL;DR": "Batch Normalization and its variants work by performing a least-squares fit during back-propagation, which zero-centers and decorrelates partial derivatives from normalized activations.", "pdf": "/pdf/f908a8a98dd5669d57361e1b7ebad10bb139fb23.pdf", "paperhash": "anonymous|normalization_gradients_are_leastsquares_residuals", "_bibtex": "@inproceedings{    \nanonymous2019normalization,    \ntitle={Normalization Gradients are Least-squares Residuals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMq0oRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgsCjCqt7", "original": "rJeTqnk_KQ", "number": 924, "cdate": 1538087890666, "ddate": null, "tcdate": 1538087890666, "tmdate": 1538156028230, "tddate": null, "forum": "SJgsCjCqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Autoencoders with Jointly Optimized Latent Dependency Structure", "abstract": "We propose a method for learning the dependency structure between latent variables in deep latent variable models.  Our general modeling and inference framework combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, we express the latent variable space of a variational autoencoder (VAE) in terms of a Bayesian network with a learned, flexible dependency structure.  The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single variational objective.  Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top-down and bottom-up reasoning over latent variable values.  We validate our framework in extensive experiments on MNIST, Omniglot, and CIFAR-10. Comparisons to state-of-the-art structured variational autoencoder baselines show improvements in terms of the expressiveness of the learned model.", "keywords": ["deep generative models", "structure learning"], "authorids": ["ICLR.cc/2019/Conference/Paper924/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method for learning latent dependency structure in variational autoencoders.", "pdf": "/pdf/c94ddfeefe34b8890aabb5cbf8135fbe611c0ac9.pdf", "paperhash": "anonymous|variational_autoencoders_with_jointly_optimized_latent_dependency_structure", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Autoencoders with Jointly Optimized Latent Dependency Structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgsCjCqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkloRs0qK7", "original": "BJeNwd_qK7", "number": 925, "cdate": 1538087890843, "ddate": null, "tcdate": 1538087890843, "tmdate": 1538156028021, "tddate": null, "forum": "BkloRs0qK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A comprehensive, application-oriented study of catastrophic forgetting in DNNs", "abstract": "We present a large-scale empirical study of catastrophic forgetting (CF) in modern Deep Neural Network (DNN) models that perform sequential (or: incremental) learning.\nA new experimental protocol is proposed that takes into account typical constraints encountered in application scenarios.\nAs the investigation is empirical, we evaluate CF behavior on the hitherto largest number of visual classification datasets, from each of which we construct a representative number of Sequential Learning Tasks (SLTs) in close alignment to previous works on CF.\nOur results clearly indicate that there is no model that avoids CF for all investigated datasets and SLTs under application conditions. We conclude with a discussion of potential solutions and workarounds to CF, notably for the EWC and IMM models.", "keywords": ["incremental learning", "deep neural networks", "catatrophic forgetting", "sequential learning"], "authorids": ["ICLR.cc/2019/Conference/Paper925/Authors"], "authors": ["Anonymous"], "TL;DR": "We check DNN models for catastrophic forgetting using a new evaluation scheme that reflects typical application conditions, with surprising results.", "pdf": "/pdf/c7cb211b6888b6b0096f4635441d5ca00ccc9b1d.pdf", "paperhash": "anonymous|a_comprehensive_applicationoriented_study_of_catastrophic_forgetting_in_dnns", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A comprehensive, application-oriented study of catastrophic forgetting in DNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkloRs0qK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkes0iR9KX", "original": "HkgK-kCtF7", "number": 926, "cdate": 1538087891010, "ddate": null, "tcdate": 1538087891010, "tmdate": 1538156027812, "tddate": null, "forum": "Hkes0iR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DEEP GEOMETRICAL GRAPH Classification WITH DYNAMIC POOLING", "abstract": "Most of the existing Graph Neural Networks (GNNs) are the mere extension of the Convolutional Neural Networks (CNNs) to graphs. Generally, they consist of several steps of message passing between the nodes followed by a global indiscriminate feature pooling function. However, most of the times the nodes are unlabeled or their labels (or the given feature vectors of the nodes) provide no information about the similarity between the nodes and the locations of the nodes in the graph. Accordingly, message passing may not propagate helpful information throughout the graph. We show that this conventional approach fails to learn to solve even simple graph classification tasks. We alleviate this serious shortcoming of the GNNs by making them a two step method where in the second step, the message passing block is given the continuous features obtained by the embedding algorithm in the first step. The GNN learns to solve the given task by inferring the topological structure of the graph encoded in the spatial distribution of the embedded vectors. The second challenge we address in this paper is designing a pooling algorithm applicable to graphs. We turn the problem of graph down-sampling into a column sampling problem, i.e., the sampling algorithm samples a subset of the nodes whose feature vectors preserve the spatial distribution of all the feature vectors. We apply the proposed approach to several established benchmark data sets and it is shown that the proposed geometrical approach strongly improves the state-of-the-art for several data-sets.", "keywords": ["Graph classification", "Deep Learning", "Graph pooling", "Embedding"], "authorids": ["ICLR.cc/2019/Conference/Paper926/Authors"], "authors": ["Anonymous"], "TL;DR": "A deep learning based graph classification method plus a new adaptive method for graph pooling. ", "pdf": "/pdf/8b727d5824842c38ea8dcf3b8774affc3c560d58.pdf", "paperhash": "anonymous|deep_geometrical_graph_classification_with_dynamic_pooling", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={DEEP GEOMETRICAL GRAPH Classification WITH DYNAMIC POOLING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkes0iR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxsCiAqKm", "original": "ryepiKs5YQ", "number": 927, "cdate": 1538087891179, "ddate": null, "tcdate": 1538087891179, "tmdate": 1538156027604, "tddate": null, "forum": "ryxsCiAqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Spectral Convolutional Networks on Hierarchical Multigraphs", "abstract": "Spectral Graph Convolutional Networks (GCNs) are a generalization of convolutional networks to learning on graph-structured data. Applications of spectral GCNs have been successful, but limited to a few problems where the graph is fixed, such as shape correspondence and node classification. In this work, we address this limitation by revisiting a particular family of spectral graph networks, Chebyshev GCNs, showing its efficacy in solving graph classification tasks with a variable graph structure and size. Current GCNs also restrict graphs to have at most one edge between any pair of nodes. To this end, we propose a novel multigraph network that learns from multi-relational graphs. We explicitly model different types of edges: annotated edges, learned edges with abstract meaning, and hierarchical edges. We also experiment with different ways to fuse the representations extracted from different edge types. This restriction is sometimes implied from a dataset, however, we relax this restriction for all kinds of datasets. We achieve state-of-the-art results on a variety of chemical, social, and vision graph classification benchmarks.", "keywords": ["graph convolution", "hierarchical models", "neural networks", "multigraph", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper927/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel approach to graph classification based on spectral graph convolutional networks and its extension to multigraphs with learnable relations and hierarchical structure. We show state-of-the art results on chemical, social and image datasets.", "pdf": "/pdf/2780766fb8a334a6488b6abc29ffd6f8348d30a8.pdf", "paperhash": "anonymous|spectral_convolutional_networks_on_hierarchical_multigraphs", "_bibtex": "@inproceedings{    \nanonymous2019spectral,    \ntitle={Spectral Convolutional Networks on Hierarchical Multigraphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxsCiAqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgs0oAqFQ", "original": "BJeRQ_nqYX", "number": 928, "cdate": 1538087891356, "ddate": null, "tcdate": 1538087891356, "tmdate": 1538156027393, "tddate": null, "forum": "rkgs0oAqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Rethinking Knowledge Graph Propagation for Zero-Shot Learning", "abstract": "Graph convolutional neural networks have recently shown great potential for the task of zero-shot learning. These models are highly sample efficient as related concepts in the graph structure share statistical strength allowing generalization to new classes when faced with a lack of data. However, we find that the extensive use of Laplacian smoothing at each layer in current approaches can easily dilute the knowledge from distant nodes and consequently decrease the performance in zero-shot learning. In order to still enjoy the benefit brought by the graph structure while preventing the dilution of knowledge from distant nodes, we propose a Dense Graph Propagation (DGP) module with carefully designed direct links among distant nodes. DGP allows us to exploit the hierarchical graph structure of the knowledge graph through additional connections. These connections are added based on a node's relationship to its ancestors and descendants. A weighting scheme is further used to weigh their contribution depending on the distance to the node. Combined with finetuning of the representations in a two-stage training approach our method outperforms state-of-the-art zero-shot learning approaches.", "keywords": ["Dense graph propagation", "zero-shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper928/Authors"], "authors": ["Anonymous"], "TL;DR": "We rethink the way information can be exploited more efficiently in the knowledge graph in order to improve performance on the Zero-Shot Learning task and propose a dense graph propagation (DGP) module for this purpose.", "pdf": "/pdf/e2bc39d191235b44aa49d8a22bff2ef1f2e5e214.pdf", "paperhash": "anonymous|rethinking_knowledge_graph_propagation_for_zeroshot_learning", "_bibtex": "@inproceedings{    \nanonymous2019rethinking,    \ntitle={Rethinking Knowledge Graph Propagation for Zero-Shot Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgs0oAqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hke20iA9Y7", "original": "HkeJa7p5FX", "number": 929, "cdate": 1538087891541, "ddate": null, "tcdate": 1538087891541, "tmdate": 1538156027186, "tddate": null, "forum": "Hke20iA9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Training on Very Large Corpora via Gramian Estimation", "abstract": "We study the problem of learning similarity functions over very large corpora using neural network embedding models. These models are typically trained using SGD with random sampling of unobserved pairs, with a sample size that grows quadratically with the corpus size, making it expensive to scale.\nWe propose new efficient methods to train these models without having to sample unobserved pairs. Inspired by matrix factorization, our approach relies on adding a global quadratic penalty and expressing this term as the inner-product of two generalized Gramians. We show that the gradient of this term can be efficiently computed by maintaining estimates of the Gramians, and develop variance reduction schemes to improve the quality of the estimates. We conduct large-scale experiments that show a significant improvement both in training time and generalization performance compared to sampling methods.", "keywords": ["similarity learning", "pairwise learning", "matrix factorization", "Gramian estimation", "variance reduction", "neural embedding models", "recommender systems"], "authorids": ["ICLR.cc/2019/Conference/Paper929/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.", "pdf": "/pdf/570ccd4b03b9dec54fd5778b94c5b594b08c1852.pdf", "paperhash": "anonymous|efficient_training_on_very_large_corpora_via_gramian_estimation", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Training on Very Large Corpora via Gramian Estimation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hke20iA9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1g30j0qF7", "original": "BygW0PTqtm", "number": 930, "cdate": 1538087891708, "ddate": null, "tcdate": 1538087891708, "tmdate": 1538156026969, "tddate": null, "forum": "B1g30j0qF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bayesian Convolutional Neural Networks with Many Channels are Gaussian Processes", "abstract": "There is a previously identified equivalence between wide fully connected neural networks (FCNs) and Gaussian processes (GPs). This equivalence enables, for instance, test set predictions that would have resulted from a fully Bayesian, infinitely wide trained FCN to be computed without ever instantiating an FCN, but by instead evaluating the corresponding GP. In this work, we derive an analogous equivalence for multi-layer convolutional neural networks (CNNs) both with and without pooling layers. Surprisingly, in the absence of pooling layers, the corresponding GP is identical for CNNs with and without weight sharing. This means that translation equivariance in SGD-trained finite CNNs has no corresponding property in the Bayesian treatment of the infinite-width limit -- a qualitative difference between the two regimes that is not present in the FCN case. We confirm experimentally that in some scenarios, while the performance of trained finite CNNs becomes similar to that of the corresponding GP with increasing channel count, with careful tuning SGD-trained CNNs can significantly outperform their corresponding GPs. Finally, we introduce a Monte Carlo method to estimate the GP corresponding to a NN architecture, even in cases where the analytic form has too many terms to be computationally feasible.", "keywords": ["Deep Convolutional Neural Networks", "Gaussian Processes"], "authorids": ["ICLR.cc/2019/Conference/Paper930/Authors"], "authors": ["Anonymous"], "TL;DR": "Finite-width SGD trained CNNs vs. infinitely wide fully Bayesian CNNs. Who wins?", "pdf": "/pdf/f12f1a69d6d2e9f8ba0f5573bb744e41101b785d.pdf", "paperhash": "anonymous|bayesian_convolutional_neural_networks_with_many_channels_are_gaussian_processes", "_bibtex": "@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Convolutional Neural Networks with Many Channels are Gaussian Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1g30j0qF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklhAj09K7", "original": "BJeLJ6KUFm", "number": 931, "cdate": 1538087891880, "ddate": null, "tcdate": 1538087891880, "tmdate": 1538156026749, "tddate": null, "forum": "BklhAj09K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Domain Adaptation for Distance Metric Learning", "abstract": "Unsupervised domain adaptation is a promising avenue to enhance the performance of deep neural networks on a target domain, using labels only from a source domain. However, the two predominant methods, domain discrepancy reduction learning and semi-supervised learning, are not readily applicable when source and target domains do not share a common label space. This paper addresses the above scenario by learning a representation space that retains discriminative power on both the (labeled) source and (unlabeled) target domains while keeping representations for the two domains well-separated. Inspired by a theoretical analysis, we first reformulate the disjoint classification task, where the source and target domains correspond to non-overlapping class labels, to a verification one. To handle both within and cross domain verifications, we propose a Feature Transfer Network (FTN) to separate the target feature space from the original source space while aligned with a transformed source space. Moreover, we present a non-parametric multi-class entropy minimization loss to further boost the discriminative power of FTNs on the target domain. In experiments, we first illustrate how FTN works in a controlled setting of adapting from MNIST-M to MNIST with disjoint digit classes between the two domains and then demonstrate the effectiveness of FTNs through state-of-the-art performances on a cross-ethnicity face recognition problem.\n", "keywords": ["domain adaptation", "distance metric learning", "face recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper931/Authors"], "authors": ["Anonymous"], "TL;DR": "A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.", "pdf": "/pdf/05d61078a2c461cf8941ca1f36805e8ea5673d8d.pdf", "paperhash": "anonymous|unsupervised_domain_adaptation_for_distance_metric_learning", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Domain Adaptation for Distance Metric Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklhAj09K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1en0sRqKm", "original": "SylrH0p5tX", "number": 932, "cdate": 1538087892053, "ddate": null, "tcdate": 1538087892053, "tmdate": 1538156026535, "tddate": null, "forum": "S1en0sRqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent", "abstract": "Increasing the mini-batch size for stochastic gradient descent offers significant opportunities to reduce wall-clock training time, but there are a variety of theoretical and systems challenges that impede the widespread success of this technique (Daset al., 2016; Keskar et al., 2016). We investigate these issues, with an emphasis on time to convergence and total computational cost, through an extensive empirical analysis of network training across several architectures and problem domains, including image classification, image segmentation, and language modeling.  Although it is common practice to increase the batch size in order to fully exploit available computational resources, we find a substantially more nuanced picture. Our main finding is that across a wide range of network architectures and problem domains, increasing the batch size beyond a certain point yields no decrease in wall-clock time to convergence for either train or test loss.  This batch size is usually substantially below the capacity of current systems.  We show that popular training strategies for large batch size optimization begin to fail before we can populate all available compute resources, and we show that the point at which these methods break down depends more on attributes like model architecture and data complexity than it does directly on the size of the dataset.", "keywords": ["Deep learning", "large batch training", "scaling rules", "stochastic gradient descent"], "authorids": ["ICLR.cc/2019/Conference/Paper932/Authors"], "authors": ["Anonymous"], "TL;DR": "Large batch training results in rapidly diminishing returns in wall-clock time to convergence to find a good model.", "pdf": "/pdf/779ab8c3f35f53393b64ff46209b4044b4427d59.pdf", "paperhash": "anonymous|on_the_computational_inefficiency_of_large_batch_sizes_for_stochastic_gradient_descent", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1en0sRqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1enCo0cK7", "original": "HylWXNj5Y7", "number": 933, "cdate": 1538087892218, "ddate": null, "tcdate": 1538087892218, "tmdate": 1538156026324, "tddate": null, "forum": "B1enCo0cK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy", "abstract": "Adversarial examples have somewhat disrupted the enormous success of machine learning (ML) and are causing concern with regards to its trustworthiness: A small perturbation of an input results in an arbitrary failure of an otherwise seemingly well-trained ML system. While studies are being conducted to discover the intrinsic properties of adversarial examples, such as their transferability and universality, there is insufficient theoretic analysis to help understand the phenomenon in a way that can influence the design process of ML experiments. In this paper, we deduce an information-theoretic model which explains adversarial attacks universally as the abuse of feature redundancies in ML algorithms. We prove that feature redundancy is a necessary condition for the existence of adversarial examples. Our model helps to explain the major questions raised in many anecdotal studies on adversarial examples. Our theory is backed up by empirical measurements of the information content of benign and adversarial examples on both image and text datasets. Our measurements show that typical adversarial examples introduce just enough redundancy to overflow the decision making of a machine learner trained on corresponding benign examples. We conclude with actionable recommendations to improve the robustness of machine learners against adversarial examples.", "keywords": ["adversarial examples", "information theory", "robust neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper933/Authors"], "authors": ["Anonymous"], "TL;DR": "A new theoretical explanation for the existence of adversarial examples", "pdf": "/pdf/798ae8f944a2e7cd9542845816f87e35fbb44be9.pdf", "paperhash": "anonymous|one_bit_matters_understanding_adversarial_examples_as_the_abuse_of_redundancy", "_bibtex": "@inproceedings{    \nanonymous2019one,    \ntitle={One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1enCo0cK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryG2Cs09Y7", "original": "BJeorAp9KQ", "number": 934, "cdate": 1538087892403, "ddate": null, "tcdate": 1538087892403, "tmdate": 1538156026117, "tddate": null, "forum": "ryG2Cs09Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "FEATURE PRIORITIZATION AND REGULARIZATION IMPROVE STANDARD ACCURACY AND ADVERSARIAL ROBUSTNESS", "abstract": "Adversarial training has been successfully applied to build robust models at a certain cost. While the robustness of a model increases, the standard classification accuracy declines. This phenomenon is suggested to be an inherent trade-off between standard accuracy and robustness. We propose a model that employs feature prioritization by a nonlinear attention module and L2 regularization as implicit denoising to improve the adversarial robustness and the standard accuracy relative to adversarial training. Focusing sharply on the regions of interest, the attention maps encourage the model to rely heavily on features extracted from the most relevant areas while suppressing the unrelated background. Penalized by a regularizer, the model extracts similar features for the natural and adversarial images, effectively ignoring the added perturbation. In addition to qualitative evaluation, we also propose a novel experimental strategy that quantitatively demonstrates that our model is almost ideally aligned with salient data characteristics. Additional experimental results illustrate the power of our model relative to the state of the art methods", "keywords": ["adversarial robustness", "feature prioritization", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper934/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a model that employs feature prioritization and regularization to improve the adversarial robustness and the standard accuracy.", "pdf": "/pdf/8ddd67de2adcf93474aa10992aeb0094967d2199.pdf", "paperhash": "anonymous|feature_prioritization_and_regularization_improve_standard_accuracy_and_adversarial_robustness", "_bibtex": "@inproceedings{    \nanonymous2019feature,    \ntitle={FEATURE PRIORITIZATION AND REGULARIZATION IMPROVE STANDARD ACCURACY AND ADVERSARIAL ROBUSTNESS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryG2Cs09Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJl6AjC5F7", "original": "B1eWmCoqYm", "number": 935, "cdate": 1538087892584, "ddate": null, "tcdate": 1538087892584, "tmdate": 1538156025907, "tddate": null, "forum": "BJl6AjC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Represent Edits", "abstract": "We introduce the problem of learning distributed representations of edits. By combining a\n\"neural editor\" with an \"edit encoder\", our models learn to represent the salient\ninformation of an edit and can be used to apply edits to new inputs.\nWe experiment on natural language and source code edit data. Our evaluation yields\npromising results that suggest that our neural network models learn to capture\nthe structure and semantics of edits. We hope that this interesting task and\ndata source will inspire other researchers to work further on this problem.", "keywords": ["Representation Learning", "Source Code", "Natural Language", "edit"], "authorids": ["ICLR.cc/2019/Conference/Paper935/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9e9037316ac54c796eaaee3ff7d0c053f08e7d3b.pdf", "paperhash": "anonymous|learning_to_represent_edits", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Represent Edits},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl6AjC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlpCsC5Km", "original": "ByloBTTcY7", "number": 936, "cdate": 1538087892754, "ddate": null, "tcdate": 1538087892754, "tmdate": 1538156025689, "tddate": null, "forum": "BJlpCsC5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Gibbs-regularized GANs with variational discriminator reparameterization", "abstract": " We propose a novel approach to regularizing generative adversarial networks (GANs) leveraging learned {\\em structured Gibbs distributions}.  Our method consists of reparameterizing the discriminator to be an explicit function of two densities: the generator PDF $q$ and a structured Gibbs distribution $\\nu$.  Leveraging recent work on invertible pushforward density estimators, this reparameterization is made possible by assuming the generator is invertible, which enables the analytic evaluation of the generator PDF $q$.  We further propose optimizing the Jeffrey divergence, which balances mode coverage with sample quality.  The combination of this loss and  reparameterization allows us to effectively regularize the generator by imposing structure from domain knowledge on $\\nu$, as in classical graphical models. Applying our method to a vehicle trajectory forecasting task, we observe that we are able to obtain quantitatively superior mode coverage as well as better-quality samples compared to traditional methods.", "keywords": ["deep generative models", "graphical models", "trajectory forecasting", "GANs", "density estimation", "structured prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper936/Authors"], "authors": ["Anonymous"], "TL;DR": "We reparameterize a GAN's discriminator into a form that admits regularization using a structured Gibbs distribution", "pdf": "/pdf/709b680834a332747d758df32c764e9901039643.pdf", "paperhash": "anonymous|learning_gibbsregularized_gans_with_variational_discriminator_reparameterization", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Gibbs-regularized GANs with variational discriminator reparameterization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlpCsC5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgpCoRctm", "original": "H1eDnUo9YQ", "number": 937, "cdate": 1538087892979, "ddate": null, "tcdate": 1538087892979, "tmdate": 1538156025483, "tddate": null, "forum": "rkgpCoRctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics", "abstract": "The ability to detect when an input sample was not drawn from the training distribution is an important  desirable property of deep neural networks. In this paper, we show that a simple ensembling of first and second order deep feature statistics can be exploited to effectively differentiate in-distribution and out-of-distribution samples. Specifically, we observe that  the mean and standard deviation within feature maps  differs greatly between in-distribution and out-of-distribution samples. Based on this observation, we propose a simple and  efficient plug-and-play detection procedure that does not require re-training, pre-processing or changes to the model.  The proposed method outperforms the state-of-the-art by a large margin in all standard benchmarking tasks, while being much simpler to implement and execute. Notably, our method improves the true negative rate from 86.6% to 96.8% when 95% of in-distribution (CIFAR-100) are correctly detected using a DenseNet and the out-of-distribution dataset is TinyImageNet resize. The source code of our method will be made publicly available.", "keywords": ["computer vision", "out-of-distribution detection", "image classification"], "authorids": ["ICLR.cc/2019/Conference/Paper937/Authors"], "authors": ["Anonymous"], "TL;DR": "Detecting out-of-distribution samples by using low-order feature statistics without requiring any change in underlying DNN.", "pdf": "/pdf/75cfbe00298525441b85e896568b720c40aa1b8d.pdf", "paperhash": "anonymous|detecting_outofdistribution_samples_using_loworder_deep_features_statistics", "_bibtex": "@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgpCoRctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkl6As0cF7", "original": "SkgpPa69Y7", "number": 938, "cdate": 1538087893149, "ddate": null, "tcdate": 1538087893149, "tmdate": 1538156025269, "tddate": null, "forum": "rkl6As0cF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Recursive Reasoning for Mutli-Agent Reinforcement Learning", "abstract": "Humans are capable of attributing latent mental contents such as beliefs, or intentions to others. The social skill is critical in everyday life to reason about the potential consequences of their behaviors so as to plan ahead. It is known that humans use this reasoning ability recursively, i.e. considering what others believe about their own beliefs.  In this paper, we introduce a probabilistic recursive reasoning (PR2) framework for multi-agent reinforcement learning (RL). Our hypothesis is that it is beneficial for each agent to consider how the opponents would react to its future behaviors. Under the PR2 framework, we adopt variational Bayes methods to approximate the opponents' conditional policy, to which each agent finds the  best response and then improve their own policy. We develop  decentralized-training-decentralized-execution  algorithms, PR2-Q and PR2-Actor-Critic, that are proved to converge in the self-play scenario.  Our methods are tested on both the matrix game and the differential game, which have a non-trivial equilibrium where common gradient-based methods fail to converge.  Our experiments show that it is critical to reason about how the opponents believe about what the agent believes. We expect our work to offer a new idea of embedding opponent modeling into the multi-agent RL context.  ", "keywords": ["Multi-agent Reinforcement Learning", "Recursive Reasoning"], "authorids": ["ICLR.cc/2019/Conference/Paper938/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.", "pdf": "/pdf/08148d090a8de435832f612f1bf9ca9118c12f94.pdf", "paperhash": "anonymous|probabilistic_recursive_reasoning_for_mutliagent_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Recursive Reasoning for Mutli-Agent Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl6As0cF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkg6RiCqY7", "original": "rJlsyL6cKm", "number": 939, "cdate": 1538087893315, "ddate": null, "tcdate": 1538087893315, "tmdate": 1538156025050, "tddate": null, "forum": "Bkg6RiCqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Decoupled Weight Decay Regularization", "abstract": "L$_2$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \\emph{not} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L$_2$ regularization (often calling it ``weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \\emph{decoupling} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments will be available after the review process.", "keywords": ["optimization", "regularization", "weight decay", "Adam"], "authorids": ["ICLR.cc/2019/Conference/Paper939/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3d3e5d918f0deb88a4bf7756c4fbdf92a3aa1b9d.pdf", "paperhash": "anonymous|decoupled_weight_decay_regularization", "_bibtex": "@inproceedings{    \nanonymous2019decoupled,    \ntitle={Decoupled Weight Decay Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg6RiCqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1GaAjRcF7", "original": "HJlzwzQqKm", "number": 940, "cdate": 1538087893486, "ddate": null, "tcdate": 1538087893486, "tmdate": 1538156024843, "tddate": null, "forum": "r1GaAjRcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Differentiable Greedy Networks", "abstract": "Optimal selection of a subset of items from a given set is a hard problem that requires combinatorial optimization. In this paper, we propose a subset selection algorithm that is trainable with gradient based methods yet achieves near optimal performance via submodular optimization. We focus on the task of identifying a relevant set of sentences for claim verification in the context of the FEVER task. Conventional methods for this task look at sentences on their individual merit and thus do not optimize the informativeness of sentences as a set. We show that our proposed method which builds on the idea of unfolding a greedy algorithm into a computational graph allows both interpretability and gradient based training. The proposed differentiable greedy network (DGN) outperforms discrete optimization algorithms as well as other baseline methods in terms of precision and recall.", "keywords": ["submodular optimization", "fact verification", "differentiable module", "deep unfolding"], "authorids": ["ICLR.cc/2019/Conference/Paper940/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a subset selection algorithm that is trainable with gradient based methods yet achieves near optimal performance via submodular optimization.", "pdf": "/pdf/be28a51d3a63c6692d0b4a879ed956652173e307.pdf", "paperhash": "anonymous|differentiable_greedy_networks", "_bibtex": "@inproceedings{    \nanonymous2019differentiable,    \ntitle={Differentiable Greedy Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GaAjRcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklACjAqFm", "original": "BkeI_CacY7", "number": 941, "cdate": 1538087893713, "ddate": null, "tcdate": 1538087893713, "tmdate": 1538156024627, "tddate": null, "forum": "BklACjAqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Successor Uncertainties: exploration and uncertainty in temporal difference learning", "abstract": "We consider the problem of balancing exploration and exploitation in sequential decision making problems. To explore efficiently, it is vital to consider the uncertainty over all consequences of a decision, and not just those that follow immediately; the uncertainties need to be propagated according to the dynamics of the problem. To this end, we develop Successor Uncertainties, a probabilistic model for the state-action function of a Markov Decision Process that propagates uncertainties in a coherent and scalable way. Our model achieves this by combining successor features and online Bayesian uncertainty estimation. We relate our approach to other classical and contemporary methods for exploration and present an empirical analysis of successor uncertainties.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper941/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9b9679607e4c1731693b79061e46dbb211bfd418.pdf", "paperhash": "anonymous|successor_uncertainties_exploration_and_uncertainty_in_temporal_difference_learning", "_bibtex": "@inproceedings{    \nanonymous2019successor,    \ntitle={Successor Uncertainties: exploration and uncertainty in temporal difference learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklACjAqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkx0RjA9tX", "original": "Bklwu0TqK7", "number": 942, "cdate": 1538087893880, "ddate": null, "tcdate": 1538087893880, "tmdate": 1538156024414, "tddate": null, "forum": "Bkx0RjA9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative Question Answering: Learning to Answer the Whole Question", "abstract": "Discriminative  question  answering  models  can  overfit  to  superficial  biases  in datasets,  because their loss function saturates when any clue makes the answer likely.  We introduce generative models of the joint distribution of questions and answers, which are trained to explain the whole question, not just to answer it.Our  question  answering  (QA)  model  is  implemented  by  learning  a  prior  over answers,  and  a  conditional  language  model  to  generate  the  question  given  the answer\u2014allowing scalable and interpretable many-hop reasoning as the question is generated word-by-word.  Our model achieves competitive performance with specialised discriminative models on the SQUAD and CLEVR benchmarks, indicating that it is a more general architecture for language understanding and reasoning than previous work. The model greatly improves generalisation both from biased training data and to adversarial testing data, achieving a new state-of-the-art on ADVERSARIAL SQUAD. We will release our code.", "keywords": ["Question answering", "question generation", "reasoning", "squad", "clevr"], "authorids": ["ICLR.cc/2019/Conference/Paper942/Authors"], "authors": ["Anonymous"], "TL;DR": "Question answering models that model the joint distribution of questions and answers can learn more than discriminative models", "pdf": "/pdf/bd627440b6d7f8f9f7e6376656ef48b847d11ab6.pdf", "paperhash": "anonymous|generative_question_answering_learning_to_answer_the_whole_question", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Question Answering: Learning to Answer the Whole Question},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkx0RjA9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gRCiA5Ym", "original": "HkltZ9a9Fm", "number": 943, "cdate": 1538087894051, "ddate": null, "tcdate": 1538087894051, "tmdate": 1538156024209, "tddate": null, "forum": "r1gRCiA5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Jumpout: Improved Dropout for Deep Neural Networks with Rectified Linear Units", "abstract": "Dropout is a simple yet effective technique to improve the generalization\nperformance and prevent overfitting in deep neural networks (DNNs). In this\npaper, we discuss three novel observations about dropout to better understand\nthe generalization of DNNs with rectified linear unit (ReLU) activations: 1)\ndropout is a smoothing technique that encourages each local linear model of a\nDNN to be trained on data points from nearby regions; 2) a constant dropout\nrate can result in effective neural-deactivation rates that are significantly\ndifferent for layers with different fractions of activated neurons; and 3) the\nrescaling factor of dropout causes an inconsistency to occur between the\nnormalization during training and testing conditions when batch normalization\nis also used.  The above leads to three simple but nontrivial improvements to\ndropout resulting in our proposed method \"Jumpout.\" Jumpout samples the\ndropout rate using a monotone decreasing distribution (such as the right part\nof a truncated Gaussian), so the local linear model at each data point is\ntrained, with high probability, to work better for data points from nearby\nthan from more distant regions. Instead of tuning a dropout rate for each\nlayer and applying it to all samples, jumpout moreover adaptively normalizes\nthe dropout rate at each layer and every training sample/batch, so the\neffective dropout rate applied to the activated neurons are kept the same.\nMoreover, we rescale the outputs of jumpout for a better trade-off that keeps\nboth the variance and mean of neurons more consistent between training and\ntest phases, which mitigates the incompatibility between dropout and batch\nnormalization. Compared to the original dropout, jumpout shows significantly\nimproved performance on CIFAR10, CIFAR100, Fashion- MNIST, STL10, SVHN,\nImageNet-1k, etc., while introducing negligible additional memory and\ncomputation costs.", "keywords": ["Dropout", "deep neural networks with ReLU", "local linear model"], "authorids": ["ICLR.cc/2019/Conference/Paper943/Authors"], "authors": ["Anonymous"], "TL;DR": "Jumpout applies three simple yet effective modifications to dropout, based on novel understandings about the generalization performance of DNN with ReLU in local regions.", "pdf": "/pdf/08b0b5bf155d92c61aad4547f7de0c958181d9a6.pdf", "paperhash": "anonymous|jumpout_improved_dropout_for_deep_neural_networks_with_rectified_linear_units", "_bibtex": "@inproceedings{    \nanonymous2019jumpout:,    \ntitle={Jumpout: Improved Dropout for Deep Neural Networks with Rectified Linear Units},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gRCiA5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eCCoR5tm", "original": "SJlJ0O_qFm", "number": 944, "cdate": 1538087894218, "ddate": null, "tcdate": 1538087894218, "tmdate": 1538156023991, "tddate": null, "forum": "B1eCCoR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pseudosaccades: A simple ensemble scheme for improving classification performance of deep nets", "abstract": "We describe a simple ensemble approach that, unlike conventional ensembles,\nuses multiple random data sketches (\u2018pseudosaccades\u2019) rather than multiple classifiers\nto improve classification performance. Using this simple, but novel, approach\nwe obtain statistically significant improvements in classification performance on\nAlexNet, GoogLeNet, ResNet-50 and ResNet-152 baselines on Imagenet data \u2013\ne.g. of the order of 0.3% to 0.6% in Top-1 accuracy and similar improvements in\nTop-k accuracy \u2013 essentially nearly for free.", "keywords": ["Ensemble classification", "random subspace", "data sketching"], "authorids": ["ICLR.cc/2019/Conference/Paper944/Authors"], "authors": ["Anonymous"], "TL;DR": "Inspired by saccades we describe a simple, cheap, effective way to improve deep net performance on an image labelling task.", "pdf": "/pdf/a9ec0296dd47dbd5ad016d98de10f927212f77b7.pdf", "paperhash": "anonymous|pseudosaccades_a_simple_ensemble_scheme_for_improving_classification_performance_of_deep_nets", "_bibtex": "@inproceedings{    \nanonymous2019pseudosaccades:,    \ntitle={Pseudosaccades: A simple ensemble scheme for improving classification performance of deep nets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eCCoR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gARiAcFm", "original": "B1eGDiactQ", "number": 945, "cdate": 1538087894387, "ddate": null, "tcdate": 1538087894387, "tmdate": 1538156023778, "tddate": null, "forum": "S1gARiAcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Modeling Dynamics of Biological Systems with Deep Generative Neural Networks", "abstract": "Biological data often contains measurements of dynamic entities such as cells or organisms in various states of progression. However, biological systems are notoriously difficult to describe analytically due to their many interacting components, and in many cases, the technical challenge of taking longitudinal measurements. This leads to difficulties in studying the features of the dynamics, for examples the drivers of the transition. To address this problem, we present a deep neural network framework we call Dynamics Modeling Network or DyMoN. DyMoN is a neural network framework trained as a deep generative Markov model whose next state is a probability distribution based on the current state. DyMoN is well-suited to the idiosyncrasies of biological data, including noise, sparsity, and the lack of longitudinal measurements in many types of systems. Thus, DyMoN can be trained using probability distributions derived from the data in any way, such as trajectories derived via dimensionality reduction methods, and does not require longitudinal measurements. We show the advantage of learning deep models over shallow models such as Kalman filters and hidden Markov models that do not learn representations of the data, both in terms of learning embeddings of the data and also in terms training efficiency, accuracy and ability to multitask. We perform three case studies of applying DyMoN to different types of biological systems and extracting features of the dynamics in each case by examining the learned model. ", "keywords": ["neural networks", "markovian dynamics", "single-cell biology", "calcium imaging", "stochastic dynamics", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper945/Authors"], "authors": ["Anonymous"], "TL;DR": "Dynamics Modeling Networks (DyMoN) offer advantages in representation, generation, visualization and feature extraction over shallow learning techniques for modeling stochastic dynamical systems in biology.", "pdf": "/pdf/991e2b1de4ebb49b53f18bc824b362fe744afffd.pdf", "paperhash": "anonymous|modeling_dynamics_of_biological_systems_with_deep_generative_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019modeling,    \ntitle={Modeling Dynamics of Biological Systems with Deep Generative Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gARiAcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJl11nCctX", "original": "SygjnkmcF7", "number": 946, "cdate": 1538087894564, "ddate": null, "tcdate": 1538087894564, "tmdate": 1538156023570, "tddate": null, "forum": "SJl11nCctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TFGAN: Improving Conditioning for Text-to-Video Synthesis", "abstract": "Developing conditional generative models for text-to-video synthesis is an extremely challenging yet an important topic of research in machine learning. In this work, we address this problem by introducing Text-Filter conditioning Generative Adversarial Network (TFGAN), a GAN model with novel conditioning scheme that aids improving the text-video associations. With a combination of this conditioning scheme and a deep GAN architecture, TFGAN generates photo-realistic videos from text on very challenging real-world video datasets. In addition, we construct a benchmark synthetic dataset of moving shapes to systematically evaluate our conditioning scheme. Extensive experiments demonstrate that TFGAN significantly outperforms the existing approaches, and can also generate videos of novel categories not seen during training.\n", "keywords": ["Conditional GAN", "Video Generation", "Text-to-Video Synthesis", "Conditional Generative Models", "Deep Generative Models"], "authorids": ["ICLR.cc/2019/Conference/Paper946/Authors"], "authors": ["Anonymous"], "TL;DR": "An effective text-conditioning GAN framework for generating videos from text", "pdf": "/pdf/059c7c20d075a8066b344f47beab9a6724fb7cb3.pdf", "paperhash": "anonymous|tfgan_improving_conditioning_for_texttovideo_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019tfgan:,    \ntitle={TFGAN: Improving Conditioning for Text-to-Video Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl11nCctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJekyhCctQ", "original": "HylvtrgcK7", "number": 947, "cdate": 1538087894732, "ddate": null, "tcdate": 1538087894732, "tmdate": 1538156023366, "tddate": null, "forum": "SJekyhCctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Detecting Adversarial Examples Via Neural Fingerprinting", "abstract": "Deep neural networks are vulnerable to adversarial examples: input data that has been manipulated to cause dramatic model output errors. To defend against such attacks, we propose NeuralFingerprinting: a simple, yet effective method to detect adversarial examples that verifies whether model behavior is consistent with a set of fingerprints. These fingerprints are encoded into the model response during training and are inspired by the use of biometric and cryptographic signatures. In contrast to previous defenses, our method does not rely on knowledge of the adversary and can scale to large networks and input data. The benefits of our method are that 1) it is fast, 2) it is prohibitively expensive for an attacker to reverse-engineer which fingerprints were used, and 3) it does not assume knowledge of the adversary. In this work, we 1) theoretically analyze NeuralFingerprinting for linear models and 2) show that NeuralFingerprinting significantly improves on state-of-the-art detection mechanisms for deep neural networks, by detecting the strongest known adversarial attacks with 98-100% AUC-ROC scores on the MNIST, CIFAR-10 and MiniImagenet (20 classes) datasets.  In particular, we consider several threat models, including the most conservative one in which the attacker has full knowledge of the defender's strategy. In all settings, the detection accuracy of NeuralFingerprinting generalizes well to unseen test-data and is robust over a wide range of hyperparameters.", "keywords": ["Adversarial Attacks", "Deep Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper947/Authors"], "authors": ["Anonymous"], "TL;DR": "Novel technique for detecting adversarial examples -- robust across gradient-based and gradient-free attacks, AUC-ROC >95%", "pdf": "/pdf/4034fc12e381bf618f8e5da5b923f44bf8255d7a.pdf", "paperhash": "anonymous|detecting_adversarial_examples_via_neural_fingerprinting", "_bibtex": "@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Adversarial Examples Via Neural Fingerprinting},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJekyhCctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygkk305YQ", "original": "B1g1HvhqKQ", "number": 948, "cdate": 1538087894902, "ddate": null, "tcdate": 1538087894902, "tmdate": 1538156023151, "tddate": null, "forum": "rygkk305YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Generative Modeling for Controllable Speech Synthesis", "abstract": "This paper proposes a neural end-to-end text-to-speech (TTS) model which can control latent attributes in the generated speech that are rarely annotated in the training data, such as speaking style, accent, background noise, and recording conditions. The model is formulated as a conditional generative model with two levels of hierarchical latent variables. The first level is a categorical variable, which represents attribute groups (e.g. clean/noisy) and provides interpretability. The second level, conditioned on the first, is a multivariate Gaussian variable, which characterizes specific attribute configurations (e.g. noise level, speaking rate) and enables disentangled fine-grained control over these attributes. This amounts to using a Gaussian mixture model (GMM) for the latent distribution. Extensive evaluation demonstrates its ability to control the aforementioned attributes. In particular, it is capable of consistently synthesizing high-quality clean speech regardless of the quality of the training data for the target speaker.", "keywords": ["speech synthesis", "representation learning", "deep generative model", "sequence-to-sequence model"], "authorids": ["ICLR.cc/2019/Conference/Paper948/Authors"], "authors": ["Anonymous"], "TL;DR": "Building a TTS model with Gaussian Mixture VAEs enables fine-grained control of speaking style, noise condition, and more.", "pdf": "/pdf/9aaa58e7ae3839296299c2c54b804dc05779ce52.pdf", "paperhash": "anonymous|hierarchical_generative_modeling_for_controllable_speech_synthesis", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Generative Modeling for Controllable Speech Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygkk305YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJe1y3CqtX", "original": "ryxcCppqF7", "number": 949, "cdate": 1538087895084, "ddate": null, "tcdate": 1538087895084, "tmdate": 1538156022942, "tddate": null, "forum": "rJe1y3CqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Reinforcement Learning of Universal Policies with Diverse Environment Summaries", "abstract": "Deep reinforcement learning has enabled robots to complete complex tasks in simulation. However, the resulting policies do not transfer to real robots due to model errors in the simulator. One solution is to randomize the simulation environment, so that the resulting, trained policy achieves high performance in expectation over a variety of configurations that could represent the real-world. However, the distribution over simulator configurations must be carefully selected to represent the relevant dynamic modes of the system, as otherwise it can be unlikely to sample challenging configurations frequently enough. Moreover, the ideal distribution to improve the policy changes as the policy (un)learns to solve tasks in certain configurations. In this paper, we propose to use an inexpensive, kernel-based summarization method method that identifies configurations that lead to diverse behaviors. Since failure modes for the given task are naturally diverse, the policy trains on a mixture of representative and challenging configurations, which leads to more robust policies. In experiments, we show that the proposed method achieves the same performance as domain randomization in simple cases, but performs better when domain randomization does not lead to diverse dynamic modes.", "keywords": ["Domain Randomization", "Diverse Summaries", "Reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper949/Authors"], "authors": ["Anonymous"], "TL;DR": "As an alternative to domain randomization, we summarize simulator configurations to ensure that the policy is trained on a diverse set of induced state-trajectories.", "pdf": "/pdf/dfa4e50fdab1517a7e1d0d98b8779c3a601acab4.pdf", "paperhash": "anonymous|deep_reinforcement_learning_of_universal_policies_with_diverse_environment_summaries", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Reinforcement Learning of Universal Policies with Diverse Environment Summaries},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJe1y3CqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lJJnR5Ym", "original": "S1x-r2T5KX", "number": 950, "cdate": 1538087895251, "ddate": null, "tcdate": 1538087895251, "tmdate": 1538156022728, "tddate": null, "forum": "H1lJJnR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploration by random distillation", "abstract": "We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access the underlying state of the game, and occasionally completes the first level. This suggests that relatively simple methods that scale well can be sufficient to tackle challenging exploration problems.", "keywords": ["reinforcement learning", "exploration", "curiosity"], "authorids": ["ICLR.cc/2019/Conference/Paper950/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.", "pdf": "/pdf/044c44326fb23a7edfdbf8e6eb009d388a882002.pdf", "paperhash": "anonymous|exploration_by_random_distillation", "_bibtex": "@inproceedings{    \nanonymous2019exploration,    \ntitle={Exploration by random distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lJJnR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgkJn05YX", "original": "Hke6nDo9Fm", "number": 951, "cdate": 1538087895411, "ddate": null, "tcdate": 1538087895411, "tmdate": 1538156022521, "tddate": null, "forum": "SkgkJn05YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RANDOM MASK: Towards Robust Convolutional Neural Networks", "abstract": "Robustness of neural networks has recently been highlighted by the adversarial examples, i.e., inputs added with well-designed  perturbations which are imperceptible to humans but can cause the network to give incorrect outputs. In this paper, we design a new CNN architecture that by itself has good robustness. We introduce a simple but powerful technique, Random Mask, to modify existing CNN structures. We show that CNN with Random Mask achieves state-of-the-art performance against black-box adversarial attacks without applying any adversarial training. We next investigate the adversarial examples which \u201cfool\u201d a CNN with Random Mask. Surprisingly, we find that these adversarial examples often \u201cfool\u201d humans as well. This raises fundamental questions on how to define adversarial examples and robustness properly.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper951/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/192c93afed6f68d131bd66ee8949b56c07d26299.pdf", "paperhash": "anonymous|random_mask_towards_robust_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019random,    \ntitle={RANDOM MASK: Towards Robust Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgkJn05YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xeyhCctQ", "original": "r1gxupaqFX", "number": 952, "cdate": 1538087895601, "ddate": null, "tcdate": 1538087895601, "tmdate": 1538156022310, "tddate": null, "forum": "B1xeyhCctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bias Also Matters: Bias Attribution for Deep Neural Network Explanation", "abstract": "The gradient of a deep neural network (DNN) w.r.t. the input provides\ninformation that can be used to explain the output prediction in terms of the\ninput features and has been widely studied to assist in interpreting DNNs.  In\na linear model (i.e., $g(x)=wx+b$), the gradient corresponds solely to the\nweights $w$. Such a model can reasonably locally linearly approximate a smooth\nnonlinear DNN, and hence the weights of this local model are the gradient.\nThe other part, however, of a local linear model, i.e., the bias $b$, is\nusually overlooked in attribution methods since it is not part of the\ngradient. In this paper, we observe that since the bias in a DNN also has a\nnon-negligible contribution to the correctness of predictions, it can also\nplay a significant role in understanding DNN behaviors. In particular, we\nstudy how to attribute a DNN's bias to its input features. We propose a\nbackpropagation-type algorithm ``bias back-propagation (BBp)'' that starts at\nthe output layer and iteratively attributes the bias of each layer to its\ninput nodes as well as combining the resulting bias term of the previous\nlayer. This process stops at the input layer, where summing up the\nattributions over all the input features exactly recovers $b$. Together with\nthe backpropagation of the gradient generating $w$, we can fully recover the\nlocally linear model $g(x)=wx+b$. Hence, the attribution of the DNN outputs to\nits inputs is decomposed into two parts, the gradient $w$ and the bias\nattribution, providing separate and complementary explanations. We study\nseveral possible attribution methods applied to the bias of each layer in BBp.\nIn experiments, we show that BBp can generate complementary and highly\ninterpretable explanations of DNNs in addition to gradient-based attributions.", "keywords": ["explainable AI", "interpreting deep neural networks", "bias", "attribution method", "piecewise linear activation function", "backpropagation"], "authorids": ["ICLR.cc/2019/Conference/Paper952/Authors"], "authors": ["Anonymous"], "TL;DR": "Attribute the bias terms of deep neural networks to input features by a backpropagation-type algorithm; Generate complementary and highly interpretable explanations of DNNs in addition to gradient-based attributions.", "pdf": "/pdf/454fcd18c486384174c3abc2c15b42b6515ac45f.pdf", "paperhash": "anonymous|bias_also_matters_bias_attribution_for_deep_neural_network_explanation", "_bibtex": "@inproceedings{    \nanonymous2019bias,    \ntitle={Bias Also Matters: Bias Attribution for Deep Neural Network Explanation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xeyhCctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1geJhC9Km", "original": "Syxe6C6ctm", "number": 953, "cdate": 1538087895772, "ddate": null, "tcdate": 1538087895772, "tmdate": 1538156022102, "tddate": null, "forum": "S1geJhC9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Feature quantization for parsimonious and meaningful predictive models", "abstract": "For regulatory and interpretability reasons, the logistic regression is still widely used by financial institutions to learn the refunding probability of a loan given the applicant's characteristics from historical data. Although logistic regression handles naturally both continuous and categorical data, a preprocessing step to quantize them is usually performed for improving simultaneously prediction accuracy and user interpretability: continuous features are discretized by assigning factor levels to intervals; some levels of categorical features (with numerous levels) are grouped.\nHowever, a better predictive accuracy can be reached by embedding this quantization estimation step directly into the predictive estimation step itself. A related information criterion has then to be optimized on a huge and untractable discontinuous quantization set, requiring to introduce a specific two-step optimization strategy: first, the optimization problem is relaxed in order to deal with smooth functions; second, a particular neural network is involved through a stochastic gradient algorithm to optimize the resulting criterion, giving access to good candidates for the initial optimization problem. The good performances of this approach are illustrated on simulated and real data from Cr\u00e9dit Agricole Consumer Finance (a major European historic player in the consumer credit market).", "keywords": ["discretization", "grouping", "interpretability", "shallow neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper953/Authors"], "authors": ["Anonymous"], "TL;DR": "We tackle discretization of continuous features and grouping of factor levels as a representation learning problem and provide a rigorous way of estimating the best quantization to yield good performance and interpretability.", "pdf": "/pdf/d09eaaa21d7b16e7acb32d15f35b3c1df45e3cb4.pdf", "paperhash": "anonymous|feature_quantization_for_parsimonious_and_meaningful_predictive_models", "_bibtex": "@inproceedings{    \nanonymous2019feature,    \ntitle={Feature quantization for parsimonious and meaningful predictive models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1geJhC9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxgknCcK7", "original": "rkgWtPhcYX", "number": 954, "cdate": 1538087895940, "ddate": null, "tcdate": 1538087895940, "tmdate": 1538156021887, "tddate": null, "forum": "rJxgknCcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Scalable Reversible Generative Models with Free-form Continuous Dynamics", "abstract": "A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network.   Likelihood-based training  of  these  models  requires  restricting  their  architectures  to  allow  cheap computation of Jacobian determinants.  Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson\u2019s trace estimator to give a scalable unbiased estimate of the log-density.  The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density  estimation,  image  generation,  and  variational  inference,  achieving  the state-of-the-art among exact likelihood methods with efficient sampling.", "keywords": ["generative models", "density estimation", "approximate inference", "ordinary differential equations"], "authorids": ["ICLR.cc/2019/Conference/Paper954/Authors"], "authors": ["Anonymous"], "TL;DR": "We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.", "pdf": "/pdf/b26b11a971f38107136bf68aa2fd8948bdc74aa4.pdf", "paperhash": "anonymous|scalable_reversible_generative_models_with_freeform_continuous_dynamics", "_bibtex": "@inproceedings{    \nanonymous2019scalable,    \ntitle={Scalable Reversible Generative Models with Free-form Continuous Dynamics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxgknCcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkzeJ3A9F7", "original": "SkgD99aqtm", "number": 955, "cdate": 1538087896110, "ddate": null, "tcdate": 1538087896110, "tmdate": 1538156021680, "tddate": null, "forum": "SkzeJ3A9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Beyond Games: Bringing Exploration to Robots in Real-world", "abstract": "Exploration has been a long standing problem in both model-based and model-free learning methods for sensorimotor control. While there has been major advances over the years, most of these successes have been demonstrated in either video games or simulation environments. This is primarily because the rewards (even the intrinsic ones) are non-differentiable since they are function of the environment (which is a black-box). In this paper, we focus on the policy optimization aspect of the intrinsic reward function. Specifically, by using a local approximation, we formulate intrinsic reward as a differentiable function so as to perform policy optimization using likelihood maximization -- much like supervised learning instead of reinforcement learning. This leads to a significantly sample efficient exploration policy. Our experiments clearly show that our approach outperforms both on-policy and off-policy optimization approaches like REINFORCE and DQN respectively. But most importantly, we are able to implement an exploration policy on a robot which learns to interact with objects completely from scratch just using data collected via the differentiable exploration module.", "keywords": ["Exploration", "curiosity", "manipulation"], "authorids": ["ICLR.cc/2019/Conference/Paper955/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2ed67a548dd537b453643e5d2d0bfc68c96ffc2d.pdf", "paperhash": "anonymous|beyond_games_bringing_exploration_to_robots_in_realworld", "_bibtex": "@inproceedings{    \nanonymous2019beyond,    \ntitle={Beyond Games: Bringing Exploration to Robots in Real-world},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkzeJ3A9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkelJnRqt7", "original": "HkeNU955FX", "number": 956, "cdate": 1538087896282, "ddate": null, "tcdate": 1538087896282, "tmdate": 1538156021475, "tddate": null, "forum": "SkelJnRqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural separation of observed and unobserved distributions", "abstract": "Separating mixed distributions is a long standing challenge for machine learning and signal processing. Applications include: single-channel multi-speaker separation (cocktail party problem), singing voice separation and separating reflections from images. Most current methods either rely on making strong assumptions on the source distributions (e.g. sparsity, low rank, repetitiveness) or rely on having training samples of each source in the mixture. In this work, we tackle the scenario of extracting an unobserved distribution additively mixed with a signal from an observed (arbitrary) distribution. We introduce a new method: Neural Egg Separation - an iterative method that learns to separate the known distribution from progressively finer estimates of the unknown distribution. In some settings, Neural Egg Separation is initialization sensitive, we therefore introduce GLO Masking which ensures a good initialization. Extensive experiments show that our method outperforms current methods that use the same level of supervision and often achieves similar performance to full supervision. ", "keywords": ["source separation", "non-adversarial training", "source unmixing", "iterative neural training", "generative modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper956/Authors"], "authors": ["Anonymous"], "TL;DR": "An iterative neural method for extracting signals that are only observed mixed with other signals", "pdf": "/pdf/20a53b512be032b01ed97f9619ffcc4c6b7050cd.pdf", "paperhash": "anonymous|neural_separation_of_observed_and_unobserved_distributions", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural separation of observed and unobserved distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkelJnRqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlg1n05YX", "original": "Sklkvtp5Km", "number": 957, "cdate": 1538087896451, "ddate": null, "tcdate": 1538087896451, "tmdate": 1538156021262, "tddate": null, "forum": "rJlg1n05YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Penetrating the Fog: the Path to Efficient CNN Models", "abstract": "With the increasing demand to deploy convolutional neural networks (CNNs) on mobile platforms, the sparse kernel approach was proposed, which could save more parameters than the standard convolution while maintaining accuracy. However, despite the great potential, no prior research has pointed out how to craft an sparse kernel design with such potential (i.e., effective design), and all prior works just adopt simple combinations of existing sparse kernels such as group convolution. Meanwhile due to the large design space it is also impossible to try all combinations of existing sparse kernels. In this paper, we are the first in the field to consider how to craft an effective sparse kernel design by eliminating the large design space. Specifically, we present a sparse kernel scheme to illustrate how to reduce the space from three aspects. First, in terms of composition we remove designs composed of repeated layers. Second, to remove designs with large accuracy degradation, we find an unified property named~\\emph{information field} behind various sparse kernel designs, which could directly indicate the final accuracy. Last, we remove designs in two cases where a better parameter efficiency could be achieved. Additionally, we provide detailed efficiency analysis on the final 4 designs in our scheme. Experimental results validate the idea of our scheme by showing that our scheme is able to find designs which are more efficient in using parameters and computation with similar or higher accuracy.", "keywords": ["Efficient CNN models", "Computer Vision"], "authorids": ["ICLR.cc/2019/Conference/Paper957/Authors"], "authors": ["Anonymous"], "TL;DR": "We are the first in the field to show how to craft an effective sparse kernel design from three aspects: composition, performance and efficiency.", "pdf": "/pdf/09dd80df69fc22779a3fa0bb14dedb8f31fa2232.pdf", "paperhash": "anonymous|penetrating_the_fog_the_path_to_efficient_cnn_models", "_bibtex": "@inproceedings{    \nanonymous2019penetrating,    \ntitle={Penetrating the Fog: the Path to Efficient CNN Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlg1n05YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygZJ2RcF7", "original": "HJgdo-69tQ", "number": 958, "cdate": 1538087896632, "ddate": null, "tcdate": 1538087896632, "tmdate": 1538156021050, "tddate": null, "forum": "rygZJ2RcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Out-of-Sample Extrapolation with Neuron Editing", "abstract": "While neural networks can be trained to map from one specific dataset to another, they usually do not learn a generalized transformation that can extrapolate accurately outside the space of training. For instance, a generative adversarial network (GAN) exclusively trained to transform images of cars from light to dark might not have the same effect on images of horses. This is because neural networks are good at generation within the manifold of the data that they are trained on. However, generating new samples outside of the manifold or extrapolating \"out-of-sample\" is a much harder problem that has been less well studied. To address this, we introduce a technique called neuron editing that learns how neurons encode an edit for a particular transformation in a latent space. We use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in a latent trained space, we encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron's activations. We showcase our technique on image domain/style transfer and two biological applications: removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs.", "keywords": ["generative adversarial networks", "computational biology", "generating", "generation", "extrapolation", "out-of-sample", "neural network inference"], "authorids": ["ICLR.cc/2019/Conference/Paper958/Authors"], "authors": ["Anonymous"], "TL;DR": "We reframe the generation problem as one of editing existing points, and as a result extrapolate better than traditional GANs.", "pdf": "/pdf/85b6f6aec1bc2cb6cbd511b6282d2b97c6467066.pdf", "paperhash": "anonymous|outofsample_extrapolation_with_neuron_editing", "_bibtex": "@inproceedings{    \nanonymous2019out-of-sample,    \ntitle={Out-of-Sample Extrapolation with Neuron Editing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygZJ2RcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hke-JhA9Y7", "original": "rylSWld5YX", "number": 959, "cdate": 1538087896802, "ddate": null, "tcdate": 1538087896802, "tmdate": 1538156020844, "tddate": null, "forum": "Hke-JhA9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning concise representations for regression by evolving networks of trees", "abstract": " We propose and study a method for learning interpretable representations for the task of regression. Features are represented as networks of multi-type expression trees comprised of activation functions common in neural networks in addition to other elementary functions. Differentiable features are trained via gradient descent, and the performance of features in a linear model is used to weight the rate of change among subcomponents of each representation. The search process maintains an archive of representations with accuracy-complexity trade-offs to assist in generalization and interpretation. We compare several stochastic optimization approaches within this framework. We benchmark these variants on 99 open-source regression problems in comparison to state-of-the-art machine learning approaches. Our main finding is that this approach produces the highest average test scores across problems while producing representations that are orders of magnitude smaller than the next best performing method (gradient boosting). We also report a negative result in which attempts to directly optimize the disentanglement of the representation results in more highly correlated features.  ", "keywords": ["regression", "stochastic optimization", "evolutionary compution", "feature engineering"], "authorids": ["ICLR.cc/2019/Conference/Paper959/Authors"], "authors": ["Anonymous"], "TL;DR": "Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. ", "pdf": "/pdf/1545965aaf68cee8839bd3b3ecf2a5c3781b357b.pdf", "paperhash": "anonymous|learning_concise_representations_for_regression_by_evolving_networks_of_trees", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning concise representations for regression by evolving networks of trees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hke-JhA9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkxWJnC9tX", "original": "HJgfgkRqKm", "number": 960, "cdate": 1538087896963, "ddate": null, "tcdate": 1538087896963, "tmdate": 1538156020631, "tddate": null, "forum": "BkxWJnC9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diversity and Depth in Per-Example Routing Models", "abstract": "Routing models, a form of conditional computation where examples are routed through a subset of components in a larger network, have shown promising results in recent works. Surprisingly, routing models to date have lacked important properties, such as architectural diversity and large numbers of routing decisions. Both architectural diversity and routing depth can increase the representational power of a routing network. In this work, we address both of these deficiencies. We discuss the significance of architectural diversity in routing models, and explain the tradeoffs between capacity and optimization when increasing routing depth. In our experiments, we find that adding architectural diversity to routing models significantly improves performance, cutting the error rates of a strong baseline by 35% on an Omniglot setup. However, when scaling up routing depth, we find that modern routing techniques struggle with optimization. We conclude by discussing both the positive and negative results, and suggest directions for future research.", "keywords": ["conditional computation", "routing models", "depth"], "authorids": ["ICLR.cc/2019/Conference/Paper960/Authors"], "authors": ["Anonymous"], "TL;DR": "Per-example routing models benefit from architectural diversity, but still struggle to scale to a large number of routing decisions.", "pdf": "/pdf/3b6a5d3e7328905af1cec0c99ac260245e31beb5.pdf", "paperhash": "anonymous|diversity_and_depth_in_perexample_routing_models", "_bibtex": "@inproceedings{    \nanonymous2019diversity,    \ntitle={Diversity and Depth in Per-Example Routing Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkxWJnC9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxZJn05YX", "original": "SylsaGzUY7", "number": 961, "cdate": 1538087897134, "ddate": null, "tcdate": 1538087897134, "tmdate": 1538156020423, "tddate": null, "forum": "SyxZJn05YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Feature Intertwiners", "abstract": "A well-trained model should classify objects with unanimous score for every category. This requires the high-level semantic features should be alike among samples, despite a wide span in resolution, texture, deformation, etc. Previous works focus on re-designing the loss function or proposing new regularization constraints on the loss. In this paper, we address this problem via a new perspective. For each category, it is assumed that there are two sets in the feature space: one with more reliable information and the other with less reliable source. We argue that the reliable set could guide the feature learning of the less reliable set during training - in spirit of student mimicking teacher\u2019s behavior and thus pushing towards a more compact class centroid in the high-dimensional space. Such a scheme also benefits the reliable set since samples become more closer within the same category - implying that it is easilier for the classifier to identify. We refer to this mutual learning process as feature intertwiner and embed the spirit into object detection. It is well-known that objects of low resolution are more difficult to detect due to the loss of detailed information during network forward pass. We thus regard objects of high resolution as the reliable set and objects of low resolution as the less reliable set. Specifically, an intertwiner is achieved by minimizing the distribution divergence between two sets. We design a historical buffer to represent all previous samples in the reliable set and utilize them to guide the feature learning of the less reliable set. The design of obtaining an effective feature representation for the reliable set is further investigated, where we introduce the optimal transport (OT) algorithm into the framework. Samples in the less reliable set are better aligned with the reliable set with aid of OT metric. Incorporated with such a plug-and-play intertwiner, we achieve an evident improvement over previous state-of-the-arts on the COCO object detection benchmark.", "keywords": ["feature learning", "computer vision", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper961/Authors"], "authors": ["Anonymous"], "TL;DR": "A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.", "pdf": "/pdf/128a4d0207433e4890b7e9344ace2e6b1865dcef.pdf", "paperhash": "anonymous|feature_intertwiners", "_bibtex": "@inproceedings{    \nanonymous2019feature,    \ntitle={Feature Intertwiners},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxZJn05YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1zW13R5tm", "original": "BJlWMAbdKX", "number": 962, "cdate": 1538087897306, "ddate": null, "tcdate": 1538087897306, "tmdate": 1538156020215, "tddate": null, "forum": "H1zW13R5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions", "abstract": "Deep neural networks (DNNs) are widely adopted in real-world cognitive applications because of their high accuracy. The robustness of DNN models, however, has been recently challenged by adversarial attacks where small disturbance on input samples may result in misclassification. State-of-the-art defending algorithms, such as adversarial training or robust optimization, improve DNNs' resilience to adversarial attacks by paying high computational costs. Moreover, these approaches are usually designed to defend one or a few known attacking techniques only. The effectiveness to defend other types of attacking methods, especially those that have not yet been discovered or explored, cannot be guaranteed. This work aims for a general approach of enhancing the robustness of DNN models under adversarial attacks. In particular, we propose Bamboo -- the first data augmentation method designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms. Bamboo augments the training data set with a small amount of data uniformly sampled on a fixed radius ball around each training data and hence, effectively increase the distance between natural data points and decision boundary. Our experiments show that Bamboo substantially improve the general robustness against arbitrary types of attacks and noises, achieving better results comparing to previous adversarial training methods, robust optimization methods and other data augmentation methods with the same amount of data points.", "keywords": ["DNN robustness", "Adversarial attack", "Data augmentation"], "authorids": ["ICLR.cc/2019/Conference/Paper962/Authors"], "authors": ["Anonymous"], "TL;DR": "The first data augmentation method specially designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms.", "pdf": "/pdf/6896bc9431ad602b5f7330cd8759094e753c037b.pdf", "paperhash": "anonymous|bamboo_ballshape_data_augmentation_against_adversarial_attacks_from_all_directions", "_bibtex": "@inproceedings{    \nanonymous2019bamboo:,    \ntitle={Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1zW13R5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkMW1hRqKX", "original": "rke4OqhcK7", "number": 963, "cdate": 1538087897472, "ddate": null, "tcdate": 1538087897472, "tmdate": 1538156020004, "tddate": null, "forum": "rkMW1hRqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimal Completion Distillation for Sequence Learning", "abstract": "We present Optimal Completion Distillation (OCD), a training procedure for optimizing sequence to sequence models based on edit distance. OCD is efficient, has no hyper-parameters of its own, and does not require pre-training or joint optimization with conditional log-likelihood. Given a partial sequence generated by the model, we first identify the set of optimal suffixes that minimize the total edit distance, using an efficient dynamic programming algorithm.  Then, for each position of the generated sequence, we use a target distribution which puts equal probability on the first token of all the optimal suffixes. OCD achieves the state-of-the-art performance on end-to-end speech recognition, on both Wall Street Journal and Librispeech datasets, achieving $9.3\\%$ WER and $4.8\\%$ WER, respectively.", "keywords": ["Sequence Learning", "Edit Distance", "Speech Recognition", "Deep Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper963/Authors"], "authors": ["Anonymous"], "TL;DR": "Optimal Completion Distillation (OCD) is a training procedure for optimizing sequence to sequence models based on edit distance which achieves state-of-the-art on end-to-end Speech Recognition tasks.", "pdf": "/pdf/496b76a206dba05254e649b9e3058b3665c024cf.pdf", "paperhash": "anonymous|optimal_completion_distillation_for_sequence_learning", "_bibtex": "@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal Completion Distillation for Sequence Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMW1hRqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bklzkh0qFm", "original": "S1xxzkCcFX", "number": 964, "cdate": 1538087897637, "ddate": null, "tcdate": 1538087897637, "tmdate": 1538156019798, "tddate": null, "forum": "Bklzkh0qFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Relational Graph Attention Networks", "abstract": "In this paper we present Relational Graph Attention Networks, an extension of Graph Attention Networks to incorporate both node features and relational information into a masked attention mechanism, extending graph-based attention methods to a wider variety of problems, specifically, predicting the properties of molecules. We demonstrate that our attention mechanism gives competitive results on a molecular toxicity classification task (Tox21), enhancing the performance of its spectral-based convolutional equivalent. We also investigate the model on a series of transductive knowledge base completion tasks, where its performance is noticeably weaker. We provide insights as to why this may be, and suggest when it is appropriate to incorporate an attention layer into a graph architecture.", "keywords": ["RGCN", "attention", "graph convolutional networks", "semi-supervised learning", "graph classification", "molecules"], "authorids": ["ICLR.cc/2019/Conference/Paper964/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new model for relational graphs and evaluate it on relational transductive and inductive tasks.", "pdf": "/pdf/c05d7ab6a0a780c490f1f734aa58193a74b50b23.pdf", "paperhash": "anonymous|relational_graph_attention_networks", "_bibtex": "@inproceedings{    \nanonymous2019relational,    \ntitle={Relational Graph Attention Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bklzkh0qFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgzJh0qtQ", "original": "HketzJA5Ym", "number": 965, "cdate": 1538087897812, "ddate": null, "tcdate": 1538087897812, "tmdate": 1538156019587, "tddate": null, "forum": "SJgzJh0qtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A SINGLE SHOT PCA-DRIVEN ANALYSIS OF NETWORK STRUCTURE TO REMOVE REDUNDANCY", "abstract": "Deep learning models have outperformed traditional methods in many fields such\nas natural language processing and computer vision. However, despite their\ntremendous success, the methods of designing optimal Convolutional Neural Networks\n(CNNs) are still based on heuristics or grid search. The resulting networks\nobtained using these techniques are often overparametrized with huge computational\nand memory requirements. This paper focuses on a structured, explainable\napproach towards optimal model design that maximizes accuracy while keeping\ncomputational costs tractable. We propose a single-shot analysis of a trained CNN\nthat uses Principal Component Analysis (PCA) to determine the number of filters\nthat are doing significant transformations per layer, without the need for retraining.\nIt can be interpreted as identifying the dimensionality of the hypothesis space\nunder consideration. The proposed technique also helps estimate an optimal number\nof layers by looking at the expansion of dimensions as the model gets deeper.\nThis analysis can be used to design an optimal structure of a given network on\na dataset, or help to adapt a predesigned network on a new dataset. We demonstrate\nthese techniques by optimizing VGG and AlexNet networks on CIFAR-10,\nCIFAR-100 and ImageNet datasets.", "keywords": ["deep learning", "model compression", "pruning", "PCA"], "authorids": ["ICLR.cc/2019/Conference/Paper965/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a single shot analysis of a trained neural network to remove redundancy and identify optimal network structure", "pdf": "/pdf/24bdde0b474f890711e4dc02615ca038609a17f5.pdf", "paperhash": "anonymous|a_single_shot_pcadriven_analysis_of_network_structure_to_remove_redundancy", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A SINGLE SHOT PCA-DRIVEN ANALYSIS OF NETWORK STRUCTURE TO REMOVE REDUNDANCY},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgzJh0qtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyzMyhCcK7", "original": "r1xsVYhKtm", "number": 966, "cdate": 1538087897979, "ddate": null, "tcdate": 1538087897979, "tmdate": 1538156019376, "tddate": null, "forum": "HyzMyhCcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ProxQuant: Quantized Neural Networks via Proximal Operators", "abstract": "To make deep neural networks feasible in resource-constrained environments (such as mobile devices), it is beneficial to quantize models by using low-precision weights. One common technique for quantizing neural networks is the straight-through gradient method, which enables back-propagation through the quantization mapping. Despite its empirical success, little is understood about why the straight-through gradient method works.\nBuilding upon a novel observation that the straight-through gradient method is in fact identical to the well-known Nesterov\u2019s dual-averaging algorithm on a quantization constrained optimization problem, we propose a more principled alternative approach, called ProxQuant , that formulates quantized network training as a regularized learning problem instead and optimizes it via the prox-gradient method. ProxQuant does back-propagation on the underlying full-precision vector and applies an efficient prox-operator in between stochastic gradient steps to encourage quantizedness. For quantizing ResNets and LSTMs, ProxQuant outperforms state-of-the-art results on binary quantization and is on par with state-of-the-art on multi-bit quantization. For binary quantization, our analysis shows both theoretically and experimentally that ProxQuant is more stable than the straight-through gradient method (i.e. BinaryConnect), challenging the indispensability of the straight-through gradient method and providing a powerful alternative.", "keywords": ["Model quantization", "Optimization", "Regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper966/Authors"], "authors": ["Anonymous"], "TL;DR": "A principled framework for model quantization using the proximal gradient method.", "pdf": "/pdf/bebf97fe48477be14aec8b508483d340650bf185.pdf", "paperhash": "anonymous|proxquant_quantized_neural_networks_via_proximal_operators", "_bibtex": "@inproceedings{    \nanonymous2019proxquant:,    \ntitle={ProxQuant: Quantized Neural Networks via Proximal Operators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyzMyhCcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xzyhR9Y7", "original": "BklnKGFtKX", "number": 967, "cdate": 1538087898154, "ddate": null, "tcdate": 1538087898154, "tmdate": 1538156019169, "tddate": null, "forum": "S1xzyhR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving Sentence Representations with Multi-view Frameworks", "abstract": "Multi-view learning can provide self-supervision when different views are available of the same data. Distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are plentiful in large unlabelled corpora. Motivated by the asymmetry in the two hemispheres of the human brain as well as the observation that different learning architectures tend to emphasise different aspects of sentence meaning, we present two multi-view frameworks for learning sentence representations in an unsupervised fashion. One framework uses a generative objective and the other a discriminative one. In both frameworks, the final representation is an ensemble of two views, in which, one view encodes the input sentence with a Recurrent Neural Network (RNN), and the other view encodes it with a simple linear model. We show that, after learning, the vectors produced by our multi-view frameworks provide improved representations over their single-view learned counterparts, and the combination of different views gives representational improvement over each view and demonstrates solid transferability on standard downstream tasks.", "keywords": ["multi-view", "learning", "sentence", "representation"], "authorids": ["ICLR.cc/2019/Conference/Paper967/Authors"], "authors": ["Anonymous"], "TL;DR": "Multi-view learning improves unsupervised sentence representation learning", "pdf": "/pdf/11b3b05f54d864347047897926172e8091d4d75b.pdf", "paperhash": "anonymous|improving_sentence_representations_with_multiview_frameworks", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Sentence Representations with Multi-view Frameworks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xzyhR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxG13R9Km", "original": "r1g77y0cY7", "number": 968, "cdate": 1538087898327, "ddate": null, "tcdate": 1538087898327, "tmdate": 1538156018962, "tddate": null, "forum": "SyxG13R9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification", "abstract": "Recent work has demonstrated the lack of robustness of well-trained deep neural networks (DNNs) to adversarial examples.  For example, visually indistinguishable perturbations, when mixed with an original image, can easily lead deep learning models to misclassifications.  In light of a recent study on the mutual influence between robustness and accuracy over 18 different ImageNet models, this paper investigates how training data affect the accuracy and robustness of deep neural\nnetworks. We conduct extensive experiments on four different datasets, including CIFAR-10, MNIST, STL-10, and Tiny ImageNet, with several representative neural networks. Our results reveal previously unknown phenomena that exist between the size of training data and characteristics of the resulting models. In particular, besides confirming that the model accuracy improves as the amount of training data increases, we also observe that the model robustness improves initially, but there exists a turning point after which robustness starts to deteriorate.  How and when such turning points occur vary for different neural networks and different datasets.", "keywords": ["Adversarial attacks", "Robustness", "CW", "I-FGSM"], "authorids": ["ICLR.cc/2019/Conference/Paper968/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c4a7bc22229085357d859b5f713f8ccb319fac28.pdf", "paperhash": "anonymous|how_training_data_affect_the_accuracy_and_robustness_of_neural_networks_for_image_classification", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxG13R9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxfJnC9YX", "original": "HyexZ_h9FQ", "number": 969, "cdate": 1538087898491, "ddate": null, "tcdate": 1538087898491, "tmdate": 1538156018762, "tddate": null, "forum": "BJxfJnC9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Spatio-Temporal Representations Using Spike-Based Backpropagation", "abstract": "Spiking neural networks (SNNs) offer a promising alternative to current artificial neural networks to enable low-power event-driven neuromorphic hardware. However, training SNNs remains a challenge primarily because of the complex non-differentiable neuronal behavior arising from their spike-based computation. In this paper, we propose an algorithm to train spiking autoencoders on regenerative learning tasks. A sigmoid approximation is used in place of the Leaky Integrate-and-Fire neuron's threshold based activation during backpropagation to enable differentiability. The loss is computed on the membrane potential of the output layer, which is then backpropagated through the network at each time step. These spiking autoencoders learn meaningful spatio-temporal representations of the data, across two modalities - audio and visual. We demonstrate audio to image synthesis in a spike-based environment by sharing these spatio-temporal representations between the two modalities. These models achieve very low reconstruction loss, comparable to ANNs, on MNIST and Fashion-MNIST datasets, and while converting TI-46 digits audio samples to MNIST images. ", "keywords": ["spiking neural networks", "autoencoders", "representation learning", "backpropagation", "multimodal"], "authorids": ["ICLR.cc/2019/Conference/Paper969/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/820d782a1eb38bc17b02b942b7d13c7bdf1d6648.pdf", "paperhash": "anonymous|learning_spatiotemporal_representations_using_spikebased_backpropagation", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Spatio-Temporal Representations Using Spike-Based Backpropagation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxfJnC9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rye7knCqK7", "original": "SygohGe9KQ", "number": 970, "cdate": 1538087898659, "ddate": null, "tcdate": 1538087898659, "tmdate": 1538156018554, "tddate": null, "forum": "rye7knCqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Individualized Controlled Continuous Communication Model for Multiagent Cooperative and Competitive Tasks", "abstract": "Learning when to communicate and doing that effectively is essential in multi-agent tasks. Recent works show that continuous communication allows efficient training with back-propagation in multi-agent scenarios, but have been restricted to fully-cooperative tasks. In this paper, we present Individualized Controlled Continuous Communication Model (IC3Net) which has better training efficiency than simple continuous communication model, and can be applied to semi-cooperative and competitive settings along with the cooperative settings. IC3Net controls continuous communication with a gating mechanism and uses individualized rewards foreach agent to gain better performance and scalability while fixing credit assignment issues. Using variety of tasks including StarCraft BroodWars explore and combat scenarios, we show that our network yields improved performance and convergence rates than the baselines as the scale increases. Our results convey that IC3Net agents learn when to communicate based on the scenario and profitability.", "keywords": ["multiagent", "communication", "competitive", "cooperative", "continuous", "emergent"], "authorids": ["ICLR.cc/2019/Conference/Paper970/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce IC3Net, a single network which can be used to train agents in cooperative, competitive and mixed scenarios. We also show that agents can learn when to communicate using our model.", "pdf": "/pdf/32d6830f4a88c46b5a39c8420234a038274b4df7.pdf", "paperhash": "anonymous|individualized_controlled_continuous_communication_model_for_multiagent_cooperative_and_competitive_tasks", "_bibtex": "@inproceedings{    \nanonymous2019individualized,    \ntitle={Individualized Controlled Continuous Communication Model for Multiagent Cooperative and Competitive Tasks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rye7knCqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxXynC9t7", "original": "HkeICYi9FQ", "number": 971, "cdate": 1538087898831, "ddate": null, "tcdate": 1538087898831, "tmdate": 1538156018348, "tddate": null, "forum": "HJxXynC9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Expressiveness in Deep Reinforcement Learning", "abstract": "Representation learning in reinforcement learning (RL) algorithms focuses on extracting useful features for choosing good actions. Expressive representations are essential for learning well-performed policies. In this paper, we study the relationship between the state representation assigned by the state extractor and the performance of the RL agent. We observe that representations assigned by the better state extractor are more scattered than which assigned by the worse one. Moreover, RL agents achieving high performances always have high rank matrices which are composed by their representations. Based on our observations, we formally define expressiveness of the state extractor as the rank of the matrix composed by representations. Therefore, we propose to promote expressiveness so as to improve algorithm performances, and we call it Expressiveness Promoted DRL. We apply our method on both policy gradient and value-based algorithms, and experimental results on 55 Atari games show the superiority of our proposed method.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper971/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/87421afc848df50f51a0b546dafb8c2ef2703750.pdf", "paperhash": "anonymous|expressiveness_in_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019expressiveness,    \ntitle={Expressiveness in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxXynC9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1g7y2RqYX", "original": "r1gXQxCYKm", "number": 972, "cdate": 1538087899061, "ddate": null, "tcdate": 1538087899061, "tmdate": 1538156018141, "tddate": null, "forum": "r1g7y2RqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Label Propagation Networks", "abstract": "Graph networks have recently attracted considerable interest, and in particular in the context of semi-supervised learning. These methods typically work by generating node representations that are propagated throughout a given weighted graph.\n\nHere we argue that for semi-supervised learning, it is more natural to consider propagating labels in the graph instead. Towards this end, we propose a differentiable neural version of the classic Label Propagation (LP) algorithm. This formulation can be used for learning edge weights, unlike other methods where weights are set heuristically. Starting from a layer implementing a single iteration of LP, we proceed by adding several important non-linear steps that significantly enhance the label-propagating mechanism.\n\nExperiments in two distinct settings demonstrate the utility of our approach.\n", "keywords": ["semi supervised learning", "graph networks", "deep learning architectures"], "authorids": ["ICLR.cc/2019/Conference/Paper972/Authors"], "authors": ["Anonymous"], "TL;DR": "Neural net for graph-based semi-supervised learning; revisits the classics and propagates *labels* rather than feature representations", "pdf": "/pdf/2768addc12ba552c746bf9512007c16cea2465d1.pdf", "paperhash": "anonymous|label_propagation_networks", "_bibtex": "@inproceedings{    \nanonymous2019label,    \ntitle={Label Propagation Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g7y2RqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bylmkh05KX", "original": "SyxCUa_cK7", "number": 973, "cdate": 1538087899228, "ddate": null, "tcdate": 1538087899228, "tmdate": 1538156017929, "tddate": null, "forum": "Bylmkh05KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching", "abstract": "We consider the problem of training speech recognition systems without using any labeled data, under the assumption that the learner can only access to the input utterances and a phoneme language model estimated from a non-overlapping corpus. We propose a fully unsupervised learning algorithm that alternates between solving two sub-problems: (i) learn a phoneme classifier for a given set of phoneme segmentation boundaries, and (ii) refining the phoneme boundaries based on a given classifier. To solve the first sub-problem, we introduce a novel unsupervised cost function named Segmental Empirical Output Distribution Matching, which generalizes the work in (Liu et al., 2017) to segmental structures. For the second sub-problem, we develop an approximate MAP approach to refining the boundaries obtained from Wang et al. (2017). Experimental results on TIMIT dataset demonstrate the success of this first fully unsupervised phoneme recognition system, which achieves a phone error rate (PER) of 41.6%. Although it is still far away from the state-of-the-art supervised systems, we show that with oracle boundaries and matching language model, the PER could be improved to 32.5%. This performance approaches the supervised system of the same model architecture, demonstrating the great potential of the proposed method. ", "keywords": ["Unsupervised speech recognition", "unsupervised learning", "phoneme classification"], "authorids": ["ICLR.cc/2019/Conference/Paper973/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/896dc3365c9b551c67b35458ccdc1103fe49e814.pdf", "paperhash": "anonymous|unsupervised_speech_recognition_via_segmental_empirical_output_distribution_matching", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bylmkh05KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkMXkhA5Fm", "original": "r1l0zTTqKX", "number": 974, "cdate": 1538087899398, "ddate": null, "tcdate": 1538087899398, "tmdate": 1538156017717, "tddate": null, "forum": "BkMXkhA5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning State Representations in Complex Systems with Multimodal Data", "abstract": "Representation learning becomes especially important for complex systems with multimodal data sources such as cameras or sensors. Recent advances in reinforcement learning and optimal control make it possible to design control algorithms on these latent representations, but the field still lacks a large-scale standard dataset for unified comparison. In this work, we present a large-scale dataset and evaluation framework for representation learning for the complex task of landing an airplane. We implement and compare several approaches to representation learning on this dataset in terms of the quality of simple supervised learning tasks and disentanglement scores. The resulting representations can be used for further tasks such as anomaly detection, optimal control, model-based reinforcement learning, and other applications.", "keywords": ["deep learning", "representation learning", "state representation", "disentangled representation", "dataset", "autonomous system", "temporal multimodal data"], "authorids": ["ICLR.cc/2019/Conference/Paper974/Authors"], "authors": ["Anonymous"], "TL;DR": "Multimodal synthetic dataset, collected from X-plane flight simulator, used for learning state representation and unified evaluation framework for representation learning", "pdf": "/pdf/3b11013c10c7dc27e8badac5e92beddab407a397.pdf", "paperhash": "anonymous|learning_state_representations_in_complex_systems_with_multimodal_data", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning State Representations in Complex Systems with Multimodal Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMXkhA5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rke41hC5Km", "original": "Hyx6Ct6qFQ", "number": 975, "cdate": 1538087899570, "ddate": null, "tcdate": 1538087899570, "tmdate": 1538156017510, "tddate": null, "forum": "rke41hC5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generating Realistic Stock Market Order Streams", "abstract": "We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks.\nWe model the order stream as a stochastic process with finite history dependence, and employ a conditional Wasserstein GAN to capture history dependence of orders in a stock market. \nWe test our approach with actual market and synthetic data on a number of different statistics, and find the generated data to be close to real data. ", "keywords": ["application in finance", "stock markets", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper975/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks.", "pdf": "/pdf/b20e2bef7c68f57187170b2a6eba82b79191ab04.pdf", "paperhash": "anonymous|generating_realistic_stock_market_order_streams", "_bibtex": "@inproceedings{    \nanonymous2019generating,    \ntitle={Generating Realistic Stock Market Order Streams},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rke41hC5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyx4knR9Ym", "original": "SygVFzS5Ym", "number": 976, "cdate": 1538087899747, "ddate": null, "tcdate": 1538087899747, "tmdate": 1538156017296, "tddate": null, "forum": "Hyx4knR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generalizable Adversarial Training via Spectral Normalization", "abstract": "Deep neural networks (DNNs) have set benchmarks on a wide array of supervised learning tasks. Trained DNNs, however, often lack robustness to minor adversarial perturbations to the input, which undermines their true practicality. Recent works have increased the robustness of DNNs by fitting networks using adversarially-perturbed training samples, but the improved performance can still be far below the performance seen in non-adversarial settings. A significant portion of this gap can be attributed to the decrease in generalization performance due to adversarial training. In this work, we extend the notion of margin loss to adversarial settings and bound the generalization error for DNNs trained under several well-known gradient-based attack schemes, motivating an effective regularization scheme based on spectral normalization of the DNN's weight matrices. We also provide a computationally-efficient method for normalizing the spectral norm of convolutional layers with arbitrary stride and padding schemes in deep convolutional networks. We evaluate the power of spectral normalization extensively on combinations of datasets, network architectures, and adversarial training schemes.", "keywords": ["Adversarial attacks", "adversarial training", "spectral normalization", "generalization guarantee"], "authorids": ["ICLR.cc/2019/Conference/Paper976/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/59864086ec60f5706d162c04c75bf01abc8e9fcc.pdf", "paperhash": "anonymous|generalizable_adversarial_training_via_spectral_normalization", "_bibtex": "@inproceedings{    \nanonymous2019generalizable,    \ntitle={Generalizable Adversarial Training via Spectral Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyx4knR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1g4k309F7", "original": "HJxyIyA9F7", "number": 977, "cdate": 1538087899921, "ddate": null, "tcdate": 1538087899921, "tmdate": 1538156017085, "tddate": null, "forum": "H1g4k309F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Wasserstein Barycenter Model Ensembling", "abstract": "In this paper we propose to perform model ensembling in a multiclass or a multilabel learning setting using Wasserstein barycenters. Optimal transport metrics, such as the Wasserstein distance, allow incorporating semantic side information such as word embeddings. Using Wass. barycenters to find the consensus between models allows us to balance confidence and semantics in finding the agreement between the models. We show applications of Wasserstein ensembling in attribute-based classification, multilabel learning and image captioning generation. These results show that the Wass. ensembling is a viable alternative to the basic geometric or arithmetic mean ensembling.", "keywords": ["Wasserstein barycenter model ensembling"], "authorids": ["ICLR.cc/2019/Conference/Paper977/Authors"], "authors": ["Anonymous"], "TL;DR": "we propose to use Wasserstein barycenters for semantic model ensembling", "pdf": "/pdf/25394fe54dcf908e115f6bafcefd46fbadefe2c0.pdf", "paperhash": "anonymous|wasserstein_barycenter_model_ensembling", "_bibtex": "@inproceedings{    \nanonymous2019wasserstein,    \ntitle={Wasserstein Barycenter Model Ensembling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g4k309F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJg4J3CqFm", "original": "Skepida5tX", "number": 978, "cdate": 1538087900096, "ddate": null, "tcdate": 1538087900096, "tmdate": 1538156016876, "tddate": null, "forum": "rJg4J3CqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Discrete Wasserstein Embeddings", "abstract": "Despite their prevalence, Euclidean embeddings of data are fundamentally limited in their ability to capture latent semantic structures, which need not conform to Euclidean spatial assumptions. Here we consider an alternative, which embeds data as discrete probability distributions in a Wasserstein space, endowed with an optimal transport metric. Wasserstein spaces are much larger and more flexible than Euclidean spaces, in that they can successfully embed a wider variety of metric structures. We propose to exploit this flexibility by learning an embedding that captures the semantic information in the Wasserstein distance between embedded distributions. We examine empirically the representational capacity of such learned Wasserstein embeddings, showing that they can embed a wide variety of complex metric structures with smaller distortion than an equivalent Euclidean embedding. We also investigate an application to word embedding, demonstrating a unique advantage of Wasserstein embeddings: we can directly visualize the high-dimensional embedding, as it is a probability distribution on a low-dimensional space. This obviates the need for dimensionality reduction techniques such as t-SNE for visualization.", "keywords": ["Embedding", "Wasserstein", "Optimal Transport"], "authorids": ["ICLR.cc/2019/Conference/Paper978/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.", "pdf": "/pdf/6e2db40f353e7064fc5aa12dade0c4940c623e3d.pdf", "paperhash": "anonymous|learning_discrete_wasserstein_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Discrete Wasserstein Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJg4J3CqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1fNJhRqFX", "original": "S1xcUkA9FQ", "number": 979, "cdate": 1538087900277, "ddate": null, "tcdate": 1538087900277, "tmdate": 1538156016670, "tddate": null, "forum": "S1fNJhRqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploration using Distributional RL and UCB", "abstract": "    We establish the relation between Distributional RL and the Upper Confidence Bound (UCB) approach to exploration.\n    In this paper we show that the density of the Q function estimated by Distributional RL can be successfully used for the estimation of UCB. This approach does not require counting and, therefore, generalizes well to the Deep RL. We also point to the asymmetry of the empirical densities estimated by the Distributional RL algorithms like QR-DQN. This observation leads to the reexamination of the variance's performance in the UCB type approach to exploration. We introduce truncated variance as an alternative estimator of the UCB and a novel algorithm based on it. We empirically show that newly introduced algorithm achieves better performance in multi-armed bandits setting. Finally, we extend this approach to high-dimensional setting and test it on the Atari 2600 games. New approach achieves better performance compared to QR-DQN in 26 of games, 13 ties out of 49 games.", "keywords": ["Distributional RL", "UCB", "exploration", "Atari 2600", "multi-armed bandits"], "authorids": ["ICLR.cc/2019/Conference/Paper979/Authors"], "authors": ["Anonymous"], "TL;DR": "Exploration using Distributional RL and truncagted variance.", "pdf": "/pdf/c848962619a0820a6a346f72a374a44d821def86.pdf", "paperhash": "anonymous|exploration_using_distributional_rl_and_ucb", "_bibtex": "@inproceedings{    \nanonymous2019exploration,    \ntitle={Exploration using Distributional RL and UCB},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1fNJhRqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylE1205Fm", "original": "SJgV3JL5Km", "number": 980, "cdate": 1538087900448, "ddate": null, "tcdate": 1538087900448, "tmdate": 1538156016455, "tddate": null, "forum": "BylE1205Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer", "abstract": "We study the problem of learning to map, in an unsupervised way, between domains A and B, such that the samples b in B contain all the information that exists in samples $\\va\\in A$ and some additional information. For example, ignoring occlusions, B can be people with glasses, A people without, and the glasses, would be the added information. When mapping a sample a from the first domain to the other domain, the missing information is replicated from an independent reference sample b in B. Thus, in the above example, we can create, for every person without glasses a version with the glasses observed in any face image. \n\nOur solution employs a single two-pathway encoder and a single decoder for both domains. The common part of the two domains and the separate part are encoded as two vectors, and the separate part is fixed at zero for domain A. The loss terms are minimal and involve reconstruction losses for the two domains and a domain confusion term. Our analysis shows that under mild assumptions, this architecture, which is much simpler than the literature guided-translation methods, is enough to ensure disentanglement between the two domains. We present convincing results in a few visual domains, such as no-glasses to glasses, adding facial hair based on a reference image, etc.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper980/Authors"], "authors": ["Anonymous"], "TL;DR": "An image to image translation method which adds to one image the content of another thereby creating a new image.", "pdf": "/pdf/edc1369c74c7a385e3915835b6d4832ea1721691.pdf", "paperhash": "anonymous|emerging_disentanglement_in_autoencoder_based_unsupervised_image_content_transfer", "_bibtex": "@inproceedings{    \nanonymous2019emerging,    \ntitle={Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylE1205Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgHk3RctX", "original": "S1lLRz-9tX", "number": 981, "cdate": 1538087900682, "ddate": null, "tcdate": 1538087900682, "tmdate": 1538156016247, "tddate": null, "forum": "HkgHk3RctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Seq2Slate: Re-ranking and Slate Optimization with RNNs", "abstract": "Ranking is a central task in machine learning and information retrieval. In this task, it is especially important to present the user with a slate of items that is appealing as a whole. This in turn requires taking into account interactions between items, since intuitively, placing an item on the slate affects the decision of which other items should be chosen alongside it.\nIn this work, we propose a sequence-to-sequence model for ranking called seq2slate. At each step, the model predicts the next item to place on the slate given the items already chosen. The recurrent nature of the model allows complex dependencies between items to be captured directly in a flexible and scalable way. We show how to learn the model end-to-end from weak supervision in the form of easily obtained click-through data. We further demonstrate the usefulness of our approach in experiments on standard ranking benchmarks as well as in a real-world recommendation system.", "keywords": ["Recurrent neural networks", "learning to rank", "pointer networks"], "authorids": ["ICLR.cc/2019/Conference/Paper981/Authors"], "authors": ["Anonymous"], "TL;DR": "A pointer network architecture for re-ranking items, learned from click-through logs.", "pdf": "/pdf/dc4fd08c5eeb3146c32f551d9a2ac1622e25c4ba.pdf", "paperhash": "anonymous|seq2slate_reranking_and_slate_optimization_with_rnns", "_bibtex": "@inproceedings{    \nanonymous2019seq2slate:,    \ntitle={Seq2Slate: Re-ranking and Slate Optimization with RNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgHk3RctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylSk205YQ", "original": "BkxzYA6ctQ", "number": 982, "cdate": 1538087900866, "ddate": null, "tcdate": 1538087900866, "tmdate": 1538156016040, "tddate": null, "forum": "HylSk205YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations", "abstract": "Multi-agent reinforcement learning systems aim to provide interacting agents with the ability to collaboratively learn and adapt to the behaviour of other agents. In many real-world applications, the agents can only acquire a partial view of the world. Here we consider a setting whereby most agents' observations are also extremely noisy, hence only weakly correlated to the true state of the environment. Under these circumstances, learning an optimal policy becomes particularly challenging, even in the unrealistic case that an agent's policy can be made conditional upon all other agents\u2019 observations. To overcome these difficulties, we propose a multi-agent deep deterministic policy gradient algorithm enhanced by a communication medium (MADDPG-M), which implements a two-level, concurrent learning mechanism. An agent's policy depends on its own private observations as well as those explicitly shared by others through a communication medium. At any given point in time, an agent must decide whether its private observations are sufficiently informative to be shared with others. However, our environments provide no explicit feedback informing an agent whether a communication action is beneficial, rather the communication policies must also be learned through experience concurrently to the main policies. Our experimental results demonstrate that the algorithm performs well in six highly non-stationary environments of progressively higher complexity, and offers substantial performance gains compared to the baselines.", "keywords": ["Reinforcement learning", "multi-agent", "hierarchical", "noisy observation", "partial observability", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper982/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/14ebf091135f2701d77e64bfbf1a4ff860fee70d.pdf", "paperhash": "anonymous|multiagent_deep_reinforcement_learning_with_extremely_noisy_observations", "_bibtex": "@inproceedings{    \nanonymous2019multi-agent,    \ntitle={Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylSk205YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgSk2A9Y7", "original": "H1lriETcYX", "number": 983, "cdate": 1538087901106, "ddate": null, "tcdate": 1538087901106, "tmdate": 1538156015837, "tddate": null, "forum": "HkgSk2A9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Gradient Push for Distributed Deep Learning", "abstract": "Large mini-batch parallel SGD is commonly used for distributed training of deep\nnetworks. Approaches that use tightly-coupled exact distributed averaging based\non AllReduce are sensitive to slow nodes and high-latency communication. In\nthis work we show the applicability of Stochastic Gradient Push (SGP) for distributed\ntraining. SGP uses a gossip algorithm called PushSum for approximate\ndistributed averaging, allowing for much more loosely coupled communications\nwhich can be beneficial in high-latency or high-variability scenarios. The tradeoff\nis that approximate distributed averaging injects additional noise in the gradient\nwhich can affect the train and test accuracies. We prove that SGP converges to\na stationary point of smooth, non-convex objective functions. Furthermore, we\nvalidate empirically the potential of SGP. For example, using 32 nodes with 8\nGPUs per node to train ResNet-50 on ImageNet, where nodes communicate over\n10Gbps Ethernet, SGP completes 90 epochs in around 1.5 hours while AllReduce\nSGD takes over 5 hours, and the top-1 validation accuracy of SGP remains within\n1.2% of that obtained using AllReduce SGD.", "keywords": ["optimization", "distributed", "large scale", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper983/Authors"], "authors": ["Anonymous"], "TL;DR": "For distributed training over high-latency networks, use gossip-based approximate distributed averaging instead of exact distribute averaging like AllReduce.", "pdf": "/pdf/d0d33db85752bdd51a0a55a3be871f7c4384c3a1.pdf", "paperhash": "anonymous|stochastic_gradient_push_for_distributed_deep_learning", "_bibtex": "@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Gradient Push for Distributed Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgSk2A9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GHJ3R9tQ", "original": "rke2P-p5Fm", "number": 984, "cdate": 1538087901277, "ddate": null, "tcdate": 1538087901277, "tmdate": 1538156015634, "tddate": null, "forum": "B1GHJ3R9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "HyperGAN:  Exploring the Manifold of Neural Networks", "abstract": "We introduce HyperGAN, a generative adversarial network that learns to generate all the parameters of a deep  neural network. HyperGAN first transforms low dimensional noise into a latent space, which can be sampled from to obtain diverse, performant sets of parameters for a target architecture. We utilize an architecture that bears resemblance to adversarial autoencoders, but with the data term substituted to be classification loss, which is equivalent to minimizing the KL-divergence between the generated network parameter distribution with a unknown true parameter distribution. We apply HyperGAN to classification, showing that HyperGAN can learn to generate parameters which solve the MNIST and CIFAR-10 datasets with competitive performance to fully supervised learning, while learning a rich distribution of effective parameters. We also show that HyperGAN can also provide better uncertainty than standard ensembles. We show this by evaluating the robustness of HyperGAN-generated ensembles to domain-shift, testing with out of distribution data as well as adversarial examples. We see that in addition to being highly accurate on inlier data, HyperGAN can provide reasonable uncertainty estimates.", "keywords": ["hypernetworks", "generative adversarial networks", "anomaly detection"], "authorids": ["ICLR.cc/2019/Conference/Paper984/Authors"], "authors": ["Anonymous"], "TL;DR": "We use a GAN to generate parameters of a neural network in one forward pass.", "pdf": "/pdf/877daff5129441f118a58ee345e6cf34585d5dce.pdf", "paperhash": "anonymous|hypergan_exploring_the_manifold_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019hypergan:,    \ntitle={HyperGAN:  Exploring the Manifold of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GHJ3R9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkxr1nCcFm", "original": "HkeT8V9cFQ", "number": 985, "cdate": 1538087901441, "ddate": null, "tcdate": 1538087901441, "tmdate": 1538156015419, "tddate": null, "forum": "Hkxr1nCcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An investigation of model-free planning", "abstract": "The field of reinforcement learning (RL) is facing increasingly challenging domains with combinatorial complexity. For an RL agent to address these challenges, it is essential that it can plan effectively. Prior work has typically utilized an explicit model of the environment, combined with a specific planning algorithm (such as tree search).  More recently, a new family of methods have been proposed that learn how to plan, by providing the structure for planning via an inductive bias in the function approximator (such as a tree structured neural network), trained end-to-end by a model-free RL algorithm. In this paper, we go even further, and suggest that an entirely model-free approach, without any special structure beyond standard neural network components such as convolutional networks and LSTMs, can learn to plan effectively.  We measure our agent's effectiveness at planning in terms of its ability to generalize across a combinatorial and irreversible state space, its data efficiency, and its ability to utilize additional thinking time.  We find that our agent has the characteristics that one might expect to find in a true planning algorithm. Furthermore, it exceeds the state-of-the-art in challenging combinatorial domains such as Sokoban and outperforms other model-free approaches that utilize strong inductive biases towards planning. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper985/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d31da2f2899123cf4a29782ec18c5416d2bc0d80.pdf", "paperhash": "anonymous|an_investigation_of_modelfree_planning", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An investigation of model-free planning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkxr1nCcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJl8J30qFX", "original": "SkltIMwcKQ", "number": 986, "cdate": 1538087901670, "ddate": null, "tcdate": 1538087901670, "tmdate": 1538156015207, "tddate": null, "forum": "SJl8J30qFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Global Additive Explanations for Neural Nets Using Model Distillation", "abstract": "Interpretability has largely focused on local explanations, i.e. explaining why a model made a particular prediction for a sample. These explanations are appealing due to their simplicity and local fidelity. However, they do not provide information about the general behavior of the model. We propose to leverage model distillation to learn global additive explanations that describe the relationship between input features and model predictions. These global explanations take the form of feature shapes, which are more expressive than feature attributions. Through careful experimentation, we show qualitatively and quantitatively that global additive explanations are able to describe model behavior and yield insights about models such as neural nets. A visualization of our approach applied to a neural net as it is trained is available at https://youtu.be/ErQYwNqzEdc", "keywords": ["global interpretability", "additive explanations", "model distillation", "neural nets", "tabular data"], "authorids": ["ICLR.cc/2019/Conference/Paper986/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose to leverage model distillation to learn global additive explanations in the form of feature shapes (that are more expressive than feature attributions) for models such as neural nets trained on tabular data.", "pdf": "/pdf/e85b64d7325f3836eb4250782b5c18d3676def25.pdf", "paperhash": "anonymous|learning_global_additive_explanations_for_neural_nets_using_model_distillation", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Global Additive Explanations for Neural Nets Using Model Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl8J30qFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylIy3R9K7", "original": "SygKkVaqtm", "number": 987, "cdate": 1538087901840, "ddate": null, "tcdate": 1538087901840, "tmdate": 1538156015003, "tddate": null, "forum": "rylIy3R9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understand the dynamics of GANs via Primal-Dual Optimization", "abstract": "Generative adversarial network (GAN) is one of the best known unsupervised learning techniques these days due to its superior ability to learn data distributions. In spite of its great success in applications, GAN is known to be notoriously hard to train. The tremendous amount of time it takes to run the training algorithm and its sensitivity to hyper-parameter tuning have been haunting researchers in this area. To resolve these issues, we need to first understand how GANs work. Herein, we take a step toward this direction by examining the dynamics of GANs. We relate a large class of GANs including the Wasserstein GANs to max-min optimization problems with the coupling term being linear over the discriminator. By developing new primal-dual optimization tools, we show that, with a proper stepsize choice, the widely used first-order iterative algorithm in training GANs would in fact converge to a stationary solution with a sublinear rate. The same framework also applies to multi-task learning and distributional robust learning problems. We verify our analysis on numerical examples with both synthetic and real data sets. We hope our analysis shed light on future studies on the theoretical properties of relevant machine learning problems.", "keywords": ["non-convex optimization", "generative adversarial network", "primal dual algorithm"], "authorids": ["ICLR.cc/2019/Conference/Paper987/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that, with a proper stepsize choice, the widely used first-order iterative algorithm in training GANs would in fact converge to a stationary solution with a sublinear rate.", "pdf": "/pdf/0c10c334a4755e423f65efbb1e200a2b59c86a37.pdf", "paperhash": "anonymous|understand_the_dynamics_of_gans_via_primaldual_optimization", "_bibtex": "@inproceedings{    \nanonymous2019understand,    \ntitle={Understand the dynamics of GANs via Primal-Dual Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylIy3R9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGLy2RqtQ", "original": "rJeOCTicFX", "number": 988, "cdate": 1538087902016, "ddate": null, "tcdate": 1538087902016, "tmdate": 1538156014802, "tddate": null, "forum": "HyGLy2RqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Over-parameterization Improves Generalization in the XOR Detection Problem", "abstract": "Empirical evidence suggests that neural networks with ReLU activations generalize better with over-parameterization. However, there is currently no theoretical analysis that explains this observation. In this work, we study a simplified learning task with over-parameterized convolutional networks that empirically exhibits the same qualitative phenomenon.  For this setting, we provide a theoretical analysis of the optimization and generalization performance of gradient descent. Specifically, we prove data-dependent sample complexity bounds which show that over-parameterization improves the generalization performance of gradient descent.", "keywords": ["deep learning", "theory", "non convex optimization", "over-parameterization"], "authorids": ["ICLR.cc/2019/Conference/Paper988/Authors"], "authors": ["Anonymous"], "TL;DR": "We show in a simplified learning task that over-parameterization improves generalization of a convnet that is trained with gradient descent.", "pdf": "/pdf/bffe7960e0b37c129a2deb2dcffd1377ad380cd3.pdf", "paperhash": "anonymous|overparameterization_improves_generalization_in_the_xor_detection_problem", "_bibtex": "@inproceedings{    \nanonymous2019over-parameterization,    \ntitle={Over-parameterization Improves Generalization in the XOR Detection Problem},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGLy2RqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJg8yhAqKm", "original": "r1lw89YqKX", "number": 989, "cdate": 1538087902183, "ddate": null, "tcdate": 1538087902183, "tmdate": 1538156014596, "tddate": null, "forum": "rJg8yhAqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transfer and Exploration via the Information Bottleneck", "abstract": "A central challenge in reinforcement learning is discovering effective policies for tasks where rewards are sparsely distributed. We postulate that in the absence of useful reward signals, an effective exploration strategy should seek out {\\it decision states}. These states lie at critical junctions in the state space from where the agent can transition to new, potentially unexplored regions. We propose to learn about decision states from prior experience. By training a goal-conditioned model with an information bottleneck, we can identify decision states by examining where the model accesses the goal state through the bottleneck. We find that this simple mechanism effectively identifies decision states, even in partially observed settings. In effect, the model learns the sensory cues that correlate with potential subgoals. In new environments, this model can then identify novel subgoals for further exploration, guiding the agent through a sequence of potential decision  states and through new regions of the state space.", "keywords": ["Information bottleneck", "policy transfer", "policy generalization", "exploration"], "authorids": ["ICLR.cc/2019/Conference/Paper989/Authors"], "authors": ["Anonymous"], "TL;DR": "Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus", "pdf": "/pdf/55ba10561ce7b4ee308d202aca6d973e07a4b58d.pdf", "paperhash": "anonymous|transfer_and_exploration_via_the_information_bottleneck", "_bibtex": "@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer and Exploration via the Information Bottleneck},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJg8yhAqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyeU1hRcFX", "original": "HJey_dT9FQ", "number": 990, "cdate": 1538087902361, "ddate": null, "tcdate": 1538087902361, "tmdate": 1538156014387, "tddate": null, "forum": "HyeU1hRcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Conditional Generation using noise engineered mode matching GAN", "abstract": "Conditional generation refers to the process of sampling from an unknown distribution conditioned on semantics of the data. This can be achieved by augmenting the generative model with the desired semantic labels, albeit it is not straightforward in an unsupervised setting where the semantic label of every data sample is unknown. In this paper, we address this issue by proposing a method that can generate samples conditioned on the properties of a latent distribution engineered in accordance with a certain data prior. In particular, a latent space inversion network is trained in tandem with a generative adversarial network such that the modal properties of the latent space distribution are induced in the data generating distribution. We demonstrate that our model despite being fully unsupervised, is effective in learning meaningful representations through its mode matching property. We validate our method on multiple unsupervised tasks such as conditional generation, dataset attribute discovery and inference using three real world image datasets namely MNIST, CIFAR-10 and CELEB-A and show that the results are comparable to the state-of-the-art methods. ", "keywords": ["Noise engineered GAN", "Latent space engineering", "Mode matching", "Unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper990/Authors"], "authors": ["Anonymous"], "TL;DR": "A GAN model where an inversion mapping from the generated data space to an engineered latent space is learned such that properties of the data generating distribution are matched to those of the latent distribution.", "pdf": "/pdf/c294dd9ba46eaa875abbaec9c7cfff39842d2300.pdf", "paperhash": "anonymous|unsupervised_conditional_generation_using_noise_engineered_mode_matching_gan", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Conditional Generation using noise engineered mode matching GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeU1hRcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJePy3RcF7", "original": "SkgKg1pqFQ", "number": 991, "cdate": 1538087902527, "ddate": null, "tcdate": 1538087902527, "tmdate": 1538156014183, "tddate": null, "forum": "HJePy3RcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Rethinking learning rate schedules for stochastic optimization", "abstract": "There is a stark disparity between the learning rate schedules used in the practice of large scale machine learning and what are considered admissible learning rate schedules prescribed in the theory of stochastic approximation. Recent results, such as in the 'super-convergence' methods which use oscillating learning rates, serve to emphasize this point even more.\nOne plausible explanation is that non-convex neural network training procedures are better suited to the use of fundamentally different learning rate  schedules, such as the ``cut the learning rate every constant number of epochs'' method (which more closely resembles an exponentially decaying learning rate schedule); note that this widely used schedule is in stark contrast to the polynomial decay schemes prescribed in the stochastic approximation literature, which are indeed shown to be (worst case) optimal for classes of convex optimization problems.\n\nThe main contribution of this work shows that the picture is far more nuanced, where we do not even need to move to non-convex optimization to show other learning rate schemes can be far more effective. In fact, even for the simple case of stochastic linear regression with a fixed time horizon, the rate achieved by any polynomial decay scheme is sub-optimal compared to the statistical minimax rate (by a factor of condition number); in contrast the ```''cut the learning rate every constant number of epochs'' provides an exponential improvement (depending only logarithmically on the condition number) compared to any polynomial decay scheme.  Finally, it is important to ask if our theoretical insights are somehow fundamentally tied to quadratic loss minimization (where we have circumvented minimax lower bounds for more general convex optimization problems)? Here, we conjecture that recent results which make the gradient norm small at a near optimal rate, for both convex and non-convex optimization, may also provide more insights into learning rate schedules used in practice.\n", "keywords": ["SGD", "learning rate", "step size schedules", "stochastic approximation", "stochastic optimization", "deep learning", "non-convex optimization", "stochastic gradient descent"], "authorids": ["ICLR.cc/2019/Conference/Paper991/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a rigorous study of why practically used learning rate schedules (for a given computational budget) offer significant advantages even though these schemes are not advocated by the classical theory of Stochastic Approximation.", "pdf": "/pdf/cff24fbf0f01c04ba5f0b5b2d33e453deb2bda9d.pdf", "paperhash": "anonymous|rethinking_learning_rate_schedules_for_stochastic_optimization", "_bibtex": "@inproceedings{    \nanonymous2019rethinking,    \ntitle={Rethinking learning rate schedules for stochastic optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJePy3RcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxPk2A9Km", "original": "BkePw0hqYX", "number": 992, "cdate": 1538087902706, "ddate": null, "tcdate": 1538087902706, "tmdate": 1538156013980, "tddate": null, "forum": "BJxPk2A9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning What to Remember: Long-term Episodic Memory Networks for Learning from Streaming Data", "abstract": "Current generation of memory-augmented neural networks has limited scalability as they cannot efficiently process data that are too large to fit in the external memory storage. One example of this is lifelong learning scenario where the model receives unlimited length of data stream as an input which contains vast majority of uninformative entries. We tackle this problem by proposing a memory network fit for long-term lifelong learning scenario, which we refer to as Long-term Episodic Memory Networks (LEMN), that features a RNN-based retention agent that learns to replace less important memory entries based on the retention probability generated on each entry that is learned to identify data instances of generic importance relative to other memory entries, as well as its historical importance. Such learning of retention agent allows our long-term episodic memory network to retain memory entries of generic importance for a given task. We validate our model on a path-finding task as well as synthetic and real question answering tasks, on which our model achieves significant improvements over the memory augmented networks with rule-based memory scheduling as well as an RL-based baseline that does not consider relative or historical importance of the memory.", "keywords": ["Memory Network", "Lifelong Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper992/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/53e3fa3166fc7d49e5832f68d4c3216c5087ab61.pdf", "paperhash": "anonymous|learning_what_to_remember_longterm_episodic_memory_networks_for_learning_from_streaming_data", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning What to Remember: Long-term Episodic Memory Networks for Learning from Streaming Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxPk2A9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJfvknCqFQ", "original": "ryxRiJAqFQ", "number": 993, "cdate": 1538087902888, "ddate": null, "tcdate": 1538087902888, "tmdate": 1538156013777, "tddate": null, "forum": "BJfvknCqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations", "abstract": "We show that simple spatial transformations, namely translations and rotations alone, suffice to fool neural networks on a significant fraction of their inputs in multiple image classification tasks. Our results are in sharp contrast to previous work in adversarial robustness that relied on more complicated optimization ap- proaches unlikely to appear outside a truly adversarial context. Moreover, the misclassifying rotations and translations are easy to find and require only a few black-box queries to the target model. Overall, our findings emphasize the need to design robust classifiers even for natural input transformations in benign settings.\n", "keywords": ["robustness", "spatial transformations", "invariance", "rotations", "data augmentation", "robust optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper993/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that CNNs are not robust to simple rotations and translation and explore methods of improving this.", "pdf": "/pdf/3a95ee20b9313f1ab539108bda763e4511ba6e2a.pdf", "paperhash": "anonymous|a_rotation_and_a_translation_suffice_fooling_cnns_with_simple_transformations", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfvknCqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJfwJ2A5KX", "original": "S1x0h8gwY7", "number": 994, "cdate": 1538087903067, "ddate": null, "tcdate": 1538087903067, "tmdate": 1538156013576, "tddate": null, "forum": "HJfwJ2A5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds", "abstract": "We present an efficient coresets-based neural network compression algorithm that sparsifies the parameters of a trained fully-connected neural network in a manner that provably approximates the network's output. Our approach is based on an importance sampling scheme that judiciously defines a sampling distribution over the neural network parameters, and as a result, retains parameters of high importance while discarding redundant ones. We leverage a novel, empirical notion of sensitivity and extend traditional coreset constructions to the application of compressing parameters. Our theoretical analysis establishes guarantees on the size and accuracy of the resulting compressed network and gives rise to generalization bounds that may provide new insights into the generalization properties of neural networks. We demonstrate the practical effectiveness of our algorithm on a variety of neural network configurations and real-world data sets.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper994/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/1f92919b1004e4753965552d69cbc7b555fd07f5.pdf", "paperhash": "anonymous|datadependent_coresets_for_compressing_neural_networks_with_applications_to_generalization_bounds", "_bibtex": "@inproceedings{    \nanonymous2019data-dependent,    \ntitle={Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJfwJ2A5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyNPk2R9K7", "original": "BJgJakAqYQ", "number": 995, "cdate": 1538087903233, "ddate": null, "tcdate": 1538087903233, "tmdate": 1538156013372, "tddate": null, "forum": "SyNPk2R9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Describe Scenes with Programs", "abstract": "Human scene perception goes beyond recognizing a collection of objects and their pairwise relations. We are able to understand the higher-level, abstract regularities within the scene such as symmetry and repetition. Current vision recognition modules and scene representations fall short in this dimension. In this paper, we present scene programs, representing a scene via a symbolic program for its objects and their attributes. We also propose a model that infers such scene programs by exploiting a hierarchical, object-based scene representation. Experiments demonstrate that our model works well on synthetic data and is able to transfer to real images with such compositional structure. The use of scene programs has enabled a number of applications, such as complex visual analogy-making and scene extrapolation.", "keywords": ["Structured scene representations", "program synthesis"], "authorids": ["ICLR.cc/2019/Conference/Paper995/Authors"], "authors": ["Anonymous"], "TL;DR": "We present scene programs, a structured scene representation that captures both low-level object appearance and high-level regularity in the scene.", "pdf": "/pdf/ae43464a56ea8c22db437f74149dca78ff561bc9.pdf", "paperhash": "anonymous|learning_to_describe_scenes_with_programs", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Describe Scenes with Programs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyNPk2R9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxwJhC9YX", "original": "B1eRB-V5tm", "number": 996, "cdate": 1538087903397, "ddate": null, "tcdate": 1538087903397, "tmdate": 1538156013160, "tddate": null, "forum": "ryxwJhC9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Instance-aware Image-to-Image Translation", "abstract": "Unsupervised image-to-image translation has gained considerable attention due to the recent impressive progress based on generative adversarial networks (GANs). However, previous methods often fail in challenging cases, in particular, when an image has multiple target instances and a translation task involves significant changes in shape, e.g., translating pants to skirts in fashion images. To tackle the issues, we propose a novel method, coined instance-aware GAN (InstaGAN), that incorporates the instance information (e.g., object segmentation masks) and improves multi-instance transfiguration. The proposed method translates both an image and the corresponding set of instance attributes while maintaining the permutation invariance property of the instances. To this end, we introduce a context preserving loss that encourages the network to learn the identity function outside of target instances. We also propose a sequential mini-batch inference/training technique that handles multiple instances with a limited GPU memory and enhances the network to generalize better for multiple instances. Our comparative evaluation demonstrates the effectiveness of the proposed method on different image datasets, in particular, in the aforementioned challenging cases.", "keywords": ["Image-to-Image Translation", "Generative Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper996/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel method to incorporate the set of instance attributes for image-to-image translation.", "pdf": "/pdf/feff040defedceab91af618cd603f04df16d3e52.pdf", "paperhash": "anonymous|instanceaware_imagetoimage_translation", "_bibtex": "@inproceedings{    \nanonymous2019instance-aware,    \ntitle={Instance-aware Image-to-Image Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxwJhC9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgd1nAqFX", "original": "Hyl76J0qF7", "number": 997, "cdate": 1538087903625, "ddate": null, "tcdate": 1538087903625, "tmdate": 1538156012953, "tddate": null, "forum": "HJgd1nAqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DOM-Q-NET:  Grounded RL on Structured Language", "abstract": "The World Wide Web is a rich repository of knowledge about the real world. The ability for agents to interact with the web would allow for significant improvements in knowledge understanding and representation learning. However, web navigation tasks are difficult for the current deep reinforcement learning (RL) models due to the large discrete action space and the varying number of actions between the states. In this work, we introduce DOM-Q-NET, a novel architecture for RL-based web navigation to address both of these problems. DOM-Q-NET utilizes a graph neural network to represent tree-structured HTML along with a shared state space across multiple tasks. We show 2x improvements in sample efficiency when training in the multi-task setting, allowing our model to transfer learned behaviours across tasks. Furthermore, we demonstrate the capabilities of our model on the WorldOfBits environments where we can match or outperform existing work without the use of expert demonstrations.", "keywords": ["Reinforcement Learning", "Web Navigation", "Graph Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper997/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c7474e607fd56756a50e69e545112f28059ddfe9.pdf", "paperhash": "anonymous|domqnet_grounded_rl_on_structured_language", "_bibtex": "@inproceedings{    \nanonymous2019dom-q-net:,    \ntitle={DOM-Q-NET:  Grounded RL on Structured Language},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgd1nAqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkluJ2R9KQ", "original": "ryx19ra9Ym", "number": 998, "cdate": 1538087903798, "ddate": null, "tcdate": 1538087903798, "tmdate": 1538156012749, "tddate": null, "forum": "rkluJ2R9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A new dog learns old tricks:  RL finds classic optimization algorithms", "abstract": "This paper introduces a novel framework for learning algorithms to solve online combinatorial optimization problems. Towards this goal, we introduce a number of key ideas from traditional algorithms and complexity theory. First, we draw a new connection between primal-dual methods and reinforcement learning. Next, we introduce the concept of adversarial distributions (universal and high-entropy training sets), which are distributions that encourage the learner to find algorithms that work well in the worst case. We test our new ideas on a number of optimization problem such as the AdWords problem, the online knapsack problem, and the secretary problem. Our results indicate that the models have learned behaviours that are consistent with the traditional optimal algorithms for these problems.", "keywords": ["reinforcement learning", "algorithms", "adwords", "knapsack", "secretary"], "authorids": ["ICLR.cc/2019/Conference/Paper998/Authors"], "authors": ["Anonymous"], "TL;DR": "By combining ideas from traditional algorithms design and reinforcement learning, we introduce a novel framework for learning algorithms that solve online combinatorial optimization problems.", "pdf": "/pdf/914f2d1373a70ffaaf6880f49f953c0f1b8cd144.pdf", "paperhash": "anonymous|a_new_dog_learns_old_tricks_rl_finds_classic_optimization_algorithms", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A new dog learns old tricks:  RL finds classic optimization algorithms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkluJ2R9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByGuynAct7", "original": "S1e7ZhpcKX", "number": 999, "cdate": 1538087903978, "ddate": null, "tcdate": 1538087903978, "tmdate": 1538156012541, "tddate": null, "forum": "ByGuynAct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Weight Prior", "abstract": "Bayesian inference is known to provide a general framework for incorporating prior knowledge or specific properties into machine learning models via carefully choosing a prior distribution. In this work, we propose a new type of prior distributions for convolutional neural networks, deep weight prior, that in contrast to previously published techniques, favors empirically estimated structure of convolutional filters e.g., spatial correlations of weights.  We define deep weight prior as an implicit distribution and propose a method for variational inference with such type of implicit priors.  In experiments, we show that deep weight priors can improve the performance of Bayesian neural networks on several problems when training data is limited.  Also, we found that initialization of weights of conventional convolutional networks with samples from deep weight prior leads to faster training.", "keywords": ["deep learning", "variational inference", "prior distributions"], "authorids": ["ICLR.cc/2019/Conference/Paper999/Authors"], "authors": ["Anonymous"], "TL;DR": "An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.", "pdf": "/pdf/8d7a1013259857862956d7247ddef4089900387f.pdf", "paperhash": "anonymous|deep_weight_prior", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Weight Prior},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByGuynAct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJluy2RcFm", "original": "rJl2fBp5F7", "number": 1000, "cdate": 1538087904322, "ddate": null, "tcdate": 1538087904322, "tmdate": 1538156012333, "tddate": null, "forum": "BJluy2RcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs", "abstract": "We consider a simple and overarching representation for permutation-invariant functions of sequences (or set functions). Our approach, which we call Janossy pooling, expresses a permutation-invariant function as the average of a permutation-sensitive function applied to all reorderings of the input sequence. This allows us to leverage the rich and mature literature on permutation-sensitive functions to construct novel and flexible permutation-invariant functions. If carried out naively, Janossy pooling can be computationally prohibitive. To allow computational tractability, we consider three kinds of approximations: canonical orderings of sequences, functions with k-order interactions, and stochastic optimization algorithms with random permutations. Our framework unifies a variety of existing work in the literature, and suggests possible modeling and algorithmic extensions. We explore a few in our experiments, which demonstrate improved performance over current state-of-the-art methods.", "keywords": ["representation learning", "permutation invariance", "set functions", "feature pooling"], "authorids": ["ICLR.cc/2019/Conference/Paper1000/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Janossy pooling, a method for learning deep permutation invariant functions designed to exploit relationships within the input sequence and tractable inference strategies such as a stochastic optimization procedure we call piSGD", "pdf": "/pdf/bc8ca4ef368a3d6ebf6e7102ce20f0f285e4ca45.pdf", "paperhash": "anonymous|janossy_pooling_learning_deep_permutationinvariant_functions_for_variablesize_inputs", "_bibtex": "@inproceedings{    \nanonymous2019janossy,    \ntitle={Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJluy2RcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skluy2RcK7", "original": "S1xXQQFcFm", "number": 1001, "cdate": 1538087904494, "ddate": null, "tcdate": 1538087904494, "tmdate": 1538156012100, "tddate": null, "forum": "Skluy2RcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks.  Here we undertake a comparison of four such measures on the well studied network AlexNet. In contrast to work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in the hidden layers of AlexNet, and demonstrate that previous assessments of selectivity suggest a higher level of selectivity than is warranted, with the most selective units only responding most strongly to a small minority of images from within a category. No difference in selectivity was found between layers \\layer{fc6} and \\layer{fc7}, and \\layer{fc8} was much more selective. Only the output \\layer{prob} layer contained any localist units. We also  generated images that maximally activated individual units and found that under (5\\%) of units in \\layer{fc6} and \\layer{conv5} produced images of interpretable objects that humans consistently labeled, whereas \\layer{fc8} produced over 50\\% interpretable images. We consider why different degrees of selectivity are observed with RNNs and AlexNet, and suggest visualizing activations with jitterplots, aside from being comparable to neuroscience techniques, are a good first step to assessing unit selectivity.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper1001/Authors"], "authors": ["Anonymous"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors and localist codes are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9984f73c24e0e894eab8587776c975fc1bdc3411.pdf", "paperhash": "anonymous|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@inproceedings{    \nanonymous2019selectivity,    \ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skluy2RcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eKJ3R5KQ", "original": "r1l_6Bh9tm", "number": 1002, "cdate": 1538087904666, "ddate": null, "tcdate": 1538087904666, "tmdate": 1538156011896, "tddate": null, "forum": "S1eKJ3R5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Answer-based Adversarial Training for Generating Clarification Questions", "abstract": "We propose a generative adversarial training approach for the problem of clarification question generation. Our approach generates clarification questions with the goal of eliciting new information that would make the given context more complete. We develop a Generative Adversarial Network (GAN) where the generator is a sequence-to-sequence model and the discriminator is a utility function that models the value of updating the context with the answer to the clarification question. We evaluate on two datasets, using both automatic metrics and human judgments of usefulness, specificity and relevance, showing that our approach outperforms both a retrieval-based model and ablations that exclude the utility model and the adversarial training.\n", "keywords": ["natural language processing", "text generation", "generative adversarial network"], "authorids": ["ICLR.cc/2019/Conference/Paper1002/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an adversarial training approach to the problem of clarification question generation which uses the answer to the question to model the reward. ", "pdf": "/pdf/d5a432da55cdc0f50e0c6ec4e642e57ca3abda5e.pdf", "paperhash": "anonymous|answerbased_adversarial_training_for_generating_clarification_questions", "_bibtex": "@inproceedings{    \nanonymous2019answer-based,    \ntitle={Answer-based Adversarial Training for Generating Clarification Questions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eKJ3R5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxtJh0qYm", "original": "rylrQ2T5KQ", "number": 1003, "cdate": 1538087904831, "ddate": null, "tcdate": 1538087904831, "tmdate": 1538156011691, "tddate": null, "forum": "SyxtJh0qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Autoencoder with Arbitrary Conditioning", "abstract": "We propose a single neural probabilistic model based on variational autoencoder that can be conditioned on an arbitrary subset of observed features and then sample the remaining features in \"one shot\". The features may be both real-valued and categorical. Training of the model is performed by stochastic variational Bayes. The experimental evaluation on synthetic data, as well as feature imputation and image inpainting problems, shows the effectiveness of the proposed approach and diversity of the generated samples.", "keywords": ["unsupervised learning", "generative models", "conditional variational autoencoder", "variational autoencoder", "missing features multiple imputation", "inpainting"], "authorids": ["ICLR.cc/2019/Conference/Paper1003/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an extension of conditional variational autoencoder that allows conditioning on an arbitrary subset of the features and sampling the remaining ones.", "pdf": "/pdf/3ed0661941487d8bd34cd7a12d8741d74c79dd28.pdf", "paperhash": "anonymous|variational_autoencoder_with_arbitrary_conditioning", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Autoencoder with Arbitrary Conditioning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxtJh0qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylKJhCcKm", "original": "ByeeIy5cYX", "number": 1004, "cdate": 1538087905012, "ddate": null, "tcdate": 1538087905012, "tmdate": 1538156011478, "tddate": null, "forum": "HylKJhCcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generalized Capsule Networks with Trainable Routing Procedure", "abstract": "CapsNet (Capsule Network) was first proposed by Sabour et al. (2017) and lateranother version of CapsNet was proposed by Hinton et al. (2018).  CapsNet hasbeen proved effective in modeling spatial features with much fewer parameters.However, the routing procedures (dynamic routing and EM routing) in both pa-pers are not well incorporated into the whole training process,  and the optimalnumber for the routing procedure has to be found manually.  We propose Gen-eralized GapsNet (G-CapsNet) to overcome this disadvantages by incorporatingthe routing procedure into the optimization.  We implement two versions of G-CapsNet (fully-connected and convolutional) on CAFFE (Jia et al. (2014)) andevaluate them by testing the accuracy on MNIST & CIFAR10, the robustness towhite-box & black-box attack, and the generalization ability on GAN-generatedsynthetic images.  We also explore the scalability of G-CapsNet by constructinga relatively deep G-CapsNet.   The experiment shows that G-CapsNet has goodgeneralization ability and scalability. ", "keywords": ["Capsule networks", "generalization", "scalability", "adversarial robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper1004/Authors"], "authors": ["Anonymous"], "TL;DR": "A scalable capsule network", "pdf": "/pdf/879862ec204ec733901e0ac88e56a36e876b6c8a.pdf", "paperhash": "anonymous|generalized_capsule_networks_with_trainable_routing_procedure", "_bibtex": "@inproceedings{    \nanonymous2019generalized,    \ntitle={Generalized Capsule Networks with Trainable Routing Procedure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylKJhCcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eKk2CcKm", "original": "S1gr5TTqt7", "number": 1005, "cdate": 1538087905186, "ddate": null, "tcdate": 1538087905186, "tmdate": 1538156011272, "tddate": null, "forum": "B1eKk2CcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Kmer2vec: Towards transcriptomic representations by learning kmer embeddings", "abstract": "In this work we propose kmer2vec, a method to compute continuous embeddings for kmers from raw RNA-seq data, in a reference-free fashion. We report that our model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. We confirm the quality of these vectors by comparing them to known gene sub-structures and report that the latent space recovers exon information from raw RNA-Seq data from acute myeloid leukemia patients. Furthermore we show that this latent space allows the detection of genomic abnormalities such as translocations as well as patient-specific mutations, making this representation space both useful for visualization as well as analysis.", "keywords": ["representation learning", "RNA-Seq", "gene expression", "bioinformatics", "computational biology", "transcriptomics", "deep learning", "genomics"], "authorids": ["ICLR.cc/2019/Conference/Paper1005/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8801eda4683da9bebbab7a0718334aa8d4f1e4b9.pdf", "paperhash": "anonymous|kmer2vec_towards_transcriptomic_representations_by_learning_kmer_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019kmer2vec:,    \ntitle={Kmer2vec: Towards transcriptomic representations by learning kmer embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eKk2CcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklY120cYm", "original": "S1gBV3LFYX", "number": 1006, "cdate": 1538087905357, "ddate": null, "tcdate": 1538087905357, "tmdate": 1538156011063, "tddate": null, "forum": "HklY120cYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "abstract": "In this work, we propose a new solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet~ (Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a novel regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation.  In addition, we propose the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet~(Ping et al., 2018).  We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model.", "keywords": ["text-to-speech", "deep generative models", "end-to-end", "text to waveform"], "authorids": ["ICLR.cc/2019/Conference/Paper1006/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/918a94700a40aa7b1a7bc457be9a9f57597c83df.pdf", "paperhash": "anonymous|clarinet_parallel_wave_generation_in_endtoend_texttospeech", "_bibtex": "@inproceedings{    \nanonymous2019clarinet:,    \ntitle={ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklY120cYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lq1hRqYQ", "original": "H1xgN6ncKQ", "number": 1007, "cdate": 1538087905526, "ddate": null, "tcdate": 1538087905526, "tmdate": 1538156010852, "tddate": null, "forum": "r1lq1hRqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following", "abstract": "Reinforcement learning is a promising framework for solving control problems, but its use in practical situations is hampered by the fact that reward functions are often difficult to engineer. Specifying goals and tasks for autonomous machines, such as robots, is a significant challenge: conventionally, reward functions and goal states have been used to communicate objectives. But people can communicate objectives to each other simply by describing or demonstrating them. How can we build learning algorithms that will allow us to tell machines what we want them to do? In this work, we investigate the problem of grounding language commands as reward functions using inverse reinforcement learning, and argue that language-conditioned rewards are more transferable than language-conditioned policies to new environments. We propose language-conditioned reward learning (LC-RL), which grounds language commands as a reward function represented by a deep neural network. We demonstrate that our model learns rewards that transfer to novel tasks and environments on realistic, high-dimensional visual environments with natural language commands, whereas directly learning a language-conditioned policy leads to poor performance.", "keywords": ["inverse reinforcement learning", "language grounding", "instruction following", "language-based learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1007/Authors"], "authors": ["Anonymous"], "TL;DR": "We ground language commands in a high-dimensional visual environment by learning language-conditioned rewards using inverse reinforcement learning.", "pdf": "/pdf/00602547104676a31d155c0b1af82871d8f1e115.pdf", "paperhash": "anonymous|from_language_to_goals_inverse_reinforcement_learning_for_visionbased_instruction_following", "_bibtex": "@inproceedings{    \nanonymous2019from,    \ntitle={From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lq1hRqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryl5khRcKm", "original": "rkgDBzwcFQ", "number": 1008, "cdate": 1538087905694, "ddate": null, "tcdate": 1538087905694, "tmdate": 1538156010635, "tddate": null, "forum": "ryl5khRcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Human-level Protein Localization with Convolutional Neural Networks", "abstract": "Localizing a specific protein in a human cell is essential for understanding cellular functions and biological processes of underlying diseases. A promising, low-cost, and time-efficient biotechnology for localizing proteins is high-throughput fluorescence microscopy imaging (HTI). HTI stains the protein of interest in a cell with fluorescent antibodies and subsequently takes a microscopic image. Together with images of other stained proteins or cell organelles and the annotation by the Human Protein Atlas project, these images provide a rich source of information on the protein location which can be utilized by computational methods. It is yet unclear how precise such methods are and whether they can compete with human experts. We here focus on deep learning image analysis methods and, in particular, on Convolutional Neural Networks (CNNs) since they showed overwhelming success across different imaging tasks. We propose a novel CNN architecture \u201cGapNet-PL\u201d that has been designed to tackle the characteristics of HTI data and uses global averages of filters at different abstraction levels. We present the largest comparison of CNN architectures including GapNet-PL for protein localization in HTI images of human cells. GapNet-PL outperforms all other competing methods and reaches close to perfect localization in all 13 tasks with an average AUC of 98% and F1 score of 78%. On a separate test set the performance of GapNet-PL was compared with a human expert. GapNet-PL achieved an accuracy of 91%, significantly (p-value 2e-10) outperforming the human expert with an accuracy of 61%.", "keywords": ["Convolutional Neural Networks", "High-resolution images", "Multiple-Instance Learning", "Microscopy Imaging", "Protein Localization"], "authorids": ["ICLR.cc/2019/Conference/Paper1008/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b884b920a8511100f39659461e5570607dc1f4a8.pdf", "paperhash": "anonymous|humanlevel_protein_localization_with_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019human-level,    \ntitle={Human-level Protein Localization with Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryl5khRcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJf9k305Fm", "original": "HkgmxpKqKQ", "number": 1009, "cdate": 1538087905864, "ddate": null, "tcdate": 1538087905864, "tmdate": 1538156010418, "tddate": null, "forum": "BJf9k305Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visualizing and Discovering Behavioural Weaknesses in Deep Reinforcement Learning", "abstract": "As deep reinforcement learning is being applied to more and more tasks, there is a growing need to better understand and probe the learned agents. Visualizing and understanding the decision making process can be very valuable to comprehend and identify problems in the learned behavior. However, this topic has been relatively under-explored in the reinforcement learning community. In this work we present a method for synthesizing states of interest for a trained agent. Such states could be situations (e.g. crashing or damaging a car) in which specific actions are necessary. Further, critical states in which a very high or a very low reward can be achieved (e.g. risky states) are often interesting to understand the situational awareness of the system. To this end, we learn a generative model over the state space of the environment and use its latent space to optimize a target function for the state of interest. In our experiments we show that this method can generate insightful visualizations for a variety of environments and reinforcement learning methods. We explore these issues in the standard Atari benchmark games as well as in an autonomous driving simulator. Based on the efficiency with which we have been able to identify significant decision scenarios with this technique, we believe this general approach could serve as an important tool for AI safety applications.", "keywords": ["Visualization", "Deep Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1009/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a method to synthesize states of interest for reinforcement learning agents in order to analyze their behavior. ", "pdf": "/pdf/031b1e528623d3b1cb5273e2cef20bd448bb5e26.pdf", "paperhash": "anonymous|visualizing_and_discovering_behavioural_weaknesses_in_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019visualizing,    \ntitle={Visualizing and Discovering Behavioural Weaknesses in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJf9k305Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygqJnCqtm", "original": "rJl6K5u9Km", "number": 1010, "cdate": 1538087906047, "ddate": null, "tcdate": 1538087906047, "tmdate": 1538156010206, "tddate": null, "forum": "HygqJnCqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Rating Continuous Actions in Spatial Multi-Agent Problems", "abstract": "We study credit assignment problems in spatial multi-agent environments where agents pursue a joint objective. On the example of soccer, we rate the movements of individual players with respect to their potential for staging a successful attack. We propose a purely data-driven approach to simultaneously learn a model of agent movements as well as their ratings via an agent-centric deep reinforcement learning framework. Our model allows for efficient learning and sampling of ratings in the continuous action space. We empirically observe on historic soccer data that the model accurately rates agent movements w.r.t. their relative contribution to the collective goal.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1010/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/afefc9fc414499637017252357755e1853bbe3b3.pdf", "paperhash": "anonymous|rating_continuous_actions_in_spatial_multiagent_problems", "_bibtex": "@inproceedings{    \nanonymous2019rating,    \ntitle={Rating Continuous Actions in Spatial Multi-Agent Problems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygqJnCqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SklckhR5Ym", "original": "rJgMziWcF7", "number": 1011, "cdate": 1538087906218, "ddate": null, "tcdate": 1538087906218, "tmdate": 1538156009998, "tddate": null, "forum": "SklckhR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improved Language Modeling by Decoding the Past", "abstract": "Highly regularized LSTMs achieve impressive results on several benchmark datasets in language modeling. We propose a new regularization method based on decoding the last token in the context using the predicted distribution of the next token. This biases the model towards retaining more contextual information, in turn improving its ability to predict the next token. With negligible overhead in the number of parameters and training time, our past decode regularization (PDR) method achieves state-of-the-art word level perplexity on the Penn Treebank (55.6) and WikiText-2 (63.5) datasets and bits-per-character on the Penn Treebank Character (1.169)  dataset for character level language modeling. Using dynamic evaluation, we also achieve the first sub 50 perplexity of 49.3 on the Penn Treebank test set.", "keywords": ["language modeling", "regularization", "LSTM"], "authorids": ["ICLR.cc/2019/Conference/Paper1011/Authors"], "authors": ["Anonymous"], "TL;DR": "Decoding the last token in the context using the predicted next token distribution acts as a regularizer and improves language modeling.", "pdf": "/pdf/2da76069b51609f240e74669fff8ce322d78e4bb.pdf", "paperhash": "anonymous|improved_language_modeling_by_decoding_the_past", "_bibtex": "@inproceedings{    \nanonymous2019improved,    \ntitle={Improved Language Modeling by Decoding the Past},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklckhR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJx5kn0cK7", "original": "BJecwMh5KQ", "number": 1012, "cdate": 1538087906406, "ddate": null, "tcdate": 1538087906406, "tmdate": 1538156009789, "tddate": null, "forum": "SJx5kn0cK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "HAPPIER: Hierarchical Polyphonic Music Generative RNN", "abstract": "Generating polyphonic music with coherent global structure is a major challenge for automatic composition algorithms. The primary difficulty arises due to the inefficiency of models to recognize underlying patterns beneath music notes across different levels of time scales and remain long-term consistency while composing. Hierarchical architectures can capture and represent learned patterns in different temporal scales and maintain consistency over long time spans, and this corresponds to the hierarchical structure in music. Motivated by this, focusing on leveraging the idea of hierarchical models and improve them to fit the sequence modeling problem, our paper proposes HAPPIER: a novel HierArchical PolyPhonic musIc gEnerative RNN. In HAPPIER, A higher `measure level' learns correlations across measures and patterns for chord progressions, and a lower `note level' learns a conditional distribution over the notes to generate within a measure. The two hierarchies operate at different clock rates: the higher one operates on a longer timescale and updates every measure, while the lower one operates on a shorter timescale and updates every unit duration. The two levels communicate with each other, and thus the entire architecture is trained jointly end-to-end by back-propagation. HAPPIER, profited from the strength of the hierarchical structure, generates polyphonic music with long-term dependencies compared to the state-of-the-art methods.", "keywords": ["hierarchical model", "RNN", "generative model", "automatic composing"], "authorids": ["ICLR.cc/2019/Conference/Paper1012/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/457475c9a969d80c693de2a0578cadadc97b92e3.pdf", "paperhash": "anonymous|happier_hierarchical_polyphonic_music_generative_rnn", "_bibtex": "@inproceedings{    \nanonymous2019happier:,    \ntitle={HAPPIER: Hierarchical Polyphonic Music Generative RNN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJx5kn0cK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xoy3CcYX", "original": "H1lHEBj9Ym", "number": 1013, "cdate": 1538087906575, "ddate": null, "tcdate": 1538087906575, "tmdate": 1538156009581, "tddate": null, "forum": "S1xoy3CcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Examples Are a Natural Consequence of Test Error in Noise", "abstract": "    Maliciously constructed inputs, or adversarial examples, can fool trained machine learning models. Over the last few years, adversarial examples have captured the attention of the research community, especially in the case where the adversary is restricted to making only small modifications of a correctly handled input. When it was first discovered that neural networks are sensitive to small perturbations, many researchers found this surprising and proposed several hypotheses to explain it. In this work, we show that this sensitivity and the poor performance of classification models (relative to humans) on noisy images are two manifestations of the same underlying phenomenon. Nearby errors simply lie on the boundary of a large set of errors whose volume can be measured using test error in additive noise. We present compelling new evidence in favor of this interpretation before discussing some preexisting results which also support our perspective. The relationship between nearby errors and failure to generalize in noise has implications for the adversarial defense literature, as it suggests that defenses which fail to reduce test error in noise will also fail to defend against small adversarial perturbations. This yields a computationally tractable evaluation metric for defenses to consider: test error in noisy image distributions.", "keywords": ["Adversarial examples", "generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1013/Authors"], "authors": ["Anonymous"], "TL;DR": "Small adversarial perturbations should be expected given observed error rates of models outside the natural data distribution.", "pdf": "/pdf/30d39e6b0a6badb1ab2401582c60df0d76f024ce.pdf", "paperhash": "anonymous|adversarial_examples_are_a_natural_consequence_of_test_error_in_noise", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Examples Are a Natural Consequence of Test Error in Noise},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xoy3CcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByloJ20qtm", "original": "rJebmyAqt7", "number": 1014, "cdate": 1538087906747, "ddate": null, "tcdate": 1538087906747, "tmdate": 1538156009373, "tddate": null, "forum": "ByloJ20qtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Program Repair by Jointly Learning to Localize and Repair", "abstract": "Due to its potential to improve programmer productivity and software quality, automated program repair has been an active topic of research. Newer techniques harness neural networks to learn directly from examples of buggy programs and their fixes. In this work, we consider a recently identified class of bugs called variable-misuse bugs. The state-of-the-art solution for variable misuse enumerates potential fixes for all possible bug locations in a program, before selecting the best prediction. We show that it is beneficial to train a model that jointly and directly localizes and repairs variable-misuse bugs. We present multi-headed pointer networks for this purpose, with one head each for localization and repair. The experimental results show that the joint model significantly outperforms an enumerative solution that uses a pointer based model for repair alone.", "keywords": ["neural program repair", "neural program embeddings", "pointer networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1014/Authors"], "authors": ["Anonymous"], "TL;DR": "Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs", "pdf": "/pdf/7c5712a1bc9f82c4192f204d4eb6579912a169b3.pdf", "paperhash": "anonymous|neural_program_repair_by_jointly_learning_to_localize_and_repair", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Program Repair by Jointly Learning to Localize and Repair},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByloJ20qtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgs1n05YQ", "original": "S1gqgLhqFX", "number": 1015, "cdate": 1538087906921, "ddate": null, "tcdate": 1538087906921, "tmdate": 1538156009164, "tddate": null, "forum": "SJgs1n05YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning and Planning with a Semantic Model", "abstract": "Building deep reinforcement learning agents that can generalize and adapt to unseen environments remains a fundamental challenge for AI. This paper describes progresses on this challenge in the context of man-made environments, which are visually diverse but contain intrinsic semantic regularities. We propose a hybrid model-based and model-free approach, LEArning and Planning with Semantics (LEAPS), consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target for the sub-policy to execute, and updates the semantic model based on new observations. We perform experiments in visual navigation tasks using House3D, a 3D environment that contains diverse human-designed indoor scenes with real-world objects. LEAPS outperforms strong baselines that do not explicitly plan using the semantic content.", "keywords": ["deep reinforcement learning", "generalization", "semantic structure", "model-based"], "authorids": ["ICLR.cc/2019/Conference/Paper1015/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a hybrid model-based & model-free approach using semantic information to improve DRL generalization in man-made environments.", "pdf": "/pdf/109813df773eec18675dc3825f22bfe8382bf44b.pdf", "paperhash": "anonymous|learning_and_planning_with_a_semantic_model", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning and Planning with a Semantic Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgs1n05YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgoyn09KQ", "original": "Skl37UhqKm", "number": 1016, "cdate": 1538087907103, "ddate": null, "tcdate": 1538087907103, "tmdate": 1538156008961, "tddate": null, "forum": "rkgoyn09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR", "abstract": "We address two challenges of probabilistic topic modelling in order to better estimate\nthe probability of a word in a given context, i.e., P(wordjcontext) : (1) No\nLanguage Structure in Context: Probabilistic topic models ignore word order by\nsummarizing a given context as a \u201cbag-of-word\u201d and consequently the semantics\nof words in the context is lost. In this work, we incorporate language structure\nby combining a neural autoregressive topic model (TM) with a LSTM based language\nmodel (LSTM-LM) in a single probabilistic framework. The LSTM-LM\nlearns a vector-space representation of each word by accounting for word order\nin local collocation patterns, while the TM simultaneously learns a latent representation\nfrom the entire document. In addition, the LSTM-LM models complex\ncharacteristics of language (e.g., syntax and semantics), while the TM discovers\nthe underlying thematic structure in a collection of documents. We unite two complementary\nparadigms of learning the meaning of word occurrences by combining\na topic model and a language model in a unified probabilistic framework, named\nas ctx-DocNADE. (2) Limited Context and/or Smaller training corpus of documents:\nIn settings with a small number of word occurrences (i.e., lack of context)\nin short text or data sparsity in a corpus of few documents, the application of TMs\nis challenging. We address this challenge by incorporating external knowledge\ninto neural autoregressive topic models via a language modelling approach: we\nuse word embeddings as input of a LSTM-LM with the aim to improve the wordtopic\nmapping on a smaller and/or short-text corpus. The proposed DocNADE\nextension is named as ctx-DocNADEe.\n\nWe present novel neural autoregressive topic model variants coupled with neural\nlanguage models and embeddings priors that consistently outperform state-of-theart\ngenerative topic models in terms of generalization (perplexity), interpretability\n(topic coherence) and applicability (retrieval and classification) over 6 long-text\nand 8 short-text datasets from diverse domains.", "keywords": ["neural topic model", "natural language processing", "text representation", "language modeling", "information retrieval", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1016/Authors"], "authors": ["Anonymous"], "TL;DR": "Unified neural model of topic and language modeling to introduce language structure  in topic models for contextualized topic vectors ", "pdf": "/pdf/471731d1077d70db693906a59d580be21c7cea79.pdf", "paperhash": "anonymous|texttovec_deep_contextualized_neural_autoregressive_models_of_language_with_distributed_compositional_prior", "_bibtex": "@inproceedings{    \nanonymous2019texttovec:,    \ntitle={textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgoyn09KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkesJ3R9YX", "original": "SkeUVTnqtm", "number": 1017, "cdate": 1538087907278, "ddate": null, "tcdate": 1538087907278, "tmdate": 1538156008749, "tddate": null, "forum": "BkesJ3R9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Where and when to look? Spatial-temporal attention for action recognition in videos", "abstract": "Inspired by the observation that humans are able to process videos efficiently by only paying attention when and where it is needed, we propose a novel spatial-temporal attention mechanism for video-based action recognition. For spatial attention, we learn a saliency mask to allow the model to focus on the most salient parts of the feature maps. \nFor temporal attention, we employ a soft temporal attention mechanism to identify the most relevant frames from an input video. Further, we propose a set of regularizers that ensure that our attention mechanism attends to coherent regions in space and time. Our model is efficient, as it proposes a separable spatio-temporal mechanism for video attention, while being able to identify important parts of the video both spatially and temporally.  We demonstrate the efficacy of our approach on three public video action recognition datasets. The proposed approach leads to state-of-the-art performance on all of them, including the new large-scale Moments in Time dataset. Furthermore, we quantitatively and qualitatively evaluate our model's ability to accurately localize discriminative regions spatially and critical frames temporally. This is despite our model only being trained with per video classification labels. ", "keywords": ["visual attention", "video action recognition", "network interpretability"], "authorids": ["ICLR.cc/2019/Conference/Paper1017/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3b393fbc310b19ac84188071e80eddfe87081d4c.pdf", "paperhash": "anonymous|where_and_when_to_look_spatialtemporal_attention_for_action_recognition_in_videos", "_bibtex": "@inproceedings{    \nanonymous2019where,    \ntitle={Where and when to look? Spatial-temporal attention for action recognition in videos},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkesJ3R9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1Gsk3R9Fm", "original": "r1luhqp5Ym", "number": 1018, "cdate": 1538087907448, "ddate": null, "tcdate": 1538087907448, "tmdate": 1538156008527, "tddate": null, "forum": "r1Gsk3R9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Shallow Learning For Deep Networks", "abstract": "Shallow supervised 1-hidden layer neural networks have a number of favorable properties that make them easier to interpret, analyze, and optimize than their deep counterparts, but lack their representational power.  Here we use 1-hiddenlayer learning problems to sequentially build deep networks layer by layer, which can inherit properties from shallow networks.  Contrary to previous approaches using shallow networks, we focus on problems where deep learning is reportedas critical for success. We thus study CNNs on two large-scale image recognition tasks:  ImageNet and CIFAR-10.   Using a simple set of ideas for architecture and training we find that solving sequential 1-hidden-layer auxiliary problemsleads to a CNN that exceeds AlexNet performance on ImageNet. Extending ourtraining methodology to construct individual layers by solving 2-and-3-hiddenlayer auxiliary problems, we obtain an 11-layer network that exceeds VGG-11 on ImageNet obtaining 89.8% top-5 single crop. To our knowledge, this is the first competitive alternative to end-to-end training of CNNs that can scale to ImageNet. We conduct a wide range of experiments to study the properties this induces on the intermediate layers.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1018/Authors"], "authors": ["Anonymous"], "TL;DR": "We build CNNs layer by layer without end to end training and show that this kind of approach can scale to Imagenet, while having multiple favorable  properties.", "pdf": "/pdf/e5596c81a12324f168710c01e25c5c12c10326b8.pdf", "paperhash": "anonymous|shallow_learning_for_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019shallow,    \ntitle={Shallow Learning For Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1Gsk3R9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkg313AcFX", "original": "ByltmgAqFm", "number": 1019, "cdate": 1538087907618, "ddate": null, "tcdate": 1538087907618, "tmdate": 1538156008316, "tddate": null, "forum": "Hkg313AcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Metropolis-Hastings view on variational inference and adversarial training", "abstract": "In this paper we propose to view the acceptance rate of the Metropolis-Hastings algorithm as a universal objective for learning to sample from target distribution -- given either as a set of samples or in the form of unnormalized density. This point of view unifies the goals of such approaches as Markov Chain Monte Carlo (MCMC), Generative Adversarial Networks (GANs), variational inference. To reveal the connection we derive the lower bound on the acceptance rate and treat it as the objective for learning explicit and implicit samplers. The form of the lower bound allows for doubly stochastic gradient optimization in case the target distribution factorizes (i.e. over data points). We empirically validate our approach on Bayesian inference for neural networks and generative models for images.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1019/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning to sample via lower bounding the acceptance rate of the Metropolis-Hastings algorithm", "pdf": "/pdf/26b07f5be5702648f240bfca4b52710896f4db6f.pdf", "paperhash": "anonymous|metropolishastings_view_on_variational_inference_and_adversarial_training", "_bibtex": "@inproceedings{    \nanonymous2019metropolis-hastings,    \ntitle={Metropolis-Hastings view on variational inference and adversarial training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkg313AcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byg3y3C9Km", "original": "BJgcXg0cYQ", "number": 1020, "cdate": 1538087907783, "ddate": null, "tcdate": 1538087907783, "tmdate": 1538156008105, "tddate": null, "forum": "Byg3y3C9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Protein Structure with a Differentiable Simulator", "abstract": "The Boltzmann distribution is a natural model for many systems, from brains to materials and biomolecules, but is often of limited utility for fitting data because Monte Carlo algorithms are unable simulate it in available time. This gap between the expressive capabilities and sampling practicalities of energy-based models is exemplified by the protein folding problem, since energy landscapes underlie contemporary knowledge of protein biophysics but computer simulations are still unable to fold all but the smallest proteins from first-principles. In this work we bridge the gap between the expressive capacity of energy functions and the practical capabilities of their simulators by using an unrolled Monte Carlo simulation as a model for data. We compose a neural energy function with a novel and efficient simulator based on Langevin dynamics to build an end-to-end-differentiable model of atomic protein structure given amino acid sequence information. We introduce techniques for stabilizing backpropagation under long roll-outs and demonstrate the model's capacity to make multimodal predictions and to generalize to unobserved protein fold types when trained on a large corpus of protein structures.", "keywords": ["generative modeling", "simulators", "molecular modeling", "proteins", "structured prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper1020/Authors"], "authors": ["Anonymous"], "TL;DR": "We use an unrolled simulator of a neural energy function as an end-to-end differentiable model of protein structure and show it can hierarchically generalize to unseen fold types.", "pdf": "/pdf/cbf8f35dfd2b0663dc75e7decf3dbafc2df0682b.pdf", "paperhash": "anonymous|learning_protein_structure_with_a_differentiable_simulator", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Protein Structure with a Differentiable Simulator},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byg3y3C9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lnJ2Rqt7", "original": "rkef6-j9Fm", "number": 1021, "cdate": 1538087908013, "ddate": null, "tcdate": 1538087908013, "tmdate": 1538156007896, "tddate": null, "forum": "H1lnJ2Rqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LARGE BATCH SIZE TRAINING OF NEURAL NETWORKS WITH ADVERSARIAL TRAINING AND SECOND-ORDER INFORMATION", "abstract": "Stochastic Gradient Descent (SGD) methods using randomly selected batches are widely-used to train neural network (NN) models. Performing design exploration to find the best NN for a particular task often requires extensive training with different models on a large dataset,  which is very computationally expensive. The most straightforward method to accelerate this computation is to distribute the batch of SGD over multiple processors. However, large batch training often times leads to degradation in accuracy, poor generalization, and even poor robustness to adversarial attacks.  Existing solutions for large batch training either do not work or require massive hyper-parameter tuning. To address this issue, we propose a novel large batch training method which combines recent results in adversarial training (to regularize against ``sharp minima'') and second order optimization (to use curvature information to change batch size adaptively during training). We extensively evaluate our method on Cifar-10/100, SVHN, TinyImageNet, and ImageNet datasets, using multiple NNs, including residual networks as well as compressed networks such as SqueezeNext.  Our new approach exceeds the performance of the existing solutions in terms of both accuracy and the number of SGD iterations (up to 1\\% and $3\\times$, respectively). We emphasize that this is achieved without any additional hyper-parameter tuning to tailor our method to any of these experiments.\n", "keywords": ["adversarial training", "large batch size", "neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper1021/Authors"], "authors": ["Anonymous"], "TL;DR": "Large batch size training using adversarial training and second order information", "pdf": "/pdf/f066053d342a2bb0d52090e6458d8e53fd11d357.pdf", "paperhash": "anonymous|large_batch_size_training_of_neural_networks_with_adversarial_training_and_secondorder_information", "_bibtex": "@inproceedings{    \nanonymous2019large,    \ntitle={LARGE BATCH SIZE TRAINING OF NEURAL NETWORKS WITH ADVERSARIAL TRAINING AND SECOND-ORDER INFORMATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lnJ2Rqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxhynC9KX", "original": "B1gS823qtm", "number": 1022, "cdate": 1538087908198, "ddate": null, "tcdate": 1538087908198, "tmdate": 1538156007685, "tddate": null, "forum": "ryxhynC9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CNNSAT: Fast, Accurate Boolean Satisfiability using Convolutional Neural Networks", "abstract": "Boolean satisfiability (SAT) is one of the most well-known NP-complete\nproblems and has been extensively studied.  State-of-the-art solvers\nexist and have found a wide range of applications. However, they still\ndo not scale well to formulas with hundreds of variables. To tackle\nthis fundamental scalability challenge, we introduce CNNSAT, a fast\nand accurate statistical decision procedure for SAT based on\nconvolutional neural networks. CNNSAT's effectiveness is due to a\nprecise and compact representation of Boolean\nformulas. On both real and synthetic formulas, CNNSAT is highly\n  accurate and orders of magnitude faster than the\nstate-of-the-art solver Z3.  We also describe how to extend CNNSAT to\npredict satisfying assignments when it predicts a formula to be\nsatisfiable.", "keywords": ["Convolutional Neural Networks", "Boolean satisfiability problem", "Satisfiability modulo theories"], "authorids": ["ICLR.cc/2019/Conference/Paper1022/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce CNNSAT, a fast and accurate statistical decision procedure for SAT based on convolutional neural networks.", "pdf": "/pdf/dde051adb37d8219abe8ddd1942657acef9d07b3.pdf", "paperhash": "anonymous|cnnsat_fast_accurate_boolean_satisfiability_using_convolutional_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019cnnsat:,    \ntitle={CNNSAT: Fast, Accurate Boolean Satisfiability using Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxhynC9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1g2JnRcFX", "original": "S1gyc_25Fm", "number": 1023, "cdate": 1538087908371, "ddate": null, "tcdate": 1538087908371, "tmdate": 1538156007456, "tddate": null, "forum": "S1g2JnRcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Local SGD Converges Fast and Communicates Little", "abstract": "Mini-batch stochastic gradient descent (SGD) is state of the art in large scale distributed training. The scheme can reach a linear speed-up with respect to the number of workers, but this is rarely seen in practice as the scheme often suffers from large network delays and bandwidth limits. To overcome this communication bottleneck recent works propose to reduce the communication frequency. An algorithm of this type is local SGD that runs SGD independently in parallel on different workers and averages the sequences only once in a while. This scheme shows promising results in practice, but eluded thorough theoretical analysis.\n    \nWe prove concise convergence rates for local SGD on convex problems and show that it converges at the same rate as mini-batch SGD in terms of number of evaluated gradients, that is, the scheme achieves linear speed-up in the number of workers and mini-batch size. The number of  communication rounds can be reduced up to a factor of T^{1/2}---where T denotes the number of total steps---compared to mini-batch SGD. This also holds for asynchronous implementations.\n\nLocal SGD can also be used for large scale training of deep learning models. The results shown here aim serving as a guideline to further explore the theoretical and practical aspects of local SGD in these applications.", "keywords": ["optimization", "communication", "theory", "stochastic gradient descent", "SGD", "mini-batch", "local SGD", "parallel restart SGD", "distributed training"], "authorids": ["ICLR.cc/2019/Conference/Paper1023/Authors"], "authors": ["Anonymous"], "TL;DR": "We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.", "pdf": "/pdf/3b6b540869c7dd7e56b01009b63b367aaba7be24.pdf", "paperhash": "anonymous|local_sgd_converges_fast_and_communicates_little", "_bibtex": "@inproceedings{    \nanonymous2019local,    \ntitle={Local SGD Converges Fast and Communicates Little},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1g2JnRcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgpy3C5tX", "original": "HkeTCro9F7", "number": 1024, "cdate": 1538087908546, "ddate": null, "tcdate": 1538087908546, "tmdate": 1538156007241, "tddate": null, "forum": "rkgpy3C5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Amortized Bayesian Meta-Learning", "abstract": "Meta-learning, or learning-to-learn, has proven to be a successful strategy in attacking problems in supervised learning and reinforcement learning that involve small amounts of data. State-of-the-art solutions involve learning an initialization and/or learning algorithm using a set of training episodes so that the meta learner can generalize to an evaluation episode quickly. These methods perform well but often lack good quantification of uncertainty, which can be vital to real-world applications when data is lacking. We propose a meta-learning method which efficiently amortizes hierarchical variational inference across tasks, learning a prior distribution over neural network weights so that a few steps of Bayes by Backprop will produce a good task-specific approximate posterior. We show that our method produces good uncertainty estimates on contextual bandit and few-shot learning benchmarks.", "keywords": ["variational inference", "meta-learning", "few-shot learning", "uncertainty quantification"], "authorids": ["ICLR.cc/2019/Conference/Paper1024/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a meta-learning method which efficiently amortizes hierarchical variational inference across training episodes.", "pdf": "/pdf/60e72bd2f7bc02b08ce3982cb52f771738524f80.pdf", "paperhash": "anonymous|amortized_bayesian_metalearning", "_bibtex": "@inproceedings{    \nanonymous2019amortized,    \ntitle={Amortized Bayesian Meta-Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgpy3C5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hygp1nR9FQ", "original": "H1gZrMa5tQ", "number": 1025, "cdate": 1538087908724, "ddate": null, "tcdate": 1538087908724, "tmdate": 1538156007025, "tddate": null, "forum": "Hygp1nR9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks", "abstract": "Recent analysis of deep neural networks has revealed their vulnerability to carefully structured adversarial examples. Many effective algorithms exist to craft these adversarial examples, but performant defenses seem to be far away. In this work,  we explore the use of edge-aware bilateral filtering as a projection back to the space of natural images. We show that bilateral filtering is an effective defense in multiple attack settings, where the strength of the adversary gradually increases. In the case of adversary who has no knowledge of the defense, bilateral filtering can remove more than 90% of adversarial examples from a variety of different attacks. To evaluate against an adversary with complete knowledge of our defense, we adapt the bilateral filter as a trainable layer in a neural network and show that adding this layer makes ImageNet images significantly more robust to attacks. When trained under a framework of adversarial training, we show that the resulting model is hard to fool with even the best attack methods. ", "keywords": ["Adversarial examples", "Image denoising"], "authorids": ["ICLR.cc/2019/Conference/Paper1025/Authors"], "authors": ["Anonymous"], "TL;DR": "We adapt bilateral filtering as a layer in a neural network which improves robustness to adversarial examples using nonlocal filtering.", "pdf": "/pdf/3b8d5c4a510af93ca0a74996fcb8aab8319bf4c9.pdf", "paperhash": "anonymous|unifying_bilateral_filtering_and_adversarial_training_for_robust_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019unifying,    \ntitle={Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygp1nR9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xaJn05FQ", "original": "r1grrxA5tX", "number": 1026, "cdate": 1538087908892, "ddate": null, "tcdate": 1538087908892, "tmdate": 1538156006817, "tddate": null, "forum": "H1xaJn05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sliced Wasserstein Auto-Encoders", "abstract": "In this paper we use the geometric properties of the optimal transport (OT) problem and the Wasserstein distances to define a prior distribution for the latent space of an auto-encoder. We introduce Sliced-Wasserstein Auto-Encoders (SWAE), that enable one to shape the distribution of the latent space into any samplable probability distribution without the need for training an adversarial network or having a likelihood function specified. In short, we regularize the auto-encoder loss with the sliced-Wasserstein distance between the distribution of the encoded training samples and a samplable prior distribution. We show that the proposed formulation has an efficient numerical solution that provides similar capabilities to Wasserstein Auto-Encoders (WAE) and Variational Auto-Encoders (VAE), while benefiting from an embarrassingly simple implementation. We provide extensive error analysis for our algorithm, and show its merits on three benchmark datasets.", "keywords": ["optimal transport", "Wasserstein distances", "auto-encoders", "unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1026/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper we use the sliced-Wasserstein distance to shape the latent distribution of an auto-encoder into any samplable prior distribution. ", "pdf": "/pdf/86f5eb47db6fbf842556e68b8b870bf10ecf1345.pdf", "paperhash": "anonymous|sliced_wasserstein_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019sliced,    \ntitle={Sliced Wasserstein Auto-Encoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xaJn05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJepJh0qKX", "original": "SkxFHlCqKX", "number": 1027, "cdate": 1538087909067, "ddate": null, "tcdate": 1538087909067, "tmdate": 1538156006612, "tddate": null, "forum": "HJepJh0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Empirical Study of Easy and Hard Examples in CNN Training", "abstract": "Deep Neural Networks (DNNs) generalize well despite their massive size and capability of memorizing all examples.\nThere is a hypothesis that DNNs start learning from simple patterns based on the observations that are consistently well-classified at early epochs (i.e., easy examples) and examples misclassified (i.e., hard examples).\nHowever, despite the importance of understanding the learning dynamics of DNNs, properties of easy and hard examples are not fully investigated.\nIn this paper, we study the similarities of easy and hard examples respectively among different CNNs, assessing those examples\u2019 contributions to generalization.\nOur results show that most easy examples are identical among different CNNs, as they share similar dataset-dependent patterns (e.g., colors, structures, and superficial cues in high-frequency).\nMoreover, while hard examples tend to contribute more to generalization than easy examples, removing a large number of easy examples leads to poor generalization, and we find that most misclassified examples in validation dataset are hard examples.\nBy analyzing intriguing properties of easy and hard examples, we discover that the reason why easy and hard examples have such properties can be explained by biases in a dataset and Stochastic Gradient Descent (SGD).", "keywords": ["easy examples", "hard example", "CNN"], "authorids": ["ICLR.cc/2019/Conference/Paper1027/Authors"], "authors": ["Anonymous"], "TL;DR": "Unknown properties of easy and hard examples are shown, and they come from biases in a dataset and SGD.", "pdf": "/pdf/0d13fbbca368863487ad2966e5ed7bf200ca19ef.pdf", "paperhash": "anonymous|empirical_study_of_easy_and_hard_examples_in_cnn_training", "_bibtex": "@inproceedings{    \nanonymous2019empirical,    \ntitle={Empirical Study of Easy and Hard Examples in CNN Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJepJh0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgTkhRcKQ", "original": "r1e-e-M5t7", "number": 1028, "cdate": 1538087909254, "ddate": null, "tcdate": 1538087909254, "tmdate": 1538156006399, "tddate": null, "forum": "HkgTkhRcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods", "abstract": "Adam is shown not being able to converge to the optimal solution in certain cases. Researchers recently propose several algorithms to avoid the issue of non-convergence of Adam, but their efficiency turns out to be unsatisfactory in practice. In this paper, we provide a new insight into the non-convergence issue of Adam as well as other adaptive learning rate methods. We argue that there exists an inappropriate correlation between gradient $g_t$ and the second moment term $v_t$ in Adam ($t$ is the timestep), which results in that a large gradient is likely to have small step size while a small gradient may have a large step size. We demonstrate that such unbalanced step sizes are the fundamental cause of non-convergence of Adam, and we further prove that decorrelating $v_t$ and $g_t$ will lead to unbiased step size for each gradient, thus solving the non-convergence problem of Adam. Finally, we propose AdaShift, a novel adaptive learning rate method that decorrelates $v_t$ and $g_t$ by temporal shifting, i.e., using temporally shifted gradient $g_{t-n}$ to calculate $v_t$. The experiment results demonstrate that AdaShift is able to address the non-convergence issue of Adam, while still maintaining a competitive performance with Adam in terms of both training speed and generalization. ", "keywords": ["optimizer", "Adam", "convergence", "decorrelation"], "authorids": ["ICLR.cc/2019/Conference/Paper1028/Authors"], "authors": ["Anonymous"], "TL;DR": "We analysis and solve the non-convergence issue of Adam.", "pdf": "/pdf/62a06f5b6f69b413ef9773705879b86e8d819dcb.pdf", "paperhash": "anonymous|adashift_decorrelation_and_convergence_of_adaptive_learning_rate_methods", "_bibtex": "@inproceedings{    \nanonymous2019adashift:,    \ntitle={AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgTkhRcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skl6k209Ym", "original": "rkgYGO6tY7", "number": 1029, "cdate": 1538087909426, "ddate": null, "tcdate": 1538087909426, "tmdate": 1538156006189, "tddate": null, "forum": "Skl6k209Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Alignment Based Mathching Networks for One-Shot Classification and Open-Set Recognition", "abstract": "Deep learning for object classification relies heavily on convolutional models. While effective, CNNs are rarely interpretable after the fact. An attention mechanism can be used to highlight the area of the image that the model focuses on thus offering a narrow view into the mechanism of classification. We expand on this idea by forcing the method to explicitly align images to be classified to reference images representing the classes. The mechanism of alignment is learned and therefore does not require that the reference objects are anything like those being classified. Beyond explanation, our exemplar based cross-alignment method enables classification with only a single example per category (one-shot). Our model cuts the 5-way, 1-shot error rate in Omniglot from 2.1\\% to 1.4\\% and in MiniImageNet from 53.5\\% to 46.5\\% while simultaneously providing point-wise alignment information providing some understanding on what the network is capturing. This method of alignment also enables the recognition of an unsupported class (open-set) in the one-shot setting while maintaining an F1-score of above 0.5 for Omniglot even with 19 other distracting classes while baselines completely fail to separate the open-set class in the one-shot setting.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1029/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b2aff749b17fb4801b3c2c8e8546b79f74c3b1d7.pdf", "paperhash": "anonymous|alignment_based_mathching_networks_for_oneshot_classification_and_openset_recognition", "_bibtex": "@inproceedings{    \nanonymous2019alignment,    \ntitle={Alignment Based Mathching Networks for One-Shot Classification and Open-Set Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skl6k209Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJg013C5KX", "original": "HJxq9AHqYQ", "number": 1030, "cdate": 1538087909596, "ddate": null, "tcdate": 1538087909596, "tmdate": 1538156005982, "tddate": null, "forum": "SJg013C5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Teaching to Teach by Structured Dark Knowledge", "abstract": "To educate hyper deep learners, \\emph{Curriculum Learnings} (CLs) require either human heuristic participation or self-deciding the difficulties of training instances. These coaching manners are blind to the coherent structures among examples, categories, and tasks, which are pregnant with more knowledgeable curriculum-routed teachers. In this paper, we propose a general methodology \\emph{Teaching to Teach} (T2T). T2T is facilitated by \\emph{Structured Dark Knowledge} (SDK) that constitutes a communication protocol between structured knowledge prior and teaching strategies. On one hand, SDK adaptively extracts structured knowledge by selecting a training subset consistent with the previous teaching decisions. On the other hand, SDK teaches curriculum-agnostic teachers by transferring this knowledge to update their teaching policy. This virtuous cycle can be flexibly-deployed in most existing CL platforms and more importantly, very generic across various structured knowledge characteristics, e.g., diversity, complementarity, and causality. We evaluate T2T across different learners, teachers, and tasks, which significantly demonstrates that structured knowledge can be inherited by the teachers to further benefit learners' training.\n", "keywords": ["teaching to teach", "dark knowledge", "curriculum learning", "teaching"], "authorids": ["ICLR.cc/2019/Conference/Paper1030/Authors"], "authors": ["Anonymous"], "TL;DR": "We newly proposed ``teaching to teach, to educate a better teacher to teach a better student by introducing structured dark knowledge.", "pdf": "/pdf/21e866806c410c1732c62a1c88852f08587f2efd.pdf", "paperhash": "anonymous|teaching_to_teach_by_structured_dark_knowledge", "_bibtex": "@inproceedings{    \nanonymous2019teaching,    \ntitle={Teaching to Teach by Structured Dark Knowledge},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJg013C5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BklAyh05YQ", "original": "B1ekjLsqFm", "number": 1031, "cdate": 1538087909768, "ddate": null, "tcdate": 1538087909768, "tmdate": 1538156005762, "tddate": null, "forum": "BklAyh05YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Network Bandit Learning by Last Layer Marginalization", "abstract": "We propose a new method for training neural networks online in a bandit setting. Similar to prior work, we model the uncertainty only in the last layer of the network, treating the rest of the network as a feature extractor. This allows us to successfully balance between exploration and exploitation due to the efficient, closed-form uncertainty estimates available for linear models. To train the rest of the network, we take advantage of the posterior we have over the last layer, optimizing over all values in the last layer distribution weighted by probability. We derive a closed form, differential approximation to this objective and show empirically over various models and datasets that training the rest of the network in this fashion leads to both better online and offline performance when compared to other methods.", "keywords": ["Bandit learning", "online learning", "contextual bandits", "neural network learning in online settings"], "authorids": ["ICLR.cc/2019/Conference/Paper1031/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes a new method for neural network learning in online bandit settings by marginalizing over the last layer", "pdf": "/pdf/e76f30548510499f3efd68bfb420d907d15aa121.pdf", "paperhash": "anonymous|neural_network_bandit_learning_by_last_layer_marginalization", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Network Bandit Learning by Last Layer Marginalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklAyh05YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylRk2A5FQ", "original": "HkehXldcYQ", "number": 1032, "cdate": 1538087909945, "ddate": null, "tcdate": 1538087909945, "tmdate": 1538156005553, "tddate": null, "forum": "HylRk2A5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Learning Network: A Structure Learning Algorithm", "abstract": "Graph prediction methods that work closely with the structure of the data, e.g., graph generation, commonly ignore the content of its nodes. On the other hand, the solutions that consider the node\u2019s information, e.g., classification, ignore the structure of the whole. And some methods exist in between, e.g., link prediction, but predict the structure piece-wise instead of considering the graph as a whole. We hypothesize that by jointly predicting the structure of the graph and its nodes\u2019 features, we can improve both tasks. We propose the Graph Learning Network (GLN), a simple yet effective process to learn node embeddings and structure prediction functions. Our model uses graph convolutions to propose expected node features, and predict the best structure based on them. We repeat these steps sequentially to enhance the prediction and the embeddings. In contrast to existing generation methods that rely only on the structure of the data, we use the feature on the nodes to predict better relations, similar to what link prediction methods do. However, we propose an holistic approach to process the whole graph for our predictions. Our experiments show that our method predicts consistent structures across a set of problems, while creating meaningful node embeddings.", "keywords": ["graph prediction", "graph structure learning", "graph neural network"], "authorids": ["ICLR.cc/2019/Conference/Paper1032/Authors"], "authors": ["Anonymous"], "TL;DR": "Methods for simultaneous prediction of nodes' feature embeddings and adjacency matrix, and how to learn this process.", "pdf": "/pdf/13426a6ef41774e9acb65816704749f9d5b8f62e.pdf", "paperhash": "anonymous|graph_learning_network_a_structure_learning_algorithm", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Learning Network: A Structure Learning Algorithm},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylRk2A5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeRkh05Km", "original": "r1x8gPpqF7", "number": 1033, "cdate": 1538087910110, "ddate": null, "tcdate": 1538087910110, "tmdate": 1538156005348, "tddate": null, "forum": "HJeRkh05Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visual Semantic Navigation using Scene Priors", "abstract": "How do humans navigate to target objects in novel scenes? Do we use the semantic/functional priors we have built over years to efficiently search and navigate? For example, to search for mugs, we search cabinets near the coffee machine and for fruits we try the fridge. In this work, we focus on incorporating semantic priors in the task of semantic navigation. We propose to use Graph Convolutional Networks for incorporating the prior knowledge into a deep reinforcement learning framework. The agent uses the features from the knowledge graph to predict the actions. For evaluation, we use the AI2-THOR framework. Our experiments show how semantic knowledge improves the  performance significantly. More importantly, we show improvement in generalization to unseen scenes and/or objects.", "keywords": ["Visual Navigation", "Scene Prior", "Knowledge Graph", "Graph Convolution Networks", "Deep Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1033/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5dce0be37ab5cf6218a7fd07567058ccf47254b9.pdf", "paperhash": "anonymous|visual_semantic_navigation_using_scene_priors", "_bibtex": "@inproceedings{    \nanonymous2019visual,    \ntitle={Visual Semantic Navigation using Scene Priors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeRkh05Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeAy3AqYm", "original": "BJxO8gCctQ", "number": 1034, "cdate": 1538087910306, "ddate": null, "tcdate": 1538087910306, "tmdate": 1538156005130, "tddate": null, "forum": "ryeAy3AqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Distilled Agent DQN for Provable Adversarial Robustness", "abstract": "As deep neural networks have become the state of the art for solving complex reinforcement learning tasks, susceptibility to perceptual adversarial examples have become a concern. The transferability of adversarial examples for neural networks is known to enable attacks capable of tricking the agent into bad states or into not being able to learn at all. In this work we demonstrate a simple poisoning attack able to fool DQNs when trained with defense methods commonly used for classification tasks. We also propose an algorithm, called DadQN, which is based on deep Q-networks and enables the use of stronger defenses, including defenses increasing provability.", "keywords": ["reinforcement learning", "dqn", "adversarial examples", "robustness analysis", "adversarial defense", "robust learning", "robust rl"], "authorids": ["ICLR.cc/2019/Conference/Paper1034/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a way of (provably) defending Deep-RL against adversarial perturbations, including a new poisoning attack.", "pdf": "/pdf/25471815f879120e40bae7242601b400a74031f9.pdf", "paperhash": "anonymous|distilled_agent_dqn_for_provable_adversarial_robustness", "_bibtex": "@inproceedings{    \nanonymous2019distilled,    \ntitle={Distilled Agent DQN for Provable Adversarial Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeAy3AqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MAJhR5YX", "original": "BJxrqUs9KX", "number": 1035, "cdate": 1538087910475, "ddate": null, "tcdate": 1538087910475, "tmdate": 1538156004919, "tddate": null, "forum": "B1MAJhR5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Empirical Bounds on Linear Regions of Deep Rectifier Networks", "abstract": "One form of characterizing the expressiveness of a piecewise linear neural network is by the number of linear regions, or pieces, of the function modeled. We have observed substantial progress in this topic through lower and upper bounds on the maximum number of linear regions and a counting procedure. However, these bounds only account for the dimensions of the network and the exact counting may take a prohibitive amount of time, therefore making it infeasible to benchmark the expressiveness of networks. In this work, we approximate the number of linear regions of specific rectifier networks with an algorithm for probabilistic lower bounds of mixed-integer linear sets. In addition, we present a tighter upper bound that leverages network coefficients. We test both on trained networks. The algorithm for probabilistic lower bounds is several orders of magnitude faster than exact counting and the values reach similar orders of magnitude, hence making our approach a viable method to compare the expressiveness of such networks. The refined upper bound is particularly stronger on networks with narrow layers.  ", "keywords": ["linear regions", "approximate model counting", "mixed-integer linear programming"], "authorids": ["ICLR.cc/2019/Conference/Paper1035/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.", "pdf": "/pdf/d9f58f980b435a26576cbac2081fa07d500cbcb2.pdf", "paperhash": "anonymous|empirical_bounds_on_linear_regions_of_deep_rectifier_networks", "_bibtex": "@inproceedings{    \nanonymous2019empirical,    \ntitle={Empirical Bounds on Linear Regions of Deep Rectifier Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MAJhR5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xyx3R9tQ", "original": "BylgM535F7", "number": 1036, "cdate": 1538087910643, "ddate": null, "tcdate": 1538087910643, "tmdate": 1538156004712, "tddate": null, "forum": "r1xyx3R9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Prototypical Examples in Deep Learning: Metrics, Characteristics, and Utility", "abstract": "Machine learning (ML) research has investigated prototypes: examples that are representative of the behavior to be learned. We systematically evaluate five methods for identifying prototypes, both ones previously introduced as well as new ones we propose, finding all of them to provide meaningful but different interpretations. Through a human study, we confirm that all five metrics are well matched to human intuition. Examining cases where the metrics disagree offers an informative perspective on the properties of data and algorithms used in learning, with implications for data-corpus construction, efficiency, adversarial robustness, interpretability, and other ML aspects. In particular, we confirm that the \"train on hard\" curriculum approach can improve accuracy on many datasets and tasks, but that it is strictly worse when there are many mislabeled or ambiguous examples.", "keywords": ["prototypes", "curriculum learning", "interpretability", "differential privacy", "adversarial robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper1036/Authors"], "authors": ["Anonymous"], "TL;DR": "We can identify prototypical and outlier examples in machine learning that are quantifiably very different, and make use of them to improve many aspects of neural networks.", "pdf": "/pdf/7e85ce76966ab102826ce0d9c2c1b860037bcc21.pdf", "paperhash": "anonymous|prototypical_examples_in_deep_learning_metrics_characteristics_and_utility", "_bibtex": "@inproceedings{    \nanonymous2019prototypical,    \ntitle={Prototypical Examples in Deep Learning: Metrics, Characteristics, and Utility},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xyx3R9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgklhAcK7", "original": "r1xllNtFYQ", "number": 1037, "cdate": 1538087910817, "ddate": null, "tcdate": 1538087910817, "tmdate": 1538156004503, "tddate": null, "forum": "BJgklhAcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning with Latent Embedding Optimization", "abstract": "Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this low-dimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data and model parameters, and can perform adaptation more effectively by optimizing in latent space.", "keywords": ["meta-learning", "few-shot", "miniImageNet", "tieredImageNet", "hypernetworks", "generative", "latent embedding", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1037/Authors"], "authors": ["Anonymous"], "TL;DR": "Latent Embedding Optimization (LEO) is a novel gradient-based meta-learner with state-of-the-art performance on the challenging 5-way 1-shot and 5-shot miniImageNet and tieredImageNet classification tasks.", "pdf": "/pdf/a67a1130f5f694d578f45610321f8679b855e98e.pdf", "paperhash": "anonymous|metalearning_with_latent_embedding_optimization", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning with Latent Embedding Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgklhAcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skeke3C5Fm", "original": "SylQnch5Ym", "number": 1038, "cdate": 1538087910988, "ddate": null, "tcdate": 1538087910988, "tmdate": 1538156004299, "tddate": null, "forum": "Skeke3C5Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multilingual Neural Machine Translation With Soft Decoupled Encoding", "abstract": "Multilingual training of neural machine translation (NMT) systems has led to impressive accuracy improvements on low-resource languages. However, there are still significant challenges in efficiently learning word representations in the face of paucity of data. In this paper, we propose Soft Decoupled Encoding (SDE), a multilingual lexicon encoding framework specifically designed to share lexical-level information intelligently without requiring heuristic preprocessing such as pre-segmenting the data. SDE represents a word by its spelling through a character encoding, and its semantic meaning through a latent embedding space shared by all languages. Experiments on a standard dataset of four low-resource languages show consistent improvements over strong multilingual NMT baselines, with gains of up to 2 BLEU on one of the tested languages, achieving the new state-of-the-art on all four language pairs.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1038/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f4bc08c9d532c7bd3762dca6704da2898fee6a56.pdf", "paperhash": "anonymous|multilingual_neural_machine_translation_with_soft_decoupled_encoding", "_bibtex": "@inproceedings{    \nanonymous2019multilingual,    \ntitle={Multilingual Neural Machine Translation With Soft Decoupled Encoding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skeke3C5Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgkx2Aqt7", "original": "S1lePw35Y7", "number": 1039, "cdate": 1538087911154, "ddate": null, "tcdate": 1538087911154, "tmdate": 1538156004082, "tddate": null, "forum": "HJgkx2Aqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning To Simulate", "abstract": "Simulation is a useful tool in situations where training data for machine learning models is costly to annotate or even hard to acquire. In this work, we propose a reinforcement learning-based method for automatically adjusting the parameters of any (non-differentiable) simulator, thereby controlling the distribution of synthesized data in order to maximize the accuracy of a model trained on that data. In contrast to prior art that hand-crafts these simulation parameters or adjusts only parts of the available parameters, our approach fully controls the simulator with the actual underlying goal of maximizing accuracy, rather than mimicking the real data distribution or randomly generating a large volume of data. We find that our approach (i) quickly converges to the optimal simulation parameters in controlled experiments and (ii) can indeed discover good sets of parameters for an image rendering simulator in actual computer vision applications.", "keywords": ["Simulation in machine learning", "reinforcement learning", "policy gradients", "image rendering"], "authorids": ["ICLR.cc/2019/Conference/Paper1039/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an algorithm that automatically adjusts parameters of a simulation engine to generate training data for a neural network such that validation accuracy is maximized.", "pdf": "/pdf/0b6114da9ce132ba91c98d9cd6987cdf7581414a.pdf", "paperhash": "anonymous|learning_to_simulate", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning To Simulate},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgkx2Aqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJz1x20cFQ", "original": "S1gfZVj9Km", "number": 1040, "cdate": 1538087911348, "ddate": null, "tcdate": 1538087911348, "tmdate": 1538156003867, "tddate": null, "forum": "SJz1x20cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies", "abstract": "In this paper we introduce a simple, robust approach to hierarchically training an agent in the setting of sparse reward tasks.\nThe agent is split into a low-level and a high-level policy. The low-level policy only accesses internal, proprioceptive dimensions of the state observation. The low-level policies are trained with a simple reward that encourages changing the values of the non-proprioceptive dimensions. Furthermore, it is induced to be periodic with the use a ``phase function.'' The high-level policy is trained using a sparse, task-dependent reward, and operates by choosing which of the low-level policies to run at any given time. Using this approach, we solve difficult maze and navigation tasks with sparse rewards using the Mujoco Ant and Humanoid agents and show improvement over recent hierarchical methods. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1040/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0c425043dc4ff682322fa41eb4c7a0e6018936fb.pdf", "paperhash": "anonymous|hierarchical_rl_using_an_ensemble_of_proprioceptive_periodic_policies", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJz1x20cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1glehC5tQ", "original": "H1xf1loYYX", "number": 1041, "cdate": 1538087911571, "ddate": null, "tcdate": 1538087911571, "tmdate": 1538156003658, "tddate": null, "forum": "r1glehC5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Distinguishability of Adversarial Examples", "abstract": "Machine learning models including traditional models and neural networks can be easily fooled by adversarial examples which are generated from the natural examples with small perturbations.  This poses a critical challenge to machine learning security, and impedes the wide application of machine learning in many important domains such as computer vision and malware detection.  Unfortunately, even state-of-the-art defense approaches such as adversarial training and defensive distillation still suffer from major limitations and can be circumvented.  From a unique angle, we propose to investigate two important research questions in this paper: Are adversarial examples distinguishable from natural examples?  Are adversarial examples generated by different methods distinguishable from each other?  These two questions concern the distinguishability of adversarial examples.  Answering them will potentially lead to a simple yet effective approach, termed as defensive distinction in this paper under the formulation of multi-label classification, for protecting against adversarial examples.  We design and perform experiments using the MNIST dataset to investigate these two questions, and obtain highly positive results demonstrating the strong distinguishability of adversarial examples.  We recommend that this unique defensive distinction approach should be seriously considered to complement other defense approaches.", "keywords": ["Adversarial Examples", "Machine Learning", "Neural Networks", "Distinguishability", "Defense"], "authorids": ["ICLR.cc/2019/Conference/Paper1041/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a defensive distinction protection approach and demonstrate the strong distinguishability of adversarial examples.", "pdf": "/pdf/dc04eae63abcb4edcbe6a17b372b4fb03a501a31.pdf", "paperhash": "anonymous|distinguishability_of_adversarial_examples", "_bibtex": "@inproceedings{    \nanonymous2019distinguishability,    \ntitle={Distinguishability of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1glehC5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJegl2C9K7", "original": "S1eiGjCvYQ", "number": 1042, "cdate": 1538087911742, "ddate": null, "tcdate": 1538087911742, "tmdate": 1538156003457, "tddate": null, "forum": "rJegl2C9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Feature Matters: A Stage-by-Stage Approach for Task Independent Knowledge Transfer", "abstract": "Convolutional Neural Networks (CNNs) become deeper and deeper in recent years, making the study of model acceleration imperative. It is a common practice to employ a shallow network, called student, to learn from a deep one, which is termed as teacher. Prior work made many attempts to transfer different types of knowledge from teacher to student, however, there are two problems remaining unsolved. Firstly, the knowledge used by existing methods is highly dependent on task and dataset, limiting their applications. Secondly, there lacks an effective training scheme for the transfer process, leading to degradation of performance. In this work, we argue that feature is the most important knowledge from teacher. It is sufficient for student to just learn good features regardless of the target task. From this discovery, we further present an efficient learning strategy to mimic features stage by stage. Extensive experiments demonstrate the importance of features and show that the proposed approach significantly narrows down the gap between student and teacher, outperforming the state-of-the-art methods.\n", "keywords": ["knowledge transfer", "task independent", "feature transfer", "stage-by-stage"], "authorids": ["ICLR.cc/2019/Conference/Paper1042/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes to transfer knowledge from deep model to shallow one by mimicking features stage by stage.", "pdf": "/pdf/06729f67091f583f6caef1c72f89e598b8f957cf.pdf", "paperhash": "anonymous|feature_matters_a_stagebystage_approach_for_task_independent_knowledge_transfer", "_bibtex": "@inproceedings{    \nanonymous2019feature,    \ntitle={Feature Matters: A Stage-by-Stage Approach for Task Independent Knowledge Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJegl2C9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJflg30qKX", "original": "r1lide0cKQ", "number": 1043, "cdate": 1538087911980, "ddate": null, "tcdate": 1538087911980, "tmdate": 1538156003253, "tddate": null, "forum": "HJflg30qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gradient descent aligns the layers of deep linear networks", "abstract": "This paper establishes risk convergence and asymptotic weight matrix alignment --- a form of implicit regularization --- of gradient flow and gradient descent when applied to deep linear networks on linearly separable data. In more detail, for gradient flow applied to strictly decreasing loss functions (with similar results for gradient descent with particular decreasing step sizes):\n(1) the risk converges to 0;\n(ii) the normalized i-th weight matrix asymptotically equals its\nrank-1 approximation u_iv_i^T;\n(iii) these rank-1 matrices are aligned across layers, meaning |v_{i+1}^T u_i| -> 1.\nIn the case of the logistic loss (binary cross entropy), more can be said: the linear function induced by the network --- the product of its weight matrices --- converges to the same direction as the maximum margin solution. This last property was identified in prior work, but only under assumptions on gradient descent which here are implied by the alignment phenomenon.", "keywords": ["implicit regularization", "alignment of layers", "deep linear networks", "gradient descent", "separable data"], "authorids": ["ICLR.cc/2019/Conference/Paper1043/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2224784cbde9a73062efb352f877943c11557bcb.pdf", "paperhash": "anonymous|gradient_descent_aligns_the_layers_of_deep_linear_networks", "_bibtex": "@inproceedings{    \nanonymous2019gradient,    \ntitle={Gradient descent aligns the layers of deep linear networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJflg30qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJglg2A9FX", "original": "HJeEh09qYm", "number": 1044, "cdate": 1538087912150, "ddate": null, "tcdate": 1538087912150, "tmdate": 1538156003034, "tddate": null, "forum": "HJglg2A9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Iteratively Learning from the Best", "abstract": "We study a simple generic framework to address the issue of bad training data; both bad labels in supervised problems, and bad samples in unsupervised ones. Our approach starts by fitting a model to the whole training dataset, but then iteratively improves it by alternating between (a) revisiting the training data to select samples with lowest current loss, and (b) re-training the model on only these selected samples. It can be applied to any existing model training setting which provides a loss measure for samples, and a way to refit on new ones. We show the merit of this approach in both theory and practice We first prove statistical consistency, and linear convergence to the ground truth and global optimum, for two simpler model settings: mixed linear regression, and gaussian mixture models.  We then demonstrate its success empirically in (a) saving the accuracy of existing deep image classifiers when there are errors in the labels of training images, and (b) improving the quality of samples generated by existing DC-GAN models, when it is given training data that contains a fraction of the images from a different and unintended dataset.  The experimental results show  significant improvement over the baseline methods that ignore the existence of bad labels/samples. ", "keywords": ["noisy samples", "deep learning", "generative adversarial network"], "authorids": ["ICLR.cc/2019/Conference/Paper1044/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a simple framework that addresses the problem of spurious data in both supervised and unsupervised settings.", "pdf": "/pdf/b3e77bf142d212666af4a2a4c655ed7d4dca3055.pdf", "paperhash": "anonymous|iteratively_learning_from_the_best", "_bibtex": "@inproceedings{    \nanonymous2019iteratively,    \ntitle={Iteratively Learning from the Best},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJglg2A9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylxxhRctX", "original": "rkeYFC65Km", "number": 1045, "cdate": 1538087912338, "ddate": null, "tcdate": 1538087912338, "tmdate": 1538156002823, "tddate": null, "forum": "rylxxhRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Coverage and Quality Driven Training of Generative Image Models", "abstract": "Generative modeling of natural images has been extensively studied in recent years, yielding remarkable progress. Current state-of-the-art methods are either based on maximum likelihood estimation or adversarial training. Both methods have their own drawbacks, which are complementary in nature. The first leads to over-generalization as the maximum likelihood criterion encourages models to cover the support of the training data by heavily penalizing small masses assigned to training data. Simplifying assumptions in such models limits their capacity and makes them spill mass on unrealistic samples. The second leads to mode-dropping since adversarial training encourages high quality samples from the model, but only indirectly enforces diversity among the samples. To overcome these drawbacks we make two contributions. First, we propose a model that extends variational autoencoders by using deterministic invertible transformation layers to map samples from the decoder to the image space. This induces correlations among the pixels given the latent variables, improving over factorial decoders commonly used in variational autoencoders. Second, we propose a unified training approach that leverages coverage and quality based criteria. Our models obtain likelihood scores competitive with state-of-the-art likelihood-based models, while achieving sample quality typical of adversarially trained networks. ", "keywords": ["deep learning", "generative modeling", "unsupervised learning", "maximum likelihood", "adversarial learning", "gan", "vae"], "authorids": ["ICLR.cc/2019/Conference/Paper1045/Authors"], "authors": ["Anonymous"], "TL;DR": "Generative models that yield Gan-like samples and achieve competitive likelihood on held-out data. ", "pdf": "/pdf/6160ac7dd4bbfbe48ded782a7dd22ca403934541.pdf", "paperhash": "anonymous|coverage_and_quality_driven_training_of_generative_image_models", "_bibtex": "@inproceedings{    \nanonymous2019coverage,    \ntitle={Coverage and Quality Driven Training of Generative Image Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylxxhRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skgge3R9FQ", "original": "B1eUNq35YX", "number": 1046, "cdate": 1538087912510, "ddate": null, "tcdate": 1538087912510, "tmdate": 1538156002620, "tddate": null, "forum": "Skgge3R9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Controlling Over-generalization and its Effect on Adversarial Examples Detection and Generation", "abstract": "Convolutional Neural Networks (CNNs) significantly improve the state-of-the-art for many applications, especially in computer vision. However, CNNs still suffer from a tendency to confidently classify out-distribution samples from unknown classes into pre-defined known classes. Further, they are also vulnerable to adversarial examples. We are relating these two issues through the tendency of CNNs to over-generalize for areas of the input space not covered well by the training set. We show that a CNN augmented with an extra output class can act as a simple yet effective end-to-end model for controlling over-generalization. As an appropriate training set for the extra class, we introduce two resources that are computationally efficient to obtain: a representative natural out-distribution set and interpolated in-distribution samples. To help select a representative natural out-distribution set among available ones, we propose a simple measurement to assess an out-distribution set's fitness. We also demonstrate that training such an augmented CNN with representative out-distribution natural datasets and some interpolated samples allows it to better handle a wide range of unseen out-distribution samples and black-box adversarial examples without training it on any adversaries. Finally, we show that generation of white-box adversarial attacks using our proposed augmented CNN can become harder, as the attack algorithms have to get around the rejection regions when generating actual adversaries.", "keywords": ["Convolutional Neural Networks", "Adversarial Instances", "Out-distribution Samples", "Rejection Option", "Over-generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1046/Authors"], "authors": ["Anonymous"], "TL;DR": "Properly training CNNs with dustbin class increase their robustness to adversarial attacks and their capacity to deal with out-distribution samples.", "pdf": "/pdf/90f0fd97d7e104314ea4596c1bffb7f2089968c2.pdf", "paperhash": "anonymous|controlling_overgeneralization_and_its_effect_on_adversarial_examples_detection_and_generation", "_bibtex": "@inproceedings{    \nanonymous2019controlling,    \ntitle={Controlling Over-generalization and its Effect on Adversarial Examples Detection and Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skgge3R9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgWl3A5YX", "original": "rkgSDoccKm", "number": 1047, "cdate": 1538087912673, "ddate": null, "tcdate": 1538087912673, "tmdate": 1538156002416, "tddate": null, "forum": "BJgWl3A5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Body is not a Given: Joint Agent Policy Learning and Morphology Evolution", "abstract": "Reinforcement learning (RL) has proven to be a powerful paradigm for deriving complex behaviors from simple reward signals in a wide range of environments. When applying RL to continuous control agents in simulated physics environments, the body is usually considered to be part of the environment. However, during evolution the physical body of biological organisms and their controlling brains are co-evolved, thus exploring a much larger space of actuator/controller configurations. Put differently, the intelligence does not reside only in the agent's mind, but also in the design of their body. \nWe propose a method for uncovering strong agents, consisting of a good combination of a body and policy, based on combining RL with an evolutionary procedure. Given the resulting agent, we also propose an approach for identifying the body changes that contributed the most to the agent performance. We use the Shapley value from cooperative game theory to find the fair contribution of individual components, taking into account synergies between components. \nWe evaluate our methods in an environment similar to the the recently proposed Robo-Sumo task, where agents in a 3D environment with simulated physics compete in tipping over their opponent or pushing them out of the arena. Our results show that the proposed methods are indeed capable of generating strong agents, significantly outperforming baselines that focus on optimizing the agent policy alone. \n\nA video is available at: www.youtube.com/watch?v=eei6Rgom3YY", "keywords": ["Reinforcement Learning", "Continuous Control", "Evolutionary Computation", "Genetic Algorithms", "Evolving Morphology", "Baldwin Effect", "Population Based Training"], "authorids": ["ICLR.cc/2019/Conference/Paper1047/Authors"], "authors": ["Anonymous"], "TL;DR": "Evolving the shape of the body in RL controlled agents improves their performance (and help learning)", "pdf": "/pdf/e0cb762e4788adb7e795f442d9f3b13bc2a17768.pdf", "paperhash": "anonymous|the_body_is_not_a_given_joint_agent_policy_learning_and_morphology_evolution", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Body is not a Given: Joint Agent Policy Learning and Morphology Evolution},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgWl3A5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1x-x309tm", "original": "BklbDgC5t7", "number": 1048, "cdate": 1538087912844, "ddate": null, "tcdate": 1538087912844, "tmdate": 1538156002209, "tddate": null, "forum": "H1x-x309tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Convergence of A Class of Adam-Type Algorithms  for Non-Convex Optimization", "abstract": "This paper studies a class of adaptive gradient based momentum algorithms that update the  search directions and learning rates simultaneously using past gradients. This class, which we refer to as the ''``Adam-type'', includes the popular algorithms such as Adam, AMSGrad, AdaGrad. Despite their popularity in training deep neural networks (DNNs), the convergence of these algorithms for solving  non-convex problems remains an open question. In this paper, we develop an analysis framework and a set of mild sufficient conditions that guarantee the convergence of the Adam-type methods, with a convergence rate of order   $O(\\log{T}/\\sqrt{T})$ for non-convex stochastic optimization. Our convergence analysis applies to a new algorithm called AdaFom (AdaGrad with First Order Momentum). We show that the conditions are essential, by identifying concrete examples in which violating the conditions makes an algorithm diverge. Besides providing one of the first comprehensive analysis for Adam-type methods in the non-convex setting, our results can also help the practitioners to easily  monitor the progress of algorithms and determine their convergence behavior. ", "keywords": ["nonconvex optimization", "Adam", "convergence analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper1048/Authors"], "authors": ["Anonymous"], "TL;DR": "We analyze convergence of Adam-type algorithms and provide mild sufficient conditions to guarantee their convergence, we also show  violating the conditions can makes an algorithm diverge.", "pdf": "/pdf/cc73a47ad3d96fce5885d96cc9ea30eb7c90a86e.pdf", "paperhash": "anonymous|on_the_convergence_of_a_class_of_adamtype_algorithms_for_nonconvex_optimization", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Convergence of A Class of Adam-Type Algorithms  for Non-Convex Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1x-x309tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syeben09FQ", "original": "Hyl_lBT5YX", "number": 1049, "cdate": 1538087913010, "ddate": null, "tcdate": 1538087913010, "tmdate": 1538156001994, "tddate": null, "forum": "Syeben09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Evaluating GANs via Duality", "abstract": "Generative Adversarial Networks (GANs) have shown great results in accurately modeling complex distributions, but their training is known to be difficult due to instabilities caused by a challenging minimax optimization problem. This is especially troublesome given the lack of an evaluation metric that can reliably detect non-convergent behaviors. We leverage the notion of duality gap from game theory in order to propose a novel convergence metric for GANs that has low computational cost. We verify the validity of the proposed metric for various test scenarios commonly used in the literature. ", "keywords": ["Generative Adversarial Networks", "GANs", "game theory"], "authorids": ["ICLR.cc/2019/Conference/Paper1049/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b12d3cb7bbf2b817c682fe5502596d5122d8e9c5.pdf", "paperhash": "anonymous|evaluating_gans_via_duality", "_bibtex": "@inproceedings{    \nanonymous2019evaluating,    \ntitle={Evaluating GANs via Duality},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syeben09FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkMWx309FX", "original": "BkepL4y5KX", "number": 1050, "cdate": 1538087913186, "ddate": null, "tcdate": 1538087913186, "tmdate": 1538156001786, "tddate": null, "forum": "BkMWx309FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reinforcement Learning with Perturbed Rewards", "abstract": "Recent studies have shown the vulnerability of reinforcement learning (RL) models in noisy settings. The sources of noises differ across scenarios. For instance, in practice, the observed reward channel is often subject to noise (e.g., when observed rewards are collected through sensors), and thus observed rewards may not be credible as a result. Also, in applications such as robotics, a deep reinforcement learning (DRL) algorithm can be manipulated to produce arbitrary errors. In this paper, we consider noisy RL problems where observed rewards by RL agents are generated with a reward confusion matrix. We call such observed rewards as perturbed rewards. We develop an unbiased reward estimator aided robust RL framework that enables RL agents to learn in noisy environments while observing only perturbed rewards. Our framework draws upon approaches for supervised learning with noisy data. The core ideas of our solution include estimating a reward confusion matrix and defining a set of unbiased surrogate rewards. We prove the convergence and sample complexity of our approach. Extensive experiments on different DRL platforms show that policies based on our estimated surrogate reward can achieve higher expected rewards, and converge faster than existing baselines. For instance, the state-of-the-art PPO algorithm is able to obtain 67.5% and 46.7% improvements in average on five Atari games, when the error rates are 10% and 30% respectively. ", "keywords": ["robust reinforcement learning", "noisy reward", "sample complexity"], "authorids": ["ICLR.cc/2019/Conference/Paper1050/Authors"], "authors": ["Anonymous"], "TL;DR": "A new approach for learning with noisy rewards in reinforcement learning", "pdf": "/pdf/f89a709407274f9152ae7a03b513930c552c2774.pdf", "paperhash": "anonymous|reinforcement_learning_with_perturbed_rewards", "_bibtex": "@inproceedings{    \nanonymous2019reinforcement,    \ntitle={Reinforcement Learning with Perturbed Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMWx309FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1l-e3Cqtm", "original": "SJg7cxA9F7", "number": 1051, "cdate": 1538087913367, "ddate": null, "tcdate": 1538087913367, "tmdate": 1538156001582, "tddate": null, "forum": "r1l-e3Cqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Probabilistic Video Compression", "abstract": "We propose a variational inference approach to deep probabilistic video compression.  Our model uses advances in variational autoencoders (VAEs) for sequential data and combines it with recent work on neural image compression. The approach jointly learns to transform the original video into a  lower-dimensional representation as well as to entropy code this representation according to a temporally-conditioned probabilistic model. We split the latent space into local (per frame) and global (per segment) variables, and show that training the VAE to utilize both representations leads to an improved rate-distortion performance. Evaluation on small videos from public data sets with varying complexity and diversity show that our model yields competitive results when trained on generic video content. Extreme compression performance is achieved for videos with specialized content if the model is trained on similar videos.", "keywords": ["variational inference", "video compression", "deep generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper1051/Authors"], "authors": ["Anonymous"], "TL;DR": "Deep Probabilistic Video Compression Via Sequential Variational Autoencoders", "pdf": "/pdf/9459cd77e2547453b2b1fc9e85e7fefe1105debf.pdf", "paperhash": "anonymous|deep_probabilistic_video_compression", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Probabilistic Video Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1l-e3Cqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BygfghAcYX", "original": "r1lWdia9K7", "number": 1052, "cdate": 1538087913544, "ddate": null, "tcdate": 1538087913544, "tmdate": 1538156001374, "tddate": null, "forum": "BygfghAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The role of over-parametrization in generalization of neural networks", "abstract": "Despite existing work on ensuring generalization of neural networks in terms of scale sensitive complexity measures, such as norms, margin and sharpness, these complexity measures do not offer an explanation of why neural networks generalize better with over-parametrization. In this work we suggest a novel complexity measure based on unit-wise capacities resulting in a tighter generalization bound for two layer ReLU networks. Our capacity bound correlates with the behavior of test error with increasing network sizes, and could potentially explain the improvement in generalization with over-parametrization. We further present a matching lower bound for the Rademacher complexity that improves over previous capacity lower bounds for neural networks.", "keywords": ["Generalization", "Over-Parametrization", "Neural Networks", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1052/Authors"], "authors": ["Anonymous"], "TL;DR": "We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.", "pdf": "/pdf/19e6138f2e3dca240567dcc95dbc1d66801d7b39.pdf", "paperhash": "anonymous|the_role_of_overparametrization_in_generalization_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The role of over-parametrization in generalization of neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygfghAcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgMlhRctm", "original": "ryxWHqa9KX", "number": 1053, "cdate": 1538087913713, "ddate": null, "tcdate": 1538087913713, "tmdate": 1538156001162, "tddate": null, "forum": "rJgMlhRctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision", "abstract": "We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neural-symbolic reasoning module that executes these programs on the latent scene representation. Analog to the human concept learning, given the parsed program, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.", "keywords": ["Neuro-Symbolic Representations", "Concept Learning", "Visual Reasoning"], "authorids": ["ICLR.cc/2019/Conference/Paper1053/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. ", "pdf": "/pdf/51de63c42340eb59c36c6e63208765754c6e3fb8.pdf", "paperhash": "anonymous|the_neurosymbolic_concept_learner_interpreting_scenes_words_and_sentences_from_natural_supervision", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgMlhRctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyefgnCqFm", "original": "B1esL46qYX", "number": 1054, "cdate": 1538087913879, "ddate": null, "tcdate": 1538087913879, "tmdate": 1538156000946, "tddate": null, "forum": "HyefgnCqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning space time dynamics with PDE guided neural networks", "abstract": "Spatio-Temporal processes bear a central importance in many applied scientific fields. Generally, differential equations are used to describe these processes. In this work, we address the problem of learning spatio-temporal dynamics with neural networks when only partial information on the system's state is available. Taking inspiration from the dynamical system approach, we outline a general framework in which complex dynamics generated by families of differential equations  can be learned in a principled way. Two models are derived from this framework. We demonstrate how they can be applied in practice by considering the problem of forecasting fluid flows. We show how the underlying equations fit into our formalism and evaluate our method by comparing with standard baselines.", "keywords": ["deep learning", "spatio-temporal dynamics", "physical processes", "differential equations", "dynamical systems"], "authorids": ["ICLR.cc/2019/Conference/Paper1054/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ab9bc51ce689069b58c29290ce63afcde8262419.pdf", "paperhash": "anonymous|learning_space_time_dynamics_with_pde_guided_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning space time dynamics with PDE guided neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyefgnCqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1Gfx3Rqtm", "original": "ryluIRcctm", "number": 1055, "cdate": 1538087914054, "ddate": null, "tcdate": 1538087914054, "tmdate": 1538156000736, "tddate": null, "forum": "H1Gfx3Rqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "End-to-End Hierarchical Text Classification with Label Assignment Policy", "abstract": "We present an end-to-end reinforcement learning approach to hierarchical text classification where documents are labeled by placing them at the right positions in a given hierarchy.\nWhile existing \u201cglobal\u201d methods construct hierarchical losses for model training, they either make \u201clocal\u201d decisions at each hierarchy node or ignore the hierarchy structure during inference. To close the gap between training/inference and optimize holistic metrics in an end-to-end manner, we propose to learn a label assignment policy to determine where to place the documents and when to stop. The proposed method, HiLAP, optimizes holistic metrics over the hierarchy, makes inter-dependent decisions during inference, and can be combined with different text encoding models for end-to-end training.\nExperiments on three public datasets show that HiLAP yields an average improvement of 33.4% in Macro-F1 and 5.0% in Samples-F1, outperforming state-of-the-art methods by a large margin.", "keywords": ["Hierarchical Classification", "Text Classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1055/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a642601d8aec01aa0d1b8004103294f753aa238f.pdf", "paperhash": "anonymous|endtoend_hierarchical_text_classification_with_label_assignment_policy", "_bibtex": "@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-End Hierarchical Text Classification with Label Assignment Policy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1Gfx3Rqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByezgnA5tm", "original": "H1ePxm8FKX", "number": 1056, "cdate": 1538087914220, "ddate": null, "tcdate": 1538087914220, "tmdate": 1538156000522, "tddate": null, "forum": "ByezgnA5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Constraining Action Sequences with Formal Languages for Deep Reinforcement Learning", "abstract": "We study the problem of deep reinforcement learning where the agent's action sequences are constrained, e.g., prohibition of dithering or overactuating action sequences that might damage a robot, drone, or other physical device.  Our model focuses on constraints that can be described by automata such as DFAs or PDAs. We then propose multiple approaches to augment the state descriptions of the Markov decision process (MDP) with summaries of recent action histories.  We empirically evaluate these methods applying DQN to three Atari games, training with reward shaping.  We found that our approaches are effective in significantly reducing, and even eliminating, constraint violations while maintaining high reward.  We  also observed that the total reward achieved by an agent can be highly sensitive to how much the constraints encourage or discourage exploration of potentially effective actions during training, and, in addition to helping ensure safe policies, the use of constraints can enhance exploration during training.", "keywords": ["reinforcement learning", "constraints", "finite state machines"], "authorids": ["ICLR.cc/2019/Conference/Paper1056/Authors"], "authors": ["Anonymous"], "TL;DR": "We constrain an agent's actions during reinforcement learning, for safety or to enhance exploration.", "pdf": "/pdf/2aaa8ae079f15e81a450751cb05ac95498eb61c4.pdf", "paperhash": "anonymous|constraining_action_sequences_with_formal_languages_for_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019constraining,    \ntitle={Constraining Action Sequences with Formal Languages for Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByezgnA5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJxfxnA9K7", "original": "BklmigC9tm", "number": 1057, "cdate": 1538087914387, "ddate": null, "tcdate": 1538087914387, "tmdate": 1538156000313, "tddate": null, "forum": "SJxfxnA9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Structured Prediction using cGANs with Fusion Discriminator", "abstract": "We propose a novel method for incorporating conditional information into a generative adversarial network (GAN) for structured prediction tasks. This method is based on fusing features from the generated and conditional information in feature space and allows the discriminator to better capture higher-order statistics from the data. This method also increases the strength of the signals passed through the network where the real or generated data and the conditional data agree. The proposed method is conceptually simpler than the joint convolutional neural network - conditional Markov random field (CNN-CRF) models and enforces higher-order consistency without being limited to a very specific class of high-order potentials. Experimental results demonstrate that this method leads to improvement on a variety of different structured prediction tasks including image synthesis, semantic segmentation, and depth estimation.", "keywords": ["Generative Adversarial Networks", "GANs", "conditional GANs", "Discriminator", "Fusion"], "authorids": ["ICLR.cc/2019/Conference/Paper1057/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel way to incorporate conditional image information into the discriminator of GANs using feature fusion that can be used for structured prediction tasks.", "pdf": "/pdf/acb4d17dbd0806deea009c6ff570731e88f83dab.pdf", "paperhash": "anonymous|structured_prediction_using_cgans_with_fusion_discriminator", "_bibtex": "@inproceedings{    \nanonymous2019structured,    \ntitle={Structured Prediction using cGANs with Fusion Discriminator},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxfxnA9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxXg2C5FX", "original": "HJlltxn5YX", "number": 1058, "cdate": 1538087914556, "ddate": null, "tcdate": 1538087914556, "tmdate": 1538156000107, "tddate": null, "forum": "SkxXg2C5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors", "abstract": "Recent literature suggests that averaged word vectors followed by simple post-processing outperform many deep learning methods on semantic textual similarity tasks. Furthermore, when averaged word vectors are trained supervised on large corpora of paraphrases, they achieve state-of-the-art results on standard STS benchmarks. Inspired by these revelations, we push the limits of word embeddings even further. We propose a novel fuzzy bag-of-word (FBoW) representation for text that contains all the words in the vocabulary simultaneously but with different degrees of membership, which are derived from similarities between word vectors. We show that max-pooled word vectors are only a special case of fuzzy BoW and should be compared via fuzzy Jaccard index rather than cosine similarity. Finally, we propose DynaMax, a completely unsupervised and non-parametric similarity measure that dynamically extracts and max-pools good features depending on the sentence pair. This method is both efficient and easy to implement, yet outperforms current baselines on STS tasks by a large margin when word vectors are trained unsupervised. When the word vectors are trained supervised to directly optimise cosine similarity, our measure is still comparable in performance despite being unrelated to the original objective.", "keywords": ["word vectors", "sentence representations", "distributed representations", "fuzzy sets", "bag-of-words", "unsupervised learning", "word vector compositionality", "max-pooling", "Jaccard index"], "authorids": ["ICLR.cc/2019/Conference/Paper1058/Authors"], "authors": ["Anonymous"], "TL;DR": "Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.", "pdf": "/pdf/679ce844e999ed4ffeaae9f748c31188ee88291d.pdf", "paperhash": "anonymous|dont_settle_for_average_go_for_the_max_fuzzy_sets_and_maxpooled_word_vectors", "_bibtex": "@inproceedings{    \nanonymous2019don't,    \ntitle={Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxXg2C5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeXehR9t7", "original": "HygBigC5tX", "number": 1059, "cdate": 1538087914775, "ddate": null, "tcdate": 1538087914775, "tmdate": 1538155999893, "tddate": null, "forum": "SkeXehR9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph2Seq: Graph to Sequence Learning with Attention-Based Neural Networks", "abstract": "The celebrated \\emph{Sequence to Sequence learning (Seq2Seq)} technique and its numerous variants achieve excellent performance on many tasks. However, many machine learning tasks have inputs naturally represented as graphs; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence. \nTo address this challenge, we introduce a general end-to-end graph-to-sequence neural encoder-decoder architecture that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors. \nOur method first generates the node and graph embeddings using an improved graph-based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings. \nWe further introduce a novel attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs.\nExperimental results on bAbI, Shortest Path, and Natural Language Generation tasks demonstrate that our model achieves state-of-the-art performance and significantly outperforms existing Seq2Seq and Tree2Seq models; using the proposed aggregation strategy, the model can converge rapidly to the optimal performance.", "keywords": ["Graph Encoder", "Graph Decoder", "Graph2Seq", "Graph Attention"], "authorids": ["ICLR.cc/2019/Conference/Paper1059/Authors"], "authors": ["Anonymous"], "TL;DR": "Graph to Sequence Learning with Attention-Based Neural Networks", "pdf": "/pdf/8d4be7bc5d5c200554d901c9e21fb746757201e7.pdf", "paperhash": "anonymous|graph2seq_graph_to_sequence_learning_with_attentionbased_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019graph2seq:,    \ntitle={Graph2Seq: Graph to Sequence Learning with Attention-Based Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeXehR9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByfXe2C5tm", "original": "BJeEmm2qtQ", "number": 1060, "cdate": 1538087914945, "ddate": null, "tcdate": 1538087914945, "tmdate": 1538155999683, "tddate": null, "forum": "ByfXe2C5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NLProlog: Reasoning with Weak Unification for Natural Language Question Answering", "abstract": "Symbolic logic allows practitioners to build systems that perform rule-based reasoning which is interpretable and which can easily be augmented with prior knowledge. However, such systems are traditionally difficult to apply to problems involving natural language due to the large linguistic variability of language. Currently, most work in natural language processing focuses on neural networks which learn distributed representations of words and their composition, thereby performing well in the presence of large linguistic variability. We propose to reap the benefits of both approaches by applying a combination of neural networks and logic programming to natural language question answering. We propose to employ an external, non-differentiable Prolog prover which utilizes a similarity function over pretrained sentence encoders. We fine-tune these representations via Evolution Strategies with the goal of multi-hop reasoning on natural language.  This allows us to create a system that can apply rule-based reasoning to natural language and induce domain-specific natural language rules from training data. We evaluate the proposed system on two different question answering tasks, showing that it complements two very strong baselines \u2013 BIDAF (Seo et al., 2016a) and FASTQA (Weissenborn et al.,2017) \u2013 and outperforms both when used in an ensemble.", "keywords": ["symbolic reasoning", "neural networks", "natural language processing", "question answering", "sentence embeddings", "evolution strategies"], "authorids": ["ICLR.cc/2019/Conference/Paper1060/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce NLProlog, a system that performs rule-based reasoning on natural language by leveraging pretrained sentence embeddings and fine-tuning with Evolution Strategies, and apply it to two multi-hop Question Answering tasks.", "pdf": "/pdf/439a8084e413bbd1728b1d8125849f66b9e8357d.pdf", "paperhash": "anonymous|nlprolog_reasoning_with_weak_unification_for_natural_language_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019nlprolog:,    \ntitle={NLProlog: Reasoning with Weak Unification for Natural Language Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByfXe2C5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklQxnC5tX", "original": "BketjhwYFm", "number": 1061, "cdate": 1538087915114, "ddate": null, "tcdate": 1538087915114, "tmdate": 1538155999461, "tddate": null, "forum": "HklQxnC5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Overlapping Community Detection with Graph Neural Networks", "abstract": "Community detection in graphs is of central importance in graph mining, machine learning and network science.  Detecting overlapping communities is especially challenging, and remains an open problem.  Motivated by the success of graph-based  deep  learning  in  other  graph-related  tasks,  we  study  the  applicability  of this framework for overlapping community detection. We propose a probabilistic model for overlapping community detection based on the graph neural network architecture.  Despite its simplicity, our model outperforms the existing approaches in the community recovery task by a large margin.  Moreover, due to the inductive formulation, the proposed model is able to perform out-of-sample community detection for nodes that were not present at training time", "keywords": ["community detection", "deep learning for graphs"], "authorids": ["ICLR.cc/2019/Conference/Paper1061/Authors"], "authors": ["Anonymous"], "TL;DR": "Detecting overlapping communities in graphs using graph neural networks", "pdf": "/pdf/f55876160fada78bec5fd7d9aac7846c59415775.pdf", "paperhash": "anonymous|overlapping_community_detection_with_graph_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019overlapping,    \ntitle={Overlapping Community Detection with Graph Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklQxnC5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJx7l309Fm", "original": "BkeIiSa5Ym", "number": 1062, "cdate": 1538087915281, "ddate": null, "tcdate": 1538087915281, "tmdate": 1538155999253, "tddate": null, "forum": "HJx7l309Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Actor-Attention-Critic for Multi-Agent Reinforcement Learning", "abstract": "Reinforcement learning in multi-agent scenarios is important for real-world applications but presents challenges beyond those seen in single-agent settings. We present an actor-critic algorithm that trains decentralized policies in multi-agent settings, using centrally computed critics that share an attention mechanism which selects relevant information for each agent at every timestep. This attention mechanism enables more effective and scalable learning in complex multi-agent environments, when compared to recent approaches. Our approach is applicable not only to cooperative settings with shared rewards, but also individualized reward settings, including adversarial settings, and it makes no assumptions about the action spaces of the agents. As such, it is flexible enough to be applied to most multi-agent learning problems", "keywords": ["multi-agent", "reinforcement learning", "attention", "actor-critic"], "authorids": ["ICLR.cc/2019/Conference/Paper1062/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.", "pdf": "/pdf/2ebfcebe70c8d3519933eadd9cd0021cd126b555.pdf", "paperhash": "anonymous|actorattentioncritic_for_multiagent_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019actor-attention-critic,    \ntitle={Actor-Attention-Critic for Multi-Agent Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJx7l309Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkMQg3C5K7", "original": "Hyg4r_a5FQ", "number": 1063, "cdate": 1538087915459, "ddate": null, "tcdate": 1538087915459, "tmdate": 1538155999042, "tddate": null, "forum": "SkMQg3C5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks", "abstract": "We analyze speed of convergence to global optimum for gradient descent training a deep linear neural network by minimizing the L2 loss over whitened data.  Convergence at a linear rate is guaranteed when the following hold: (i) dimensions of hidden layers are at least the minimum of the input and output dimensions; (ii) weight matrices at initialization are approximately balanced; and (iii) the initial loss is smaller than the loss of any rank-deficient solution.  The assumptions on initialization (conditions (ii) and (iii)) are necessary, in the sense that violating any one of them may lead to convergence failure.  Moreover, in the important case of output dimension 1, i.e. scalar regression, they are met, and thus convergence to global optimum holds, with constant probability under a random initialization scheme.  Our results significantly extend previous analyses, e.g., of deep linear residual networks (Bartlett et al., 2018).", "keywords": ["Deep Learning", "Learning Theory", "Non-Convex Optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1063/Authors"], "authors": ["Anonymous"], "TL;DR": "We analyze gradient descent for deep linear neural networks, providing a guarantee of convergence to global optimum at a linear rate.", "pdf": "/pdf/fc6794cc8c53de6a63eb60587e8ec8ad36dedb7e.pdf", "paperhash": "anonymous|a_convergence_analysis_of_gradient_descent_for_deep_linear_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkMQg3C5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hke4l2AcKQ", "original": "HyxEZna9Y7", "number": 1064, "cdate": 1538087915631, "ddate": null, "tcdate": 1538087915631, "tmdate": 1538155998830, "tddate": null, "forum": "Hke4l2AcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders", "abstract": "Variational Autoencoder (VAE), a simple and effective deep generative model, has led to a number of impressive empirical successes and spawned many advanced variants and theoretical investigations. However, recent studies demonstrate that, when equipped with expressive generative distributions (aka. decoders), VAE suffers from learning uninformative latent representations with the observation called KL Varnishing, in which case VAE collapses into an unconditional generative model. In this work, we introduce mutual posterior-divergence regularization, a novel regularization that is able to control the geometry of the latent space to accomplish meaningful representation learning, while achieving comparable or superior capability of density estimation.Experiments on three image benchmark datasets demonstrate that, when equipped with powerful decoders, our model performs well both on density estimation and representation learning.", "keywords": ["VAE", "regularization", "auto-regressive"], "authorids": ["ICLR.cc/2019/Conference/Paper1064/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/13103aac1ba6da07ca7fe2b62499e13179ded8a6.pdf", "paperhash": "anonymous|mae_mutual_posteriordivergence_regularization_for_variational_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019mae:,    \ntitle={MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hke4l2AcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJgEl3A5tm", "original": "HylNL_sqtm", "number": 1065, "cdate": 1538087915793, "ddate": null, "tcdate": 1538087915793, "tmdate": 1538155998617, "tddate": null, "forum": "SJgEl3A5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild", "abstract": "In this paper, we conduct an interesting experimental study about the physical adversarial attack on object detectors in the wild. In particular, we learn  a camouflage pattern to hide vehicles from being detected by state-of-the-art convolutional neural network based detectors. Our approach alternates between two threads. In the first, we train a neural approximation function to imitate how a simulator applies camouflages to vehicles and how a vehicle detector performs given an image generated by the simulator. In the second, we minimize the approximated detection score by searching for the optimal camouflage. Experiments show that the learned camouflage can not only hide a vehicle from the image-based detectors under many cases, but also generalizes to different environments, vehicles, and object detectors. ", "keywords": ["Adversarial Attack", "Object Detection", "Synthetic Simulation"], "authorids": ["ICLR.cc/2019/Conference/Paper1065/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method to learn physical vehicle camouflage to adversarially attack object detectors in the wild. We find our camouflage effective and transferable.", "pdf": "/pdf/428696911c2d60bf951f3f2072f3a8fabaec01e1.pdf", "paperhash": "anonymous|camou_learning_physical_vehicle_camouflages_to_adversarially_attack_detectors_in_the_wild", "_bibtex": "@inproceedings{    \nanonymous2019camou:,    \ntitle={CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgEl3A5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rye4g3AqFm", "original": "SylX2xAcFQ", "number": 1066, "cdate": 1538087915957, "ddate": null, "tcdate": 1538087915957, "tmdate": 1538155998403, "tddate": null, "forum": "rye4g3AqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep learning generalizes because the parameter-function map is biased towards simple functions", "abstract": "Deep neural networks generalize remarkably well without explicit regularization even in the strongly over-parametrized regime. This success suggests that some form of implicit regularization must be at work. In this paper we argue that a strong intrinsic bias in the parameter-function map helps explain the success of deep neural networks. We provide evidence that the parameter-function map results in a heavily biased prior over functions, if we assume that the training algorithm samples parameters close to uniformly within the zero-error region. The PAC-Bayes theorem then guarantees good expected generalization for target functions producing high-likelihood training sets.\nWe exploit connections between deep neural networks and Gaussian processes to estimate the marginal likelihood, finding remarkably good agreement between Gaussian processes and neural networks for small input sets.  Using approximate marginal likelihood calculations we produce nontrivial generalization PAC-Bayes error bounds which correlate well with the true error on realistic datasets such as MNIST and CIFAR and for architectures including convolutional and fully connected networks.\nAs predicted by recent arguments based on algorithmic information theory, we find that the prior probability drops exponentially with linear increases in several measures of descriptional complexity of the target function. As target functions in many real problems are expected to be highly structured, this simplicity bias offers an insight into why deep networks generalize well on real world problems, but badly on randomized data.", "keywords": ["generalization", "deep learning theory", "PAC-Bayes", "Gaussian processes", "parameter-function map", "simplicity bias"], "authorids": ["ICLR.cc/2019/Conference/Paper1066/Authors"], "authors": ["Anonymous"], "TL;DR": "The parameter-function map of deep networks is hugely biased; this can explain why they generalize. We use PAC-Bayes and Gaussian processes to obtain nonvacuous bounds.", "pdf": "/pdf/40f5dd65fc08ce4577d52189fa8b8a0961e7fc30.pdf", "paperhash": "anonymous|deep_learning_generalizes_because_the_parameterfunction_map_is_biased_towards_simple_functions", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep learning generalizes because the parameter-function map is biased towards simple functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rye4g3AqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1x4ghC9tQ", "original": "BJef8Ln9Y7", "number": 1067, "cdate": 1538087916133, "ddate": null, "tcdate": 1538087916133, "tmdate": 1538155998190, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1067/Authors"], "authors": ["Anonymous"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/b717515b9441e50f0c7daf570e682e1813688dc8.pdf", "paperhash": "anonymous|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{    \nanonymous2019temporal,    \ntitle={Temporal Difference Variational Auto-Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1x4ghC9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgVx3A9Km", "original": "rkltHvn9FX", "number": 1068, "cdate": 1538087916308, "ddate": null, "tcdate": 1538087916308, "tmdate": 1538155997979, "tddate": null, "forum": "BkgVx3A9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A More Globally Accurate Dimensionality Reduction Method Using Triplets", "abstract": "We first show that the commonly used dimensionality reduction (DR) methods such as t-SNE and LargeVis\npoorly capture the global structure of the data in the low dimensional embedding. We show this via a number of tests for the DR methods that can be easily applied by any practitioner to the dataset at hand. Surprisingly enough, t-SNE performs the best w.r.t. the commonly used measures that reward the local neighborhood accuracy such as precision-recall while having the worst performance in our tests for global structure. We then contrast the performance of these two DR method\nagainst our new method called TriMap. The main idea behind TriMap is to capture higher orders of structure with triplet information (instead of pairwise information used by t-SNE and LargeVis), and to minimize a robust loss function for satisfying the chosen triplets. We provide compelling experimental evidence on large natural datasets for the clear advantage of the TriMap DR results. As LargeVis, TriMap is fast and scales linearly with the number of data points.", "keywords": ["Dimensionality Reduction", "Visualization", "Triplets", "t-SNE", "LargeVis"], "authorids": ["ICLR.cc/2019/Conference/Paper1068/Authors"], "authors": ["Anonymous"], "TL;DR": "A new dimensionality reduction method using triplets which is significantly faster than t-SNE and provides more accurate results globally", "pdf": "/pdf/ded77a65ddcb04e3fbe8c8fbf1a97f3a9c372ae4.pdf", "paperhash": "anonymous|a_more_globally_accurate_dimensionality_reduction_method_using_triplets", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A More Globally Accurate Dimensionality Reduction Method Using Triplets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgVx3A9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eVe2AqKX", "original": "SJlL4lA5tm", "number": 1069, "cdate": 1538087916468, "ddate": null, "tcdate": 1538087916468, "tmdate": 1538155997767, "tddate": null, "forum": "S1eVe2AqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["ICLR.cc/2019/Conference/Paper1069/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "anonymous|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@inproceedings{    \nanonymous2019pcnn:,    \ntitle={PCNN: Environment Adaptive Model Without Finetuning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eVe2AqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gBgnR9Y7", "original": "BklI_1ccYm", "number": 1070, "cdate": 1538087916639, "ddate": null, "tcdate": 1538087916639, "tmdate": 1538155997558, "tddate": null, "forum": "S1gBgnR9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "End-to-end learning of pharmacological assays from high-resolution microscopy images", "abstract": "Predicting the outcome of pharmacological assays based on high-resolution microscopy\nimages of treated cells is a crucial task in drug discovery which tremendously\nincreases discovery rates. However, end-to-end learning on these images\nwith convolutional neural networks (CNNs) has not been ventured for this task\nbecause it has been considered infeasible and overly complex. On the largest\navailable public dataset, we compare several state-of-the-art CNNs trained in an\nend-to-end fashion with models based on a cell-centric approach involving segmentation.\nWe found that CNNs operating on full images containing hundreds\nof cells perform significantly better at assay prediction than networks operating\non a single-cell level. Surprisingly, we could predict 29% of the 209 pharmacological\nassays at high predictive performance (AUC > 0.9). We compared a\nnovel CNN architecture called \u201cGapNet\u201d against four competing CNN architectures\nand found that it performs on par with the best methods and at the same time\nhas the lowest training time. Our results demonstrate that end-to-end learning on\nhigh-resolution imaging data is not only possible but even outperforms cell-centric\nand segmentation-dependent approaches. Hence, the costly cell segmentation and\nfeature extraction steps are not necessary, in fact they even hamper predictive performance.\nOur work further suggests that many pharmacological assays could\nbe replaced by high-resolution microscopy imaging together with convolutional\nneural networks.", "keywords": ["Convolutional Neural Networks", "High-resolution images", "Multiple-Instance Learning", "Drug Discovery", "Molecular Biology"], "authorids": ["ICLR.cc/2019/Conference/Paper1070/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/38186950e7fe170b684f76f2355b2e60da84b050.pdf", "paperhash": "anonymous|endtoend_learning_of_pharmacological_assays_from_highresolution_microscopy_images", "_bibtex": "@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-end learning of pharmacological assays from high-resolution microscopy images},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gBgnR9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eSg3C9Ym", "original": "B1esaA55t7", "number": 1071, "cdate": 1538087916806, "ddate": null, "tcdate": 1538087916806, "tmdate": 1538155997353, "tddate": null, "forum": "B1eSg3C9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MEAN-FIELD ANALYSIS OF BATCH NORMALIZATION", "abstract": "Batch Normalization (BatchNorm) is an extremely useful component of modern neural network architectures, enabling optimization using higher learning rates and achieving faster convergence. In this paper, we use mean-field theory to analytically quantify the impact of BatchNorm on the geometry of the loss landscape for multi-layer networks consisting of fully-connected and convolutional layers. We show that it has a flattening effect on the loss landscape, as quantified by the maximum eigenvalue of the Fisher Information Matrix. These findings are then used to justify the use of larger learning rates for networks that use BatchNorm, and we provide quantitative characterization of the maximal allowable learning rate to ensure convergence. Experiments support our theoretically predicted maximum learning rate, and furthermore suggest that networks with smaller values of the BatchNorm parameter achieve lower loss after the same number of epochs of training.", "keywords": ["neural networks", "optimization", "batch normalization", "mean field theory", "Fisher information"], "authorids": ["ICLR.cc/2019/Conference/Paper1071/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/21d067f9263e397a49f392c9822d7e4e706613f7.pdf", "paperhash": "anonymous|meanfield_analysis_of_batch_normalization", "_bibtex": "@inproceedings{    \nanonymous2019mean-field,    \ntitle={MEAN-FIELD ANALYSIS OF BATCH NORMALIZATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eSg3C9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bygre3R9Fm", "original": "r1ltVLT9t7", "number": 1072, "cdate": 1538087916972, "ddate": null, "tcdate": 1538087916972, "tmdate": 1538155997144, "tddate": null, "forum": "Bygre3R9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation", "abstract": "Generating novel molecules with optimal properties is a crucial step in many industries such as drug discovery. Recently, deep generative models have shown a promising way of performing de-novo molecular design.  Although graph generative models are currently available they are either computationally expensive, limiting their use to only small graphs or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters, therefore preventing them to be used in scenarios such as conditional graph generation. In this work we propose a model for conditional graph generation that is computationally cheap, scalable, directly optimises properties of the graph, and generates a probabilistic graph, making the process differentiable, thus enabling end-to-end training with stochastic gradient descent. We demonstrate favourable performance of our model on prototype-based molecular graph conditional generation tasks.", "keywords": ["molecular graphs", "conditional autoencoder", "graph autoencoder"], "authorids": ["ICLR.cc/2019/Conference/Paper1072/Authors"], "authors": ["Anonymous"], "TL;DR": "New scalable graph decoding scheme that allows to perform direct molecular graph conditional generation.", "pdf": "/pdf/3efa5eccc28cdb86ce18e9edefdf71398dcf206c.pdf", "paperhash": "anonymous|defactor_differentiable_edge_factorizationbased_probabilistic_graph_generation", "_bibtex": "@inproceedings{    \nanonymous2019defactor:,    \ntitle={DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bygre3R9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzSgnRcKX", "original": "S1g4wRncYX", "number": 1073, "cdate": 1538087917134, "ddate": null, "tcdate": 1538087917134, "tmdate": 1538155996933, "tddate": null, "forum": "SJzSgnRcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "What do you learn from context? Probing for sentence structure in contextualized word representations", "abstract": "Contextualized representation models such as CoVe (McCann et al., 2017) and\nELMo (Peters et al., 2018a) have recently achieved state-of-the-art results on a\ndiverse array of downstream NLP tasks. Building on recent token-level probing\nwork, we introduce a novel edge probing task design and construct a broad suite of\nsub-sentence tasks derived from the traditional structured NLP pipeline. We probe\nword-level contextual representations from three recent models and investigate\nhow they encode sentence structure across a range of syntactic, semantic, local,\nand long-range phenomena. We find that ELMo encodes linguistic structure at the\nword level better than other comparable models, and that existing models trained\non language modeling and translation produce strong representations for syntactic\nphenomena, but only offer small improvements on semantic tasks over a noncontextual\nbaseline.", "keywords": ["natural language processing", "word embeddings", "transfer learning", "interpretability"], "authorids": ["ICLR.cc/2019/Conference/Paper1073/Authors"], "authors": ["Anonymous"], "TL;DR": "We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.", "pdf": "/pdf/35761ae4ea30b9110fdc2db7537f6a9d1ecc2937.pdf", "paperhash": "anonymous|what_do_you_learn_from_context_probing_for_sentence_structure_in_contextualized_word_representations", "_bibtex": "@inproceedings{    \nanonymous2019what,    \ntitle={What do you learn from context? Probing for sentence structure in contextualized word representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzSgnRcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJfHg2A5tQ", "original": "rJlHTlR5YX", "number": 1074, "cdate": 1538087917301, "ddate": null, "tcdate": 1538087917301, "tmdate": 1538155996721, "tddate": null, "forum": "SJfHg2A5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BNN+: Improved Binary Network Training", "abstract": "Deep neural networks (DNN) are widely used in many applications. However, their deployment on edge devices has been difficult because they are resource hungry. Binary networks (BNN) help to alleviate the prohibitive resource requirements of DNN; where both activations and weights are limited to one bit. We propose an improved binary training method (BNN+), an improvement to the popular BNN training scheme, which helps to reduce accuracy degradation compared to the full-precision counterpart.  Our method is based on linear operations that are easily implementable into the binary training framework and we show experimental results on CIFAR-10 obtaining an accuracy of 86.5%, on AlexNet and 91.6% with VGG network. On ImageNet, our method also outperforms the traditional BNN and XNOR-net, by a margin of 4% and 2% respectively. ", "keywords": ["Binary Network", "Binary Training", "Model Compression", "Quantization"], "authorids": ["ICLR.cc/2019/Conference/Paper1074/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper presents an improved training mechanism for obtaining binary networks with smaller accuracy drop compared that helps close the gap with it's full precision counterpart", "pdf": "/pdf/e20ebacde5c4438d872e8b89418945b4e5ceb63b.pdf", "paperhash": "anonymous|bnn_improved_binary_network_training", "_bibtex": "@inproceedings{    \nanonymous2019bnn+:,    \ntitle={BNN+: Improved Binary Network Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfHg2A5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkNSehA9FQ", "original": "S1eIqMn9t7", "number": 1075, "cdate": 1538087917466, "ddate": null, "tcdate": 1538087917466, "tmdate": 1538155996508, "tddate": null, "forum": "SkNSehA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["ICLR.cc/2019/Conference/Paper1075/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/8234196380aff2e27c76bfdd893de383a1f23370.pdf", "paperhash": "anonymous|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@inproceedings{    \nanonymous2019open,    \ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkNSehA9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkx8l3Cctm", "original": "rygv5JeFKX", "number": 1076, "cdate": 1538087917651, "ddate": null, "tcdate": 1538087917651, "tmdate": 1538155996299, "tddate": null, "forum": "rkx8l3Cctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Safe Policy Learning from Observations", "abstract": "In this paper, we consider the problem of learning a policy by observing numerous non-expert agents. Our goal is to extract a policy that, with high-confidence, acts better than the agents' average performance. Such a setting is important for real-world problems where expert data is scarce but non-expert data can easily be obtained, e.g. by crowdsourcing. Our approach is to pose this problem as safe policy improvement in reinforcement learning. First, we evaluate an average behavior policy and approximate its value function. Then, we develop a stochastic policy improvement algorithm that safely improves the average behavior. The primary advantages of our approach, termed Rerouted Behavior Improvement (RBI), over other safe learning methods are its stability in the presence of value estimation errors and the elimination of a policy search process.  We demonstrate these advantages in the Taxi grid-world domain and in four games from the Atari learning environment.", "keywords": ["learning from observations", "safe reinforcement learning", "deep reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1076/Authors"], "authors": ["Anonymous"], "TL;DR": "An algorithm for learning to improve upon the behavior demonstrated by multiple unknown policies, by combining imitation learning and a novel safe policy improvement step that is resilient to value estimation errors.", "pdf": "/pdf/f367ad02843dafcc859c695433f2f091ec2c8d3f.pdf", "paperhash": "anonymous|safe_policy_learning_from_observations", "_bibtex": "@inproceedings{    \nanonymous2019safe,    \ntitle={Safe Policy Learning from Observations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkx8l3Cctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxLl309Ym", "original": "HkgomVn5tQ", "number": 1077, "cdate": 1538087917817, "ddate": null, "tcdate": 1538087917817, "tmdate": 1538155996088, "tddate": null, "forum": "ByxLl309Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Conditional Inference in Pre-trained Variational Autoencoders via Cross-coding", "abstract": "Variational Autoencoders (VAEs) are a popular generative model, but one in which conditional inference can be challenging. If the decomposition into query and evidence variables is fixed, conditional VAEs provide an attractive solution. To support arbitrary queries, one is generally reduced to Markov Chain Monte Carlo sampling methods that  can suffer from long mixing times.  In this paper, we propose an idea we term cross-coding to approximate the distribution over the latent variables after conditioning on an evidence assignment to some subset of the variables. This allows generating query samples without retraining the full VAE.  We experimentally evaluate three variations of cross-coding showing that (i) can be quickly optimized for different decompositions of evidence and query and (ii) they quantitatively and qualitatively outperform Hamiltonian Monte Carlo.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1077/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2acbda5f3f5a9ca4de0b727c8e5892acaea113cd.pdf", "paperhash": "anonymous|conditional_inference_in_pretrained_variational_autoencoders_via_crosscoding", "_bibtex": "@inproceedings{    \nanonymous2019conditional,    \ntitle={Conditional Inference in Pre-trained Variational Autoencoders via Cross-coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxLl309Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygLehCqtm", "original": "ryxRA6n5FQ", "number": 1078, "cdate": 1538087917980, "ddate": null, "tcdate": 1538087917980, "tmdate": 1538155995879, "tddate": null, "forum": "SygLehCqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning protein sequence embeddings using information from structure", "abstract": "Inferring structural properties of a protein given only its amino acid sequence is a challenging problem. Existing approaches based solely on sequence are unable to recognize and exploit structural patterns when sequences have diverged too far. We introduce a novel framework for infusing structural information into position-specific representations of protein sequences. We train bidirectional long short-term memory (LSTM) models on protein sequences with a two-part feedback mechanism to incorporate (i) pairwise residue contact maps for individual proteins and (ii) co-membership in structural categories based on a curated database (SCOPe). For co-membership, we introduce soft symmetric alignment (SSA) between sequences of vector embeddings. We show empirically that our approach outperforms existing direct sequence alignment methods and also a structure-based alignment method when predicting structural similarity. SSA also enables learning informative position-specific embeddings even when no residue level supervision is available. Finally, we demonstrate that the learned embeddings can be transferred to other protein sequence problems, improving state-of-the-art in transmembrane domain prediction.", "keywords": ["sequence embedding", "sequence alignment", "RNN", "LSTM", "protein structure", "amino acid sequence", "contextual embeddings", "transmembrane prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper1078/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a method for learning protein sequence embedding models using structural information in the form of global structural similarity between proteins and within protein residue-residue contacts.", "pdf": "/pdf/807475e1b3357b96b8c16a8122b84d25a75bee9d.pdf", "paperhash": "anonymous|learning_protein_sequence_embeddings_using_information_from_structure", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning protein sequence embeddings using information from structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygLehCqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGLg2C9K7", "original": "SylrRxActm", "number": 1079, "cdate": 1538087918155, "ddate": null, "tcdate": 1538087918155, "tmdate": 1538155995637, "tddate": null, "forum": "HyGLg2C9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification", "abstract": "Recent work has demonstrated the lack of robustness of well-trained deep neural networks (DNNs) to adversarial examples.  For example, visually indistinguishable perturbations, when mixed with an original image, can easily lead deep learning models to misclassifications.  In light of a recent study on the mutual influence between robustness and accuracy over 18 different ImageNet models, this paper investigates how training data affect the accuracy and robustness of deep neural\nnetworks. We conduct extensive experiments on four different datasets, including CIFAR-10, MNIST, STL-10, and Tiny ImageNet, with several representative neural networks. Our results reveal previously unknown phenomena that exist between the size of training data and characteristics of the resulting models. In particular, besides confirming that the model accuracy improves as the amount of training data increases, we also observe that the model robustness improves initially, but there exists a turning point after which robustness starts to deteriorate.  How and when such turning points occur vary for different neural networks and different datasets.", "keywords": ["Adversarial attacks", "Robustness", "CW", "I-FGSM"], "authorids": ["ICLR.cc/2019/Conference/Paper1079/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/afbc083efb9253ee20f25651950c74d87d78c52f.pdf", "paperhash": "anonymous|how_training_data_affect_the_accuracy_and_robustness_of_neural_networks_for_image_classification", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGLg2C9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgLg3R9KQ", "original": "HJemiu39K7", "number": 1080, "cdate": 1538087918315, "ddate": null, "tcdate": 1538087918315, "tmdate": 1538155995439, "tddate": null, "forum": "BJgLg3R9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning what and where to attend with humans in the loop", "abstract": " Most recent gains in visual recognition have originated from the incorporation of attention mechanisms in deep convolutional networks (DCNs). Because these networks are optimized for object recognition, they learn where to attend using only a weak form of supervision derived from image class labels. Here, we demonstrate the benefit of using stronger supervisory signals by teaching DCNs to attend to image regions that humans deem important for object recognition. We first describe a large-scale online experiment (ClickMe) used to supplement ImageNet with nearly half a million human-derived \"top-down\" attention maps. Using human psychophysics, we confirm that the identified \"top-down\" features from ClickMe are more diagnostic than \"bottom-up\" features for rapid image categorization. As a proof of concept, we extend a state-of-the-art attention network and demonstrate that adding humans-in-the-loop with ClickMe supervision significantly improves its accuracy, while also yielding visual features that are more interpretable and more similar to those used by human observers.", "keywords": ["Attention models", "human feature importance", "object recognition", "cognitive science"], "authorids": ["ICLR.cc/2019/Conference/Paper1080/Authors"], "authors": ["Anonymous"], "TL;DR": "A large-scale dataset for training attention models for object recognition leads to more accurate, interpretable, and human-like object recognition.", "pdf": "/pdf/67ab40eb7162e341d7ee1d1ec2079d9fc0d89bda.pdf", "paperhash": "anonymous|learning_what_and_where_to_attend_with_humans_in_the_loop", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning what and where to attend with humans in the loop},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgLg3R9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJl8gnAqtX", "original": "SkeKwpQuKX", "number": 1081, "cdate": 1538087918482, "ddate": null, "tcdate": 1538087918482, "tmdate": 1538155995241, "tddate": null, "forum": "SJl8gnAqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["ICLR.cc/2019/Conference/Paper1081/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "anonymous|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@inproceedings{    \nanonymous2019prob2vec:,    \ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl8gnAqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgvg30ctX", "original": "HJxeyZRqKQ", "number": 1082, "cdate": 1538087918653, "ddate": null, "tcdate": 1538087918653, "tmdate": 1538155995039, "tddate": null, "forum": "BJgvg30ctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Information Regularized Neural Networks", "abstract": "We formulate an information-based optimization problem for supervised classification. For invertible neural networks, the control of these information terms is passed down to the latent features and parameter matrix in the last fully connected layer, given that mutual information is invariant under invertible map.  We propose an objective function and prove that it solves the optimization problem. Our framework allows us to learn latent features in an more interpretable form while improving the classification performance. We perform extensive quantitative and qualitative experiments in comparison with the existing state-of-the-art classification models.", "keywords": ["supervised classification", "information theory", "deep learning", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper1082/Authors"], "authors": ["Anonymous"], "TL;DR": "we propose a regularizer that improves the classification performance of neural networks", "pdf": "/pdf/c2467c3a358b3cca4accfb1dca86d3459c62b0d7.pdf", "paperhash": "anonymous|information_regularized_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019information,    \ntitle={Information Regularized Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgvg30ctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxPx3R9tm", "original": "rkgyNUnct7", "number": 1083, "cdate": 1538087918820, "ddate": null, "tcdate": 1538087918820, "tmdate": 1538155994829, "tddate": null, "forum": "HyxPx3R9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["ICLR.cc/2019/Conference/Paper1083/Authors"], "authors": ["Anonymous"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/7e0649b2d8ac29a50096f52c599802f0ab209a77.pdf", "paperhash": "anonymous|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxPx3R9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gDgn0qY7", "original": "BylPJZCcYm", "number": 1084, "cdate": 1538087918995, "ddate": null, "tcdate": 1538087918995, "tmdate": 1538155994625, "tddate": null, "forum": "H1gDgn0qY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Study of Robustness of Neural Nets Using Approximate Feature Collisions", "abstract": "In recent years, various studies have focused on the robustness of neural nets. While it is known that neural nets are not robust to examples with adversarially chosen perturbations as a result of linear operations on the input data, we show in this paper there could be a convex polytope within which all examples are misclassified by neural nets due to the properties of ReLU activation functions. We propose a way to finding such polytopes empirically and demonstrate that such polytopes exist in practice. Furthermore, we show that such polytopes exist even after constraining the examples to be a composition of image patches, resulting in perceptibly different examples at different locations in the polytope that are all misclassified. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1084/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/64fdaeefbe67621486b1f237e7fb5c315e1ee661.pdf", "paperhash": "anonymous|a_study_of_robustness_of_neural_nets_using_approximate_feature_collisions", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Study of Robustness of Neural Nets Using Approximate Feature Collisions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gDgn0qY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hygvln09K7", "original": "SygkcCs9FQ", "number": 1085, "cdate": 1538087919159, "ddate": null, "tcdate": 1538087919159, "tmdate": 1538155994423, "tddate": null, "forum": "Hygvln09K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta Learning with Fast/Slow Learners", "abstract": "Meta-learning has recently achieved success in many optimization problems. In general, a meta learner g(.) could be learned for a base model f(.) on a variety of tasks, such that it can be more efficient on a new task. In this paper, we make some key modifications to enhance the performance of meta-learning models. (1) we leverage different meta-strategies for different modules to optimize them separately: we use conservative \u201cslow learners\u201d on low-level basic feature representation layers and \u201cfast learners\u201d on high-level task-specific layers; (2) Furthermore, we provide theoretical analysis on why the proposed approach works, based on a case study on a two-layer MLP. We evaluate our model on synthetic MLP regression, as well as low-shot learning tasks on Omniglot and ImageNet benchmarks. We demonstrate that our approach is able to achieve state-of-the-art performance.", "keywords": ["computer vision", "meta learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1085/Authors"], "authors": ["Anonymous"], "TL;DR": "We applied multiple meta-strategy to improve meta-learning performance on base CNNs. ", "pdf": "/pdf/50464de80c7928c82c356173530565720a58249a.pdf", "paperhash": "anonymous|meta_learning_with_fastslow_learners", "_bibtex": "@inproceedings{    \nanonymous2019meta,    \ntitle={Meta Learning with Fast/Slow Learners},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygvln09K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJGven05Y7", "original": "ByeDzz65Ym", "number": 1086, "cdate": 1538087919328, "ddate": null, "tcdate": 1538087919328, "tmdate": 1538155994212, "tddate": null, "forum": "HJGven05Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How to train your MAML", "abstract": "The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem.Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.", "keywords": ["meta-learning", "deep-learning", "few-shot learning", "supervised learning", "neural-networks", "stochastic optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1086/Authors"], "authors": ["Anonymous"], "TL;DR": "MAML is great, but it has many problems, we solve many of those problems and as a result we learn most hyper parameters end to end, speed-up training and inference and set a new SOTA in few-shot learning", "pdf": "/pdf/ab52191bdf94a242efadfff20f589a99a3898563.pdf", "paperhash": "anonymous|how_to_train_your_maml", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How to train your MAML},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJGven05Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJ4vlh0qtm", "original": "S1g_FofFOX", "number": 1087, "cdate": 1538087919491, "ddate": null, "tcdate": 1538087919491, "tmdate": 1538155994002, "tddate": null, "forum": "rJ4vlh0qtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration", "abstract": "Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.", "keywords": ["reinforcement learning", "multi-agent learning", "multi-agent communication", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1087/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.", "pdf": "/pdf/1099efbf8c05d5cb6ce83ac0a5bd18c5211a097c.pdf", "paperhash": "anonymous|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration", "_bibtex": "@inproceedings{    \nanonymous2019ssoc:,    \ntitle={SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJ4vlh0qtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJgOl3AqY7", "original": "SJgu0df_F7", "number": 1088, "cdate": 1538087919664, "ddate": null, "tcdate": 1538087919664, "tmdate": 1538155993781, "tddate": null, "forum": "HJgOl3AqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Modulated Variational Auto-Encoders for Many-to-Many Musical Timbre Transfer", "abstract": "Generative models have been successfully applied to image style transfer and domain translation. However, there is still a wide gap in the quality of results when learning such tasks on musical audio. Furthermore, most translation models only enable one-to-one or one-to-many transfer by relying on separate encoders or decoders and complex, computationally-heavy models. In this paper, we introduce the Modulated Variational auto-Encoders (MoVE) to perform musical timbre transfer. First, we define timbre transfer as applying parts of the auditory properties of a musical instrument onto another. We show that we can achieve and improve this task by conditioning existing domain translation techniques with Feature-wise Linear Modulation (FiLM). Then, by replacing the usual adversarial translation criterion by a Maximum Mean Discrepancy (MMD) objective, we alleviate the need for an auxiliary pair of discriminative networks. This allows a faster and more stable training, along with a controllable latent space encoder. By further conditioning our system on several different instruments, we can generalize to many-to-many transfer within a single variational architecture able to perform multi-domain transfers. Our models map inputs to 3-dimensional representations, successfully translating timbre from one instrument to another and supporting sound synthesis on a reduced set of control parameters. We evaluate our method in reconstruction and generation tasks while analyzing the auditory descriptor distributions across transferred domains. We show that this architecture incorporates generative controls in multi-domain transfer, yet remaining rather light, fast to train and effective on small datasets.", "keywords": ["Musical Timbre", "Instrument Translation", "Domain Translation", "Style Transfer", "Sound Synthesis", "Musical Information", "Deep Learning", "Variational Auto-Encoder", "Generative Models", "Network Conditioning"], "authorids": ["ICLR.cc/2019/Conference/Paper1088/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper uses Variational Auto-Encoding and network conditioning for Musical Timbre Transfer, we develop and generalize our architecture for many-to-many instrument transfers together with visualizations and evaluations.", "pdf": "/pdf/8d84da61b7a7ccea762a0eb61988ad6f1e2f079c.pdf", "paperhash": "anonymous|modulated_variational_autoencoders_for_manytomany_musical_timbre_transfer", "_bibtex": "@inproceedings{    \nanonymous2019modulated,    \ntitle={Modulated Variational Auto-Encoders for Many-to-Many Musical Timbre Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgOl3AqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByldlhAqYQ", "original": "rkxTMWt9Fm", "number": 1089, "cdate": 1538087919839, "ddate": null, "tcdate": 1538087919839, "tmdate": 1538155993566, "tddate": null, "forum": "ByldlhAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transfer Learning for Sequences via Learning to Collocate", "abstract": "Transfer learning aims to solve the data sparsity for a specific domain by applying information of another domain. Given a sequence (e.g. a natural language sentence), the transfer learning, usually enabled by recurrent neural network (RNN), represent the sequential information transfer. RNN uses a chain of repeating cells to model the sequence data. However, previous studies of neural network based transfer learning simply transfer the information across the whole layers, which are unfeasible for seq2seq and sequence labeling. Meanwhile, such layer-wise transfer learning mechanisms also lose the fine-grained cell-level information from the source domain.\n\nIn this paper, we proposed the aligned recurrent transfer, ART, to achieve cell-level information transfer. ART is in a recurrent manner that different cells share the same parameters. Besides transferring the corresponding information at the same position, ART transfers information from all collocated words in the source domain. This strategy enables ART to capture the word collocation across domains in a more flexible way. We conducted extensive experiments on both sequence labeling tasks (POS tagging, NER) and sentence classification (sentiment analysis). ART outperforms the state-of-the-arts over all experiments.\n", "keywords": ["transfer learning", "recurrent neural network", "attention", "natural language processing"], "authorids": ["ICLR.cc/2019/Conference/Paper1089/Authors"], "authors": ["Anonymous"], "TL;DR": "Transfer learning for sequence via learning to align cell-level information across domains.", "pdf": "/pdf/8ebc6ad01a3da3b39892a9df71721b4e4916a44c.pdf", "paperhash": "anonymous|transfer_learning_for_sequences_via_learning_to_collocate", "_bibtex": "@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer Learning for Sequences via Learning to Collocate},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByldlhAqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lug3R5FX", "original": "Byx40kC9tX", "number": 1090, "cdate": 1538087920007, "ddate": null, "tcdate": 1538087920007, "tmdate": 1538155993357, "tddate": null, "forum": "H1lug3R5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On the Geometry of Adversarial Examples", "abstract": "Adversarial examples are a pervasive phenomenon of machine learning models where seemingly imperceptible perturbations to the input lead to misclassifications for otherwise statistically accurate models. We propose a geometric framework, drawing on tools from the manifold reconstruction literature, to analyze the high-dimensional geometry of adversarial examples. In particular, we highlight the importance of codimension: for low-dimensional data manifolds embedded in high-dimensional space there are many directions off the manifold in which to construct adversarial examples. Adversarial examples are a natural consequence of learning a decision boundary that classifies the low-dimensional data manifold well, but classifies points near the manifold incorrectly. Using our geometric framework we prove (1) a tradeoff between robustness under different norms, (2) that adversarial training in balls around the data is sample inefficient, and (3) sufficient sampling conditions under which nearest neighbor classifiers and ball-based adversarial training are robust.", "keywords": ["adversarial examples", "high-dimensional geometry"], "authorids": ["ICLR.cc/2019/Conference/Paper1090/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a geometric framework for proving robustness guarantees and highlight the importance of codimension in adversarial examples. ", "pdf": "/pdf/28aa43ab133f6fe6178ae0cf2cf50d0c5e1fa92c.pdf", "paperhash": "anonymous|on_the_geometry_of_adversarial_examples", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On the Geometry of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lug3R5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1zOg309tX", "original": "B1gDbVM5KX", "number": 1091, "cdate": 1538087920167, "ddate": null, "tcdate": 1538087920167, "tmdate": 1538155993148, "tddate": null, "forum": "r1zOg309tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets", "abstract": "In this paper, we investigate the underlying factor that leads to the failure and success in training of GANs. Specifically, we study the property of the optimal discriminative function $\\ff(x)$ and show that $\\ff(x)$ in most GANs can only reflect the local densities at $x$, which means the value of $\\ff(x)$ for points in the fake distribution ($P_g$) does not contain any information useful about the location of other points in the real distribution ($P_r$). Given that the supports of the real and fake distributions are usually disjoint, we argue that such a $\\ff(x)$ and its gradient tell nothing about ``how to pull $P_g$ to $P_r$'', which turns out to be the fundamental cause of failure in training of GANs. We further demonstrate that a well-defined distance metric (including Wasserstein distance) does not necessarily ensure the convergence of GANs. Finally, we propose Lipschitz-continuity condition as a general solution and show that in a large family of GAN objectives, Lipschitz condition is capable of connecting $P_g$ and $P_r$ through $\\ff(x)$ such that the gradient $\\nabla_{\\!x}\\ff(x)$ at each sample $x \\tsim P_g$ points towards some real sample $y \\tsim P_r$. ", "keywords": ["GANs", "Lipschitz-continuity", "convergence"], "authorids": ["ICLR.cc/2019/Conference/Paper1091/Authors"], "authors": ["Anonymous"], "TL;DR": "We disclose the fundamental cause of failure in training of GANs, and demonstrate that Lipschitz-continuity is a general solution to this issue.", "pdf": "/pdf/a12fe616b152d8dbc13c399dbbeaa06aa5c93692.pdf", "paperhash": "anonymous|understanding_the_effectiveness_of_lipschitzcontinuity_in_generative_adversarial_nets", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1zOg309tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gOe209t7", "original": "HJeOZ-CcFQ", "number": 1092, "cdate": 1538087920335, "ddate": null, "tcdate": 1538087920335, "tmdate": 1538155992929, "tddate": null, "forum": "r1gOe209t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout", "abstract": "Recently convolutional neural networks (CNNs) achieve great accuracy in visual recognition tasks. DenseNet becomes one of the most popular CNN models due to its effectiveness in feature-reuse. However, like other CNN models, DenseNets also face overfitting problem if not severer. Existing dropout method can be applied but not as effective due to the introduced nonlinear connections. In particular, the property of feature-reuse in DenseNet will be impeded, and the dropout effect will be weakened by the spatial correlation inside feature maps. To address these problems, we craft the design of a specialized dropout method from three aspects, dropout location, dropout granularity, and dropout probability. The insights attained here could potentially be applied as a general approach for boosting the accuracy of other CNN models with similar nonlinear connections. Experimental results show that DenseNets with our specialized dropout method yield better accuracy compared to vanilla DenseNet and state-of-the-art CNN models, and such accuracy boost increases with the model depth.", "keywords": ["Specialized dropout", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper1092/Authors"], "authors": ["Anonymous"], "TL;DR": "Realizing the drawbacks when applying original dropout on DenseNet, we craft the design of dropout method from three aspects, the idea of which could also be applied on other CNN models.", "pdf": "/pdf/2939c75d31519701b96f705bb886e29725429b45.pdf", "paperhash": "anonymous|reconciling_featurereuse_and_overfitting_in_densenet_with_specialized_dropout", "_bibtex": "@inproceedings{    \nanonymous2019reconciling,    \ntitle={Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gOe209t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxug2R9Km", "original": "SJxeuxT-YX", "number": 1093, "cdate": 1538087920497, "ddate": null, "tcdate": 1538087920497, "tmdate": 1538155992718, "tddate": null, "forum": "rJxug2R9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning for Contextual Bandit Exploration", "abstract": "We describe M\u00caL\u00c9E, a meta-learning algorithm for learning a good exploration policy in the interactive contextual bandit setting. Here, an algorithm must take actions based on contexts, and learn based only on a reward signal from the action taken, thereby generating an exploration/exploitation trade-off. M\u00caL\u00c9E addresses this trade-off by learning a good exploration strategy based on offline synthetic tasks, on which it can simulate the contextual bandit setting. Based on these simulations, M\u00caL\u00c9E uses an imitation learning strategy to learn a good exploration policy that can then be applied to true contextual bandit tasks at test time. We compare M\u00caL\u00c9E to seven strong baseline contextual bandit algorithms on a set of three hundred real-world datasets, on which it outperforms alternatives in most settings, especially when differences in rewards are large. Finally, we demonstrate the importance of having a rich feature representation for learning how to explore.\n", "keywords": ["meta-learning", "bandits", "exploration", "imitation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1093/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a meta-learning algorithm, ME\u0302LE\u0301E, for learning a good exploration function in the interactive contextual bandit setting.", "pdf": "/pdf/dc2298039804e0454caff65a4df83e29da6cd652.pdf", "paperhash": "anonymous|metalearning_for_contextual_bandit_exploration", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning for Contextual Bandit Exploration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxug2R9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xFxh0cKX", "original": "SklPRGh5tm", "number": 1094, "cdate": 1538087920665, "ddate": null, "tcdate": 1538087920665, "tmdate": 1538155992508, "tddate": null, "forum": "B1xFxh0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Guided Evolutionary Strategies: Escaping the curse of dimensionality in random search", "abstract": "Many applications in machine learning require optimizing a function whose true gradient is unknown, but where surrogate gradient information (directions that may be correlated with, but not necessarily identical to, the true gradient) is available instead. This arises when an approximate gradient is easier to compute than the full gradient (e.g. in meta-learning or unrolled optimization), or when a true gradient is intractable and is replaced with a surrogate (e.g. in certain reinforcement learning applications or training networks with discrete variables). We propose Guided Evolutionary Strategies, a method for optimally using surrogate gradient directions along with random search. We define a search distribution for evolutionary strategies that is elongated along a subspace spanned by the surrogate gradients. This allows us to estimate a descent direction which can then be passed to a first-order optimizer. We analytically and numerically characterize the tradeoffs that result from tuning how strongly the search distribution is stretched along the guiding subspace, and use this to derive a setting of the hyperparameters that works well across problems. Finally, we apply our method to example problems including truncated unrolled optimization and training neural networks with discrete variables, demonstrating improvement over both standard evolutionary strategies and first-order methods (that directly follow the surrogate gradient). We provide a demo of Guided ES at: redacted URL", "keywords": ["evolutionary strategies", "optimization", "gradient estimators", "biased gradients"], "authorids": ["ICLR.cc/2019/Conference/Paper1094/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose an optimization method for when only biased gradients are available--we define a new gradient estimator for this scenario, derive the bias and variance of this estimator, and apply it to example problems.", "pdf": "/pdf/0b14c36140480f115b0847908574fc08e2bfb320.pdf", "paperhash": "anonymous|guided_evolutionary_strategies_escaping_the_curse_of_dimensionality_in_random_search", "_bibtex": "@inproceedings{    \nanonymous2019guided,    \ntitle={Guided Evolutionary Strategies: Escaping the curse of dimensionality in random search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xFxh0cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgYl205tQ", "original": "Skl34l7qYQ", "number": 1095, "cdate": 1538087920851, "ddate": null, "tcdate": 1538087920851, "tmdate": 1538155992296, "tddate": null, "forum": "BJgYl205tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality", "abstract": "Generative Adversarial Networks (GANs) are an elegant mechanism for data generation.  However, a key challenge when using GANs is how to best measure their ability to generate realistic data. In this paper, we demonstrate that an intrinsic dimensional characterization of the data space learned by a GAN model leads to an effective evaluation metric for GAN quality.  In particular, we propose a new evaluation measure, CrossLID, that assesses the local intrinsic dimensionality (LID) of input data with respect to neighborhoods within GAN-generated samples.  In experiments on 3 benchmark image datasets, we compare our proposed measure to several state-of-the-art evaluation metrics. Our experiments show that CrossLID is strongly correlated with sample quality, is sensitive to mode collapse, is robust to small-scale noise and image transformations, and can be applied in a model-free  manner.  Furthermore, we show how CrossLID can be used within the GAN training process to improve generation quality.\n", "keywords": ["Generative Adversarial Networks", "Evaluation Metric", "Local Intrinsic Dimensionality"], "authorids": ["ICLR.cc/2019/Conference/Paper1095/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new metric for evaluating GAN models.", "pdf": "/pdf/e6ccd2320fffed60dd5c99d1f8ff72e4fde4b5af.pdf", "paperhash": "anonymous|quality_evaluation_of_gans_using_cross_local_intrinsic_dimensionality", "_bibtex": "@inproceedings{    \nanonymous2019quality,    \ntitle={Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgYl205tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxtl3C5YX", "original": "B1gAb099YQ", "number": 1097, "cdate": 1538087921188, "ddate": null, "tcdate": 1538087921188, "tmdate": 1538155991871, "tddate": null, "forum": "rkxtl3C5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding & Generalizing AlphaGo Zero", "abstract": "AlphaGo Zero (AGZ) introduced a new {\\em tabula rasa} reinforcement learning algorithm that has achieved superhuman performance in the games of Go, Chess, and Shogi with no prior knowledge other than the rules of the game. This success naturally begs the question whether it is possible to develop similar high-performance reinforcement learning algorithms for generic sequential decision-making problems (beyond two-player games), using only the constraints of the environment as the ``rules.'' To address this challenge, we start by taking steps towards developing a formal understanding of AGZ.  AGZ includes two key innovations: (1) it learns a policy (represented as a neural network) using {\\em supervised learning} with cross-entropy loss from samples generated via Monte-Carlo Tree Search (MCTS); (2) it uses {\\em self-play} to learn without training data. \n\nWe argue that the self-play in AGZ corresponds to learning a Nash equilibrium for the two-player game; and the supervised learning with MCTS is attempting to learn the policy corresponding to the Nash equilibrium, by establishing a novel bound on the difference between the expected return achieved by two policies in terms of the expected KL divergence (cross-entropy) of their induced distributions. To extend AGZ to generic sequential decision-making problems, we introduce a {\\em robust MDP} framework, in which the agent and nature effectively play a zero-sum game: the agent aims to take actions to maximize reward while nature seeks state transitions, subject to the constraints of that environment, that minimize the agent's reward. For a challenging network scheduling domain, we find that AGZ within the robust MDP framework provides near-optimal performance, matching one of the best known scheduling policies that has taken the networking community three decades of intensive research to develop.\n", "keywords": ["reinforcement learning", "AlphaGo Zero"], "authorids": ["ICLR.cc/2019/Conference/Paper1097/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cf9c4ba3d4036b7f8cb7126bf1bfd8dc1ce647d8.pdf", "paperhash": "anonymous|understanding_generalizing_alphago_zero", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding & Generalizing AlphaGo Zero},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxtl3C5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgYxn09Fm", "original": "ryxvKh3qFQ", "number": 1098, "cdate": 1538087921362, "ddate": null, "tcdate": 1538087921362, "tmdate": 1538155991664, "tddate": null, "forum": "rJgYxn09Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Implicitly Recurrent CNNs Through Parameter Sharing", "abstract": "We introduce a parameter sharing scheme, in which different layers of a convolutional neural network (CNN) are defined by a learned linear combination of parameter tensors from a global bank of templates.  Restricting the number of templates yields a flexible hybridization of traditional CNNs and recurrent networks.  Compared to traditional CNNs, we demonstrate substantial parameter savings on standard image classification tasks, while maintaining accuracy.\n\nOur simple parameter sharing scheme, though defined via soft weights, in practice yields trained networks with near strict recurrent structure; with negligible side effects, they convert into networks with actual recurrent loops.  Training these networks thus implicitly involves discovery of suitable recurrent architectures.  As a consequence, our hybrid networks are not only more parameter efficient, but also learn some tasks faster.  Specifically, on synthetic tasks which are algorithmic in nature, our hybrid networks both train faster and extrapolate better on test examples outside the span of the training set.", "keywords": ["deep learning", "architecture search", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper1098/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a method that enables CNN folding to create recurrent connections", "pdf": "/pdf/1abfcbe4c16d8d3ac7bb17798366ce6b404967be.pdf", "paperhash": "anonymous|learning_implicitly_recurrent_cnns_through_parameter_sharing", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Implicitly Recurrent CNNs Through Parameter Sharing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgYxn09Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hye9lnCct7", "original": "B1gCvwTqtm", "number": 1099, "cdate": 1538087921525, "ddate": null, "tcdate": 1538087921525, "tmdate": 1538155991457, "tddate": null, "forum": "Hye9lnCct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Actionable Representations with Goal Conditioned Policies", "abstract": "Representation learning is a central challenge across a range of machine learning areas. In reinforcement learning, effective and functional representations have the potential to tremendously accelerate learning progress and solve more challenging problems. Most prior work on representation learning has focused on generative approaches, learning representations that capture all the underlying factors of variation in the observation space in a more disentangled or well-ordered manner. In this paper, we instead aim to learn functionally salient representations: representations that are not necessarily complete in terms of capturing all factors of variation in the observation space, but rather aim to capture those factors of variation that are important for decision making -- that are \"actionable\". These representations are aware of the dynamics of the environment, and capture only the elements of the observation that are necessary for decision making rather than all factors of variation, eliminating the need for explicit reconstruction. We show how these learned representations can be useful to improve exploration for sparse reward problems, to enable long horizon hierarchical reinforcement learning, and as a state representation for learning policies for downstream tasks. We evaluate our method on a number of simulated environments, and compare it to prior methods for representation learning, exploration, and hierarchical reinforcement learning.", "keywords": ["Representation Learning", "Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1099/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning state representations which capture factors necessary for control", "pdf": "/pdf/0e121bbb1b6cf5ddeb4869becc185a819d037e8b.pdf", "paperhash": "anonymous|learning_actionable_representations_with_goal_conditioned_policies", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Actionable Representations with Goal Conditioned Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hye9lnCct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xce3ActX", "original": "HJxztehcYm", "number": 1100, "cdate": 1538087921693, "ddate": null, "tcdate": 1538087921693, "tmdate": 1538155991252, "tddate": null, "forum": "r1xce3ActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Deep Embeddings in Krein Spaces", "abstract": "The non-linear embedding achieved by a Siamese network is indeed a realization of a Hilbert space, \\ie, a metric space with a positive definite inner product.  Krein spaces generalize the notion of Hilbert spaces to geometrical structures with indefinite inner products. As a result, distances and norms in a Krein space can become negative. The negative spectral of an inner product is usually attributed to observation noise, though such a claim has never been fully studied, nor proved. Seeking how Krein spaces can be constructed from data, we propose a simple and innocent-looking modification to Siamese networks, equipping them with the power to realize indefinite inner-products. This provides a data-driven technique to decide whether the negative spectrum of an inner-product is helpful or not. We empirically show that our Krein embeddings outperform Hilbert space embeddings on recognition tasks. ", "keywords": ["Krein spaces", "Deep embedding learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1100/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a solution that realizes deep embeddings in Krein spaces.", "pdf": "/pdf/55885ecd3ac372ab7a6b939d1e8d079153d9275a.pdf", "paperhash": "anonymous|learning_deep_embeddings_in_krein_spaces", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Deep Embeddings in Krein Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xce3ActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xcx3C5FX", "original": "ByxoV8n5KX", "number": 1101, "cdate": 1538087921863, "ddate": null, "tcdate": 1538087921863, "tmdate": 1538155991045, "tddate": null, "forum": "S1xcx3C5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Statistical Verification of Neural Networks", "abstract": "We present a new approach to neural network verification based on estimating the proportion of inputs for which a property is violated. Specifically, we estimate the probability of the event that the property is violated under an input model. This permits classic verification as a special case, for which one considers only the question of whether this expectation is exactly zero or not. When the property can be violated, our approach provides an informative notion of how robust the network is, rather than just the conventional assertion that the network is not verifiable. Furthermore, it provides an ability to scale to larger networks than classical formal verification approaches. Key to achieving this is an adaptation of multi-level splitting, a Monte Carlo approach for estimating the probability of rare events, to our statistical verification framework. We demonstrate that our approach is able to emulate existing verification procedures on benchmark problems, while scaling to larger networks and providing reliable additional information in the form of accurate estimates of the violation probability.", "keywords": ["neural network verification", "multi-level splitting", "formal verification"], "authorids": ["ICLR.cc/2019/Conference/Paper1101/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a statistical approach to neural network verification that provides an informative notion of how robust a network is, rather than just the conventional binary assertion of whether or not of property is violated.", "pdf": "/pdf/eed0681e96bb21558f7510d6ac9f1bdf1d14d004.pdf", "paperhash": "anonymous|statistical_verification_of_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019statistical,    \ntitle={Statistical Verification of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xcx3C5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1z9ehAqYX", "original": "HJex_Ja5KQ", "number": 1102, "cdate": 1538087922026, "ddate": null, "tcdate": 1538087922026, "tmdate": 1538155990834, "tddate": null, "forum": "S1z9ehAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Shrinkage-based Bias-Variance Trade-off for Deep Reinforcement Learning", "abstract": "Deep reinforcement learning has achieved remarkable successes in solving various challenging artificial intelligence tasks. A variety of different algorithms have been introduced and improved towards human-level performance. Although technical advances have been developed for each individual algorithms, there has been strong evidence showing that further substantial improvements can be achieved by properly combining multiple approaches with difference biases and variances. In this work, we propose to use the James-Stein (JS) shrinkage estimator to combine on-policy policy gradient estimators which have low bias but high variance, with low-variance high-bias gradient estimates such as those constructed based on model-based methods or temporally smoothed averaging of historical gradients. Empirical results show that our simple shrinkage approach is very effective in practice and substantially improve the sample efficiency of the state-of-the-art on-policy methods on various continuous control tasks.\n", "keywords": ["bias-variance trade-off", "James-stein estimator", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1102/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/0669c9494e7e1ad3a35b87edb358a4af9aeb09d1.pdf", "paperhash": "anonymous|shrinkagebased_biasvariance_tradeoff_for_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019shrinkage-based,    \ntitle={Shrinkage-based Bias-Variance Trade-off for Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1z9ehAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGcghRct7", "original": "HJeFZPJ9Ym", "number": 1103, "cdate": 1538087922194, "ddate": null, "tcdate": 1538087922194, "tmdate": 1538155990628, "tddate": null, "forum": "HyGcghRct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Random mesh projectors for inverse problems", "abstract": " We propose a new learning-based approach to solve ill-posed inverse problems in imaging. We address the case where ground truth training samples are rare and the problem is severely ill-posed---both because of the underlying physics and because we can only get few measurements. This setting is common in geophysical imaging and remote sensing.We show that in this case the common approach to directly learn the mapping from the measured data to the reconstruction becomes unstable. Instead, we propose to first learn an ensemble of simpler mappings from the data to projections of the unknown image into random piecewise-constant subspaces. We then combine the projections to form a final reconstruction by solving a deconvolution-like problem. We show experimentally the proposed method is more robust to measurement noise and corruptions not seen during training than a directly learned inverse.", "keywords": ["imaging", "inverse problems", "subspace projections", "random Delaunay triangulations", "CNN", "geophysics", "regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper1103/Authors"], "authors": ["Anonymous"], "TL;DR": "We solve ill-posed inverse problems with scarce ground truth examples by estimating an ensemble of random projections of the model instead of the model itself.", "pdf": "/pdf/bf500146eda22305eddbeb62d868737d33f3ab09.pdf", "paperhash": "anonymous|random_mesh_projectors_for_inverse_problems", "_bibtex": "@inproceedings{    \nanonymous2019random,    \ntitle={Random mesh projectors for inverse problems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGcghRct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJNceh0cFX", "original": "HJle4WC5Km", "number": 1104, "cdate": 1538087922355, "ddate": null, "tcdate": 1538087922355, "tmdate": 1538155990420, "tddate": null, "forum": "SJNceh0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A   RECURRENT NEURAL CASCADE-BASED MODEL FOR CONTINUOUS-TIME DIFFUSION PROCESS", "abstract": "Many works have been proposed in the literature to capture the dynamics of diffusion in networks. While some of them define graphical markovian models to extract temporal relationships between node infections in networks, others consider diffusion episodes as sequences of infections via recurrent neural models. In this paper we propose a model at the crossroads of these two extremes, which embeds the history of diffusion in infected nodes as hidden continuous states. Depending on the trajectory followed by the content before reaching a given node, the distribution of influence probabilities may vary. However, content trajectories  are usually hidden in the data, which induces challenging learning problems. We propose a topological recurrent neural model which exhibits good experimental performances for diffusion modelling and prediction. ", "keywords": ["Information Diffusion", "Recurrent Neural Network", "Black Box Inference"], "authorids": ["ICLR.cc/2019/Conference/Paper1104/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f09c2a275267cebf093074f40762ff3e56f1e833.pdf", "paperhash": "anonymous|a_recurrent_neural_cascadebased_model_for_continuoustime_diffusion_process", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A   RECURRENT NEURAL CASCADE-BASED MODEL FOR CONTINUOUS-TIME DIFFUSION PROCESS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJNceh0cFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyxsl2AqKm", "original": "rylWVZRctQ", "number": 1105, "cdate": 1538087922518, "ddate": null, "tcdate": 1538087922518, "tmdate": 1538155990212, "tddate": null, "forum": "Hyxsl2AqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING", "abstract": "We describe a DNN for video classification and captioning, trained end-to-end,\nwith shared features, to solve tasks at different levels of granularity, exploring the\nlink between granularity in a source task and the quality of learned features for\ntransfer learning. For solving the new task domain in transfer learning, we freeze\nthe trained encoder and fine-tune an MLP on the target domain. We train on the\nSomething-Something dataset with over 220, 000 videos, and multiple levels of\ntarget granularity, including 50 action groups, 174 fine-grained action categories\nand captions. Classification and captioning with Something-Something are challenging\nbecause of the subtle differences between actions, applied to thousands\nof different object classes, and the diversity of captions penned by crowd actors.\nOur model performs better than existing classification baselines for SomethingSomething,\nwith impressive fine-grained results. And it yields a strong baseline on\nthe new Something-Something captioning task. Experiments reveal that training\nwith more fine-grained tasks tends to produce better features for transfer learning.", "keywords": ["Transfer Learning", "Video Understanding", "Fine-grained Video Classification", "Video Captioning", "Common Sense", "Something-Something Dataset."], "authorids": ["ICLR.cc/2019/Conference/Paper1105/Authors"], "authors": ["Anonymous"], "TL;DR": "If the model architecture is fixed, how would the complexity and granularity of task, effect the quality of learned features for transferring to a new task.", "pdf": "/pdf/59be2f74b76794a3b5e5b2d439bd3d5f00e28e49.pdf", "paperhash": "anonymous|on_the_effectiveness_of_task_granularity_for_transfer_learning", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyxsl2AqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeoxnRqKQ", "original": "HJgxQic9F7", "number": 1106, "cdate": 1538087922682, "ddate": null, "tcdate": 1538087922682, "tmdate": 1538155989995, "tddate": null, "forum": "ryeoxnRqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NATTACK: A STRONG AND UNIVERSAL GAUSSIAN BLACK-BOX ADVERSARIAL ATTACK", "abstract": "Recent works find that DNNs are  vulnerable to adversarial examples, whose changes from the benign ones are imperceptible and yet lead DNNs to make wrong predictions. One can find various adversarial examples for the same input to a DNN using different attack methods. In other words, there is a population of adversarial examples, instead of only one, for any input to a DNN. By explicitly modeling this adversarial population with a Gaussian distribution, we propose a new black-box attack called NATTACK. The adversarial attack is hence formalized as an optimization problem, which searches the mean of the Gaussian under the guidance of increasing the target DNN's prediction error. NATTACK achieves 100%  attack success rate  on six out of ten recently published defense methods (and greater than 90% for the other four), all using the same algorithm. Such results are on par with or better than  powerful state-of-the-art white-box attacks. While the white-box attacks are often model-specific or defense-specific, the proposed black-box NATTACK is universally applicable to different defenses. ", "keywords": ["adversarial attack", "black-box", "evolutional strategy", "policy gradient"], "authorids": ["ICLR.cc/2019/Conference/Paper1106/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7af762761b27dd8b502607e74b9ed0c8ec76f16a.pdf", "paperhash": "anonymous|nattack_a_strong_and_universal_gaussian_blackbox_adversarial_attack", "_bibtex": "@inproceedings{    \nanonymous2019nattack:,    \ntitle={NATTACK: A STRONG AND UNIVERSAL GAUSSIAN BLACK-BOX ADVERSARIAL ATTACK},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeoxnRqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1ejxnCctX", "original": "Hkl9eOnctm", "number": 1107, "cdate": 1538087922854, "ddate": null, "tcdate": 1538087922854, "tmdate": 1538155989784, "tddate": null, "forum": "r1ejxnCctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Representation Flow for Action Recognition", "abstract": "In this paper, we propose a convolutional layer inspired by optical flow algorithms to learn motion representations. Our representation flow layer is a fully-differentiable layer designed to optimally capture the '`flow' of any representation channel within a convolutional neural network. Its parameters for iterative flow optimization are learned in an end-to-end fashion together with the other model parameters, maximizing the action recognition performance. Furthermore, we newly introduce the concept of learning '`flow of flow' representations by stacking multiple representation flow layers. We conducted extensive experimental evaluations, confirming its advantages over previous recognition models using traditional optical flows in both computational speed and performance.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1107/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d8f411319fbba96c0aea29ffad4d045ae0de88ca.pdf", "paperhash": "anonymous|representation_flow_for_action_recognition", "_bibtex": "@inproceedings{    \nanonymous2019representation,    \ntitle={Representation Flow for Action Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1ejxnCctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syeil309tX", "original": "HylNneAcK7", "number": 1108, "cdate": 1538087923022, "ddate": null, "tcdate": 1538087923022, "tmdate": 1538155989577, "tddate": null, "forum": "Syeil309tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimized Gated Deep Learning Architectures for Sensor Fusion", "abstract": "Sensor fusion is a key technology that integrates various sensory inputs to allow for robust decision making in many applications such as autonomous driving and robot control. Deep neural networks have been adopted for sensor fusion in a body of recent studies. Among these, the so-called netgated architecture was proposed, which has demonstrated improved performances over the conventional convolu- tional neural networks (CNN). In this paper, we address several limitations of the baseline negated architecture by proposing two further optimized architectures: a coarser-grained gated architecture employing (feature) group-level fusion weights and a two-stage gated architectures leveraging both the group-level and feature- level fusion weights. Using driving mode prediction and human activity recogni- tion datasets, we demonstrate the significant performance improvements brought by the proposed gated architectures and also their robustness in the presence of sensor noise and failures.\n", "keywords": ["deep learning", "convolutional neural network", "sensor fusion", "activity recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper1108/Authors"], "authors": ["Anonymous"], "TL;DR": "Optimized gated deep learning architectures for sensor fusion is proposed.", "pdf": "/pdf/81dec7e6b7a567cbb7cd27f10bfa56c813204143.pdf", "paperhash": "anonymous|optimized_gated_deep_learning_architectures_for_sensor_fusion", "_bibtex": "@inproceedings{    \nanonymous2019optimized,    \ntitle={Optimized Gated Deep Learning Architectures for Sensor Fusion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syeil309tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgolhR9Km", "original": "HklwKej9K7", "number": 1109, "cdate": 1538087923197, "ddate": null, "tcdate": 1538087923197, "tmdate": 1538155989367, "tddate": null, "forum": "BJgolhR9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Networks with Structural Resistance to Adversarial Attacks", "abstract": "In adversarial attacks to machine-learning classifiers, small perturbations are added to input that is correctly classified. The perturbations yield adversarial examples, which are virtually indistinguishable from the unperturbed input, and yet are misclassified. In standard neural networks used for deep learning, attackers can craft adversarial examples from most input to cause a misclassification of their choice. \n\nWe introduce a new type of network units, called RBFI units, whose non-linear structure makes them inherently resistant to adversarial attacks. On permutation-invariant MNIST, in absence of adversarial attacks, networks using RBFI units match the performance of networks using sigmoid units, and are slightly below the accuracy of networks with ReLU units. When subjected to adversarial attacks, networks with RBFI units retain accuracies above 93% for projected gradient descent (PGD) attacks that degrade the accuracy of networks with ReLU or sigmoid units to below 70%.Considering a variety of attack mechanisms, RBFI networks trained on regular input either exceed or closely match the accuracy of sigmoid and ReLU network trained with the help of adversarial examples.\n\nThe non-linear structure of RBFI units makes them difficult to train using standard gradient descent. We show that RBFI networks of RBFI units can be efficiently trained to high accuracies using pseudogradients, computed using functions especially crafted to facilitate learning instead of their true derivatives.", "keywords": ["machine learning", "adversarial attacks"], "authorids": ["ICLR.cc/2019/Conference/Paper1109/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a type of neural network that is structurally resistant to adversarial attacks, even when trained on unaugmented training sets.  The resistance is due to the stability of network units wrt input perturbations.", "pdf": "/pdf/f4bc9a28cb214e50f09abaaeea0677cf2e722b0c.pdf", "paperhash": "anonymous|neural_networks_with_structural_resistance_to_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Networks with Structural Resistance to Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgolhR9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylsgnCcFQ", "original": "HJg-np25K7", "number": 1110, "cdate": 1538087923362, "ddate": null, "tcdate": 1538087923362, "tmdate": 1538155989160, "tddate": null, "forum": "HylsgnCcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dynamic Graph Representation Learning via Self-Attention Networks", "abstract": "Learning latent representations of nodes in graphs is an important and ubiquitous task with widespread applications such as link prediction, node classification, and graph visualization. Previous methods on graph representation learning mainly focus on static graphs, however, many real-world graphs are dynamic and evolve over time. In this paper, we present Dynamic Self-Attention Network (DySAT), a novel neural architecture that operates on dynamic graphs and learns node representations that capture both structural properties and temporal evolutionary patterns. Specifically, DySAT computes node representations by jointly employing self-attention layers along two dimensions: structural neighborhood and temporal dynamics. We conduct link prediction experiments on two classes of graphs: communication networks and bipartite rating networks. Our experimental results show that DySAT has a significant performance gain over several different state-of-the-art graph embedding baselines.", "keywords": ["Graph Representation Learning", "Dynamic Graphs", "Attention", "Self-Attention", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1110/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel neural architecture named DySAT to learn node representations on dynamic graphs by employing self-attention along two dimensions: structural neighborhood and temporal dynamics, achieves state-of-the-art results in dynamic link prediction.", "pdf": "/pdf/39b6aa54f2df048fda97ee088362aec4e8774aa8.pdf", "paperhash": "anonymous|dynamic_graph_representation_learning_via_selfattention_networks", "_bibtex": "@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Graph Representation Learning via Self-Attention Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylsgnCcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkg3g2R9FX", "original": "B1lUTmp9YX", "number": 1111, "cdate": 1538087923529, "ddate": null, "tcdate": 1538087923529, "tmdate": 1538155988945, "tddate": null, "forum": "Bkg3g2R9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Gradient Methods with Dynamic Bound of Learning Rate", "abstract": "Adaptive optimization methods such as AdaGrad, RMSProp and Adam have been proposed to achieve a rapid training process with an element-wise scaling term on learning rates. \nThough prevailing, they are observed to generalize poorly compared with SGD or even fail to converge due to unstable and extreme learning rates. \nRecent work has put forward some algorithms such as AMSGrad to tackle this issue but they failed to achieve considerable improvement over existing methods. \nIn our paper, we demonstrate that extreme learning rates can lead to poor performance.\nWe provide new variants of Adam and AMSGrad, called AdaBound and AMSBound respectively, which employ dynamic bounds on learning rates to achieve a gradual and smooth transition from adaptive methods to SGD and give a theoretical proof of convergence.\nWe further conduct experiments on various popular tasks and models, which is often insufficient in previous work.\nExperimental results show that new variants can eliminate the generalization gap between adaptive methods and SGD and maintain higher learning speed early in training at the same time.\nMoreover, they can bring significant improvement over their prototypes, especially on complex deep networks.", "keywords": ["Optimization", "Adam", "Generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1111/Authors"], "authors": ["Anonymous"], "TL;DR": "Novel variants of optimization methods that combine the benefits of both adaptive and non-adaptive methods.", "pdf": "/pdf/98546fa95f55bda5b05d16d19c15cfe7ebcdeabe.pdf", "paperhash": "anonymous|adaptive_gradient_methods_with_dynamic_bound_of_learning_rate", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Gradient Methods with Dynamic Bound of Learning Rate},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg3g2R9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bylnx209YX", "original": "BJxDjehqKm", "number": 1112, "cdate": 1538087923688, "ddate": null, "tcdate": 1538087923688, "tmdate": 1538155988734, "tddate": null, "forum": "Bylnx209YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Attacks on Graph Neural Networks via Meta Learning", "abstract": "Deep learning models for graphs have advanced the state of the art on many tasks. Despite their recent success, little is known about their robustness. We investigate training time attacks on graph neural networks for node classification that perturb the discrete graph structure.  Our core principle is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. Our experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings. Remarkably, the perturbations created by our algorithm misguide the graph neural networks such that they perform worse than a simple baseline that ignores all relational information. Our attacks do not assume any knowledge about or access to the target classifiers.", "keywords": ["graph mining", "adversarial attacks", "meta learning", "graph neural networks", "node classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1112/Authors"], "authors": ["Anonymous"], "TL;DR": "We use meta-gradients to attack the training procedure of deep neural networks for graphs.", "pdf": "/pdf/dcf4e228c1f2a341bbee726d4e39fa322092e8b9.pdf", "paperhash": "anonymous|adversarial_attacks_on_graph_neural_networks_via_meta_learning", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Attacks on Graph Neural Networks via Meta Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bylnx209YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1Gnx2CqKQ", "original": "H1l3Oxn5F7", "number": 1113, "cdate": 1538087923848, "ddate": null, "tcdate": 1538087923848, "tmdate": 1538155988529, "tddate": null, "forum": "H1Gnx2CqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hiding Objects from Detectors: Exploring Transferrable Adversarial Patterns", "abstract": "Adversaries in neural networks have drawn much attention since their first debut. \nWhile most existing methods aim at deceiving image classification models into misclassification or crafting attacks for specific object instances in the object setection tasks, we focus on creating universal adversaries to fool object detectors and hide objects from the detectors. \nThe adversaries we examine are universal in three ways: \n(1) They are not specific for specific object instances; \n(2) They are image-independent; \n(3) They can further transfer to different unknown models. \nTo achieve this, we propose two novel techniques to improve the transferability of the adversaries: \\textit{piling-up} and \\textit{monochromatization}. \nBoth techniques prove to simplify the patterns of generated adversaries, and ultimately result in higher transferability. ", "keywords": ["adversarial", "object detection"], "authorids": ["ICLR.cc/2019/Conference/Paper1113/Authors"], "authors": ["Anonymous"], "TL;DR": "We focus on creating universal adversaries to fool object detectors and hide objects from the detectors. ", "pdf": "/pdf/149f561d0eefc9662e0400f8b3dbb345c6cab4e3.pdf", "paperhash": "anonymous|hiding_objects_from_detectors_exploring_transferrable_adversarial_patterns", "_bibtex": "@inproceedings{    \nanonymous2019hiding,    \ntitle={Hiding Objects from Detectors: Exploring Transferrable Adversarial Patterns},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1Gnx2CqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkG3e205K7", "original": "HyxmiuYYY7", "number": 1114, "cdate": 1538087924006, "ddate": null, "tcdate": 1538087924006, "tmdate": 1538155988322, "tddate": null, "forum": "HkG3e205K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives", "abstract": "Deep latent variable models have become a popular model choice due to the scalable learning algorithms introduced by (Kingma & Welling 2013, Rezende et al. 2014). These approaches maximize a variational lower bound on the intractable log likelihood of the observed data. Burda et al. (2015) introduced a multi-sample variational bound, IWAE, that is at least as tight as the standard variational lower bound and becomes increasingly tight as the number of samples increases. Counterintuitively, the typical inference network gradient estimator for the IWAE bound performs poorly as the number of samples increases (Rainforth et al. 2018, Le et al. 2018). Roeder et a. (2017) propose an improved gradient estimator, however, are unable to show it is unbiased. We show that it is in fact biased and that the bias can be estimated efficiently with a second application of the reparameterization trick. The doubly reparameterized gradient (DReG) estimator does not suffer as the number of samples increases, resolving the previously raised issues. The same idea can be used to improve many recently introduced training techniques for latent variable models. In particular, we show that this estimator reduces the variance of the IWAE gradient, the reweighted wake-sleep update (RWS) (Bornschein & Bengio 2014), and the jackknife variational inference (JVI) gradient (Nowozin 2018). Finally, we show that this computationally efficient, drop-in estimator translates to improved performance for all three objectives on several modeling tasks.", "keywords": ["variational autoencoder", "reparameterization trick", "IWAE", "VAE", "RWS", "JVI"], "authorids": ["ICLR.cc/2019/Conference/Paper1114/Authors"], "authors": ["Anonymous"], "TL;DR": "Doubly reparameterized gradient estimators provide unbiased variance reduction which leads to improved performance.", "pdf": "/pdf/afdaa9f8a72487e7277315f124ad36fed77b5ac3.pdf", "paperhash": "anonymous|doubly_reparameterized_gradient_estimators_for_monte_carlo_objectives", "_bibtex": "@inproceedings{    \nanonymous2019doubly,    \ntitle={Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkG3e205K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkVhlh09tX", "original": "BkxV9H65tm", "number": 1115, "cdate": 1538087924174, "ddate": null, "tcdate": 1538087924174, "tmdate": 1538155988115, "tddate": null, "forum": "SkVhlh09tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pay Less Attention with Lightweight and Dynamic Convolutions", "abstract": "Self-attention is a useful mechanism to build generative models for language and images. It determines the importance of context elements by comparing each element to the current time step. In this paper, we show that a very lightweight convolution can perform competitively to the best reported self-attention results. Next, we introduce dynamic convolutions which are simpler and more efficient than self-attention. We predict separate convolution kernels based solely on the current time-step in order to determine the importance of context elements. The number of operations required by this approach scales linearly in the input length, whereas self-attention is quadratic. Experiments on large-scale machine translation, language modeling and abstractive summarization show that dynamic convolutions improve over strong self-attention models. On the WMT'14 English-German test set dynamic convolutions achieve a new state of the art of 29.7 BLEU.", "keywords": ["Deep learning", "sequence to sequence learning", "convolutional neural networks", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper1115/Authors"], "authors": ["Anonymous"], "TL;DR": "Dynamic lightweight convolutions are competitive to self-attention on language tasks.", "pdf": "/pdf/1cd147e51e2b223efa01aeba772ee4e35632dfbe.pdf", "paperhash": "anonymous|pay_less_attention_with_lightweight_and_dynamic_convolutions", "_bibtex": "@inproceedings{    \nanonymous2019pay,    \ntitle={Pay Less Attention with Lightweight and Dynamic Convolutions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkVhlh09tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyVhg20cK7", "original": "S1e0Tnnctm", "number": 1116, "cdate": 1538087924334, "ddate": null, "tcdate": 1538087924334, "tmdate": 1538155987906, "tddate": null, "forum": "SyVhg20cK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Inducing Cooperation via Learning to reshape rewards in semi-cooperative multi-agent reinforcement learning", "abstract": "We propose a deep reinforcement learning algorithm for semi-cooperative multi-agent tasks, where agents are equipped with their separate reward functions, yet with willingness to cooperate. Under these semi-cooperative scenarios, popular methods of centralized training with decentralized execution for inducing cooperation and removing the non-stationarity problem do not work well due to lack of a common shared reward as well as inscalability in centralized training. Our algorithm, called Peer-Evaluation based Dual DQN (PED-DQN), proposes to give peer evaluation signals to observed agents, which quantifies how they feel about a certain transition. This exchange of peer evaluation over time turns out to render agents to gradually reshape their reward functions so that their action choices from the myopic best-response tend to result in the good joint action with high cooperation. This evaluation-based method also allows flexible and scalable training by not assuming knowledge of the number of other agents and their observation and action spaces. We provide the performance evaluation of PED-DQN for the scenarios ranging from a simple two-person prisoner's dilemma to more complex semi-cooperative multi-agent tasks. In special cases where agents share a common reward function as in the centralized training methods, we show that inter-agent evaluation allows faster convergence. \n", "keywords": ["multiagent reinforcement learning", "deep reinforcement learning", "multiagent systems"], "authorids": ["ICLR.cc/2019/Conference/Paper1116/Authors"], "authors": ["Anonymous"], "TL;DR": "We use an peer evaluation mechanism to make semi-cooperative agents learn collaborative strategies in multiagent reinforcement learning settings", "pdf": "/pdf/ac02f5dfab961642b24e16f2603849f146d5aafb.pdf", "paperhash": "anonymous|inducing_cooperation_via_learning_to_reshape_rewards_in_semicooperative_multiagent_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019inducing,    \ntitle={Inducing Cooperation via Learning to reshape rewards in semi-cooperative multi-agent reinforcement learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyVhg20cK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJLhxnRqFQ", "original": "HJxyE_6qKX", "number": 1117, "cdate": 1538087924503, "ddate": null, "tcdate": 1538087924503, "tmdate": 1538155987695, "tddate": null, "forum": "SJLhxnRqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarially Learned Mixture Model", "abstract": "The Adversarially Learned Mixture Model (AMM) is a generative model for unsupervised or semi-supervised data clustering. The AMM is the first adversarially optimized method to model the conditional dependence between inferred continuous and categorical latent variables. Experiments on the MNIST and SVHN datasets show that the AMM allows for semantic separation of complex data when little or no labeled data is available. The AMM achieves unsupervised clustering error rates of 3.32% and 20.4% on the MNIST and SVHN datasets, respectively.  A semi-supervised extension of the AMM achieves a classification error rate of 5.60% on the SVHN dataset.", "keywords": ["Unsupervised", "Semi-supervised", "Generative", "Adversarial", "Clustering"], "authorids": ["ICLR.cc/2019/Conference/Paper1117/Authors"], "authors": ["Anonymous"], "TL;DR": "The AMM is the first fully adversarially optimized method to model the conditional dependence between categorical and continuous latent variables.", "pdf": "/pdf/a9c763e04547d54f26eb22dd6be464853364e81e.pdf", "paperhash": "anonymous|adversarially_learned_mixture_model", "_bibtex": "@inproceedings{    \nanonymous2019adversarially,    \ntitle={Adversarially Learned Mixture Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJLhxnRqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJg6e2CcK7", "original": "rJxyLCaqYQ", "number": 1118, "cdate": 1538087924661, "ddate": null, "tcdate": 1538087924661, "tmdate": 1538155987481, "tddate": null, "forum": "HJg6e2CcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Clean-Label Backdoor Attacks", "abstract": "Deep neural networks have been recently demonstrated to be vulnerable to backdoor attacks. Specifically, by altering a small set of training examples, an adversary can install a backdoor that is able to be used during inference to fully control the model's behavior. While the attack is very powerful, it crucially relies on the adversary being able to introduce arbitrary, often clearly mislabeled, inputs to the training set and can thus be foiled even by fairly rudimentary data sanitization. In this paper, we introduce a new approach to executing backdoor attacks. This approach utilizes adversarial examples and GAN-generated data. The key feature is that the resulting poisoned inputs appear to be consistent with their label and thus seem benign even upon human inspection.", "keywords": ["data poisoning", "backdoor attacks", "clean labels", "adversarial examples", "generative adversarial networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1118/Authors"], "authors": ["Anonymous"], "TL;DR": "We show how to successfully perform backdoor attacks without changing training labels.", "pdf": "/pdf/e177d8f391b53031c7de05d76ffd80c49ac33068.pdf", "paperhash": "anonymous|cleanlabel_backdoor_attacks", "_bibtex": "@inproceedings{    \nanonymous2019clean-label,    \ntitle={Clean-Label Backdoor Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJg6e2CcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lTg3RqYQ", "original": "H1e0SGsctX", "number": 1119, "cdate": 1538087924820, "ddate": null, "tcdate": 1538087924820, "tmdate": 1538155987260, "tddate": null, "forum": "S1lTg3RqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency", "abstract": "Image-to-image translation has recently received significant attention due to advances in deep learning. Most works focus on learning either a one-to-one mapping in an unsupervised way or a many-to-many mapping in a supervised way. However, a more practical setting is many-to-many mapping in an unsupervised way, which is harder due to the lack of supervision and the complex inner- and cross-domain variations. To alleviate these issues, we propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain. We assume that an image comprises of a content component which is shared across domains, and a style component specific to each domain. Under the guidance of an exemplar from the target domain we apply Adaptive Instance Normalization to the shared content component, which allows us to transfer the style information of the target domain to the source domain. To avoid semantic inconsistencies during translation that naturally appear due to the large inner- and cross-domain variations, we introduce the concept of feature masks that provide coarse semantic guidance without requiring the use of any semantic labels. Experimental results on various datasets show that EGSC-IT does not only translate the source image to diverse instances in the target domain, but also preserves the semantic consistency during the process. ", "keywords": ["image-to-image translation", "image generation", "domain adaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper1119/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain.", "pdf": "/pdf/8a8302ddc810a625058707e8fc14179432869a80.pdf", "paperhash": "anonymous|exemplar_guided_unsupervised_imagetoimage_translation_with_semantic_consistency", "_bibtex": "@inproceedings{    \nanonymous2019exemplar,    \ntitle={Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lTg3RqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lpx3A9K7", "original": "SJlfQAp9t7", "number": 1120, "cdate": 1538087924994, "ddate": null, "tcdate": 1538087924994, "tmdate": 1538155987052, "tddate": null, "forum": "r1lpx3A9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1120/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "anonymous|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@inproceedings{    \nanonymous2019featurized,    \ntitle={Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lpx3A9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lTg3RcFm", "original": "S1xzkZC9FQ", "number": 1121, "cdate": 1538087925159, "ddate": null, "tcdate": 1538087925159, "tmdate": 1538155986841, "tddate": null, "forum": "S1lTg3RcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Perception-Aware Point-Based Value Iteration for Partially Observable Markov Decision Processes", "abstract": "Partially observable Markov decision processes (POMDPs) are a widely-used framework to model decision-making with uncertainty about the environment and under stochastic outcome. In conventional POMDP models, the observations that the agent receives originate from fixed known distribution. However, in a variety of real-world scenarios the agent has an active role in its perception by selecting which observations to receive. Due to combinatorial nature of such selection process, it is computationally intractable to integrate the perception decision with the planning decision. To prevent such expansion of the action space, we propose a greedy strategy for observation selection. \nWe develop a novel point-based value iteration algorithm that incorporates the greedy strategy to find near-optimal selection decision for sampled belief points. This in turn enables the solver to efficiently approximate the reachable subspace of belief simplex by essentially separating computations related to perception from planning.\nLastly, we implement the proposed solver and demonstrate its performance and computational advantage in a range of robotic scenarios where the robot simultaneously performs active perception and planning.", "keywords": ["partially observable Markov decision processes", "active perception", "submodular optimization", "point-based value iteration", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1121/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a point-based value iteration solver for POMDPs with active perception and planning tasks.", "pdf": "/pdf/c7c9a0fa3662d32839a8077a7af3f909b54bb826.pdf", "paperhash": "anonymous|perceptionaware_pointbased_value_iteration_for_partially_observable_markov_decision_processes", "_bibtex": "@inproceedings{    \nanonymous2019perception-aware,    \ntitle={Perception-Aware Point-Based Value Iteration for Partially Observable Markov Decision Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lTg3RcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1l6e3RcF7", "original": "SJgwzJRcFm", "number": 1122, "cdate": 1538087925320, "ddate": null, "tcdate": 1538087925320, "tmdate": 1538155986632, "tddate": null, "forum": "B1l6e3RcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Walk with SGD: How SGD Explores Regions of Deep Network Loss?", "abstract": "The non-convex nature of the loss landscape of deep neural networks (DNN) lends them the intuition that over the course of training, stochastic optimization algorithms explore different regions of the loss surface by entering and escaping many local minima due to the noise induced by mini-batches. But is this really the case? This question couples the geometry of the DNN loss landscape with how stochastic optimization algorithms like SGD interact with it during training. Answering this question may help us qualitatively understand the dynamics of deep neural network optimization. We show evidence through qualitative and quantitative experiments that mini-batch SGD rarely crosses barriers during DNN optimization. As we show, the mini-batch induced noise helps SGD explore different regions of the loss surface using a seemingly different mechanism. To complement this finding, we also investigate the qualitative reason behind the slowing down of this exploration when using larger batch-sizes. We show this happens because gradients from larger batch-sizes align more with the top eigenvectors of the Hessian, which makes SGD oscillate in the proximity of the parameter initialization, thus preventing exploration.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1122/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f47da99158df06a898f20d9f1e18c0175bb96ef2.pdf", "paperhash": "anonymous|a_walk_with_sgd_how_sgd_explores_regions_of_deep_network_loss", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Walk with SGD: How SGD Explores Regions of Deep Network Loss?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l6e3RcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1xpe2C5Km", "original": "rkg6w-CcKX", "number": 1123, "cdate": 1538087925478, "ddate": null, "tcdate": 1538087925478, "tmdate": 1538155986418, "tddate": null, "forum": "H1xpe2C5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Trace-back along capsules and its application on semantic segmentation  \t\t", "abstract": "In this paper, we propose a capsule-based neural network model to solve the semantic segmentation problem. By taking advantage of the extractable part-whole dependencies available in capsule layers, we derive the probabilities of the class labels for individual capsules through a layer-by-layer recursive procedure. We model this procedure as a traceback layer, and take it as a central piece to build an end-to-end segmentation network. In addition to object boundaries, image-level class labels are also explicitly sought in our model, which poses a significant advantage over the state-of-the-art fully convolutional network (FCN) solutions. Experiments conducted on modified MNIST and neuroimages demonstrate that our model considerably enhance the segmentation performance compared to the leading FCN variant.\n", "keywords": ["capsule", "capsule network", "semantic segmentation", "FCN"], "authorids": ["ICLR.cc/2019/Conference/Paper1123/Authors"], "authors": ["Anonymous"], "TL;DR": "A capsule-based semantic segmentation, which the probabilities of the class labels are traced back through capsule layers. ", "pdf": "/pdf/4ac43f6305cf3652abc7d1f79b64afabe86b167c.pdf", "paperhash": "anonymous|traceback_along_capsules_and_its_application_on_semantic_segmentation", "_bibtex": "@inproceedings{    \nanonymous2019trace-back,    \ntitle={Trace-back along capsules and its application on semantic segmentation  \t\t},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xpe2C5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxCenR5F7", "original": "HklxOh35KQ", "number": 1124, "cdate": 1538087925639, "ddate": null, "tcdate": 1538087925639, "tmdate": 1538155986211, "tddate": null, "forum": "HkxCenR5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational recurrent models for representation learning", "abstract": "We study the problem of learning representations of sequence data. Recent work has built on variational autoencoders to develop variational recurrent models for generation. Our main goal is not generation but rather representation learning for downstream prediction tasks. Existing variational recurrent models typically use stochastic recurrent connections to model the dependence among neighboring latent variables, while generation assumes independence of generated data per time step given the latent sequence. In contrast, our models assume independence among all latent variables given non-stochastic hidden states, which speeds up inference, while assuming dependence of observations at each time step on all latent variables, which improves representation quality.  In addition, we propose and study extensions for improving downstream performance, including hierarchical auxiliary latent variables and prior updating during training. Experiments show improved performance on several speech and language tasks with different levels of supervision, as well as in a multi-view learning setting.", "keywords": ["Representation learning", "variational model"], "authorids": ["ICLR.cc/2019/Conference/Paper1124/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/dc11b8a1ae602fbe146f7f105be5aa5aa62d6218.pdf", "paperhash": "anonymous|variational_recurrent_models_for_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational recurrent models for representation learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxCenR5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxCxhRcY7", "original": "H1eYYyAcKX", "number": 1125, "cdate": 1538087925806, "ddate": null, "tcdate": 1538087925806, "tmdate": 1538155986000, "tddate": null, "forum": "HyxCxhRcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Anomaly Detection with Outlier Exposure", "abstract": "It is important to detect and handle anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data commonly used by deep learning systems are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). In extensive experiments in vision and natural language processing settings, we find that Outlier Exposure significantly improves the performance of existing anomaly detectors, including detectors based on density estimation, and that OE improves classifier calibration in the presence of anomalous inputs.  We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.", "keywords": ["confidence", "uncertainty", "anomaly", "robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper1125/Authors"], "authors": ["Anonymous"], "TL;DR": "We teach anomaly detection methods to learn heuristics for spotting new anomalies; experiments are in NLP and vision settings", "pdf": "/pdf/8dc286ba2a228c39bc67a621df3a3f6bb6642928.pdf", "paperhash": "anonymous|deep_anomaly_detection_with_outlier_exposure", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Anomaly Detection with Outlier Exposure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxCxhRcY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1x0enCcK7", "original": "SJxcZCp9tX", "number": 1126, "cdate": 1538087925985, "ddate": null, "tcdate": 1538087925985, "tmdate": 1538155985782, "tddate": null, "forum": "B1x0enCcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Automatic generation of object shapes with desired functionalities", "abstract": "3D objects (artefacts) are made to fulfill functions. Designing an object often starts with defining a list of functionalities that it should provide, also known as functional requirements. Today, the design of 3D object models is still a slow and largely artisanal activity, with few CAD tools existing to aid the exploration of the design solution space. To accelerate the design process, we introduce an algorithm for generating object shapes with desired functionalities.  Following the concept of form follows function, we assume that existing object shapes were rationally chosen to provide desired functionalities. First, we use an artificial neural network to learn a function-to-form mapping by analysing a dataset of objects labeled with their functionalities. Then, we combine forms providing one or more desired functions, generating an object shape that is expected to provide all of them. Finally, we verify in simulation whether the generated object possesses the desired functionalities, by defining and executing functionality tests on it.\n", "keywords": ["automated design", "affordance learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1126/Authors"], "authors": ["Anonymous"], "TL;DR": "It's difficult to make objects with desired affordances. We propose an automated method for generating object shapes with desired affordances, based on neural networks.", "pdf": "/pdf/9f63d5eb812e36a4ffd4a27675d9a68ed7288ed1.pdf", "paperhash": "anonymous|automatic_generation_of_object_shapes_with_desired_functionalities", "_bibtex": "@inproceedings{    \nanonymous2019automatic,    \ntitle={Automatic generation of object shapes with desired functionalities},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1x0enCcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkx0g3R5tX", "original": "Bklz782qK7", "number": 1127, "cdate": 1538087926153, "ddate": null, "tcdate": 1538087926153, "tmdate": 1538155985572, "tddate": null, "forum": "rkx0g3R5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Partially Mutual Exclusive Softmax for Positive and Unlabeled data", "abstract": "In recent years, softmax together with its fast approximations has become the de-facto loss function for deep neural networks with multiclass predictions. However, softmax is used in many problems that do not fully fit the multiclass framework and where the softmax assumption of mutually exclusive outcomes can lead to biased results. This is often the case for applications such as language modeling, next event prediction and matrix factorization, where many of the potential outcomes are not mutually exclusive, but are more likely to be independent conditionally on the state. To this end, for the set of problems with positive and unlabeled data, we propose a relaxation of the original softmax formulation, where, given the observed state, each of the outcomes are conditionally independent but share a common set of negatives. Since we operate in a regime where explicit negatives are missing, we create an adversarially-trained model of negatives and derive a new negative sampling and weighting scheme which we denote as Cooperative Importance Sampling (CIS). We show empirically the advantages of our newly introduced negative sampling scheme by pluging it in the Word2Vec algorithm and benching it extensively against other negative sampling schemes on both language modeling and matrix factorization tasks and show large lifts in performance.", "keywords": ["Negative Sampling", "Sampled Softmax", "Word embeddings", "Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1127/Authors"], "authors": ["Anonymous"], "TL;DR": "Defining a partially mutual exclusive softmax loss for postive data and implementing a cooperative based sampling scheme", "pdf": "/pdf/e15329822a8671eb6c7cfde053e9a9f9eba6ba12.pdf", "paperhash": "anonymous|partially_mutual_exclusive_softmax_for_positive_and_unlabeled_data", "_bibtex": "@inproceedings{    \nanonymous2019partially,    \ntitle={Partially Mutual Exclusive Softmax for Positive and Unlabeled data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkx0g3R5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylRgh0qK7", "original": "rJgCTJA4FQ", "number": 1128, "cdate": 1538087926320, "ddate": null, "tcdate": 1538087926320, "tmdate": 1538155985360, "tddate": null, "forum": "rylRgh0qK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deterministic Policy Gradients with General State Transitions", "abstract": "We study a reinforcement learning setting, where the state transition function is a convex combination of a stochastic continuous function and a deterministic function. Such a setting generalizes the widely-studied stochastic state transition setting, namely the setting of deterministic policy gradient (DPG).\n\nWe firstly give a simple example to illustrate that the deterministic policy gradient may be infinite under deterministic state transitions, and introduce a theoretical technique to prove the existence of the policy gradient in this generalized setting. Using this technique, we prove that the deterministic policy gradient indeed exists for a certain set of discount factors, and further prove two conditions that guarantee the existence for all discount factors. We then derive a closed form of the policy gradient whenever exists. Furthermore, to overcome the challenge of high sample complexity of DPG in this setting, we propose the Generalized Deterministic Policy Gradient (GDPG) algorithm. The main innovation of the algorithm is a new method of applying model-based techniques to the model-free algorithm, the deep deterministic policy gradient algorithm (DDPG). GDPG optimize the long-term rewards of the model-based augmented MDP subject to a constraint that the long-rewards of the MDP is less than the original one.\n\nWe finally conduct extensive experiments comparing GDPG with state-of-the-art methods and the direct model-based extension method of DDPG on several standard continuous control benchmarks. Results demonstrate that GDPG substantially outperforms DDPG, the model-based extension of DDPG and other baselines in terms of both convergence and long-term rewards in most environments.", "keywords": ["Reinforcement Learning", "Deterministic Policy Gradients", "Model-based"], "authorids": ["ICLR.cc/2019/Conference/Paper1128/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/39c31f52844c80d9625b533a93af3594bf8d0fe7.pdf", "paperhash": "anonymous|deterministic_policy_gradients_with_general_state_transitions", "_bibtex": "@inproceedings{    \nanonymous2019deterministic,    \ntitle={Deterministic Policy Gradients with General State Transitions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylRgh0qK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJeRg205Fm", "original": "HJeJL44PKQ", "number": 1129, "cdate": 1538087926482, "ddate": null, "tcdate": 1538087926482, "tmdate": 1538155985149, "tddate": null, "forum": "BJeRg205Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs", "abstract": "We propose a method for quantifying uncertainty in neural network regression models when the targets are real values on a $d$-dimensional simplex, such as probabilities. We show that each target can be modeled as a sample from a Dirichlet distribution, where the parameters of the Dirichlet are provided by the output of a neural network, and that the combined model can be trained using the gradient of the data likelihood. This approach provides interpretable predictions in the form of multidimensional distributions, rather than point estimates, from which one can obtain confidence intervals or quantify risk in decision making. Furthermore, we show that the same approach can be used to model targets in the form of empirical counts as samples from the Dirichlet-multinomial compound distribution. In experiments, we verify that our approach provides these benefits without harming the performance of the point estimate predictions on two diverse applications: (1) distilling deep convolutional networks trained on CIFAR-100, and (2) predicting the location of particle collisions in the XENON1T Dark Matter detector.", "keywords": ["regression", "uncertainty", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1129/Authors"], "authors": ["Anonymous"], "TL;DR": "Neural network regression should use Dirichlet output distribution when targets are probabilities in order to quantify uncertainty of predictions.", "pdf": "/pdf/307f854d16a91d35691110152d1995c9dfb8a767.pdf", "paperhash": "anonymous|neural_network_regression_with_beta_dirichlet_and_dirichletmultinomial_outputs", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeRg205Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Ske1-209Y7", "original": "rkxiIx65YX", "number": 1130, "cdate": 1538087926661, "ddate": null, "tcdate": 1538087926661, "tmdate": 1538155984939, "tddate": null, "forum": "Ske1-209Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Model-Based Dynamic Architecture Search", "abstract": "The architecture search methods for convolutional neural networks (CNNs) have shown promising results. These methods require significant computational resources, as they repeat the neural network training many times to evaluate and search the architectures. Developing the computationally efficient architecture search method is an important research topic. In this paper, we assume that the structure parameters of CNNs are categorical variables, such as types and connectivities of layers, and they are regarded as the learnable parameters. Introducing the multivariate categorical distribution as the underlying distribution for the structure parameters, we formulate a differentiable loss for the training task, where the training of the weights and the optimization of the parameters of the distribution for the structure parameters are coupled. They are trained using the stochastic gradient descent, leading to the optimization of the structure parameters within a single training. We apply the proposed method to search the architecture for two computer vision tasks: image classification and inpainting. The experimental results show that the proposed architecture search method is fast and can achieve comparable performance to the existing methods.", "keywords": ["architecture search", "stochastic natural gradient", "convolutional neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1130/Authors"], "authors": ["Anonymous"], "TL;DR": "We present an efficient neural network architecture search method based on stochastic natural gradient method via probabilistic modeling.", "pdf": "/pdf/8045cadcb6c967a6a029b65375a700bb61e45ffb.pdf", "paperhash": "anonymous|probabilistic_modelbased_dynamic_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Model-Based Dynamic Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Ske1-209Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkxJ-309FQ", "original": "H1xgIIpqtm", "number": 1131, "cdate": 1538087926826, "ddate": null, "tcdate": 1538087926826, "tmdate": 1538155984738, "tddate": null, "forum": "SkxJ-309FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hallucinations in Neural Machine Translation", "abstract": "Neural machine translation (NMT) systems have reached state of the art performance in translating text and are in wide deployment.  Yet little is understood about how these systems function or break.  Here we show that NMT systems are susceptible to producing highly pathological translations that are completely untethered from the source material, which we term hallucinations.  Such pathological translations are problematic because they are are deeply disturbing of user trust and easy to find with a simple search.  We describe a method to generate hallucinations and show that many common variations of the NMT architecture are susceptible to them. We study a variety of approaches to reduce the frequency of hallucinations, including data augmentation, dynamical systems and regularization techniques, showing that data augmentation significantly reduces hallucination frequency. Finally, we analyze networks that produce hallucinations and show that there are signatures in the attention matrix as well as in the stability measures of the decoder.", "keywords": ["nmt", "translate", "dynamics", "rnn"], "authorids": ["ICLR.cc/2019/Conference/Paper1131/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce and analyze the phenomenon of \"hallucinations\" in NMT, or spurious translations unrelated to source text, and propose methods to reduce its frequency.", "pdf": "/pdf/5670d12cb8d5a89de116dbabaab9d109aeae60d6.pdf", "paperhash": "anonymous|hallucinations_in_neural_machine_translation", "_bibtex": "@inproceedings{    \nanonymous2019hallucinations,    \ntitle={Hallucinations in Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxJ-309FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1l1b205KX", "original": "HJxST2XqY7", "number": 1132, "cdate": 1538087926992, "ddate": null, "tcdate": 1538087926992, "tmdate": 1538155984528, "tddate": null, "forum": "B1l1b205KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Disentangling Structure and Appearance", "abstract": "It is challenging to disentangle an object into two orthogonal spaces of structure and appearance since each can influence the visual observation in a different and unpredictable way. It is rare for one to have access to a large number of data to help separate the influences. In this paper, we present a novel framework to learn this disentangled representation in a completely unsupervised manner. We address this problem in a two-branch Variational Autoencoder framework. For the structure branch, we project the latent factor into a soft structured point tensor and constrain it with losses derived from prior knowledge. This encourages the branch to distill geometry information. Another branch learns the complementary appearance information. The two branches form an effective framework that can disentangle object's structure-appearance representation without any human annotation. We evaluate our approach on four image datasets, on which we demonstrate the superior disentanglement and visual analogy quality both in synthesis and real-world data. We are able to generate photo-realistic images with 256*256 resolution that are clearly disentangled in structure and appearance.", "keywords": ["disentangled representations", "VAE", "generative models", "unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1132/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel framework to learn the disentangled representation of structure and appearance in a completely unsupervised manner. ", "pdf": "/pdf/e4e29d156e204dca1bf7c15a20486b2687fa4fa8.pdf", "paperhash": "anonymous|unsupervised_disentangling_structure_and_appearance", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Disentangling Structure and Appearance},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l1b205KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkeyZhC9F7", "original": "rJx_Yj15KQ", "number": 1133, "cdate": 1538087927163, "ddate": null, "tcdate": 1538087927163, "tmdate": 1538155984320, "tddate": null, "forum": "HkeyZhC9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Heuristics for Automated Reasoning through Reinforcement Learning", "abstract": "We demonstrate how to learn efficient heuristics for automated reasoning algorithms through deep reinforcement learning. We focus on backtracking search algorithms for quantified Boolean logics, which already can solve formulas of impressive size - up to 100s of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For challenging problems, the heuristic learned through our approach reduces execution time by >=90% compared to the existing handwritten heuristics.", "keywords": ["reinforcement learning", "deep learning", "logics", "formal methods", "automated reasoning", "backtracking search", "satisfiability", "quantified Boolean formulas"], "authorids": ["ICLR.cc/2019/Conference/Paper1133/Authors"], "authors": ["Anonymous"], "TL;DR": "RL finds better heuristics for automated reasoning algorithms.", "pdf": "/pdf/f8c0b0d641707dab695ceaf0046e0f0c3c6c63a5.pdf", "paperhash": "anonymous|learning_heuristics_for_automated_reasoning_through_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Heuristics for Automated Reasoning through Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkeyZhC9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlJ-2CqtX", "original": "B1eHgWA5tX", "number": 1134, "cdate": 1538087927329, "ddate": null, "tcdate": 1538087927329, "tmdate": 1538155984116, "tddate": null, "forum": "rJlJ-2CqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Success at any cost: value constrained model-free continuous control", "abstract": "Applying Reinforcement Learning algorithms to continuous control problems -- such as locomotion and robot control -- often results in policies which rely on high-amplitude, high-frequency control signals, known colloquially as bang-bang control. While such policies can implement the optimal solution, particularly in simulated systems, they are often not desirable for real world systems since bang-bang control can lead to increased wear and tear and energy consumption and tends to excite undesired second-order dynamics.  To counteract this issue, multi-objective optimization can be used to simultaneously optimize both the reward and some auxiliary cost that discourages undesired (e.g. high-amplitude) control. In principle, such an approach can yield the sought after, smooth, control policies. It can, however, be hard to find the correct trade-off between cost and return that results in the desired behavior. In this paper we propose a new constraint-based approach which defines a lower bound on the return while minimizing one or more costs (such as control effort). We employ Lagrangian relaxation to learn both (a) the parameters of a control policy that satisfies the desired constraints and (b) the Lagrangian multipliers for the optimization. Moreover, we demonstrate policy optimization which satisfies constraints either in expectation or in a per-step fashion, and we learn a single conditional policy that is able to dynamically change the trade-off between return and cost. We demonstrate the efficiency of our approach using both the cart-pole swing-up task as well as a realistic, energy-optimized quadruped locomotion task.", "keywords": ["reinforcement learning", "continuous control", "robotics", "constrained optimization", "multi-objective optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1134/Authors"], "authors": ["Anonymous"], "TL;DR": "We apply constrained optimization to continuous control tasks subject to a penalty to ensure a lower bound on the return, and learn the resulting conditional Lagrangian multipliers simultaneously with the policy.", "pdf": "/pdf/cbb0a12e9a7f63ff0819ceea61cb7326661bb07f.pdf", "paperhash": "anonymous|success_at_any_cost_value_constrained_modelfree_continuous_control", "_bibtex": "@inproceedings{    \nanonymous2019success,    \ntitle={Success at any cost: value constrained model-free continuous control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlJ-2CqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgy-n0cK7", "original": "Hkgn6AhqFX", "number": 1135, "cdate": 1538087927496, "ddate": null, "tcdate": 1538087927496, "tmdate": 1538155983910, "tddate": null, "forum": "BJgy-n0cK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video", "abstract": "Models optimized for accuracy on single images are often prohibitively slow to\nrun on each frame in a video, especially on challenging dense prediction tasks,\nsuch as semantic segmentation. Recent work exploits the use of optical flow to\nwarp image features forward from select keyframes, as a means to conserve computation\non video. This approach, however, achieves only limited speedup, even\nwhen optimized, due to the accuracy degradation introduced by repeated forward\nwarping, and the inference cost of optical flow estimation. To address these problems,\nwe propose a new scheme that propagates features using the block motion\nvectors (BMV) present in compressed video (e.g. H.264 codecs), instead of optical\nflow, and bi-directionally warps and fuses features from enclosing keyframes\nto capture scene context on each video frame. Our technique, interpolation-BMV,\nenables us to accurately estimate the features of intermediate frames, while keeping\ninference costs low. We evaluate our system on the CamVid and Cityscapes\ndatasets, comparing to both a strong single-frame baseline and related work. We\nfind that we are able to substantially accelerate segmentation on video, achieving\nnear real-time frame rates (20+ frames per second) on large images (e.g. 960 x \u0002720\npixels), while maintaining competitive accuracy. This represents an improvement\nof almost 6\u0002x over the single-frame baseline and 2.5x\u0002 over the fastest prior work.", "keywords": ["semantic segmentation", "video", "efficient inference", "video segmentation", "video compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1135/Authors"], "authors": ["Anonymous"], "TL;DR": "We exploit video compression techniques (in particular, the block motion vectors in H.264 video) and feature similarity across frames to accelerate a classical image recognition task, semantic segmentation, on video.", "pdf": "/pdf/ac549c52c3095d3757bfe623cbb4f7a37e32d359.pdf", "paperhash": "anonymous|interbmv_interpolation_with_block_motion_vectors_for_fast_semantic_segmentation_on_video", "_bibtex": "@inproceedings{    \nanonymous2019inter-bmv:,    \ntitle={Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgy-n0cK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hygxb2CqKm", "original": "H1xtrh-cYm", "number": 1136, "cdate": 1538087927658, "ddate": null, "tcdate": 1538087927658, "tmdate": 1538155983696, "tddate": null, "forum": "Hygxb2CqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stable Recurrent Models", "abstract": "Stability is a fundamental property of dynamical systems, yet to this date it has had little bearing on the practice of recurrent neural networks. In this work, we conduct a thorough investigation of stable recurrent models. Theoretically, we prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent. Empirically, we demonstrate stable recurrent models often perform as well as their unstable counterparts on benchmark sequence tasks. Taken together, these findings shed light on the effective power of recurrent networks and suggest much of sequence learning happens, or can be made to happen, in the stable regime. Moreover, our results help to explain why in many cases practitioners succeed in replacing recurrent models by feed-forward models.\n", "keywords": ["stability", "gradient descent", "non-convex optimization", "recurrent neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1136/Authors"], "authors": ["Anonymous"], "TL;DR": "Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.", "pdf": "/pdf/c256e5a891fe9a4a2b998f660da98c510b640ef1.pdf", "paperhash": "anonymous|stable_recurrent_models", "_bibtex": "@inproceedings{    \nanonymous2019stable,    \ntitle={Stable Recurrent Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygxb2CqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkxgbhCqtQ", "original": "BkgsvM6cF7", "number": 1137, "cdate": 1538087927814, "ddate": null, "tcdate": 1538087927814, "tmdate": 1538155983483, "tddate": null, "forum": "BkxgbhCqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Predictive Uncertainty through Quantization", "abstract": "High-risk domains require reliable confidence estimates from predictive models. \nDeep latent variable models provide these, but suffer from the rigid variational distributions used for tractable inference, which err on the side of overconfidence.\nWe propose Stochastic Quantized Activation Distributions (SQUAD), which imposes a flexible yet tractable distribution over discretized latent variables.\nThe proposed method is scalable, self-normalizing and sample efficient. We demonstrate that the model fully utilizes the flexible distribution, learns interesting non-linearities, and provides predictive uncertainty of competitive quality.\n", "keywords": ["variational inference", "information bottleneck", "bayesian deep learning", "latent variable models", "amortized variational inference", "uncertainty", "learning non-linearities"], "authorids": ["ICLR.cc/2019/Conference/Paper1137/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel tractable and flexible variational distribution through quantization of latent variables, applied to the deep variational information bottleneck objective for improved uncertainty.", "pdf": "/pdf/40076519eac44b8b67cb5c4cddfb7b6b07a3fb11.pdf", "paperhash": "anonymous|predictive_uncertainty_through_quantization", "_bibtex": "@inproceedings{    \nanonymous2019predictive,    \ntitle={Predictive Uncertainty through Quantization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkxgbhCqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syxgbh05tQ", "original": "rkg9z-AqYm", "number": 1138, "cdate": 1538087927976, "ddate": null, "tcdate": 1538087927976, "tmdate": 1538155983271, "tddate": null, "forum": "Syxgbh05tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Lyapunov-based Safe Policy Optimization", "abstract": "In many reinforcement learning applications, it is crucial that the agent interacts with the environment only through safe policies, i.e.,~policies that do not take the agent to certain undesirable situations. These problems are often formulated as a constrained Markov decision process (CMDP) in which the agent's goal is to optimize its main objective while not violating a number of safety constraints. In this paper, we propose safe policy optimization algorithms that are based on the Lyapunov approach to CMDPs, an approach that has well-established theoretical guarantees in control engineering. We first show how to generate a set of state-dependent Lyapunov constraints from the original CMDP safety constraints. We then propose safe policy gradient algorithms that train a neural network policy using DDPG or PPO, while guaranteeing near-constraint satisfaction at every policy update by projecting either the policy parameter or the action onto the set of feasible solutions induced by the linearized Lyapunov constraints. Unlike the existing (safe) constrained PG algorithms, ours are more data efficient as they are able to utilize both on-policy and off-policy data. Furthermore, the action-projection version of our algorithms often leads to less conservative policy updates and allows for natural integration into an end-to-end PG training pipeline. We evaluate our algorithms and compare them with CPO and the Lagrangian method on several high-dimensional continuous state and action simulated robot locomotion tasks, in which the agent must satisfy certain safety constraints while minimizing its expected cumulative cost. ", "keywords": ["Reinforcement Learning", "Safe Learning", "Lyapunov Functions", "Constrained Markov Decision Problems"], "authorids": ["ICLR.cc/2019/Conference/Paper1138/Authors"], "authors": ["Anonymous"], "TL;DR": "Safe Reinforcement Learning Algorithms for Continuous Control", "pdf": "/pdf/e1b5a891dd1876cf6c8f99dc7ee5970d7ca1b65d.pdf", "paperhash": "anonymous|lyapunovbased_safe_policy_optimization", "_bibtex": "@inproceedings{    \nanonymous2019lyapunov-based,    \ntitle={Lyapunov-based Safe Policy Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syxgbh05tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxeWnCcF7", "original": "SJlrSiN9KQ", "number": 1139, "cdate": 1538087928159, "ddate": null, "tcdate": 1538087928159, "tmdate": 1538155983063, "tddate": null, "forum": "HJxeWnCcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Mixed-Curvature Representations in Product Spaces", "abstract": "The quality of the representations achieved by embeddings is determined by how well the geometry of the embedding space matches the structure of the data. Euclidean space has been the workhorse space for embeddings; recently hyperbolic and spherical spaces are gaining popularity due to their ability to better embed new types of structured data---such as hierarchical data---but most data is not structured so uniformly. We address this problem by proposing embedding into a product manifold combining multiple copies of spherical, hyperbolic, and Euclidean spaces, providing a space of heterogeneous curvature suitable for a wide variety of structures. We introduce a heuristic to estimate the sectional curvature of graph data and directly determine the signature---the number of component spaces and their dimensions---of the product manifold. Empirically, we jointly learn the curvature and the embedding in the product space via Riemannian optimization. We discuss how to define and compute intrinsic quantities such as means---a challenging notion for product manifolds---and provably learnable optimization functions. On a range of datasets and reconstruction tasks, our product space embeddings outperform single Euclidean or hyperbolic spaces used in previous works, reducing distortion by 32.55% on a Facebook social network dataset. We learn word embeddings and find that a product of hyperbolic spaces in 50 dimensions consistently improves on baseline Euclidean and hyperbolic embeddings by 2.6 points in Spearman rank correlation on similarity tasks and 3.4 points on analogy accuracy.", "keywords": ["embeddings", "non-Euclidean geometry", "manifolds", "geometry of data"], "authorids": ["ICLR.cc/2019/Conference/Paper1139/Authors"], "authors": ["Anonymous"], "TL;DR": "Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.", "pdf": "/pdf/853036bd64b6cd560e7e8208344589531b7f4227.pdf", "paperhash": "anonymous|learning_mixedcurvature_representations_in_product_spaces", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Mixed-Curvature Representations in Product Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxeWnCcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJfxbhR9KQ", "original": "HkxDoqa5YQ", "number": 1140, "cdate": 1538087928331, "ddate": null, "tcdate": 1538087928331, "tmdate": 1538155982850, "tddate": null, "forum": "HJfxbhR9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mimicking actions is a good strategy for beginners: Fast Reinforcement Learning with Expert Action Sequences", "abstract": "Imitation Learning is the task of mimicking the behavior of an expert player in a Reinforcement Learning(RL) Environment to enhance the training of a fresh agent (called novice) beginning from scratch. Most of the Reinforcement Learning environments are stochastic in nature, i.e., the state sequences that an agent may encounter usually follow a Markov Decision Process (MDP). This makes the task of mimicking difficult as it is very unlikely that a new agent may encounter same or similar state sequences as an expert. Prior research in Imitation Learning proposes various ways to learn a mapping between the states encountered and the respective actions taken by the expert while mostly being agnostic to the order in which these were performed. Most of these methods need considerable number of states-action pairs to achieve good results. We propose a simple alternative to Imitation Learning by appending the novice\u2019s action space with the frequent short action sequences that the expert has taken. This simple modification, surprisingly improves the exploration and significantly outperforms alternative approaches like Dataset Aggregation. We experiment with several popular Atari games and show significant and consistent growth in the score that the new agents achieve using just a few expert action sequences.", "keywords": ["Reinforcement Learning", "Imitation Learning", "Atari", "A3C", "GA3C"], "authorids": ["ICLR.cc/2019/Conference/Paper1140/Authors"], "authors": ["Anonymous"], "TL;DR": "Appending most frequent action pairs from an expert player to a novice RL agent's action space improves the scores by huge margin.", "pdf": "/pdf/260f1cb5afb61580445e2a9bf67a7c2b62782857.pdf", "paperhash": "anonymous|mimicking_actions_is_a_good_strategy_for_beginners_fast_reinforcement_learning_with_expert_action_sequences", "_bibtex": "@inproceedings{    \nanonymous2019mimicking,    \ntitle={Mimicking actions is a good strategy for beginners: Fast Reinforcement Learning with Expert Action Sequences},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJfxbhR9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJggZnRcFQ", "original": "B1eVpJO9YQ", "number": 1141, "cdate": 1538087928499, "ddate": null, "tcdate": 1538087928499, "tmdate": 1538155982640, "tddate": null, "forum": "SJggZnRcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Programmatically Structured Representations with Perceptor Gradients", "abstract": "We present the perceptor gradients algorithm -- a novel approach to learning symbolic representations based on the idea of decomposing an agent's policy into i) a perceptor network extracting symbols from raw observation data and ii) a task encoding program which maps the input symbols to output actions. We show that the proposed algorithm is able to learn representations that can be directly fed into a Linear-Quadratic Regulator (LQR) or a general purpose A* planner. Our experimental results confirm that the perceptor gradients algorithm is able to efficiently learn transferable symbolic representations as well as generate new observations according to a semantically meaningful specification.\n", "keywords": ["representation learning", "structured representations", "symbols", "programs"], "authorids": ["ICLR.cc/2019/Conference/Paper1141/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/fcc826dc1c1edbfe6c8fda6813cb5854b9428e1e.pdf", "paperhash": "anonymous|learning_programmatically_structured_representations_with_perceptor_gradients", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Programmatically Structured Representations with Perceptor Gradients},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJggZnRcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1eWW2RqFX", "original": "r1gC5b09Fm", "number": 1142, "cdate": 1538087928663, "ddate": null, "tcdate": 1538087928663, "tmdate": 1538155982428, "tddate": null, "forum": "r1eWW2RqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention", "abstract": "A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry. However, these surface-centric properties also pose challenges on designing tools to recognize and synthesize point clouds. This work presents a novel autoregressive model, PointGrow, which generates realistic point cloud samples from scratch or conditioned from given semantic contexts. Our model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points. Since point cloud object shapes are typically encoded by long-range interpoint dependencies, we augment our model with dedicated self-attention modules to capture these relations. Extensive evaluation demonstrates that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to fidelity, diversity and semantic preservation. Further, conditional PointGrow learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside.", "keywords": ["point cloud generation", "autoregressive models", "self-attention"], "authorids": ["ICLR.cc/2019/Conference/Paper1142/Authors"], "authors": ["Anonymous"], "TL;DR": "An autoregressive deep learning model for generating diverse point clouds.", "pdf": "/pdf/462e50728f340bfda0a678c6c987050199c82f4e.pdf", "paperhash": "anonymous|pointgrow_autoregressively_learned_point_cloud_generation_with_selfattention", "_bibtex": "@inproceedings{    \nanonymous2019pointgrow:,    \ntitle={PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eWW2RqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylbWhC5Ym", "original": "SJg2EHictm", "number": 1143, "cdate": 1538087928838, "ddate": null, "tcdate": 1538087928838, "tmdate": 1538155982220, "tddate": null, "forum": "rylbWhC5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "HR-TD: A Regularized TD Method to Avoid Over-Generalization", "abstract": "Temporal Difference learning with function approximation has been widely used recently and has led to several successful results.  However, compared with the original tabular-based methods, one major drawback of temporal difference learning with neural networks and other function approximators is that they tend to over-generalize across temporally successive states, resulting in slow convergence and even instability. In this work, we propose a novel TD learning method, Hadamard product Regularized TD (HR-TD), that reduces over-generalization and thus leads to faster convergence. This approach can be easily applied to both linear and nonlinear function approximators. \nHR-TD is evaluated on several linear and nonlinear benchmark domains, where we show improvement in learning behavior and performance.", "keywords": ["Reinforcement Learning", "TD Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1143/Authors"], "authors": ["Anonymous"], "TL;DR": "A regularization technique for TD learning that avoids temporal over-generalization, especially in Deep Networks", "pdf": "/pdf/7c8f69e154640f8fa0e114300691784da51551aa.pdf", "paperhash": "anonymous|hrtd_a_regularized_td_method_to_avoid_overgeneralization", "_bibtex": "@inproceedings{    \nanonymous2019hr-td:,    \ntitle={HR-TD: A Regularized TD Method to Avoid Over-Generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylbWhC5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkGb-3C5t7", "original": "r1lGgStcFm", "number": 1144, "cdate": 1538087929006, "ddate": null, "tcdate": 1538087929006, "tmdate": 1538155982010, "tddate": null, "forum": "HkGb-3C5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "IMPROVING ADVERSARIAL DISCRIMINATIVE DOMAIN ADAPTATION", "abstract": "Adversarial discriminative domain adaptation (ADDA) is an efficient framework for unsupervised domain adaptation, where the source and target domains are assumed to have the same classes, but no labels are available for the target domain. While ADDA has already achieved better training efficiency and competitive accuracy in comparison to other adversarial based methods, we investigate whether we can improve performance by incorporating task knowledge into the adversarial loss functions. We achieve this by extending the discriminator output over the source classes and leverage on the distribution over the source encoder posteriors, which is fixed during adversarial training, in order to align a shared encoder distribution to the source domain. The shared encoder receives a proportion of examples from both the source and target datasets, in order to smooth the learned distribution and improve its convergence properties during adversarial training. We additionally consider how the extended discriminator can be regularized in order to further improve performance, by treating the discriminator as a denoising autoencoder and corrupting its input. Our final design employs maximum mean discrepancy and reconstruction-based loss functions for adversarial training. We validate our framework on standard datasets like MNIST, USPS, SVHN, MNISTM and Office-31. Our results on all datasets show that our proposal is both simple and efficient, as it competes or outperforms the state-of-the-art in unsupervised domain adaptation, whilst offering lower complexity than other recent adversarial methods such as DIFA and CoGAN.", "keywords": ["domain adaptation", "unsupervised learning", "adversarial methods"], "authorids": ["ICLR.cc/2019/Conference/Paper1144/Authors"], "authors": ["Anonymous"], "TL;DR": "We improve the performance of ADDA by incorporating task knowledge into the adversarial loss functions and treating the discriminator as a denoising autoencoder.", "pdf": "/pdf/ea22bd3a19a32ff4fee174b6239e40fa71b8882d.pdf", "paperhash": "anonymous|improving_adversarial_discriminative_domain_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={IMPROVING ADVERSARIAL DISCRIMINATIVE DOMAIN ADAPTATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGb-3C5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gWWh05Y7", "original": "SyxAOwa9KQ", "number": 1145, "cdate": 1538087929185, "ddate": null, "tcdate": 1538087929185, "tmdate": 1538155981798, "tddate": null, "forum": "B1gWWh05Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploration in Policy Mirror Descent", "abstract": "Policy optimization is a core problem in reinforcement learning. In this paper, we investigate Reversed Entropy Policy Mirror Descent (REPMD), an on-line policy optimization strategy that improves exploration behavior while assuring monotonic progress in a principled objective. REPMD conducts a form of maximum entropy exploration within a mirror descent framework, but uses an alternative policy update with a reversed KL projection. This modified formulation bypasses undesirable mode seeking behavior and avoids premature convergence to sub-optimal policies, while still supporting strong theoretical properties such as guaranteed policy improvement. An experimental evaluation demonstrates that this approach significantly improves practical exploration and surpasses the empirical performance of state-of-the art policy optimization methods in a set of benchmark tasks.", "keywords": ["Reinforcement Learning", "Exploration", "Policy Optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1145/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ec568121b7663f6ad015f33c0be2cea2562db6bc.pdf", "paperhash": "anonymous|exploration_in_policy_mirror_descent", "_bibtex": "@inproceedings{    \nanonymous2019exploration,    \ntitle={Exploration in Policy Mirror Descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gWWh05Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl-b3RcF7", "original": "rklNr_YqKX", "number": 1146, "cdate": 1538087929352, "ddate": null, "tcdate": 1538087929352, "tmdate": 1538155981592, "tddate": null, "forum": "rJl-b3RcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks", "abstract": "Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance.\n\nWe find that a standard technique for pruning weights naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the \"lottery ticket hypothesis:\" unpruned, randomly-initialized feed-forward networks contain subnetworks (\"winning tickets\") that---when trained in isolation---converge in a comparable number of iterations to comparable generalization accuracy. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective.\n\nWe present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations.  We consistently find winning tickets that are less than 10\\% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Furthermore, the winning tickets we find above that size converge faster than the original network and exhibit higher test accuracy.", "keywords": ["Neural networks", "sparsity", "pruning", "compression", "performance", "architecture search"], "authorids": ["ICLR.cc/2019/Conference/Paper1146/Authors"], "authors": ["Anonymous"], "TL;DR": "Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training", "pdf": "/pdf/c6e3b4bf4713f581b29e70a2f81e1bce35da86f6.pdf", "paperhash": "anonymous|the_lottery_ticket_hypothesis_finding_sparse_trainable_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl-b3RcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyMWn05F7", "original": "r1era9T5F7", "number": 1147, "cdate": 1538087929517, "ddate": null, "tcdate": 1538087929517, "tmdate": 1538155981378, "tddate": null, "forum": "SyMWn05F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Exploration Policies for Navigation", "abstract": "Numerous past works have tackled the problem of task-driven navigation. But, how to effectively explore a new environment to enable a variety of down-stream tasks has received much less attention. In this work, we study how agents can autonomously explore realistic and complex 3D environments without the context of task-rewards. We propose a learning-based approach and investigate different policy architectures, reward functions, and training paradigms. We find that use of policies with spatial memory that are bootstrapped with imitation learning and finally finetuned with coverage rewards derived purely from on-board sensors can be effective at exploring novel environments. We show that our learned exploration policies can explore better than classical approaches based on geometry alone and generic learning-based exploration techniques. Finally, we also show how such task-agnostic exploration can be used for down-stream tasks. Videos are available at https://sites.google.com/view/exploration-for-nav/.", "keywords": ["Exploration", "navigation", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1147/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ece554567e11c4d86e1c0821dfaa8f0167c6303d.pdf", "paperhash": "anonymous|learning_exploration_policies_for_navigation", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Exploration Policies for Navigation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyMWn05F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxMWh09KX", "original": "r1gYibA5YQ", "number": 1148, "cdate": 1538087929686, "ddate": null, "tcdate": 1538087929686, "tmdate": 1538155981167, "tddate": null, "forum": "SyxMWh09KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification", "abstract": "Current deep learning based text classification methods are limited by their ability to achieve fast learning and generalization when the data is scarce. We address this problem by integrating a meta-learning procedure that uses the knowledge learned across many tasks as an inductive bias towards better natural language understanding. Inspired by the Model-Agnostic Meta-Learning framework (MAML), we introduce the Attentive Task-Agnostic Meta-Learning (ATAML) algorithm for text classification. The proposed ATAML is designed to encourage task-agnostic representation learning by way of task-agnostic parameterization and facilitate task-specific adaptation via attention mechanisms. We provide evidence to show that the attention mechanism in ATAML has a synergistic effect on learning performance. Our experimental results reveal that, for few-shot text classification tasks, gradient-based meta-learning approaches ourperform popular transfer learning methods. In comparisons with models trained from random initialization, pretrained models and meta trained MAML, our proposed ATAML method generalizes better on single-label and multi-label classification tasks in miniRCV1 and miniReuters-21578 datasets.", "keywords": ["meta-learning", "learning to learn", "few-shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1148/Authors"], "authors": ["Anonymous"], "TL;DR": "Meta-learning task-agnostic representations with attention.", "pdf": "/pdf/b2e1422643e66521ec17675ea6c013fc7d58c0c0.pdf", "paperhash": "anonymous|attentive_taskagnostic_metalearning_for_fewshot_text_classification", "_bibtex": "@inproceedings{    \nanonymous2019attentive,    \ntitle={Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxMWh09KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJWfW2C9Y7", "original": "HJxVTDqYtm", "number": 1149, "cdate": 1538087929850, "ddate": null, "tcdate": 1538087929850, "tmdate": 1538155980962, "tddate": null, "forum": "BJWfW2C9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Predictive Local Smoothness for Stochastic Gradient Methods", "abstract": "Stochastic gradient methods are dominant in nonconvex optimization especially for deep models but have low asymptotical convergence due to the fixed smoothness. To address this problem, we propose a simple yet effective method for improving stochastic gradient methods named predictive local smoothness (PLS). First, we create a convergence condition to build a learning rate varied adaptively with local smoothness. Second, the local smoothness can be predicted by the latest gradients. Third, we use the adaptive learning rate to update the stochastic gradients for exploring linear convergence rates. By applying the PLS method, we implement new variants of three popular algorithms: PLS-stochastic gradient descent (PLS-SGD), PLS-accelerated SGD (PLS-AccSGD), and PLS-AMSGrad. Moreover, we provide much simpler proofs to ensure their linear convergence. Empirical results show that our variants have better performance gains than the popular algorithms, such as, faster convergence and alleviating explosion and vanish of gradients.", "keywords": ["stochastic gradient method", "local smoothness", "linear system", "AMSGrad"], "authorids": ["ICLR.cc/2019/Conference/Paper1149/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ddb07bb24b7bf0524af557f7195870382d60e310.pdf", "paperhash": "anonymous|predictive_local_smoothness_for_stochastic_gradient_methods", "_bibtex": "@inproceedings{    \nanonymous2019predictive,    \ntitle={Predictive Local Smoothness for Stochastic Gradient Methods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJWfW2C9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkfMWhAqYQ", "original": "HkgToZ05Ym", "number": 1150, "cdate": 1538087930011, "ddate": null, "tcdate": 1538087930011, "tmdate": 1538155980756, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x32 px features and Alexnet performance for 16 x 16 px features). The constraint on local features makes it straight-forward to analyse how exactly each feature of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts, suggesting that modern DNNs approximately follow a similar bag-of-feature strategy.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "authors": ["Anonymous"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/4d4950f80a0ef84e60db6e69dc64e020b3d0bda8.pdf", "paperhash": "anonymous|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{    \nanonymous2019approximating,    \ntitle={Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkfMWhAqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkgfWh0qKX", "original": "r1xoJSWcY7", "number": 1151, "cdate": 1538087930189, "ddate": null, "tcdate": 1538087930189, "tmdate": 1538155980541, "tddate": null, "forum": "rkgfWh0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Do Language Models Have Common Sense?", "abstract": "It has been argued that current machine learning models do not have commonsense, and therefore must be hard-coded with prior knowledge (Marcus, 2018). Here we show surprising evidence that language models can already learn to capture certain common sense knowledge. Our key observation is that a language model can compute the probability of any statement, and this probability can be used to evaluate the truthfulness of that statement.  On the Winograd Schema Challenge (Levesque et al., 2011), language models are 11% higher in accuracy than previous state-of-the-art supervised methods. Language models can also be fine-tuned for the task of Mining Commonsense Knowledge on ConceptNet to achieve an F1 score of 0.912 and 0.824, outperforming previous best results (Jastrzebskiet al., 2018).  Further analysis demonstrates that language models can discover unique features of Winograd Schema contexts that decide the correct answers without explicit supervision.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1151/Authors"], "authors": ["Anonymous"], "TL;DR": "We present evidence that LMs do capture common sense with state-of-the-art results on both Winograd Schema Challenge and Commonsense Knowledge Mining.", "pdf": "/pdf/66733cd0185bdc64077133178135d382c35f8ae2.pdf", "paperhash": "anonymous|do_language_models_have_common_sense", "_bibtex": "@inproceedings{    \nanonymous2019do,    \ntitle={Do Language Models Have Common Sense?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgfWh0qKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lz-3Rct7", "original": "S1lVbDa9Y7", "number": 1152, "cdate": 1538087930358, "ddate": null, "tcdate": 1538087930358, "tmdate": 1538155980331, "tddate": null, "forum": "B1lz-3Rct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Three Mechanisms of Weight Decay Regularization", "abstract": "Weight decay is one of the standard tricks in the neural network toolbox, but the reasons for its regularization effect are poorly understood, and recent results have cast doubt on the traditional interpretation in terms of L2 regularization. Literal weight decay has been shown to outperform L2 regularization for optimizers for which they differ.  We empirically investigate weight decay for three optimization algorithms (SGD, Adam, and KFAC) and a variety of network architectures. We identify three distinct mechanisms by which weight decay exerts a regularization effect, depending on the particular optimization algorithm and architecture: (1) increasing the effective learning rate, (2) regularizing approximated input-output Jacobian norm, and (3) reducing the effective damping coefficient for second-order optimization. Our results provide insight into how to improve the regularization of neural networks.", "keywords": ["Generalization", "Regularization", "Optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1152/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate weight decay regularization for different optimizers and identify three distinct mechanisms by which weight decay improves generalization.", "pdf": "/pdf/7d20958ff96fb67d0bb69e3ef41caae5deebf255.pdf", "paperhash": "anonymous|three_mechanisms_of_weight_decay_regularization", "_bibtex": "@inproceedings{    \nanonymous2019three,    \ntitle={Three Mechanisms of Weight Decay Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lz-3Rct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxQ-nA9FX", "original": "H1eaMjpqYQ", "number": 1153, "cdate": 1538087930522, "ddate": null, "tcdate": 1538087930522, "tmdate": 1538155980131, "tddate": null, "forum": "rkxQ-nA9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Theoretical Analysis of Auto Rate-Tuning by Batch Normalization", "abstract": "Batch Normalization (BN) has become a cornerstone of deep learning across diverse architectures, appearing to help optimization as well as generalization. While the idea makes intuitive sense, theoretical analysis of its effectiveness has been lacking. Here theoretical support is provided for one of its conjectured properties, namely, the ability to allow gradient descent to succeed with less tuning of learning rates. It is shown that even if we fix the learning rate of scale-invariant parameters (e.g., weights of each layer with BN) to a constant (say, 0.3), gradient descent still approaches a stationary point (i.e., a solution where gradient is zero) in the rate of T^{\u22121/2} in T iterations, asymptotically matching the best bound for gradient descent with well-tuned learning rates. A similar result with convergence rate T^{\u22121/4} is also shown for stochastic gradient descent.", "keywords": ["batch normalization", "scale invariance", "learning rate", "stationary point"], "authorids": ["ICLR.cc/2019/Conference/Paper1153/Authors"], "authors": ["Anonymous"], "TL;DR": "We give a theoretical analysis of the ability of batch normalization to automatically tune learning rates, in the context of finding stationary points for a deep learning objective.", "pdf": "/pdf/49b97f2150e7a169e44117319034e589e2fb06aa.pdf", "paperhash": "anonymous|theoretical_analysis_of_auto_ratetuning_by_batch_normalization", "_bibtex": "@inproceedings{    \nanonymous2019theoretical,    \ntitle={Theoretical Analysis of Auto Rate-Tuning by Batch Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxQ-nA9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eX-nA5KX", "original": "ByxIugT9F7", "number": 1154, "cdate": 1538087930686, "ddate": null, "tcdate": 1538087930686, "tmdate": 1538155979918, "tddate": null, "forum": "S1eX-nA5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "VHEGAN: Variational Hetero-Encoder Randomized GAN for Zero-Short Learning", "abstract": "To extract and relate visual and linguistic concepts from images and textual descriptions for text-based zero-shot learning (ZSL), we develop variational hetero-encoder (VHE) that decodes text via a deep probabilisitic topic model, the variational posterior of whose local latent variables is encoded from an image via a Weibull distribution based inference network. To further improve VHE and add an image generator, we propose VHE randomized generative adversarial net (VHEGAN) that exploits the synergy between VHE and GAN through their shared latent space. After training with a hybrid stochastic-gradient MCMC/variational inference/stochastic gradient descent inference algorithm, VHEGAN can be used in a variety of settings, such as text generation/retrieval conditioning on an image, image generation/retrieval conditioning on a document/image, and generation of text-image pairs. The efficacy of VHEGAN is demonstrated quantitatively with experiments on both conventional and generalized ZSL tasks, and qualitatively on (conditional) image and/or text generation/retrieval.", "keywords": ["Deep generative models", "deep topic modeling", "generative adversarial learning", "variational encoder", "zero-short learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1154/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/288b8ddfaa1d57e7a1159641af52b8b83c186c33.pdf", "paperhash": "anonymous|vhegan_variational_heteroencoder_randomized_gan_for_zeroshort_learning", "_bibtex": "@inproceedings{    \nanonymous2019vhegan:,    \ntitle={VHEGAN: Variational Hetero-Encoder Randomized GAN for Zero-Short Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eX-nA5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeX-nC9YQ", "original": "SyeljTpcKX", "number": 1155, "cdate": 1538087930846, "ddate": null, "tcdate": 1538087930846, "tmdate": 1538155979711, "tddate": null, "forum": "ryeX-nC9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dimension-Free Bounds for Low-Precision Training", "abstract": "Low-precision training is a promising way of decreasing the time and energy cost of training machine learning models.\nPrevious work has analyzed low-precision training algorithms, such as low-precision stochastic gradient descent, and derived theoretical bounds on their convergence rates.\nThese bounds tend to depend on the dimension of the model $d$ in that the number of bits needed to achieve a particular error bound increases as $d$ increases.\nThis is undesirable because a motivating application for low-precision training is large-scale models, such as deep learning, where $d$ can be huge.\nIn this paper, we prove dimension-independent bounds for low-precision training algorithms that use fixed-point arithmetic, which lets us better understand what affects the convergence of these algorithms as parameters scale.\nOur methods also generalize naturally to let us prove new convergence bounds on low-precision training with other quantization schemes, such as low-precision floating-point computation and logarithmic quantization.", "keywords": ["low precision", "stochastic gradient descent"], "authorids": ["ICLR.cc/2019/Conference/Paper1155/Authors"], "authors": ["Anonymous"], "TL;DR": "we proved dimension-independent bounds for low-precision training algorithms", "pdf": "/pdf/dbad092cf35d187ba7689a7a36a2d85ed6ebdc2d.pdf", "paperhash": "anonymous|dimensionfree_bounds_for_lowprecision_training", "_bibtex": "@inproceedings{    \nanonymous2019dimension-free,    \ntitle={Dimension-Free Bounds for Low-Precision Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeX-nC9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkeX-3Rqtm", "original": "HJx82b05Km", "number": 1156, "cdate": 1538087931009, "ddate": null, "tcdate": 1538087931009, "tmdate": 1538155979501, "tddate": null, "forum": "rkeX-3Rqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Training Hard-Threshold Networks with Combinatorial Search in a Discrete Target Propagation Setting", "abstract": "Learning deep neural networks with hard-threshold activation has recently become an important problem due to the proliferation of resource-constrained computing devices. In order to circumvent the inability to train with backpropagation in the present of hard-threshold activations, \\cite{friesen2017} introduced a discrete target propagation framework for training hard-threshold networks in a layer-by-layer fashion. Rather than using a gradient-based target heuristic, we explore the use of search methods for solving the target setting problem. Building on both traditional combinatorial optimization algorithms and gradient-based techniques, we develop a novel search algorithm Guided Random Local Search (GRLS). We demonstrate the effectiveness of our algorithm in training small networks on several datasets and evaluate our target-setting algorithm compared to simpler search methods and gradient-based techniques. Our results indicate that combinatorial optimization is a viable method for training hard-threshold networks that may have the potential to eventually surpass gradient-based methods in many settings. ", "keywords": ["hard-threshold network", "combinatorial optimization", "search", "target propagation"], "authorids": ["ICLR.cc/2019/Conference/Paper1156/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/79de3bbc5cbd1165f3632d65918edc0e158681fa.pdf", "paperhash": "anonymous|training_hardthreshold_networks_with_combinatorial_search_in_a_discrete_target_propagation_setting", "_bibtex": "@inproceedings{    \nanonymous2019training,    \ntitle={Training Hard-Threshold Networks with Combinatorial Search in a Discrete Target Propagation Setting},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeX-3Rqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1eXbn05t7", "original": "SyeZ2x39tm", "number": 1157, "cdate": 1538087931171, "ddate": null, "tcdate": 1538087931171, "tmdate": 1538155979294, "tddate": null, "forum": "B1eXbn05t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Open-Ended Content-Style Recombination Via Leakage Filtering", "abstract": "We consider visual domains in which a class label specifies the content of an image, and class-irrelevant properties that differentiate instances constitute the style.  We present a domain-independent method that permits the open-ended recombination of style of one image with the content of another. Open ended simply means that the method generalizes to style and content not present in the training data. The method starts by constructing a content embedding using an existing deep metric-learning technique. This trained content encoder is incorporated into a variational autoencoder (VAE), paired with a to-be-trained style encoder. The VAE reconstruction loss alone is inadequate to ensure a decomposition of the latent representation into style and content. Our method thus includes an auxiliary loss, leakage filtering, which ensures that no style information remaining in the content representation is used for reconstruction and vice versa. We synthesize novel images by decoding the style representation obtained from one image with the content representation from another. Using this method for data-set augmentation, we obtain state-of-the-art performance on few-shot learning tasks.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1157/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cd65307b830c64e683a59dfbcefb64b7eaee98db.pdf", "paperhash": "anonymous|openended_contentstyle_recombination_via_leakage_filtering", "_bibtex": "@inproceedings{    \nanonymous2019open-ended,    \ntitle={Open-Ended Content-Style Recombination Via Leakage Filtering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eXbn05t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeQbnA5tm", "original": "HylfABpcY7", "number": 1158, "cdate": 1538087931335, "ddate": null, "tcdate": 1538087931335, "tmdate": 1538155979086, "tddate": null, "forum": "HJeQbnA5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Noisy Information Bottlenecks for Generalization", "abstract": "We propose Noisy Information Bottlenecks (NIB) to limit mutual information between learned parameters and the data through noise. We show why this benefits generalization and allows mitigation of model overfitting both for supervised and unsupervised learning, even for arbitrarily complex architectures. We reinterpret methods including the Variational Autoencoder, beta-VAE, network weight uncertainty and a variant of dropout combined with weight decay as special cases of our approach, explaining and quantifying regularizing properties and vulnerabilities within information theory.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1158/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/dc27771dff37a33481399992b77f1a04b654bb0d.pdf", "paperhash": "anonymous|noisy_information_bottlenecks_for_generalization", "_bibtex": "@inproceedings{    \nanonymous2019noisy,    \ntitle={Noisy Information Bottlenecks for Generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeQbnA5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1l7bnR5Ym", "original": "rklDf85cKQ", "number": 1159, "cdate": 1538087931499, "ddate": null, "tcdate": 1538087931499, "tmdate": 1538155978876, "tddate": null, "forum": "H1l7bnR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bayesian Modelling and Monte Carlo Inference for GAN", "abstract": "Bayesian modelling is a principal framework to perform model aggregation, which has been a primary mechanism to combat mode collapsing in the context of Generative Adversarial Networks (GANs). In this paper, we propose a novel Bayesian modelling framework for GANs, which iteratively learns a distribution over generators with a carefully crafted prior.  Learning is efficiently triggered by a tailored stochastic gradient Hamiltonian Monte Carlo with novel gradient approximation to perform Bayesian inference. Our theoretical analysis further reveals that our treatment is the first Bayesian modelling framework that yields an equilibrium where generator distributions are faithful to the data distribution. Empirical evidence on synthetic high-dimensional multi-modal data and the natural image database CIFAR-10 demonstrates the superiority of our method over both start-of-the-art multi-generator GANs and other Bayesian treatment for GANs.", "keywords": ["Generative Adversarial Networks", "Bayesian Deep Learning", "Mode Collapse", "Inception Score", "Generator", "Discriminator", "CIFAR-10"], "authorids": ["ICLR.cc/2019/Conference/Paper1159/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel Bayesian treatment for GAN with theoretical guarantee.", "pdf": "/pdf/9fd8eac65456798ca5a6436dd58486f6b93cc2fc.pdf", "paperhash": "anonymous|bayesian_modelling_and_monte_carlo_inference_for_gan", "_bibtex": "@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Modelling and Monte Carlo Inference for GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1l7bnR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hkg4W2AcFm", "original": "SylwzBnqFm", "number": 1160, "cdate": 1538087931666, "ddate": null, "tcdate": 1538087931666, "tmdate": 1538155978661, "tddate": null, "forum": "Hkg4W2AcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Overcoming the Disentanglement vs Reconstruction Trade-off via Jacobian Supervision", "abstract": "Learning image representations where the factors of variation are disentangled\nis typically achieved with an encoder-decoder architecture where a subset of the\nlatent variables is constrained to correspond to specific factors, and the rest\nof them are considered nuisance variables. This widely used approach has an\nimportant drawback: as the dimension of the nuisance variables is increased,\nbetter image reconstruction is achieved, but the decoder has the flexibility to\nignore the specified factors, thus losing the ability to condition the output on\nthose factors.\nIn this work, we propose to overcome this trade-off by progressively growing the\ndimension of the latent code, while constraining the Jacobian of the output\nimage with respect to the disentangled variables to remain the same.  As a\nresult, the obtained models are effective at both disentangling and reconstruction.\nWe demonstrate the aplicability of this method in both unsupervised and\nsupervised scenarios for learning disentangled representations. In a facial\nattribute manipulation task, we obtain high quality image generation while\nsmoothly controlling dozens of attributes with a single model. This is an order\nof magnitude more disentangled factors than state-of-the-art methods, while\nobtaining visually similar or superior results, and avoiding adversarial\ntraining", "keywords": ["disentangling", "autoencoders", "jacobian", "face manipulation"], "authorids": ["ICLR.cc/2019/Conference/Paper1160/Authors"], "authors": ["Anonymous"], "TL;DR": "A method to learn image representations that are good at both disentangling factors of variation and obtaining faithful reconstructions.", "pdf": "/pdf/597486417d482cde34c9e1b6fdfdface1a300cf8.pdf", "paperhash": "anonymous|overcoming_the_disentanglement_vs_reconstruction_tradeoff_via_jacobian_supervision", "_bibtex": "@inproceedings{    \nanonymous2019overcoming,    \ntitle={Overcoming the Disentanglement vs Reconstruction Trade-off via Jacobian Supervision},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkg4W2AcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xNb2A9YX", "original": "HJgDw6icFQ", "number": 1161, "cdate": 1538087931828, "ddate": null, "tcdate": 1538087931828, "tmdate": 1538155978459, "tddate": null, "forum": "S1xNb2A9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images", "abstract": "The human ability to recognize objects is impaired when the object is not shown in full. \"Minimal images\" are the smallest regions of an image that remain recognizable for humans. Ullman et al. (2016) show that a slight modification of the location and size of the visible region of the minimal image produces a sharp drop in human recognition accuracy. In this paper, we demonstrate that such drops in accuracy due to changes of the visible region are a common phenomenon between humans and existing state-of-the-art deep neural networks (DNNs), and are much more prominent in DNNs. We found many cases where DNNs classified one region correctly and the other incorrectly, though they only differed by one row or column of pixels, and were often bigger than the average human minimal image size. We show that this phenomenon is independent from previous works that have reported lack of invariance to minor modifications in object location in DNNs. Our results thus reveal a new failure mode of DNNs that also affects humans to a much lesser degree. They expose how fragile DNN recognition ability is in natural images even without adversarial patterns being introduced. Bringing the robustness of DNNs in natural images to the human level remains an open challenge for the community. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1161/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/20cb85d674f05301452d5fc91519668b7c85c51d.pdf", "paperhash": "anonymous|minimal_images_in_deep_neural_networks_fragile_object_recognition_in_natural_images", "_bibtex": "@inproceedings{    \nanonymous2019minimal,    \ntitle={Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xNb2A9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylV-2C9KQ", "original": "H1xCn-AcFm", "number": 1162, "cdate": 1538087931988, "ddate": null, "tcdate": 1538087931988, "tmdate": 1538155978242, "tddate": null, "forum": "rylV-2C9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks", "abstract": "Deep neural networks, in particular convolutional neural networks, have become highly effective tools for compressing images and solving inverse problems including denoising, inpainting, and reconstruction from few and noisy measurements. \nThis success can be attributed in part to their ability to represent and generate natural images well. \nContrary to classical tools such as wavelets, image-generating deep neural networks have a large number of parameters---typically a multiple of their output dimension---and need to be trained on large datasets.\nIn this paper, we propose an untrained simple image model, called the deep decoder, which is a deep neural network that can generate natural images from very few parameters.  As a consequence, we demonstrate that this network enables efficient image compression and state-of-the-art performance for inverse problems like denoising. \nContrary to previous deep image generators (trained or not) the network is under-parameterized, and thus conforms with the classical perspective that an efficient model maps a low-dimensional parameter space to a high-dimensional image space. \nIn addition, the deep decoder is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel-wise linear combination of channels, ReLU nonlinearity, and channelwise normalization.  This simplicity makes the program amenable to theoretical analysis.  Notably, the deep decoder does not involve convolutional layers.", "keywords": ["natural image model", "image prior", "under-determined neural networks", "untrained network", "non-convolutional network", "denoising", "inverse problem"], "authorids": ["ICLR.cc/2019/Conference/Paper1162/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.", "pdf": "/pdf/f60c0db0cf104dde28678704f3184cde322ec5bc.pdf", "paperhash": "anonymous|deep_decoder_concise_image_representations_from_untrained_nonconvolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylV-2C9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJg4Z3RqF7", "original": "H1ekHTp5t7", "number": 1163, "cdate": 1538087932159, "ddate": null, "tcdate": 1538087932159, "tmdate": 1538155978039, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy and inaccurate measurements in an unsupervised fashion. Typically, we consider situations where there is no background knowledge on the structure of the unknown signal and where we do not have access to signal-measurement pairs, nor even unpaired signal data. We introduce a general framework, where a neural network is trained to recover plausible signals from the measurements in the data, by introducing an adversarial and a reconstruction loss. We evaluate our framework on different noise instances, and show that our approach yields comparable results to model variants trained with stronger supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1163/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/75ee3664f65092c145619b203d3188530b521492.pdf", "paperhash": "anonymous|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Adversarial Image Reconstruction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJg4Z3RqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeEWnR9F7", "original": "HygFmHfYtm", "number": 1164, "cdate": 1538087932329, "ddate": null, "tcdate": 1538087932329, "tmdate": 1538155977828, "tddate": null, "forum": "HJeEWnR9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Scaling up Deep Learning for PDE-based Models", "abstract": "Across numerous applications, forecasting relies on numerical solvers for partial differential equations (PDEs). Although the use of deep-learning techniques has been proposed, the uses have been restricted by the fact the training data are obtained using PDE solvers. Thereby, the uses were limited to domains, where the PDE solver was applicable, but no further. \n\nWe present methods for training on small domains, while applying the trained models on larger domains, with consistency constraints ensuring the solutions are physically meaningful even at the boundary of the small domains. We demonstrate the results on an air-pollution forecasting model for Dublin, Ireland.", "keywords": ["recurrent neural networks", "partial differential equation", "domain decomposition", "consistency constraints", "advection", "diffusion"], "authorids": ["ICLR.cc/2019/Conference/Paper1164/Authors"], "authors": ["Anonymous"], "TL;DR": "We present RNNs for training surrogate models of PDEs, wherein consistency constraints ensure the solutions are physically meaningful, even when the training uses much smaller domains than the trained model is applied to.", "pdf": "/pdf/8701bc2d7a61b4324c361822b5ec940be4b02706.pdf", "paperhash": "anonymous|scaling_up_deep_learning_for_pdebased_models", "_bibtex": "@inproceedings{    \nanonymous2019scaling,    \ntitle={Scaling up Deep Learning for PDE-based Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeEWnR9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyzVb3CcFX", "original": "S1lgKxsKtQ", "number": 1165, "cdate": 1538087932495, "ddate": null, "tcdate": 1538087932495, "tmdate": 1538155977617, "tddate": null, "forum": "SyzVb3CcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Time-Agnostic Prediction: Predicting Predictable Video Frames", "abstract": "Prediction is arguably one of the most basic functions of an intelligent system. In general, the problem of predicting events in the future or between two waypoints is exceedingly difficult. However, most phenomena naturally pass through relatively predictable bottlenecks---while we cannot predict the precise trajectory of a robot arm between being at rest and holding an object up, we can be certain that it must have picked the object up. To exploit this, we decouple visual prediction from a rigid notion of time. While conventional approaches predict frames at regularly spaced temporal intervals, our time-agnostic predictors (TAP) are not tied to specific times so that they may instead discover predictable \"bottleneck\" frames no matter when they occur. We evaluate our approach for future and intermediate frame prediction across three robotic manipulation tasks. Our predictions are not only of higher visual quality, but also correspond to coherent semantic subgoals in temporally extended tasks.", "keywords": ["visual prediction", "subgoal generation", "bottleneck states", "time-agnostic"], "authorids": ["ICLR.cc/2019/Conference/Paper1165/Authors"], "authors": ["Anonymous"], "TL;DR": "In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \"bottleneck state\" predictions, which are useful for planning.", "pdf": "/pdf/15a26f973927f3ea37d6c5a3fc5fefa8273389f6.pdf", "paperhash": "anonymous|timeagnostic_prediction_predicting_predictable_video_frames", "_bibtex": "@inproceedings{    \nanonymous2019time-agnostic,    \ntitle={Time-Agnostic Prediction: Predicting Predictable Video Frames},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyzVb3CcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xrb3CqtQ", "original": "BygjthpqKX", "number": 1166, "cdate": 1538087932665, "ddate": null, "tcdate": 1538087932665, "tmdate": 1538155977406, "tddate": null, "forum": "r1xrb3CqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Latent Domain Transfer: Crossing modalities with Bridging Autoencoders", "abstract": "Domain transfer is a exciting and challenging branch of machine learning because models must learn to smoothly transfer between domains, preserving local variations and capturing many aspects of variation without labels. \nHowever, most successful applications to date require the two domains to be closely related (ex. image-to-image, video-video), \nutilizing similar or shared networks to transform domain specific properties like texture, coloring, and line shapes. \nHere, we demonstrate that it is possible to transfer across modalities (ex. image-to-audio) by first abstracting the data with latent generative models and then learning transformations between latent spaces. \nWe find that a simple variational autoencoder is able to learn a shared latent space to bridge between two generative models in an unsupervised fashion, and even between different types of models (ex. variational autoencoder and a generative adversarial network). \nWe can further impose desired semantic alignment of attributes with a linear classifier in the shared latent space. \nThe proposed variation autoencoder enables preserving both locality and semantic alignment through the transfer process, as shown in the qualitative and quantitative evaluations.\nFinally, the hierarchical structure decouples the cost of training the base generative models and semantic alignments, enabling computationally efficient and data efficient retraining of personalized mapping functions. ", "keywords": ["Generative Model", "Latent Space", "Domain Transfer"], "authorids": ["ICLR.cc/2019/Conference/Paper1166/Authors"], "authors": ["Anonymous"], "TL;DR": "Conditional VAE on top of latent spaces of pre-trained generative models that enables  transfer between drastically different domains while preserving locality and semantic alignment.", "pdf": "/pdf/1a9b2b5cdf92d52d8b5e725150332340cf2d135f.pdf", "paperhash": "anonymous|latent_domain_transfer_crossing_modalities_with_bridging_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019latent,    \ntitle={Latent Domain Transfer: Crossing modalities with Bridging Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xrb3CqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylBZ305KQ", "original": "rJx8nCp9Y7", "number": 1167, "cdate": 1538087932829, "ddate": null, "tcdate": 1538087932829, "tmdate": 1538155977195, "tddate": null, "forum": "rylBZ305KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dynamic Recurrent Language Model", "abstract": "Language evolves over time with trends and shifts in technological, political, or cultural contexts. Capturing these variations is important to develop better language models. While recent works tackle temporal drifts by learning diachronic embeddings, we instead propose to integrate a temporal component into a recurrent language model. It takes the form of global latent variables, which are structured in time by a learned non-linear transition function. We perform experiments on three time annotated corpora. Experimental results on language modeling and classification tasks show that our model performs consistently better than temporal word embedding methods in two temporal evaluation settings: prediction and modeling. Moreover, we empirically show that the system is able to predict informative latent states in the future.", "keywords": ["language modeling", "variational inference", "dynamic model", "temporal data", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1167/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4c1d76e7b19b1ddaa81d859cb8b0120a2622ccab.pdf", "paperhash": "anonymous|dynamic_recurrent_language_model", "_bibtex": "@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Recurrent Language Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylBZ305KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygBZnRctX", "original": "BklG1p6cKQ", "number": 1168, "cdate": 1538087932989, "ddate": null, "tcdate": 1538087932989, "tmdate": 1538155976987, "tddate": null, "forum": "HygBZnRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transferring Knowledge across Learning Processes", "abstract": "In complex transfer learning scenarios new tasks might not be tightly linked to previous tasks. Approaches that transfer information contained only in the final parameters of a source model will therefore struggle. Instead, transfer learning at a higher level of abstraction is needed. We propose Leap, a framework that achieves this by transferring knowledge across learning processes. We associate each task with a manifold on which the training process travels from initialization to final parameters and construct a meta learning objective that minimizes the expected length of this path. Our framework leverages only information obtained during training and can be computed on the fly at negligible cost. We demonstrate that our framework outperforms competing methods, both in meta learning and transfer learning, on a set of computer vision tasks. Finally, we demonstrate that Leap can transfer knowledge across learning processes in demanding Reinforcement learning environments (Atari) that involve millions of gradient steps.", "keywords": ["Meta Learning", "Transfer Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1168/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Leap, a framework that transfers knowledge across learning processes by  minimizing the expected distance the training process travels on a task's loss surface.", "pdf": "/pdf/9394cbc889c123d2fe4a4b103f7c9fc71fda711c.pdf", "paperhash": "anonymous|transferring_knowledge_across_learning_processes", "_bibtex": "@inproceedings{    \nanonymous2019transferring,    \ntitle={Transferring Knowledge across Learning Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygBZnRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxHb3R5tX", "original": "Skx5zsTqF7", "number": 1169, "cdate": 1538087933163, "ddate": null, "tcdate": 1538087933163, "tmdate": 1538155976779, "tddate": null, "forum": "ByxHb3R5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal Successor Features for Transfer Reinforcement Learning", "abstract": "Transfer in Reinforcement Learning (RL) refers to the idea of applying knowledge gained from previous tasks to solving related tasks. Learning a universal value function (Schaul et al., 2015), which generalizes over goals and states, has previously been shown to be useful for transfer. However, successor features are believed to be more suitable than values for transfer (Dayan, 1993; Barreto et al.,2017), even though they cannot directly generalize to new goals. In this paper, we propose (1) Universal Successor Features (USFs) to capture the underlying dynamics of the environment while allowing generalization to unseen goals and (2) a flexible end-to-end model of USFs that can be trained by interacting with the environment. We show that learning USFs is compatible with any RL algorithm that learns state values using a temporal difference method. Our experiments in a simple gridworld and with two MuJoCo environments show that USFs can greatly accelerate training when learning multiple tasks and can effectively transfer knowledge to new tasks.", "keywords": ["Reinforcement Learning", "Successor Features", "Successor Representations", "Transfer Learning", "Representation Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1169/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2f9bb92ba68349ca11c3bf9d5a2512866192e527.pdf", "paperhash": "anonymous|universal_successor_features_for_transfer_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Successor Features for Transfer Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxHb3R5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GHb2RqYX", "original": "BklmACpqt7", "number": 1170, "cdate": 1538087933346, "ddate": null, "tcdate": 1538087933346, "tmdate": 1538155976574, "tddate": null, "forum": "B1GHb2RqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PolyCNN: Learning Seed Convolutional Filters", "abstract": "In this work, we propose the polynomial convolutional neural network (PolyCNN), as a new design of a weight-learning efficient variant of the traditional CNN. The biggest advantage of the PolyCNN is that at each convolutional layer, only one convolutional filter is needed for learning the weights, which we call the seed filter, and all the other convolutional filters are the polynomial transformations of the seed filter, which is termed as an early fan-out. Alternatively, we can also perform late fan-out on the seed filter response to create the number of response maps needed to be input into the next layer. Both early and late fan-out allow the PolyCNN to learn only one convolutional filter at each layer, which can dramatically reduce the model complexity by saving 10x to 50x parameters during learning. While being efficient during both training and testing, the PolyCNN does not suffer performance due to the non-linear polynomial expansion which translates to richer representational power within the convolutional layers. By allowing direct control over model complexity, PolyCNN provides a flexible trade-off between performance and efficiency. We have verified the on-par performance between the proposed PolyCNN and the standard CNN on several visual datasets, such as MNIST, CIFAR-10, SVHN, and ImageNet.", "keywords": ["Efficient CNN", "Seed convolutional filter"], "authorids": ["ICLR.cc/2019/Conference/Paper1170/Authors"], "authors": ["Anonymous"], "TL;DR": "PolyCNN only needs to learn one seed convolutional filter at each layer. This is an efficient variant of traditional CNN, with on-par performance.", "pdf": "/pdf/eab96709ff84ca55714b348bfcb4a9b1c82060b8.pdf", "paperhash": "anonymous|polycnn_learning_seed_convolutional_filters", "_bibtex": "@inproceedings{    \nanonymous2019polycnn:,    \ntitle={PolyCNN: Learning Seed Convolutional Filters},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GHb2RqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1MB-3RcF7", "original": "SkgWzDccYX", "number": 1171, "cdate": 1538087933507, "ddate": null, "tcdate": 1538087933507, "tmdate": 1538155976364, "tddate": null, "forum": "S1MB-3RcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-objective training of Generative Adversarial Networks with multiple discriminators", "abstract": "Recent literature has demonstrated promising results on the training of Generative Adversarial Networks by employing a set of discriminators, as opposed to the traditional game involving one generator against a single adversary. Those methods perform single-objective optimization on some simple consolidation of the losses, e.g. an average. In this work, we revisit the multiple-discriminator approach by framing the simultaneous minimization of losses provided by different models as a multi-objective optimization problem. Specifically, we evaluate the performance of multiple gradient descent and the hypervolume maximization algorithm on a number of different datasets. Moreover, we argue that the previously proposed methods and hypervolume maximization can all be seen as variations of multiple gradient descent in which the update direction computation can be done efficiently. Our results indicate that hypervolume maximization presents a better compromise between sample quality and diversity, and computational cost than previous methods.", "keywords": ["Generative Adversarial Networks", "Multi-objective optimization", "Generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper1171/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. ", "pdf": "/pdf/d2467496e1ae521e5b1dc7c604199499f030d8e5.pdf", "paperhash": "anonymous|multiobjective_training_of_generative_adversarial_networks_with_multiple_discriminators", "_bibtex": "@inproceedings{    \nanonymous2019multi-objective,    \ntitle={Multi-objective training of Generative Adversarial Networks with multiple discriminators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1MB-3RcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1xLZ2R5KQ", "original": "Skgp6bC9tm", "number": 1172, "cdate": 1538087933682, "ddate": null, "tcdate": 1538087933682, "tmdate": 1538155976157, "tddate": null, "forum": "S1xLZ2R5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Maximum a Posteriori on a Submanifold: a General Image Restoration Method with GAN", "abstract": "We propose a general method for various image restoration problems, such as denoising, deblurring, super-resolution and inpainting. The problem is formulated as a constrained optimization problem. Its objective is to maximize a posteriori probability of latent variables, and its constraint is that the image generated by these latent variables must be the same as the degraded image. We use a Generative Adversarial Network (GAN) as our density estimation model. Convincing results are obtained on MNIST dataset.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1172/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c37f6720ae7ff4c9e85a0534c3c2fa54c5246703.pdf", "paperhash": "anonymous|maximum_a_posteriori_on_a_submanifold_a_general_image_restoration_method_with_gan", "_bibtex": "@inproceedings{    \nanonymous2019maximum,    \ntitle={Maximum a Posteriori on a Submanifold: a General Image Restoration Method with GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xLZ2R5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1x8WnA5Ym", "original": "HkeIOXlKYX", "number": 1173, "cdate": 1538087933839, "ddate": null, "tcdate": 1538087933839, "tmdate": 1538155975950, "tddate": null, "forum": "S1x8WnA5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Diverse Generations using Determinantal Point Processes", "abstract": "Generative models have proven to be an outstanding tool for representing high-\ndimensional probability distributions and generating realistic looking images. A\nfundamental characteristic of generative models is their ability to produce multi-\nmodal outputs. However while training, they are often susceptible to mode col-\nlapse, which means that the model is limited in mapping the input noise to only\na few modes of the true data distribution. In this paper, we draw inspiration from\nDeterminantal Point Process (DPP) to devise a generative model that alleviates\nmode collapse problem while producing higher quality samples. DPP is an ele-\ngant probabilistic measure used to model negative correlations within a subset, and\nhence quantify its diversity. We propose a generation penalty term that encourages\nthe generator to behave as a Determinantal Point Process sampler and hence learns\nto generates diverse data. In contrast to previous state-of-the-art generative mod-\nels that tend to use additional trainable parameters or complex training paradigms,\nour method does not change the original training scheme. Embedded in an ad-\nversarial strategy, our Generative DPP approach shows a consistent resistance to\nmode-collapse on a wide-variety of synthetic data and natural image datasets in-\ncluding MNIST and CIFAR10, while outperforming state-of-the-art methods for\ndata-efficiency, convergence-time, and generation quality. Our code will be made\npublicly available.", "keywords": ["Generative Adversarial Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1173/Authors"], "authors": ["Anonymous"], "TL;DR": "The addition of a diversity criterion inspired from DPP in the GAN objective avoids mode collapse and leads to better generations. ", "pdf": "/pdf/60132625ef67cae51719bf67868c1abf4c942483.pdf", "paperhash": "anonymous|learning_diverse_generations_using_determinantal_point_processes", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Diverse Generations using Determinantal Point Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1x8WnA5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryl8-3AcFX", "original": "BklubSuqYX", "number": 1174, "cdate": 1538087934000, "ddate": null, "tcdate": 1538087934000, "tmdate": 1538155975743, "tddate": null, "forum": "ryl8-3AcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Environment Probing Interaction Policies", "abstract": "A key challenge in reinforcement learning (RL) is environment generalization: a policy trained to solve a task in one environment often fails to solve the same task in a slightly different test environment. A common approach to improve inter-environment transfer is to learn policies that are invariant to the distribution of testing environments. However, we argue that instead of being invariant, the policy should identify the specific nuances of an environment and exploit them to achieve better performance. In this work, we propose the \u201cEnvironment-Probing\u201d Interaction (EPI) policy, a policy that probes a new environment to extract an implicit understanding of that environment\u2019s behavior. Once this environment-specific information is obtained, it is used as an additional input to a task-specific policy that can now perform environment-conditioned actions to solve a task. To learn these EPI-policies, we present a reward function based on transition predictability. Specifically, a higher reward is given if the trajectory generated by the EPI-policy can be used to better predict transitions. We experimentally show that EPI-conditioned task-specific policies significantly outperform commonly used policy generalization methods on novel testing environments.", "keywords": ["Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1174/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5729f47bb76ca61354373bfcc6212f07860c773c.pdf", "paperhash": "anonymous|environment_probing_interaction_policies", "_bibtex": "@inproceedings{    \nanonymous2019environment,    \ntitle={Environment Probing Interaction Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryl8-3AcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gL-2A9Ym", "original": "H1lMzvScFX", "number": 1175, "cdate": 1538087934169, "ddate": null, "tcdate": 1538087934169, "tmdate": 1538155975538, "tddate": null, "forum": "H1gL-2A9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Personalized Embedding Propagation: Combining Neural Networks on Graphs with Personalized PageRank", "abstract": "Neural message passing algorithms for semi-supervised classification on graphs have recently achieved great success. However, these methods only consider nodes that are a few propagation steps away and the size of this utilized neighborhood cannot be easily extended. In this paper, we use the relationship between graph convolutional networks (GCN) and PageRank to derive an improved propagation scheme based on personalized PageRank. We utilize this propagation procedure to construct personalized embedding propagation (PEP) and its approximation, PEP$_\\text{A}$. Our model's training time is on par or faster and its number of parameters on par or lower than previous models. It leverages a large, adjustable neighborhood for classification and can be combined with any neural network. We show that this model outperforms several recently proposed methods for semi-supervised classification on multiple graphs in the most thorough study done so far for GCN-like models.", "keywords": ["Graph", "GCN", "Neural network", "Semi-supervised classification", "Semi-supervised learning", "PageRank", "Personalized PageRank"], "authorids": ["ICLR.cc/2019/Conference/Paper1175/Authors"], "authors": ["Anonymous"], "TL;DR": "Personalized embedding propagation combines neural networks with personalized PageRank for semi-supervised classification on graphs.", "pdf": "/pdf/3801d305bb6ead1f2ad2dee16365e1dbc8b2b1e1.pdf", "paperhash": "anonymous|personalized_embedding_propagation_combining_neural_networks_on_graphs_with_personalized_pagerank", "_bibtex": "@inproceedings{    \nanonymous2019personalized,    \ntitle={Personalized Embedding Propagation: Combining Neural Networks on Graphs with Personalized PageRank},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gL-2A9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rke8ZhCcFQ", "original": "HkxFt_5qKX", "number": 1176, "cdate": 1538087934347, "ddate": null, "tcdate": 1538087934347, "tmdate": 1538155975329, "tddate": null, "forum": "rke8ZhCcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES", "abstract": "Graph convolutional networks (GCNs) have been widely used for classifying graph nodes in the semi-supervised setting.\nPrevious works have shown that GCNs are vulnerable to the perturbation on adjacency and feature matrices of existing nodes. However, it is unrealistic to change the connections of  existing nodes in many applications, such as existing users in social networks. In this paper, we investigate methods attacking GCNs by adding fake nodes. A greedy algorithm is proposed to generate adjacency and feature matrices of fake nodes, aiming to minimize the classification accuracy on the existing ones. In additional, we introduce a discriminator to classify fake nodes from real nodes, and propose a Greedy-GAN algorithm to simultaneously update the discriminator and the attacker, to make fake nodes indistinguishable to the real ones.  Our non-targeted attack decreases the accuracy of GCN down to 0.10, and our targeted attack reaches a success rate of 0.99 for attacking the whole datasets, and 0.94 on average for attacking a single node.", "keywords": ["Graph Convolutional Network", "adversarial attack", "node classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1176/Authors"], "authors": ["Anonymous"], "TL;DR": "non-targeted and targeted attack on GCN by adding fake nodes", "pdf": "/pdf/599c2e723f3adbb416da281cc68db4a7b0841082.pdf", "paperhash": "anonymous|attack_graph_convolutional_networks_by_adding_fake_nodes", "_bibtex": "@inproceedings{    \nanonymous2019attack,    \ntitle={ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rke8ZhCcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxwW2A5Km", "original": "SJlNZOp9Fm", "number": 1177, "cdate": 1538087934519, "ddate": null, "tcdate": 1538087934519, "tmdate": 1538155975121, "tddate": null, "forum": "SyxwW2A5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Representations of Categorical Feature Combinations via Self-Attention", "abstract": "Self-attention has been widely used to model the sequential data and achieved remarkable results in many applications. Although it can be used to model dependencies without regard to positions of sequences, self-attention is seldom applied to non-sequential data. In this work, we propose to learn representations of multi-field categorical data in prediction tasks via self-attention mechanism, where features are orderless but have intrinsic relations over different fields. In most current DNN based models, feature embeddings are simply concatenated for further processing by networks. Instead, by applying self-attention to transform the embeddings, we are able to relate features in different fields and automatically learn representations of their combinations, which are known as the factors of many prevailing linear models. To further improve the effect of feature combination mining, we modify the original self-attention structure by restricting the similarity weight to have at most k non-zero values, which additionally regularizes the model. We experimentally evaluate the effectiveness of our self-attention model on non-sequential data. Across two click through rate prediction benchmark datasets, i.e., Cretio and Avazu, our model with top-k restricted self-attention achieves the state-of-the-art performance. Compared with the vanilla MLP, the gain by adding self-attention is significantly larger than that by modifying the network structures, which most current works focus on.", "keywords": ["Learning Representations", "Feature Combinations", "Self-Attention"], "authorids": ["ICLR.cc/2019/Conference/Paper1177/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/97ef18bccd200f6f3d2f03a765365e49f7a692bb.pdf", "paperhash": "anonymous|learning_representations_of_categorical_feature_combinations_via_selfattention", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Representations of Categorical Feature Combinations via Self-Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxwW2A5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxw-hAcFQ", "original": "rJeXVyCqFX", "number": 1178, "cdate": 1538087934682, "ddate": null, "tcdate": 1538087934682, "tmdate": 1538155974903, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ICLR.cc/2019/Conference/Paper1178/Authors"], "authors": ["Anonymous"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/b08aeb8f004b70ef1e4be5a84481acb2f5bee2a1.pdf", "paperhash": "anonymous|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{    \nanonymous2019generating,    \ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxw-hAcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygvZ2RcYm", "original": "Hklztd6ctQ", "number": 1179, "cdate": 1538087934850, "ddate": null, "tcdate": 1538087934850, "tmdate": 1538155974699, "tddate": null, "forum": "rygvZ2RcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Knowledge Representation for Reinforcement Learning using General Value Functions", "abstract": "Reinforcement learning (RL) is a very powerful approach for learning good control strategies from data. Value functions are a key concept for reinforcement learning, as they guide the search for good policies. A lot of effort has been devoted to designing and improving algorithms for learning value functions. In this paper, we argue that value functions are also a very natural way of providing a framework for knowledge representation for reinforcement learning agents. We show that generalized value functions provide a unifying lens for many algorithms, including policy gradient, successor features, option models and policies, and other forms of hierarchical reinforcement learning. We also demonstrate the potential of this representation to provide new, useful algorithms.", "keywords": ["Reinforcement Learning", "General Value Functions", "Policy Gradient", "Hierarchical Reinforcement Learning", "Successor Features"], "authorids": ["ICLR.cc/2019/Conference/Paper1179/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9160fb57c502bf6b206e5a51cf96dc060cb4bdba.pdf", "paperhash": "anonymous|knowledge_representation_for_reinforcement_learning_using_general_value_functions", "_bibtex": "@inproceedings{    \nanonymous2019knowledge,    \ntitle={Knowledge Representation for Reinforcement Learning using General Value Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygvZ2RcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygvZ209F7", "original": "H1xxraS9Y7", "number": 1180, "cdate": 1538087935020, "ddate": null, "tcdate": 1538087935020, "tmdate": 1538155974494, "tddate": null, "forum": "SygvZ209F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Biologically-Plausible Learning Algorithms Can Scale to Large Datasets", "abstract": "The backpropagation (BP) algorithm is often thought to be biologically implausible in the brain. One of the main reasons is that BP requires symmetric weight matrices in the feedforward and feedback pathways. To address this \u201cweight transport problem\u201d (Grossberg, 1987), two more biologically plausible algorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax BP\u2019s weight symmetry requirements and demonstrate comparable learning capabilities to that of BP on small datasets. However, a recent study by Bartunov et al. (2018) finds that although feedback alignment (FA) and some variants of target-propagation (TP) perform well on MNIST and CIFAR, they perform significantly worse than BP on ImageNet. Here, we additionally evaluate the sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and FA in that the feedback and feedforward weights do not share magnitudes but share signs. We examine the performance of sign-symmetry and feedback alignment on ImageNet and MS COCO datasets using different network architectures (ResNet-18 and AlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained with sign-symmetry can attain classification performance approaching that of BP-trained networks. These results complement the study by Bartunov et al. (2018), and establish a new benchmark for future biologically plausible learning algorithms on more difficult datasets and more complex architectures.", "keywords": ["biologically plausible learning algorithm", "ImageNet", "sign-symmetry", "feedback alignment"], "authorids": ["ICLR.cc/2019/Conference/Paper1180/Authors"], "authors": ["Anonymous"], "TL;DR": "Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet", "pdf": "/pdf/49645e2ee26700066b2c0823874be6f6007b6482.pdf", "paperhash": "anonymous|biologicallyplausible_learning_algorithms_can_scale_to_large_datasets", "_bibtex": "@inproceedings{    \nanonymous2019biologically-plausible,    \ntitle={Biologically-Plausible Learning Algorithms Can Scale to Large Datasets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygvZ209F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygD-hCcF7", "original": "SkxhYeAqKX", "number": 1181, "cdate": 1538087935187, "ddate": null, "tcdate": 1538087935187, "tmdate": 1538155974267, "tddate": null, "forum": "SygD-hCcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Dimensionality Reduction for Representing the Knowledge of Probabilistic Models", "abstract": "Most deep learning models rely on expressive high-dimensional representations to achieve good performance on tasks such as classification. However, the high dimensionality of these representations makes them difficult to interpret and prone to over-fitting. We propose a simple, intuitive and scalable dimension reduction framework that takes into account the soft probabilistic interpretation of standard deep models for classification. When applying our framework to visualization, our representations more accurately reflect inter-class distances than standard visualization techniques such as t-SNE. We show experimentally that our framework improves generalization performance to unseen categories in zero-shot learning. We also provide a finite sample error upper bound guarantee for the method.", "keywords": ["metric learning", "distance learning", "dimensionality reduction", "bound guarantees"], "authorids": ["ICLR.cc/2019/Conference/Paper1181/Authors"], "authors": ["Anonymous"], "TL;DR": "dimensionality reduction for cases where examples can be represented as soft probability distributions", "pdf": "/pdf/78ee4440d6553b1509c260917f88a2b66dce3b2a.pdf", "paperhash": "anonymous|dimensionality_reduction_for_representing_the_knowledge_of_probabilistic_models", "_bibtex": "@inproceedings{    \nanonymous2019dimensionality,    \ntitle={Dimensionality Reduction for Representing the Knowledge of Probabilistic Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygD-hCcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJzwb2RcK7", "original": "Bkgp0Ca9Km", "number": 1182, "cdate": 1538087935363, "ddate": null, "tcdate": 1538087935363, "tmdate": 1538155974051, "tddate": null, "forum": "SJzwb2RcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adversarial Decomposition of Text Representation", "abstract": "In this paper, we present a method for adversarial decomposition of text representation. This method can be used to decompose a representation of an input sentence into several independent vectors, where each vector is responsible for a specific aspect of the input sentence. We evaluate the proposed method on two case studies: the conversion between different social registers and diachronic language change. We show that the proposed method is capable of fine-grained con- trolled change of these aspects of the input sentence. For example, our model is capable of learning a continuous (rather than categorical) representation of the style of the sentence, in line with the reality of language use. The model uses adversarial-motivational training and includes a special motivational loss, which acts opposite to the discriminator and encourages a better decomposition. Finally, we evaluate the obtained meaning embeddings on a downstream task of para- phrase detection and show that they are significantly better than embeddings of a regular autoencoder.", "keywords": ["learning representation", "decomposition", "adversarial training", "style transfer"], "authorids": ["ICLR.cc/2019/Conference/Paper1182/Authors"], "authors": ["Anonymous"], "TL;DR": "A method which learns separate representations for the meaning and the form of a sentence", "pdf": "/pdf/43f023160f6e01b5aa08d7a24336bfb8197abff4.pdf", "paperhash": "anonymous|adversarial_decomposition_of_text_representation", "_bibtex": "@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Decomposition of Text Representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzwb2RcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxdbnR9YQ", "original": "SJgq1z05KQ", "number": 1183, "cdate": 1538087935529, "ddate": null, "tcdate": 1538087935529, "tmdate": 1538155973842, "tddate": null, "forum": "SyxdbnR9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING", "abstract": "We outline the problem of concept drifts for time series data. In this work, we analyze the temporal inconsistency of streaming wireless signals in the context of device-free passive indoor localization. We show that data obtained from WiFi channel state information (CSI) can be used to train a robust system capable of performing room level localization. One of the most challenging issues for such a system is the movement of input data distribution to an unexplored space over time, which leads to an unwanted shift in the learned boundaries of the output space. In this work, we propose a phase and magnitude augmented feature space along with a standardization technique that is little affected by drifts. We show that this robust representation of the data yields better learning accuracy and requires less number of retraining. ", "keywords": ["concept drift", "wifi localization", "feature representation."], "authorids": ["ICLR.cc/2019/Conference/Paper1183/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce an augmented robust feature space for streaming wifi data that is capable of tackling concept drift for indoor localization", "pdf": "/pdf/e2484cedf687793b77242d6d4f6545dc488d5741.pdf", "paperhash": "anonymous|handling_concept_drift_in_wifibased_indoor_localization_using_representation_learning", "_bibtex": "@inproceedings{    \nanonymous2019handling,    \ntitle={HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxdbnR9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJx_b3RqY7", "original": "Ske0kMA9YQ", "number": 1184, "cdate": 1538087935704, "ddate": null, "tcdate": 1538087935704, "tmdate": 1538155973636, "tddate": null, "forum": "rJx_b3RqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "AIM: Adversarial Inference by Matching Priors and Conditionals", "abstract": "Effective inference for a generative adversarial model remains an important and challenging problem. We propose a novel approach, Adversarial Inference by Matching priors and conditionals (AIM), which explicitly matches prior and conditional distributions in both data and code spaces, and puts a direct constraint on the dependency structure of the generative model. We derive an equivalent form of the prior and conditional matching objective that can be optimized efficiently without any parametric assumption on the data. We validate the effectiveness of AIM on the MNIST, CIFAR-10, and CelebA datasets by conducting quantitative and qualitative evaluations. Results demonstrate that AIM significantly improves both reconstruction and generation as compared to other adversarial inference models.", "keywords": ["Generative adversarial network", "inference", "generative model"], "authorids": ["ICLR.cc/2019/Conference/Paper1184/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5d09610ae695e1e26f9c1087777409a3973bb82c.pdf", "paperhash": "anonymous|aim_adversarial_inference_by_matching_priors_and_conditionals", "_bibtex": "@inproceedings{    \nanonymous2019aim:,    \ntitle={AIM: Adversarial Inference by Matching Priors and Conditionals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJx_b3RqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1z_Z2A5tX", "original": "H1ghPeRqK7", "number": 1185, "cdate": 1538087935874, "ddate": null, "tcdate": 1538087935874, "tmdate": 1538155973429, "tddate": null, "forum": "H1z_Z2A5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DON\u2019T JUDGE A BOOK BY ITS COVER - ON THE DYNAMICS OF RECURRENT NEURAL NETWORKS", "abstract": "To be effective in sequential data processing, Recurrent Neural Networks (RNNs)\nare required to perform data processing as well as to keep track of past events\nby creating memories. Consequently RNNs are harder to train than their not recurrent\ncounterparts. In this paper, we investigate the representation of memories\nformed in trained RNN internal state under various training protocols. It is not\nclear whether there is a trade-off between learning discriminative task, learning\nactions and learning to memorize. Having observed the RNN\u2019s apparently consistent\nperformance regardless of training protocol, we expected the internal dynamics\nto be similar as well. Instead we were surprised to discover substantial\ndifferences, leading to differences in the ability to generalize for unforeseen tasks\nor conditions. In an attempt to understand these differences we proposed a method\nfor tracking the formation of memories along the course of training, and indeed\nresults on memory shaping process were obtained.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1185/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/366a9255429aa0bfd2f1993acade7114423ddabf.pdf", "paperhash": "anonymous|dont_judge_a_book_by_its_cover_on_the_dynamics_of_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019don\u2019t,    \ntitle={DON\u2019T JUDGE A BOOK BY ITS COVER - ON THE DYNAMICS OF RECURRENT NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1z_Z2A5tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkzOWnActX", "original": "S1liZgDndm", "number": 1186, "cdate": 1538087936038, "ddate": null, "tcdate": 1538087936038, "tmdate": 1538155973219, "tddate": null, "forum": "HkzOWnActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MuMoMAML: Model-Agnostic Meta-Learning for Multimodal Task Distributions", "abstract": "Gradient-based meta-learners such as MAML (Finn et al., 2017) are able to learn a meta-prior from similar tasks to adapt to novel tasks from the same distribution with few gradient updates. However, such frameworks seek a common initialization shared across the entire task distribution, substantially limiting the diversity of the task distributions that they are able to learn from. In this paper, we aim to augment existing gradient-based meta-learners with the capability to identify the modes of a task distribution and adapt quickly through gradient updates given tasks sampled from a multimodal task distribution. Specifically, we propose a multimodal MAML algorithm (MuMoMAML), which is able to modulate its meta-learned prior according to the identified task modes, allowing further fast adaptation. We evaluate the proposed algorithm on a diverse set of problems including regression, few-shot image classification, and reinforcement learning. The results demonstrate the effectiveness of our model in efficiently acquiring a meta-learned prior under a multimodal task distribution.", "keywords": ["Meta-learning", "gradient-based meta-learning", "model-based meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1186/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed a meta-learner that generalizes across a multimodal task distribution by identifying the modes of the distribution and modulating its meta-learned prior accordingly, allowing further efficient adaptation through gradient updates.", "pdf": "/pdf/8d7e09c4b0518c895a17bb971674f0102a95e988.pdf", "paperhash": "anonymous|mumomaml_modelagnostic_metalearning_for_multimodal_task_distributions", "_bibtex": "@inproceedings{    \nanonymous2019mumomaml:,    \ntitle={MuMoMAML: Model-Agnostic Meta-Learning for Multimodal Task Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzOWnActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJedbn0ctQ", "original": "S1es565tY7", "number": 1187, "cdate": 1538087936196, "ddate": null, "tcdate": 1538087936196, "tmdate": 1538155973008, "tddate": null, "forum": "rJedbn0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Zero-training Sentence Embedding via Orthogonal Basis", "abstract": "We propose a simple and robust training-free approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is its novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace.  Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representation. This approach requires zero training and zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Experimental results show that our model outperforms all existing zero-training alternatives in all the tasks and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.", "keywords": ["Natural Language Processing", "Sentence Embeddings"], "authorids": ["ICLR.cc/2019/Conference/Paper1187/Authors"], "authors": ["Anonymous"], "TL;DR": "A simple and training-free approach for sentence embeddings with competitive performance compared with sophisticated models requiring either large amount of training data or prolonged training time.", "pdf": "/pdf/e7566e8791b2eee17b383e8bf353c445bca39153.pdf", "paperhash": "anonymous|zerotraining_sentence_embedding_via_orthogonal_basis", "_bibtex": "@inproceedings{    \nanonymous2019zero-training,    \ntitle={Zero-training Sentence Embedding via Orthogonal Basis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJedbn0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJldZ2RqFX", "original": "r1e7XbAcKm", "number": 1188, "cdate": 1538087936356, "ddate": null, "tcdate": 1538087936356, "tmdate": 1538155972794, "tddate": null, "forum": "SJldZ2RqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "D-GAN: Divergent generative adversarial network for positive unlabeled learning and counter-examples generation", "abstract": "Positive Unlabeled learning task remains an interesting challenge in the context of image analysis. Recent approaches suggest to exploit the GANs abilities to answer this problem. In this paper, we propose a new approach named Divergent-GAN (D-GAN). It keeps the light adversarial architecture of the PGAN method, with a better robustness counter the varying images complexity, while simultaneously allowing the same functionalities as the GenPU method, like the generation of relevant counter-examples. However, this is achieved without the need of prior knowledge, nor an onerous architecture and framework. Its functionning is based on the combination between the behaviour principles of Positive Unlabeled learning classification and the adversarial GAN training. Experimental results show that this divergent adversarial framework outperforms the state of the art PU learning in terms of prediction accuracy, training robustness, and its ability to work on both simple and complex real images. Combined with an additional generator, the proposed approach even allows to accomplish noisy labeled learning, and thus opening new application perspectives for GANs architectures.", "keywords": ["Representation learning. Positive Unlabeled learning. Image classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1188/Authors"], "authors": ["Anonymous"], "TL;DR": "A new two-stage positive unlabeled learning approach with GAN", "pdf": "/pdf/cde41813ba28b4a9eaf38538888b232fe3d1f5f9.pdf", "paperhash": "anonymous|dgan_divergent_generative_adversarial_network_for_positive_unlabeled_learning_and_counterexamples_generation", "_bibtex": "@inproceedings{    \nanonymous2019d-gan:,    \ntitle={D-GAN: Divergent generative adversarial network for positive unlabeled learning and counter-examples generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJldZ2RqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryetZ20ctX", "original": "HyeUeZaqYm", "number": 1189, "cdate": 1538087936527, "ddate": null, "tcdate": 1538087936527, "tmdate": 1538155972592, "tddate": null, "forum": "ryetZ20ctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Defensive Quantization: When Efficiency Meets Robustness", "abstract": "Neural network quantization is becoming an industry standard to efficiently deploy deep learning models on hardware platforms, such as CPU, GPU, TPU, and FPGAs. However, we observe that the conventional quantization approaches are vulnerable to adversarial attacks. This paper aims to raise people's awareness about the security of the quantized models, and we designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models. We first conduct an empirical study to show that vanilla quantization suffers more from adversarial attacks. We observe that the inferior robustness comes from the error amplification effect, where the quantization operation further enlarges the distance caused by amplified noise. Then we propose a novel Defensive Quantization (DQ) method by controlling the Lipschitz constant of the network during quantization, such that the magnitude of the adversarial noise remains non-expansive during inference. Extensive experiments on CIFAR-10 and SVHN datasets demonstrate that our new quantization method can defend neural networks against adversarial examples, and even achieves superior robustness than their full-precision counterparts, while maintaining the same hardware efficiency as vanilla quantization approaches. As a by-product, DQ can also improve the accuracy of quantized models without adversarial attack. ", "keywords": ["defensive quantization", "model quantization", "adversarial attack", "efficiency", "robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper1189/Authors"], "authors": ["Anonymous"], "TL;DR": "We designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models.", "pdf": "/pdf/85f3ce4e3912f7d2521c01b5fa0430818fcf9287.pdf", "paperhash": "anonymous|defensive_quantization_when_efficiency_meets_robustness", "_bibtex": "@inproceedings{    \nanonymous2019defensive,    \ntitle={Defensive Quantization: When Efficiency Meets Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryetZ20ctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklKWhC5F7", "original": "r1lOxz0qYQ", "number": 1190, "cdate": 1538087936698, "ddate": null, "tcdate": 1538087936698, "tmdate": 1538155972380, "tddate": null, "forum": "HklKWhC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification", "abstract": "Recent work has demonstrated the lack of robustness of well-trained deep neural networks (DNNs) to adversarial examples.  For example, visually indistinguishable perturbations, when mixed with an original image, can easily lead deep learning models to misclassifications.  In light of a recent study on the mutual influence between robustness and accuracy over 18 different ImageNet models, this paper investigates how training data affect the accuracy and robustness of deep neural\nnetworks. We conduct extensive experiments on four different datasets, including CIFAR-10, MNIST, STL-10, and Tiny ImageNet, with several representative neural networks. Our results reveal previously unknown phenomena that exist between the size of training data and characteristics of the resulting models. In particular, besides confirming that the model accuracy improves as the amount of training data increases, we also observe that the model robustness improves initially, but there exists a turning point after which robustness starts to decrease.  How and when such turning points occur vary for different neural networks and different datasets.", "keywords": ["Adversarial attacks", "Robustness", "CW", "I-FGSM"], "authorids": ["ICLR.cc/2019/Conference/Paper1190/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d9ebb0c0090f54f0871b450f142e10df4b292f2b.pdf", "paperhash": "anonymous|how_training_data_affect_the_accuracy_and_robustness_of_neural_networks_for_image_classification", "_bibtex": "@inproceedings{    \nanonymous2019how,    \ntitle={How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklKWhC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxF-nAqYX", "original": "HyllAkA9F7", "number": 1191, "cdate": 1538087936865, "ddate": null, "tcdate": 1538087936865, "tmdate": 1538155972168, "tddate": null, "forum": "ByxF-nAqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Locally Linear Unsupervised Feature Selection", "abstract": "The paper, interested in unsupervised feature selection, aims to retain the features best accounting for the local patterns in the data. The proposed approach, called Locally Linear Unsupervised Feature Selection, relies on a dimensionality reduction method to characterize such patterns; each feature is thereafter assessed according to its compliance w.r.t. the local patterns, taking inspiration from Locally Linear Embedding (Roweis and Saul, 2000). The experimental validation of the approach on the scikit-feature benchmark suite demonstrates its effectiveness compared to the state of the art.", "keywords": ["Unsupervised Learning", "Feature Selection", "Dimension Reduction"], "authorids": ["ICLR.cc/2019/Conference/Paper1191/Authors"], "authors": ["Anonymous"], "TL;DR": "Unsupervised feature selection through capturing the local linear structure of the data", "pdf": "/pdf/71c88ca9f4594ce9510419fc3b789f1955611b39.pdf", "paperhash": "anonymous|locally_linear_unsupervised_feature_selection", "_bibtex": "@inproceedings{    \nanonymous2019locally,    \ntitle={Locally Linear Unsupervised Feature Selection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxF-nAqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lFZnR5YX", "original": "rJgR_bA8KQ", "number": 1192, "cdate": 1538087937031, "ddate": null, "tcdate": 1538087937031, "tmdate": 1538155971951, "tddate": null, "forum": "H1lFZnR5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Regression Tree", "abstract": "Regression-via-Classification (RvC) is the process of converting a regression problem to a classification one. Current approaches for RvC use ad-hoc discretization strategies and are suboptimal. We propose a neural regression tree model for RvC. In this model, we employ a joint optimization framework where we learn optimal discretization thresholds while simultaneously optimizing the features for each node in the tree. We empirically show the validity of our model by testing it on two challenging regression tasks where we establish the state of the art.", "keywords": ["regression-via-classification", "discretization", "regression tree", "neural model", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1192/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel neural regression tree for optimal discretization in regression-via-classification problems.", "pdf": "/pdf/d060cb1461012aa0f7ff57425acf6a4c0cbed223.pdf", "paperhash": "anonymous|neural_regression_tree", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Regression Tree},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lFZnR5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xY-hRctX", "original": "BJlh-os5K7", "number": 1193, "cdate": 1538087937197, "ddate": null, "tcdate": 1538087937197, "tmdate": 1538155971744, "tddate": null, "forum": "B1xY-hRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Logic Machines", "abstract": "We propose Neural Logic Machines (NLMs), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks\u2014as function approximators for probabilistic distributions, and logic programming\u2014as symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can learn the underlying logic rules, and generalize to arbitrarily large-scale tasks (such as sorting arbitrarily long arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on family tree and general graphs, to decision making tasks including sorting, finding shortest paths, and the blocks world. Most of these tasks are hard to accomplish for neural networks or logical programming alone.", "keywords": ["Neural-symbolic", "first-order logic", "perfect generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1193/Authors"], "authors": ["Anonymous"], "TL;DR": "A fully differentiable neural-symbolic architecture to conduct first-order logic reasoning", "pdf": "/pdf/d1928699780b4edc1aa0cbc4d61f07f2f43af976.pdf", "paperhash": "anonymous|neural_logic_machines", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Logic Machines},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xY-hRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkeK-nRcFX", "original": "BkxXlBn9Fm", "number": 1194, "cdate": 1538087937365, "ddate": null, "tcdate": 1538087937365, "tmdate": 1538155971539, "tddate": null, "forum": "BkeK-nRcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Nonlinearity Coefficient - Predicting Generalization in Deep Neural Networks", "abstract": "For a long time, designing neural architectures that exhibit high performance was considered a dark art that required expert hand-tuning. One of the few well-known guidelines for architecture design is the avoidance of exploding or vanishing gradients. However, even this guideline has remained relatively vague and circumstantial, because there exists no well-defined, gradient-based metric that can be computed {\\it before} training begins and can robustly predict the performance of the network {\\it after} training is complete.\n\nWe introduce what is, to the best of our knowledge, the first such metric: the nonlinearity coefficient (NLC). Via an extensive empirical study, we show that the NLC, computed in the network's randomly initialized state, is a powerful predictor of test error and that attaining a right-sized NLC is essential for attaining an optimal test error, at least in fully-connected feedforward networks. The NLC is also conceptually simple, cheap to compute, and is robust to a range of confounders and architectural design choices that comparable metrics are not necessarily robust to. Hence, we argue the NLC is an important tool for architecture search and design, as it can robustly predict poor training outcomes before training even begins.", "keywords": ["deep learning", "neural networks", "nonlinearity", "activation functions", "exploding gradients", "vanishing gradients", "neural architecture search"], "authorids": ["ICLR.cc/2019/Conference/Paper1194/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce the NLC, a metric that is cheap to compute in the networks randomly initialized state and is highly predictive of generalization, at least in fully-connected networks.", "pdf": "/pdf/dc9b613ffbc3bff15f05169e6affddedc3bffd82.pdf", "paperhash": "anonymous|the_nonlinearity_coefficient_predicting_generalization_in_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Nonlinearity Coefficient - Predicting Generalization in Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeK-nRcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byl9bhA5F7", "original": "H1e0lGA9Fm", "number": 1195, "cdate": 1538087937532, "ddate": null, "tcdate": 1538087937532, "tmdate": 1538155971325, "tddate": null, "forum": "Byl9bhA5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Found by NEMO: Unsupervised Object Detection from Negative Examples and Motion", "abstract": "This paper introduces NEMO, an approach to unsupervised object detection that uses motion---instead of image labels---as a cue to learn object detection. To discriminate between motion of the target object and other changes in the image, it relies on negative examples that show the scene without the object. The required data can be collected very easily by recording two short videos, a positive one showing the object in motion and a negative one showing the scene without the object. Without any additional form of pretraining or supervision and despite of occlusions, distractions, camera motion, and adverse lighting, those videos are sufficient to learn object detectors that can be applied to new videos and even generalize to unseen scenes and camera angles. In a baseline comparison, unsupervised object detection outperforms off-the shelf template matching and tracking approaches that are given an initial bounding box of the object. The learned object representations are also shown to be accurate enough to capture the relevant information from manipulation task demonstrations, which makes them applicable to learning from demonstration in robotics. An example of object detection that was learned from 3 minutes of video can be found here: http://y2u.be/u_jyz9_ETz4", "keywords": ["unsupervised learning", "computer vision", "object detection"], "authorids": ["ICLR.cc/2019/Conference/Paper1195/Authors"], "authors": ["Anonymous"], "TL;DR": "Learning to detect objects without image labels from 3 minutes of video", "pdf": "/pdf/dc309db3eb610e78d83e4f3603a0edc894269939.pdf", "paperhash": "anonymous|found_by_nemo_unsupervised_object_detection_from_negative_examples_and_motion", "_bibtex": "@inproceedings{    \nanonymous2019found,    \ntitle={Found by NEMO: Unsupervised Object Detection from Negative Examples and Motion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byl9bhA5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1g5b2RcKm", "original": "HylKVmpcKQ", "number": 1196, "cdate": 1538087937698, "ddate": null, "tcdate": 1538087937698, "tmdate": 1538155971114, "tddate": null, "forum": "r1g5b2RcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "MLPrune: Multi-Layer Pruning for Automated Neural Network Compression", "abstract": "Model compression can significantly reduce the computation and memory footprint of large neural networks. To achieve a good trade-off between model size and accuracy, popular compression techniques usually rely on hand-crafted heuristics and\nrequire manually setting the compression ratio of each layer. This process is typically costly and suboptimal. In this paper, we propose a Multi-Layer Pruning method (MLPrune), which is theoretically sound, and can automatically decide appropriate compression ratios for all layers. Towards this goal, we use an efficient approximation of the Hessian as our pruning criterion, based on a Kronecker-factored Approximate Curvature method. We demonstrate the effectiveness of our method on several datasets and architectures, outperforming previous state-of-the-art by a large margin. Our experiments show that we can compress AlexNet and VGG16 by 25x without loss in accuracy on ImageNet. Furthermore, our method has much fewer hyper-parameters and requires no expert knowledge.", "keywords": ["Automated Model Compression", "Neural Network Pruning"], "authorids": ["ICLR.cc/2019/Conference/Paper1196/Authors"], "authors": ["Anonymous"], "TL;DR": "MLPrune: an automated pruning method that doesn't require any tuning for per-layer compression ratio, achieves state-of-the-art pruning results on AlexNet and VGG16.", "pdf": "/pdf/4efefe3d17702e4b5703d91ee93576371f2bdbc3.pdf", "paperhash": "anonymous|mlprune_multilayer_pruning_for_automated_neural_network_compression", "_bibtex": "@inproceedings{    \nanonymous2019mlprune:,    \ntitle={MLPrune: Multi-Layer Pruning for Automated Neural Network Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g5b2RcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1e9W3AqFX", "original": "SylX-1TqFm", "number": 1197, "cdate": 1538087937863, "ddate": null, "tcdate": 1538087937863, "tmdate": 1538155970907, "tddate": null, "forum": "B1e9W3AqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-task Learning with Gradient Communication", "abstract": "  In this paper, we describe a general framework to systematically analyze current neural models for multi-task learning, in which we find that existing models expect to disentangle features into different spaces while features learned in practice are still entangled in shared space,  leaving potential hazards for other training or unseen tasks. We propose to alleviate this problem by incorporating a new inductive bias into the process of multi-task learning, that different tasks can communicate with each other not only by passing hidden variables but gradients explicitly. Experimentally, we evaluate proposed methods on three groups of tasks and two types of settings (\\textsc{in-task} and \\textsc{out-of-task}). Quantitative and qualitative results show their effectiveness.", "keywords": ["Pretend to share", "Gradient Communication"], "authorids": ["ICLR.cc/2019/Conference/Paper1197/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce an inductive bias for multi-task learning, allowing different tasks to communicate by gradient passing.", "pdf": "/pdf/8478230b29614f80aff59b693ef929fd7b77a547.pdf", "paperhash": "anonymous|multitask_learning_with_gradient_communication", "_bibtex": "@inproceedings{    \nanonymous2019multi-task,    \ntitle={Multi-task Learning with Gradient Communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e9W3AqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lqZhRcFm", "original": "S1gDB8ocF7", "number": 1198, "cdate": 1538087938037, "ddate": null, "tcdate": 1538087938037, "tmdate": 1538155970689, "tddate": null, "forum": "H1lqZhRcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Learning of the Set of Local Maxima", "abstract": "This paper describes a new form of unsupervised learning, whose input is a set of unlabeled points that are assumed to be local maxima of an unknown value function in an unknown subset of the vector space. Two functions are learned: (i) a set indicator c, which is a binary classifier, and (ii) a comparator function h that given two nearby samples, predicts which sample has the higher value. Loss terms are used to ensure that all training samples x are a local maxima, according to h and satisfy c(x)=1. Therefore, c and h provide training signals to each other: a point x' in the vicinity of x satisfies c(x)=-1 or is deemed by h to be lower in value than x. We present an algorithm, show an example where it is more efficient to use local maxima as an indicator function than to employ conventional classification, and derive a suitable generalization bound. Our experiments show that the method is able to outperform one-class classification algorithms in the task of anomaly detection and also provide an additional signal that is extracted in a completely unsupervised way.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1198/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/17dcde260180e9b7d9344ec145782e1fa60e2859.pdf", "paperhash": "anonymous|unsupervised_learning_of_the_set_of_local_maxima", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Learning of the Set of Local Maxima},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lqZhRcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJf9ZhC9FX", "original": "rkgx2_pcYX", "number": 1199, "cdate": 1538087938212, "ddate": null, "tcdate": 1538087938212, "tmdate": 1538155970477, "tddate": null, "forum": "HJf9ZhC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization", "abstract": "Stochastic descent methods (of the gradient and mirror varieties) have become increasingly popular in optimization. In fact, it is now widely recognized that the success of deep learning is not only due to the special deep architecture of the models, but also due to the behavior of the stochastic descent methods used, which play a key role in reaching \"good\" solutions that generalize well to unseen data. In an attempt to shed some light on why this is the case, we revisit some minimax properties of stochastic gradient descent (SGD) for the square loss of linear models---originally developed in the 1990's---and extend them to \\emph{general} stochastic mirror descent (SMD) algorithms for \\emph{general} loss functions and \\emph{nonlinear} models. \nIn particular, we show that there is a fundamental identity which holds for SMD (and SGD) under very general conditions, and which implies the minimax optimality of SMD (and SGD) for sufficiently small step size, and for a general class of loss functions and general nonlinear models.\nWe further show that this identity can be used to naturally establish other properties of SMD (and SGD), namely convergence and \\emph{implicit regularization} for over-parameterized linear models (in what is now being called the \"interpolating regime\"), some of which have been shown in certain cases in prior literature. We also argue how this identity can be used in the so-called \"highly over-parameterized\" nonlinear setting (where the number of parameters far exceeds the number of data points) to provide insights into why SMD (and SGD) may have similar convergence and implicit regularization properties for deep learning. ", "keywords": ["optimization", "stochastic gradient descent", "mirror descent", "implicit regularization", "deep learning theory"], "authorids": ["ICLR.cc/2019/Conference/Paper1199/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5f3d914d6acdc1c80430ab33ad92a06577aa9a55.pdf", "paperhash": "anonymous|stochastic_gradientmirror_descent_minimax_optimality_and_implicit_regularization", "_bibtex": "@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJf9ZhC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byf5-30qFX", "original": "HkxI2fjct7", "number": 1200, "cdate": 1538087938376, "ddate": null, "tcdate": 1538087938376, "tmdate": 1538155970265, "tddate": null, "forum": "Byf5-30qFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DHER: Hindsight Experience Replay for Dynamic Goals", "abstract": "Dealing with sparse rewards is one of the most important challenges in reinforcement learning (RL), especially when a goal is dynamic (e.g., to grasp a moving object). Hindsight experience replay (HER) has been shown an effective solution to handling  sparse rewards with fixed goals. However, it does not account for dynamic goals in its vanilla form and, as a result, even degrades the performance of existing off-policy RL algorithms when the goal is changing over time. \n\nIn this paper, we present Dynamic Hindsight Experience Replay (DHER), a novel approach for tasks with dynamic goals and sparse rewards. DHER automatically assembles successful experiences from two relevant failures and learns a reliable policy to achieve the dynamic goals. We evaluate DHER on tasks of robotic manipulation and moving object tracking, and transfer the polices from simulation to physical robots. Extensive comparison and ablation studies demonstrate  the superiority of our approach, showing that DHER is a crucial ingredient to enable RL to solve tasks with dynamic goals.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1200/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b63ed34061b6887a5471e776815fde01d65ca056.pdf", "paperhash": "anonymous|dher_hindsight_experience_replay_for_dynamic_goals", "_bibtex": "@inproceedings{    \nanonymous2019dher:,    \ntitle={DHER: Hindsight Experience Replay for Dynamic Goals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byf5-30qFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJei-2RcK7", "original": "SJlCT10cYQ", "number": 1201, "cdate": 1538087938543, "ddate": null, "tcdate": 1538087938543, "tmdate": 1538155970050, "tddate": null, "forum": "HJei-2RcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Transformer ", "abstract": "Graph neural networks (GNN) have gained increasing research interests as a mean to the challenging goal of robust and universal graph learning. Previous GNNs have assumed single pre-fixed graph structure and permitted only local context encoding. This paper proposes a novel Graph Transformer (GTR) architecture that captures long-range dependency with global attention, and enables dynamic graph structures. In particular, GTR propagates features within the same graph structure via an intra-graph message passing, and transforms dynamic semantics across multi-domain graph-structured data (e.g. images, sequences, knowledge graphs) for multi-modal learning via an inter-graph message passing. Furthermore, GTR enables effective incorporation of any prior graph structure by weighted averaging of the prior and learned edges, which can be crucially useful for scenarios where prior knowledge is desired. The proposed GTR achieves new state-of-the-arts across three benchmark tasks, including few-shot learning, medical abnormality and disease classification, and graph classification. Experiments show that GTR is superior in learning robust graph representations, transforming high-level semantics across domains, and bridging between prior graph structure with automatic structure learning.  ", "keywords": ["Graph neural networks", "transformer", "attention"], "authorids": ["ICLR.cc/2019/Conference/Paper1201/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3a7848ff8d3363d0cd1fe59c2c7d9fdb9c1a688e.pdf", "paperhash": "anonymous|graph_transformer", "_bibtex": "@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Transformer },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJei-2RcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyesW2C9YQ", "original": "ryg45Aa5F7", "number": 1202, "cdate": 1538087938724, "ddate": null, "tcdate": 1538087938724, "tmdate": 1538155969839, "tddate": null, "forum": "HyesW2C9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "I Know the Feeling: Learning to Converse with Empathy", "abstract": "Beyond understanding what is being discussed, human communication requires an awareness of what someone is feeling. One challenge for dialogue agents is being able to recognize feelings in the conversation partner and reply accordingly, a key communicative skill that is trivial for humans. Research in this area is made difficult by the paucity of large-scale publicly available datasets both for emotion and relevant dialogues. This work proposes a new task for empathetic dialogue generation and EmpatheticDialogues, a dataset of 25k conversations grounded in emotional contexts to facilitate training and evaluating dialogue systems. Our experiments indicate that models explicitly leveraging emotion predictions from previous utterances are perceived to be more empathetic by human evaluators, while improving on other metrics as well (e.g. perceived relevance of responses, BLEU scores).", "keywords": ["dialogue generation", "nlp applications", "grounded text  generation", "contextual representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1202/Authors"], "authors": ["Anonymous"], "TL;DR": "We improve existing dialogue systems for responding to people sharing personal stories, incorporating emotion prediction representations and also release a new benchmark and dataset of empathetic dialogues.", "pdf": "/pdf/52b062707a776ca2357e1997e2b84f119f5f1e54.pdf", "paperhash": "anonymous|i_know_the_feeling_learning_to_converse_with_empathy", "_bibtex": "@inproceedings{    \nanonymous2019i,    \ntitle={I Know the Feeling: Learning to Converse with Empathy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyesW2C9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1eiZnAqKm", "original": "SklIyVT5Ym", "number": 1203, "cdate": 1538087938890, "ddate": null, "tcdate": 1538087938890, "tmdate": 1538155969628, "tddate": null, "forum": "H1eiZnAqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Expressive Power of Gated Recurrent Units as a Continuous Dynamical System", "abstract": "Gated recurrent units (GRUs) were inspired by the common gated recurrent unit, long short-term\nmemory (LSTM), as a means of capturing temporal structure with less complex memory unit architecture.\nDespite their incredible success in tasks such as natural and artificial language processing,\nspeech, video, and polyphonic music, very little is understood about the specific dynamic features\nrepresentable in a GRU network. As a result, it is difficult to know a priori how successful a GRU-RNN\nwill perform on a given data set. In this paper, we develop a new theoretical framework to\nanalyze one and two dimensional GRUs as a continuous dynamical system, and classify the dynamic\nfeatures obtainable with such system. In addition, we show that a two dimensional GRU\ncannot mimic the dynamics of a ring attractor, or more generally, any line attractor without near\nzero constant curvature in phase space. These results were then experimentally verified by means of\ntime series prediction.", "keywords": ["Gated Recurrent Units", "Recurrent Neural Network", "Time Series Predictions", "interpretable", "Nonlinear Dynamics", "Dynamical Systems"], "authorids": ["ICLR.cc/2019/Conference/Paper1203/Authors"], "authors": ["Anonymous"], "TL;DR": "We classify the the dynamical features one and two GRU cells can and cannot capture in continuous time, and verify our findings experimentally with k-step time series prediction.", "pdf": "/pdf/42a57050f5e2349e781bbfef4ad9fdfc694f309a.pdf", "paperhash": "anonymous|the_expressive_power_of_gated_recurrent_units_as_a_continuous_dynamical_system", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Expressive Power of Gated Recurrent Units as a Continuous Dynamical System},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eiZnAqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1liWh09F7", "original": "B1lKC-j9KX", "number": 1204, "cdate": 1538087939058, "ddate": null, "tcdate": 1538087939058, "tmdate": 1538155969413, "tddate": null, "forum": "B1liWh09F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SALSA-TEXT : SELF ATTENTIVE LATENT SPACE BASED ADVERSARIAL TEXT GENERATION", "abstract": "Inspired by the success of self attention mechanism and Transformer architecture\nin sequence transduction and image generation applications, we propose novel self\nattention-based architectures to improve the performance of adversarial latent code-\nbased schemes in text generation. Adversarial latent code-based text generation\nhas recently gained a lot of attention due to their promising results. In this paper,\nwe take a step to fortify the architectures used in these setups, specifically AAE\nand ARAE. We benchmark two latent code-based methods (AAE and ARAE)\ndesigned based on adversarial setups. In our experiments, the Google sentence\ncompression dataset is utilized to compare our method with these methods using\nvarious objective and subjective measures. The experiments demonstrate the\nproposed (self) attention-based models outperform the state-of-the-art in adversarial\ncode-based text generation.", "keywords": ["Self-attention", "Transformer", "generative adversarial networks", "GAN", "neural text generation", "NTG", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper1204/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a self-attention based GAN architecture for unconditional text generation and improve on previous adversarial code-based results.", "pdf": "/pdf/6fa73c4491eb49700d676f0b93ffb13957ac9f6d.pdf", "paperhash": "anonymous|salsatext_self_attentive_latent_space_based_adversarial_text_generation", "_bibtex": "@inproceedings{    \nanonymous2019salsa-text,    \ntitle={SALSA-TEXT : SELF ATTENTIVE LATENT SPACE BASED ADVERSARIAL TEXT GENERATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1liWh09F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJMjW3RqtX", "original": "r1eNyHhcFX", "number": 1205, "cdate": 1538087939221, "ddate": null, "tcdate": 1538087939221, "tmdate": 1538155969207, "tddate": null, "forum": "HJMjW3RqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL", "abstract": "Humans are experts at high-fidelity imitation -- closely mimicking a demonstration, often in one attempt. Humans use this ability to quickly solve a  task instance, and to bootstrap learning of new tasks. Achieving these abilities in autonomous agents is an open problem. In this paper, we introduce an off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn both (i) policies for high-fidelity one-shot imitation of diverse novel skills, and (ii) policies that enable the agent to solve tasks more efficiently than the demonstrators. MetaMimic relies on the principle of storing all experiences in a memory and replaying these to learn massive deep neural network policies by off-policy RL. This paper introduces, to the best of our knowledge, the largest existing neural networks for deep RL and shows that larger networks with normalization are needed to achieve one-shot high-fidelity imitation on a challenging manipulation task.\nThe results also show that both types of policy can be learned from vision, in spite of the task rewards being sparse, and without access to demonstrator actions. ", "keywords": ["Imitation Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1205/Authors"], "authors": ["Anonymous"], "TL;DR": "We present MetaMimic, an algorithm that takes as input a demonstration dataset and outputs (i) a one-shot high-fidelity imitation policy (ii) an unconditional task policy.", "pdf": "/pdf/34848bbbdaf97736acefe815555df81d55db8d2b.pdf", "paperhash": "anonymous|oneshot_highfidelity_imitation_training_largescale_deep_nets_with_rl", "_bibtex": "@inproceedings{    \nanonymous2019one-shot,    \ntitle={One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMjW3RqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkMiWhR5K7", "original": "S1xPwZ2YYQ", "number": 1206, "cdate": 1538087939394, "ddate": null, "tcdate": 1538087939394, "tmdate": 1538155968989, "tddate": null, "forum": "BkMiWhR5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors", "abstract": "We study the problem of generating adversarial examples in a black-box setting in which only loss-oracle access to a model is available. We introduce a framework that conceptually unifies much of the existing work on black-box attacks, and demonstrate that the current state-of-the-art methods are optimal in a natural sense. Despite this optimality, we show how to improve black-box attacks by bringing a new element into the problem: gradient priors. We give a bandit optimization-based algorithm that allows us to seamlessly integrate any such priors, and we explicitly identify and incorporate two examples. The resulting methods use two to four times fewer queries and fail two to six times less than the current state-of-the-art. The code for reproducing our work is available at https://git.io/fAjOJ.", "keywords": ["adversarial examples", "gradient estimation", "black-box attacks", "model-based optimization", "bandit optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1206/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a unifying view on black-box adversarial attacks as a gradient estimation problem, and then present a framework (based on bandits optimization) to integrate priors into gradient estimation, leading to significantly increased performance.", "pdf": "/pdf/915a3f23ece0af08b7755c64ca5dd1ebbee44aab.pdf", "paperhash": "anonymous|prior_convictions_blackbox_adversarial_attacks_with_bandits_and_priors", "_bibtex": "@inproceedings{    \nanonymous2019prior,    \ntitle={Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMiWhR5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lhbnRqF7", "original": "rJxsM4TqKX", "number": 1207, "cdate": 1538087939566, "ddate": null, "tcdate": 1538087939566, "tmdate": 1538155968769, "tddate": null, "forum": "S1lhbnRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["ICLR.cc/2019/Conference/Paper1207/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/49f782e9058edf091ac3baedde93e9f4246f1520.pdf", "paperhash": "anonymous|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{    \nanonymous2019building,    \ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lhbnRqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyghb2Rct7", "original": "BJlc-Z9qtQ", "number": 1208, "cdate": 1538087939732, "ddate": null, "tcdate": 1538087939732, "tmdate": 1538155968560, "tddate": null, "forum": "Hyghb2Rct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SIMILE: Introducing Sequential Information towards More Effective Imitation Learning", "abstract": "Reinforcement learning (RL) is a metaheuristic aiming at teaching an agent to interact with an environment and maximizing the reward in a complex task. RL algorithms often encounter the difficulty in defining a reward function in a sparse solution space. Imitation learning (IL) deals with this issue by providing a few expert demonstrations, and then either mimicking the expert's behavior (behavioral cloning, BC) or recovering the reward function by assuming the optimality of the expert (inverse reinforcement learning, IRL). Conventional IL approaches formulate the agent policy by mapping one single state to a distribution over actions, which did not consider sequential information. This strategy can be less accurate especially in IL, a weakly supervised learning environment, especially when the number of expert demonstrations is limited.\n\nThis paper presents an effective approach named Sequential IMItation LEarning (SIMILE). The core idea is to introduce sequential information, so that an agent can refer to both the current state and past state-action pairs to make a decision. We formulate our approach into a recurrent model, and instantiate it using LSTM so as to fuse both long-term and short-term information. SIMILE is a generalized IL framework which is easily applied to BL and IRL, two major types of IL algorithms. Experiments are performed on several robot controlling tasks in OpenAI Gym. SIMILE not only achieves performance gain over the baseline approaches, but also enjoys the benefit of faster convergence and better stability of testing performance. These advantages verify a higher learning efficiency of SIMILE, and implies its potential applications in real-world scenarios, i.e., when the agent-environment interaction is more difficult and/or expensive.", "keywords": ["Reinforcement Learning", "Imitation Learning", "Sequential Information"], "authorids": ["ICLR.cc/2019/Conference/Paper1208/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces sequential information to improve inverse reinforcement learning algorithms", "pdf": "/pdf/b095a3ad08413e428a99de63b23602810e353f6c.pdf", "paperhash": "anonymous|simile_introducing_sequential_information_towards_more_effective_imitation_learning", "_bibtex": "@inproceedings{    \nanonymous2019simile:,    \ntitle={SIMILE: Introducing Sequential Information towards More Effective Imitation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyghb2Rct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkl3-hA5Y7", "original": "S1lGWApqKX", "number": 1209, "cdate": 1538087939903, "ddate": null, "tcdate": 1538087939903, "tmdate": 1538155968348, "tddate": null, "forum": "rkl3-hA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards Decomposed Linguistic Representation with Holographic Reduced Representation", "abstract": "The vast majority of neural models in Natural Language Processing adopt a form of structureless distributed representations.  While these models are powerful at making predictions, the representational form is rather crude and does not provide insights into linguistic structures. In this paper we introduce novel language models with representations informed by the framework of Holographic Reduced Representation (HRR). This allows us to inject structures directly into our word-level and chunk-level representations.  Our analyses show that by using HRR as a structured compositional representation, our models are able to discover crude linguistic roles, which roughly resembles a classic division between syntax and semantics.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1209/Authors"], "authors": ["Anonymous"], "TL;DR": "Holographic Reduced Representation enables language model to discover linguistic roles.", "pdf": "/pdf/1f3b95a7c2fee0ff3bba0d21289763385a3593cc.pdf", "paperhash": "anonymous|towards_decomposed_linguistic_representation_with_holographic_reduced_representation", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Decomposed Linguistic Representation with Holographic Reduced Representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl3-hA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkfhZnC9t7", "original": "BkxXl7hcYm", "number": 1210, "cdate": 1538087940078, "ddate": null, "tcdate": 1538087940078, "tmdate": 1538155968133, "tddate": null, "forum": "BkfhZnC9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Zero-shot Learning for Speech Recognition with Universal Phonetic Model", "abstract": "There are more than 7,000 languages in the world, but due to the lack of training sets, only a small number of them have speech recognition systems. Multilingual speech recognition provides a solution if at least some audio training data is available. Often, however, phoneme inventories differ between the training languages and the target language, making this approach infeasible. In this work, we address the problem of building an acoustic model for languages with zero audio resources. Our model is able to recognize unseen phonemes in the target language, if only a small text corpus is available. We adopt the idea of zero-shot learning, and decompose phonemes into corresponding phonetic attributes such as vowel and consonant. Instead of predicting phonemes directly, we first predict distributions over phonetic attributes, and then compute phoneme distributions with a customized acoustic model. We extensively evaluate our model on 20 languages, and find that on average, it achieves 9.9% better phone error rate over the baseline model.\n", "keywords": ["zero-shot learning", "speech recognition", "acoustic modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper1210/Authors"], "authors": ["Anonymous"], "TL;DR": "We apply zero-shot learning for speech recognition to recognize unseen phonemes", "pdf": "/pdf/a326b4f07795aa98e522d3203aa49a621dd652eb.pdf", "paperhash": "anonymous|zeroshot_learning_for_speech_recognition_with_universal_phonetic_model", "_bibtex": "@inproceedings{    \nanonymous2019zero-shot,    \ntitle={Zero-shot Learning for Speech Recognition with Universal Phonetic Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkfhZnC9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxnZh0ct7", "original": "S1xHc_n5tQ", "number": 1211, "cdate": 1538087940245, "ddate": null, "tcdate": 1538087940245, "tmdate": 1538155967916, "tddate": null, "forum": "HyxnZh0ct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-learning with differentiable closed-form solvers", "abstract": "Adapting deep networks to new concepts from few examples is challenging, due to the high computational and data requirements of standard fine-tuning procedures.\nMost work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent.\nNonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently.\nIn this work we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning.\nThe main idea is to teach a deep network to use standard machine learning tools, such as logistic regression, as part of its own internal model, enabling it to quickly adapt to novel tasks.\nThis requires back-propagating errors through the solver steps.\nWhile normally the cost of the matrix operations involved in such process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage.\nWe propose both closed-form and iterative solvers, based on ridge regression and logistic regression components.\nOur methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.", "keywords": ["few-shot learning", "one-shot learning", "deep learning", "ridge regression"], "authorids": ["ICLR.cc/2019/Conference/Paper1211/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a simple meta-learning algorithm capable of adapting base learners such as ridge or logistic regression efficiently, by backpropagating through their closed-form solutions. We show strong performance on three few-shot learning benchmarks.", "pdf": "/pdf/160de9665b808312ec3eaf756146a25b46eede9f.pdf", "paperhash": "anonymous|metalearning_with_differentiable_closedform_solvers", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-learning with differentiable closed-form solvers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxnZh0ct7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklhb2R9Y7", "original": "BklTWdpctX", "number": 1212, "cdate": 1538087940419, "ddate": null, "tcdate": 1538087940419, "tmdate": 1538155967707, "tddate": null, "forum": "rklhb2R9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reinforced Imitation Learning from Observations", "abstract": "Imitation learning is an effective alternative approach to learn a policy when the reward function is sparse. In this paper, we consider a challenging setting where an agent has access to a sparse reward function and state-only expert observations. We propose a method which gradually balances between the imitation learning cost and the reinforcement learning objective.~Built upon an existing imitation learning method, our approach works with state-only observations. We show, through navigation scenarios, that (i) an agent is able to efficiently leverage sparse rewards to outperform standard state-only imitation learning, (ii) it can learn a policy even when learner's actions are different from the expert, and (iii) the performance of the agent is not bounded by that of the expert due to the optimized usage of sparse rewards.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1212/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7cdfca1d63ff1c60e780646e125daa1b155a9502.pdf", "paperhash": "anonymous|reinforced_imitation_learning_from_observations", "_bibtex": "@inproceedings{    \nanonymous2019reinforced,    \ntitle={Reinforced Imitation Learning from Observations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklhb2R9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgTZ3C5FX", "original": "BkgYsLU5t7", "number": 1213, "cdate": 1538087940590, "ddate": null, "tcdate": 1538087940590, "tmdate": 1538155967492, "tddate": null, "forum": "BJgTZ3C5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generative model based on minimizing exact empirical Wasserstein distance", "abstract": "Generative Adversarial Networks (GANs) are a very powerful framework for generative modeling. However, they are often hard to train, and learning of GANs often becomes unstable. Wasserstein GAN (WGAN) is a promising framework to deal with the instability problem as it has a good convergence property. One drawback of the WGAN is that it evaluates the Wasserstein distance in the dual domain, which requires some approximation, so that it may fail to optimize the true Wasserstein distance. In this paper, we propose evaluating the exact empirical optimal transport cost efficiently in the primal domain and performing gradient descent with respect to its derivative to train the generator network. Experiments on the MNIST dataset show that our method is significantly stable to converge, and achieves the lowest Wasserstein distance among the WGAN variants at the cost of some sharpness of generated images. Experiments on the 8-Gaussian toy dataset show that better gradients for the generator are obtained in our method. In addition, the proposed method enables more flexible generative modeling than WGAN.", "keywords": ["Generative modeling", "Generative Adversarial Networks (GANs)", "Wasserstein GAN", "Optimal transport"], "authorids": ["ICLR.cc/2019/Conference/Paper1213/Authors"], "authors": ["Anonymous"], "TL;DR": "We have proposed a flexible generative model that learns stably by directly minimizing exact empirical Wasserstein distance.", "pdf": "/pdf/5fe5e5faaf322cf8b055489acbe0b29c6b833fb4.pdf", "paperhash": "anonymous|generative_model_based_on_minimizing_exact_empirical_wasserstein_distance", "_bibtex": "@inproceedings{    \nanonymous2019generative,    \ntitle={Generative model based on minimizing exact empirical Wasserstein distance},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgTZ3C5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rklaWn0qK7", "original": "HJlk5EpcYQ", "number": 1214, "cdate": 1538087940765, "ddate": null, "tcdate": 1538087940765, "tmdate": 1538155967279, "tddate": null, "forum": "rklaWn0qK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Neural PDE Solvers with Convergence Guarantees", "abstract": "Partial differential equations (PDEs) are widely used across the physical and computational sciences. Decades of research and engineering went into designing fast iterative solution methods. Existing solvers are general purpose, but may be sub-optimal for specific classes of problems. In contrast to existing hand-crafted solutions, we propose an approach to learn a fast iterative solver tailored to a specific domain. We achieve this goal by learning to modify the updates of an existing solver using a deep neural network. Crucially, our approach is proven to preserve strong correctness and convergence guarantees. After training on a single geometry, our model generalizes to a wide variety of geometries and boundary conditions, and achieves 2-3 times speedup compared to state-of-the-art solvers.", "keywords": ["Partial differential equation", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1214/Authors"], "authors": ["Anonymous"], "TL;DR": "We learn a fast neural solver for PDEs that has convergence guarantees.", "pdf": "/pdf/5d43056428ee97ca74c5a1758c9fb7a0332395ff.pdf", "paperhash": "anonymous|learning_neural_pde_solvers_with_convergence_guarantees", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Neural PDE Solvers with Convergence Guarantees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklaWn0qK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGpW3C5KX", "original": "HJgpxmT9FX", "number": 1215, "cdate": 1538087940934, "ddate": null, "tcdate": 1538087940934, "tmdate": 1538155967059, "tddate": null, "forum": "SkGpW3C5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Heated-Up Softmax Embedding", "abstract": "Metric learning aims at learning a distance which is consistent with the semantic meaning of the samples. The problem is generally solved by learning an embedding, such that the samples of the same category are close (compact) while samples from different categories are far away (spread-out) in the embedding space. One popular way of generating such embeddings is to use the second-to-last layer of a deep neural network trained as a classifier with the softmax cross-entropy loss. In this paper, we show that training classifiers with different temperatures of the softmax function lead to different distributions of the embedding space. And finding a balance between the compactness, 'spread-out' and the generalization ability of the feature is critical in metric learning. Leveraging these insights, we propose a 'heating-up' strategy to train a classifier with increasing temperatures. Extensive experiments show that the proposed method achieves state-of-the-art embeddings on a variety of metric learning benchmarks. ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1215/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f3d00b63bef3d368d2757c2c40b7982781ff6398.pdf", "paperhash": "anonymous|heatedup_softmax_embedding", "_bibtex": "@inproceedings{    \nanonymous2019heated-up,    \ntitle={Heated-Up Softmax Embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGpW3C5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1M6Z2Cctm", "original": "HklRMC_FYm", "number": 1216, "cdate": 1538087941110, "ddate": null, "tcdate": 1538087941110, "tmdate": 1538155966843, "tddate": null, "forum": "S1M6Z2Cctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Harmonic Unpaired Image-to-image Translation", "abstract": "The recent direction of unpaired image-to-image translation is on one hand very exciting as it alleviates the big burden in obtaining label-intensive pixel-to-pixel supervision, but it is on the other hand not fully satisfactory due to the presence of artifacts and degenerated transformations. In this paper, we take a manifold view of the problem by introducing a smoothness constraint over the sample graph to attain harmonic functions to enforce consistent mappings during the translation. We develop HarmonicGAN to learn bi-directional translations between the source and the target domain. With the help of similarity-consistency, the inherent self-consistency property of samples can be maintained. Distance metrics defined on two types of features including histogram and CNN are exploited. Under an identical problem setting as CycleGAN without additional manual inputs, HarmonicGAN demonstrates a significant qualitative and quantitative improvement over the state of the art, as well as improved interpretability. We show experimental results in a number of applications including medical imaging, object transfiguration, and semantic labeling. We outperform the competing methods in all tasks, and for a medical imaging task in particular our method turns CycleGAN from a failure to a success, halving the mean-squared error, and generating images that radiologists prefer over competing methods in 95% of cases.", "keywords": ["unpaired image-to-image translation", "cyclegan", "smoothness constraint"], "authorids": ["ICLR.cc/2019/Conference/Paper1216/Authors"], "authors": ["Anonymous"], "TL;DR": "Smooth regularization over sample graph for unpaired image-to-image translation results in significantly improved consistency", "pdf": "/pdf/400b3e523a2f82db22d804c457c7aae337aafb40.pdf", "paperhash": "anonymous|harmonic_unpaired_imagetoimage_translation", "_bibtex": "@inproceedings{    \nanonymous2019harmonic,    \ntitle={Harmonic Unpaired Image-to-image Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1M6Z2Cctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gabhRcYX", "original": "BkllYFTqYm", "number": 1217, "cdate": 1538087941275, "ddate": null, "tcdate": 1538087941275, "tmdate": 1538155966632, "tddate": null, "forum": "B1gabhRcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BA-Net: Dense Bundle Adjustment Networks", "abstract": "This paper introduces a network architecture to solve the structure-from-motion (SfM) problem via feature bundle adjustment (BA), which explicitly enforces multi-view geometry constraints in the form of feature reprojection error. The whole pipeline is differentiable so that the network can learn suitable feature representations that make the BA problem more tractable. Furthermore, this work introduces a novel depth parameterization to recover dense per-pixel depth. The network first generates some bases depth maps according to the input image and optimizes the final depth as a linear combination of these bases via feature BA. The bases depth map generator is also learned via end-to-end training. \nThe whole system nicely combines domain knowledge (i.e. hard-coded multi-view geometry constraints) and machine learning (i.e. feature learning and basis depth map generator learning) to address the challenging SfM problem. Experiments on large scale real data prove the success of the proposed method.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1217/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper introduces a network architecture to solve the structure-from-motion (SfM) problem via feature bundle adjustment (BA)", "pdf": "/pdf/9268df439f6f9254123b75946675c6683ec0611f.pdf", "paperhash": "anonymous|banet_dense_bundle_adjustment_networks", "_bibtex": "@inproceedings{    \nanonymous2019ba-net:,    \ntitle={BA-Net: Dense Bundle Adjustment Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gabhRcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryeaZhRqFm", "original": "Syesige5FX", "number": 1218, "cdate": 1538087941445, "ddate": null, "tcdate": 1538087941445, "tmdate": 1538155966416, "tddate": null, "forum": "ryeaZhRqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Link Prediction in Hypergraphs using Graph Convolutional Networks", "abstract": "Link prediction in simple graphs is a fundamental problem in which new links between nodes are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among nodes which go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Even though Graph Convolutional Networks (GCN) have recently emerged as a powerful deep learning-based approach for link prediction over simple graphs, their suitability for link prediction in hypergraphs is unexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs. We propose two variants of NHP --NHP-U and NHP-D -- for link prediction over undirected and directed hypergraphs, respectively. To the best of our knowledge, NHP-D is the first method for link prediction over directed hypergraphs. Through extensive experiments on multiple real-world datasets, we show NHP's effectiveness.", "keywords": ["Graph convolution", "hypergraph", "hyperlink prediction"], "authorids": ["ICLR.cc/2019/Conference/Paper1218/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Neural Hyperlink Predictor (NHP). NHP adapts graph convolutional networks for link prediction in hypergraphs", "pdf": "/pdf/b8630d71eb258b12f8ec5c57fecd03ded7aad4db.pdf", "paperhash": "anonymous|link_prediction_in_hypergraphs_using_graph_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019link,    \ntitle={Link Prediction in Hypergraphs using Graph Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeaZhRqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lCbhAqKX", "original": "B1xB2aaqFQ", "number": 1219, "cdate": 1538087941619, "ddate": null, "tcdate": 1538087941619, "tmdate": 1538155966207, "tddate": null, "forum": "S1lCbhAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Structured Content Preservation for Unsupervised Text Style Transfer", "abstract": "Text style transfer aims to modify the style of a sentence while keeping its content unchanged. Recent style transfer systems often fail to faithfully preserve the content after changing the style. This paper proposes a structured content preserving model that leverages linguistic information in the structured fine-grained supervisions to better preserve the style-independent content \\footnote{Henceforth, we refer to style-independent content as content, for simplicity.} during style transfer. In particular, we achieve the goal by devising rich model objectives based on both the sentence's lexical information and a language model that conditions on content. The resulting model therefore is encouraged to retain the semantic meaning of the target sentences. We perform extensive experiments that compare our model to other existing approaches in the tasks of sentiment and political slant transfer. Our model achieves significant improvement in terms of both content preservation and style transfer in automatic and human evaluation.", "keywords": ["Unsupervised text style transfer"], "authorids": ["ICLR.cc/2019/Conference/Paper1219/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c520ef8b60693cf7f2edc44f109207a3aaa10537.pdf", "paperhash": "anonymous|structured_content_preservation_for_unsupervised_text_style_transfer", "_bibtex": "@inproceedings{    \nanonymous2019structured,    \ntitle={Structured Content Preservation for Unsupervised Text Style Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lCbhAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1e0-30qKm", "original": "BJxzYbO5F7", "number": 1220, "cdate": 1538087941800, "ddate": null, "tcdate": 1538087941800, "tmdate": 1538155965985, "tddate": null, "forum": "H1e0-30qKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unlabeled Disentangling of GANs with Guided Siamese Networks", "abstract": "Adversarial learning has greatly improved the abilities of generative models to learn from data (e.g. images) and generate convincing data samples by sampling from simple latent noise distributions. However, applications which could benefit from this generative power, such as image manipulation, are hindered by the lack of controlling specific interpretable factors in the latent space of the learned models. Guiding the sampling process to produce sample variation which is semantically disentangled and meaningful for humans is not possible with current generative models unless large amounts of attribute labelled data are available. In this paper, we propose Unlabeled Disentangling GAN (UD-GAN), which decomposes the latent noise space into semantically meaningful dimensions, using only weak supervision, and without using labels or explicit attributes. When we sample a new data point we can independently control each latent noise slice of UD-GAN and manipulate in a targeted fashion the properties of generated data. Our contributions encompass the introduction of our novel architecture combining an adversarial with contrastive loss, an analysis and probabilistic interpretation of the loss function, and multiple experiments to illustrate the capabilities of our method.", "keywords": ["GAN", "disentange", "siamese networks", "semantic"], "authorids": ["ICLR.cc/2019/Conference/Paper1220/Authors"], "authors": ["Anonymous"], "TL;DR": "We use Siamese Networks to control and disentangle the generation process in GANs without labeled data.", "pdf": "/pdf/bb273ab05040107e6d65e5373e8318cc4290e701.pdf", "paperhash": "anonymous|unlabeled_disentangling_of_gans_with_guided_siamese_networks", "_bibtex": "@inproceedings{    \nanonymous2019unlabeled,    \ntitle={Unlabeled Disentangling of GANs with Guided Siamese Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1e0-30qKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xRW3A9YX", "original": "BkeNpqTttm", "number": 1221, "cdate": 1538087941982, "ddate": null, "tcdate": 1538087941982, "tmdate": 1538155965769, "tddate": null, "forum": "r1xRW3A9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Riemannian TransE: Multi-relational Graph Embedding in Non-Euclidean Space", "abstract": "Multi-relational graph embedding has wide applications for social network analysis, recommendation systems, and knowledge base completion. The problem is to obtain embeddings that are beneficial for tasks with low-dimensional parameters.\nThis paper proposes a novel framework, called Riemannian TransE for multi-relational graph embedding. \nOur method realizes embedding in non-Euclidean space, where the loss function is based on the distance.\nThus, our model can use a non-Euclidean space that has good compatibility with the data, and achieves good performance with low-dimensional parameters. \nAn evaluation on real knowledge base data shows that with an appropriate choice of manifold, our method achieves comparable accuracy in graph completion with low-dimensional parameters.\n", "keywords": ["Riemannian TransE", "graph embedding", "multi-relational graph", "Riemannian manifold", "TransE", "hyperbolic space", "sphere", "knowledge base"], "authorids": ["ICLR.cc/2019/Conference/Paper1221/Authors"], "authors": ["Anonymous"], "TL;DR": "We extended TransE in Riemannian manifolds. ", "pdf": "/pdf/0f41a3fdfdc3826dcaa495200e8bf21861a24fda.pdf", "paperhash": "anonymous|riemannian_transe_multirelational_graph_embedding_in_noneuclidean_space", "_bibtex": "@inproceedings{    \nanonymous2019riemannian,    \ntitle={Riemannian TransE: Multi-relational Graph Embedding in Non-Euclidean Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xRW3A9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1g0Z3A9Fm", "original": "S1l27ARYF7", "number": 1222, "cdate": 1538087942152, "ddate": null, "tcdate": 1538087942152, "tmdate": 1538155965557, "tddate": null, "forum": "H1g0Z3A9Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Supervised Community Detection with Line Graph Neural Networks", "abstract": "We study data-driven methods for community detection on graphs, an inverse problem that is typically solved in terms of the spectrum of certain operators or via posterior inference under certain probabilistic graphical models. Focusing on random graph families such as the stochastic block model, recent research has unified both approaches and identified both statistical and computational signal-to-noise detection thresholds. \nThis graph inference task can be recast as a node-wise graph classification problem, and, as such, computational detection thresholds can be studied in terms of learning within appropriate models. We present a novel family of Graph Neural Networks (GNNs) and show that they can reach those detection thresholds in a purely data-driven manner without access to the underlying generative models, and even \nimprove upon current computational thresholds in hard regimes. For that purpose, we propose to augment GNNs with the non-backtracking operator, defined on the line graph of edge adjacencies. We also perform the first analysis of optimization landscape on using GNNs to solve community detection problems, demonstrating that under certain simplifications and assumptions, the loss value at the local minima is close to the loss value at the global minimum/minima. Finally, the resulting model is also tested on real datasets, performing significantly better than previous models. \n", "keywords": ["community detection", "graph neural networks", "belief propagation", "energy landscape", "non-backtracking operator"], "authorids": ["ICLR.cc/2019/Conference/Paper1222/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.", "pdf": "/pdf/938029835478578edcd1b2a917d861f3189492e8.pdf", "paperhash": "anonymous|supervised_community_detection_with_line_graph_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019supervised,    \ntitle={Supervised Community Detection with Line Graph Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g0Z3A9Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyxAb30cY7", "original": "BJg7Ees5FQ", "number": 1223, "cdate": 1538087942316, "ddate": null, "tcdate": 1538087942316, "tmdate": 1538155965352, "tddate": null, "forum": "SyxAb30cY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Robustness May Be at Odds with Accuracy", "abstract": "We show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed in practice. Further, we argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits: the representations learned by robust models tend to align better with salient data characteristics and human perception.", "keywords": ["adversarial examples", "robust machine learning", "robust optimization", "deep feature representations"], "authorids": ["ICLR.cc/2019/Conference/Paper1223/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.", "pdf": "/pdf/2373293e5196ed7f0f668acaf55e2717d761bcdd.pdf", "paperhash": "anonymous|robustness_may_be_at_odds_with_accuracy", "_bibtex": "@inproceedings{    \nanonymous2019robustness,    \ntitle={Robustness May Be at Odds with Accuracy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxAb30cY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxA-h05KQ", "original": "BJe7XG05Ym", "number": 1224, "cdate": 1538087942480, "ddate": null, "tcdate": 1538087942480, "tmdate": 1538155965143, "tddate": null, "forum": "rJxA-h05KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Inhibited Softmax for Uncertainty Estimation in Neural Networks", "abstract": "We present a new method for uncertainty estimation and out-of-distribution detection in neural networks with softmax output. We extend softmax layer with an additional constant input. The corresponding additional output is able to represent the uncertainty of the network. The proposed method requires neither additional parameters nor multiple forward passes nor input preprocessing nor out-of-distribution datasets. We show that our method performs comparably to more computationally expensive methods and outperforms baselines on our experiments from image recognition and sentiment analysis domains.", "keywords": ["uncertainty  estimation", "out-of-distribution detection", "inhibited softmax"], "authorids": ["ICLR.cc/2019/Conference/Paper1224/Authors"], "authors": ["Anonymous"], "TL;DR": "Uncertainty estimation in a single forward pass without additional learnable parameters.", "pdf": "/pdf/72a13c7c4514a7933774cdb8c012b6fc07f61873.pdf", "paperhash": "anonymous|inhibited_softmax_for_uncertainty_estimation_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019inhibited,    \ntitle={Inhibited Softmax for Uncertainty Estimation in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxA-h05KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlyznAcFm", "original": "S1eS9Ea9tX", "number": 1225, "cdate": 1538087942646, "ddate": null, "tcdate": 1538087942646, "tmdate": 1538155964923, "tddate": null, "forum": "BJlyznAcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Advocacy Learning", "abstract": "We introduce advocacy learning, a novel supervised training scheme for classification problems. This training scheme applies to a framework consisting of two connected networks: 1) the Advocates, composed of one subnetwork per class, which take the input and provide a convincing class-conditional argument in the form of an attention map, and 2) a Judge, which predicts the inputs class label based on these arguments. Each Advocate aims to convince the Judge that the input example belongs to their corresponding class. In contrast to a standard network, in which all subnetworks are trained to jointly cooperate, we train the Advocates to competitively argue for their class, even when the input belongs to a different class. We also explore a variant, honest advocacy learning, where the Advocates are only trained on data corresponding to their class. Applied to several different classification tasks,  we show that advocacy learning can lead to small improvements in classification accuracy over an identical supervised baseline. Through a series of follow-up experiments, we analyze when and how Advocates improve discriminative performance. Though it may seem counter-intuitive, a framework in which subnetworks are trained to competitively provide evidence in support of their class shows promise, performing as well as or better than standard approaches. This provides a foundation for further exploration into the effect of competition and class-conditional representations.", "keywords": ["competition", "supervision", "deep learning", "adversarial", "debate"], "authorids": ["ICLR.cc/2019/Conference/Paper1225/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a method that encourages different components in a networks to compete, and show that this can improve attention quality.", "pdf": "/pdf/8d12979535562eb4f369c3bda11690464b3adb13.pdf", "paperhash": "anonymous|advocacy_learning", "_bibtex": "@inproceedings{    \nanonymous2019advocacy,    \ntitle={Advocacy Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlyznAcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklyMhCqYQ", "original": "rJefbka5t7", "number": 1226, "cdate": 1538087942827, "ddate": null, "tcdate": 1538087942827, "tmdate": 1538155964717, "tddate": null, "forum": "HklyMhCqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Super-Resolution via Conditional Implicit Maximum Likelihood Estimation", "abstract": "Single-image super-resolution (SISR) is a canonical problem with diverse applications. Leading methods like SRGAN produce images that contain various artifacts, such as high-frequency noise, hallucinated colours and shape distortions, which adversely affect the realism of the result. In this paper, we propose an alternative approach based on an extension of the method of Implicit Maximum Likelihood Estimation (IMLE). We demonstrate greater effectiveness at noise reduction and preservation of the original colours and shapes, yielding more realistic super-resolved images. ", "keywords": ["super-resolution"], "authorids": ["ICLR.cc/2019/Conference/Paper1226/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a new method for image super-resolution based on IMLE. ", "pdf": "/pdf/632cb2f452acf3a2b1f3c4e911514968f9a2bafb.pdf", "paperhash": "anonymous|superresolution_via_conditional_implicit_maximum_likelihood_estimation", "_bibtex": "@inproceedings{    \nanonymous2019super-resolution,    \ntitle={Super-Resolution via Conditional Implicit Maximum Likelihood Estimation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklyMhCqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyg1G2AqtQ", "original": "rkl05pFGKX", "number": 1227, "cdate": 1538087942994, "ddate": null, "tcdate": 1538087942994, "tmdate": 1538155964509, "tddate": null, "forum": "Hyg1G2AqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variance Reduction for Reinforcement Learning in Input-Driven Environments", "abstract": "We consider reinforcement learning in input-driven environments, where an exogenous, stochastic input process affects the dynamics of the system. Input processes arise in many applications, including queuing systems, robotics control with disturbances, and object tracking. Since the state dynamics and rewards depend on the input process, the state alone provides limited information for the expected future returns. Therefore, policy gradient methods with standard state-dependent baselines suffer high variance during training. We derive a bias-free, input-dependent baseline to reduce this variance, and analytically show its benefits over state-dependent baselines. We then propose a meta-learning approach to overcome the complexity of learning a baseline that depends on a long sequence of inputs. Our experimental results show that across environments from queuing systems, computer networks, and MuJoCo robotic locomotion, input-dependent baselines consistently improve training stability and result in better eventual policies.", "keywords": ["reinforcement learning", "policy gradient", "input-driven environments", "variance reduction", "baseline"], "authorids": ["ICLR.cc/2019/Conference/Paper1227/Authors"], "authors": ["Anonymous"], "TL;DR": "For environments dictated partially by external input processes, we derive an input-dependent baseline that provably reduces the variance for policy gradient methods and improves the policy performance in a wide range of RL tasks.", "pdf": "/pdf/dbf95c409fc18778f749704544bb32c417193ac9.pdf", "paperhash": "anonymous|variance_reduction_for_reinforcement_learning_in_inputdriven_environments", "_bibtex": "@inproceedings{    \nanonymous2019variance,    \ntitle={Variance Reduction for Reinforcement Learning in Input-Driven Environments},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyg1G2AqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1GkMhAqYm", "original": "SkewPbn5F7", "number": 1228, "cdate": 1538087943160, "ddate": null, "tcdate": 1538087943160, "tmdate": 1538155964299, "tddate": null, "forum": "r1GkMhAqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication", "abstract": "In this work, we propose a goal-driven collaborative task that contains language, vision, and action in a virtual environment as its core components. Specifically, we develop a Collaborative image-Drawing game between two agents, called CoDraw. Our game is grounded in a virtual world that contains movable clip art objects. The game involves two players: a Teller and a Drawer. The Teller sees an abstract scene containing multiple clip art pieces in a semantically meaningful configuration, while the Drawer tries to reconstruct the scene on an empty canvas using available clip art pieces. The two players communicate via two-way communication using natural language. We collect the CoDraw dataset of ~10K dialogs consisting of ~138K messages exchanged between human agents. We define protocols and metrics to evaluate the effectiveness of learned agents on this testbed, highlighting the need for a novel \"crosstalk\" condition which pairs agents trained independently on disjoint subsets of the training data for evaluation. We present models for our task, including simple but effective baselines and neural network approaches trained using a combination of imitation learning and goal-driven training. All models are benchmarked using both fully automated evaluation and by playing the game with live human agents.", "keywords": ["CoDraw", "collaborative drawing", "grounded language"], "authorids": ["ICLR.cc/2019/Conference/Paper1228/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a dataset, models, and training + evaluation protocols for a collaborative drawing task that allows studying goal-driven and perceptually + actionably grounded language generation and understanding. ", "pdf": "/pdf/18e93a65693a0baa1b04ad3336f3a7c0fda01943.pdf", "paperhash": "anonymous|codraw_collaborative_drawing_as_a_testbed_for_grounded_goaldriven_communication", "_bibtex": "@inproceedings{    \nanonymous2019codraw:,    \ntitle={CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GkMhAqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylkG20qYm", "original": "SkgWzyAcYQ", "number": 1229, "cdate": 1538087943324, "ddate": null, "tcdate": 1538087943324, "tmdate": 1538155964093, "tddate": null, "forum": "BylkG20qYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models", "abstract": "Adversarial examples have been shown to be an effective way of assessing the robustness of neural sequence-to-sequence (seq2seq) models, by applying perturbations to the input of a model leading to large degradation in performance. However, these perturbations are only indicative of a weakness in the model if they do not change the semantics of the input in a way that would change the expected output. Using the example of machine translation (MT), we propose a new evaluation framework for adversarial attacks on seq2seq models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general. Based on these findings, we propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, we show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance.", "keywords": ["Sequence-to-sequence", "adversarial attacks", "evaluation", "meaning preservation", "machine translation"], "authorids": ["ICLR.cc/2019/Conference/Paper1229/Authors"], "authors": ["Anonymous"], "TL;DR": "How you should evaluate adversarial attacks on seq2seq", "pdf": "/pdf/16396c476c971c95c871925a5f3131693be2fcc4.pdf", "paperhash": "anonymous|on_meaningpreserving_adversarial_perturbations_for_sequencetosequence_models", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylkG20qYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkekMnR5Ym", "original": "BkemFt6ctQ", "number": 1230, "cdate": 1538087943500, "ddate": null, "tcdate": 1538087943500, "tmdate": 1538155963871, "tddate": null, "forum": "HkekMnR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning Neural Bloom Filters", "abstract": "There has been a recent trend in training neural networks to replace data structures that have been crafted by hand, with an aim for faster execution, better accuracy, or greater compression.  In this setting, a neural data structure is instantiated by training a network over many epochs of its inputs until convergence. In many applications this expensive initialization is not practical, for example streaming algorithms --- where inputs are ephemeral and can only be inspected a small number of times.  In this paper we explore the learning of approximate set membership over a stream of data in one-shot via meta-learning. We propose a novel memory architecture, the Neural Bloom Filter, which we show to be more compressive than Bloom Filters and several existing memory-augmented neural networks in scenarios of skewed data or structured sets.", "keywords": ["meta-learning", "memory", "one-shot learning", "bloom filter", "set membership", "familiarity", "compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1230/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate the space efficiency of memory-augmented neural nets when learning set membership.", "pdf": "/pdf/f4e848658a4d7e83acae3fb84b1e80a70f50d5a4.pdf", "paperhash": "anonymous|metalearning_neural_bloom_filters", "_bibtex": "@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning Neural Bloom Filters},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkekMnR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygeznA9YX", "original": "S1ls-2a9KX", "number": 1231, "cdate": 1538087943663, "ddate": null, "tcdate": 1538087943663, "tmdate": 1538155963659, "tddate": null, "forum": "SygeznA9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Data Interpretation and Reasoning Over Scientific Plots", "abstract": "Data Interpretation is an important part of Quantitative Aptitude exams and requires an individual to answer questions grounded in plots such as bar charts, line graphs, scatter plots, \\textit{etc}. Recently, there has been an increasing interest in building models which can perform this task by learning from datasets containing triplets of the form \\{plot, question, answer\\}. Two such datasets have been proposed in the recent past which contain plots generated from synthetic data with limited (i) $x-y$ axes variables (ii) question templates and (iii) answer vocabulary and hence do not adequately capture the challenges posed by this task. To overcome these limitations of existing datasets, we introduce a new dataset containing $9.7$ million question-answer pairs grounded over $270,000$ plots with three main differentiators. First, the plots in our dataset contain a wide variety of realistic $x$-$y$ variables such as CO2 emission, fertility rate, \\textit{etc.} extracted from  real word data sources such as World Bank, government sites, \\textit{etc}. Second, the questions in our dataset are more complex as they are based on templates extracted from interesting questions asked by a crowd of workers using a fraction of these plots. Lastly, the answers in our dataset are not restricted to a small vocabulary and a large fraction of the answers seen at test time are not present in the training vocabulary. As a result, existing models for Visual Question Answering which largely use end-to-end models in a multi-class classification framework cannot be used for this task. We establish initial results on this dataset and emphasize the complexity of the task using a multi-staged modular pipeline with various sub-components to (i) extract relevant data from the plot and convert it to a semi-structured table (ii) combine the question with this table and use compositional semantic parsing to arrive at a logical form from which the answer can be derived. We believe that such a modular framework is the best way to go forward as it would enable the research community to independently make progress on all the sub-tasks involved in plot question answering.", "keywords": ["VQA", "Data Interpretation", "Parsing", "Object Detection"], "authorids": ["ICLR.cc/2019/Conference/Paper1231/Authors"], "authors": ["Anonymous"], "TL;DR": "We created a new dataset for data interpretation over plots and also propose a baseline for the same.", "pdf": "/pdf/f7650966e80b2718ccdad847dc1649795f4dc44c.pdf", "paperhash": "anonymous|data_interpretation_and_reasoning_over_scientific_plots", "_bibtex": "@inproceedings{    \nanonymous2019data,    \ntitle={Data Interpretation and Reasoning Over Scientific Plots},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygeznA9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxgz2R9t7", "original": "SJe0W6c5Ym", "number": 1232, "cdate": 1538087943837, "ddate": null, "tcdate": 1538087943837, "tmdate": 1538155963445, "tddate": null, "forum": "BJxgz2R9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach", "abstract": "Recent efforts to combine Representation Learning with Formal Methods, commonly known as the Neuro-Symbolic Methods, have given rise to a new trend of applying rich neural architectures to solve classical combinatorial optimization problems. In this paper, we propose a neural framework that can learn to solve the Circuit Satisfiability problem. Our framework is built upon two fundamental contributions: a rich embedding architecture that encodes the problem structure and an end-to-end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT problem. The experimental results show the superior out-of-sample generalization performance of our framework compared to the recently developed NeuroSAT method.", "keywords": ["Neuro-Symbolic Methods", "Circuit Satisfiability", "Neural SAT Solver", "Graph Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1232/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a neural framework that can learn to solve the Circuit Satisfiability problem from (unlabeled) circuit instances.", "pdf": "/pdf/892d621494841b138b46e4cf190a0632e29c978b.pdf", "paperhash": "anonymous|learning_to_solve_circuitsat_an_unsupervised_differentiable_approach", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxgz2R9t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkMlGnC9KQ", "original": "r1e1RJncY7", "number": 1233, "cdate": 1538087944009, "ddate": null, "tcdate": 1538087944009, "tmdate": 1538155963239, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "Despite their success, deep neural networks suffer from several drawbacks: they lack robustness to small changes of input data known as \"adversarial examples\" and training them with small amounts of annotated data is challenging.  In this work, we study the connection between regularization and robustness by viewing neural networks as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds.  These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization.  We study the obtained algorithms for learning on small datasets, learning adversarially robust models, and discuss implications for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/dca0d01664be6726ceea96213a3dbb4856f62fde.pdf", "paperhash": "anonymous|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Regularization and Robustness of Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkMlGnC9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1MeM2RcFm", "original": "rJxHiidqF7", "number": 1234, "cdate": 1538087944181, "ddate": null, "tcdate": 1538087944181, "tmdate": 1538155963027, "tddate": null, "forum": "S1MeM2RcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks", "abstract": "Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance. The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application. A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner\u2019s binary signature as inputs. The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit \u20180\u2019 and bit \u20181\u2019. Given the owner\u2019s watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks. The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss. To extract the WM, BlackMarks queries the model with the WM key images and decodes the owner\u2019s signature from the corresponding predictions using the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks\u2019 performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.", "keywords": ["Digital Watermarking", "IP Protection", "Deep Neural Networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1234/Authors"], "authors": ["Anonymous"], "TL;DR": "Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ", "pdf": "/pdf/c4b4f13d0cba7ac0db7e3239ce7f1b794a1131a6.pdf", "paperhash": "anonymous|blackmarks_blackbox_multibit_watermarking_for_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019blackmarks:,    \ntitle={BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1MeM2RcFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1VeG309Fm", "original": "rkgxNzCcK7", "number": 1235, "cdate": 1538087944354, "ddate": null, "tcdate": 1538087944354, "tmdate": 1538155962817, "tddate": null, "forum": "S1VeG309Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Teaching Machine How to Think by Natural Language: A study on Machine Reading Comprehension", "abstract": "Deep learning ends up as a black box, in which how it makes the decision cannot be directly understood by humans, let alone guide the reasoning process of deep network. In this work, we seek the possibility to guide the learning of network in reading comprehension task by natural language. Two approaches are proposed. In the first approach, the latent representation in the neural network is deciphered into text by a decoder; in the second approach, deep network uses text as latent representation. Human tutor provides ground truth for the output of the decoder or latent representation represented by text. On the bAbI QA tasks, we found that with the guidance on a few examples, the model can achieve the same performance with remarkably less training examples.", "keywords": ["Machine Reading Comprehension"], "authorids": ["ICLR.cc/2019/Conference/Paper1235/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cf7f29b037e500917b49650ad1a51ec4b09313af.pdf", "paperhash": "anonymous|teaching_machine_how_to_think_by_natural_language_a_study_on_machine_reading_comprehension", "_bibtex": "@inproceedings{    \nanonymous2019teaching,    \ntitle={Teaching Machine How to Think by Natural Language: A study on Machine Reading Comprehension},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1VeG309Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgbzhC5Ym", "original": "ryxoHTT5Fm", "number": 1236, "cdate": 1538087944520, "ddate": null, "tcdate": 1538087944520, "tmdate": 1538155962613, "tddate": null, "forum": "BJgbzhC5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NECST: Neural Joint Source-Channel Coding", "abstract": "For reliable transmission across a noisy communication channel, classical results from information theory show that it is asymptotically optimal to separate out the source and channel coding processes. However, this decomposition can fall short in the finite bit-length regime, as it requires non-trivial tuning of hand-crafted codes and assumes infinite computational power for decoding. In this work, we propose Neural Error Correcting and Source Trimming (NECST) codes to jointly learn the encoding and decoding processes in an end-to-end fashion. By adding noise into the latent codes to simulate the channel during training, we learn to both compress and error-correct given a fixed bit-length and computational budget. We obtain codes that are not only competitive against several capacity-approaching channel codes, but also learn useful robust representations of the data for downstream tasks such as classification. Finally, we learn an extremely fast neural decoder, yielding almost an order of magnitude in speedup compared to standard decoding methods based on iterative belief propagation. ", "keywords": ["joint source-channel coding", "deep generative models", "unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1236/Authors"], "authors": ["Anonymous"], "TL;DR": "jointly learn compression + error correcting codes with deep learning", "pdf": "/pdf/467382024015be4c8339c9cd132e6ed5b4ba778b.pdf", "paperhash": "anonymous|necst_neural_joint_sourcechannel_coding", "_bibtex": "@inproceedings{    \nanonymous2019necst:,    \ntitle={NECST: Neural Joint Source-Channel Coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgbzhC5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gWz2CcKX", "original": "HJlj3-E9KX", "number": 1237, "cdate": 1538087944748, "ddate": null, "tcdate": 1538087944748, "tmdate": 1538155962395, "tddate": null, "forum": "S1gWz2CcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural MMO: A massively multiplayer game environment for intelligent agents", "abstract": "We present an artificial intelligence research platform inspired by the human game genre of MMORPGs (Massively Multiplayer Online Role-Playing Games, a.k.a. MMOs). We demonstrate how this platform can be used to study behavior and learning in large populations of neural agents. Unlike currently popular game environments, our platform supports persistent environments, with variable number of agents, and open-ended task descriptions. The emergence of complex life on Earth is often attributed to the arms race that ensued from a huge number of organisms all competing for finite resources. Our platform aims to simulate this setting in microcosm: we conduct a series of experiments to test how large-scale multiagent competition can incentivize the development of skillful behavior. We find that population size magnifies the complexity of the behaviors that emerge and results in agents that out-compete agents trained in smaller populations.", "keywords": ["MMO", "Multiagent", "Game", "Reinforcement Learning", "Platform", "Framework", "Niche Formation", "Exploration"], "authorids": ["ICLR.cc/2019/Conference/Paper1237/Authors"], "authors": ["Anonymous"], "TL;DR": "An MMO-inspired research game platform for studying emergent behaviors of large populations in a complex environment", "pdf": "/pdf/c698be855cc6db286de1773e95caa8adc2ca671f.pdf", "paperhash": "anonymous|neural_mmo_a_massively_multiplayer_game_environment_for_intelligent_agents", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural MMO: A massively multiplayer game environment for intelligent agents},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gWz2CcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJzbG20cFQ", "original": "HkgSbMnIt7", "number": 1238, "cdate": 1538087944935, "ddate": null, "tcdate": 1538087944935, "tmdate": 1538155962184, "tddate": null, "forum": "BJzbG20cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards Metamerism via Foveated Style Transfer", "abstract": "The problem of visual metamerism is defined as finding a family of perceptually\nindistinguishable, yet physically different images. In this paper, we propose our\nNeuroFovea metamer model, a foveated generative model that is based on a mixture\nof peripheral representations and style transfer forward-pass algorithms. Our\ngradient-descent free model is parametrized by a foveated VGG19 encoder-decoder\nwhich allows us to encode images in high dimensional space and interpolate\nbetween the content and texture information with adaptive instance normalization\nanywhere in the visual field. Our contributions include: 1) A framework for\ncomputing metamers that resembles a noisy communication system via a foveated\nfeed-forward encoder-decoder network \u2013 We observe that metamerism arises as a\nbyproduct of noisy perturbations that partially lie in the perceptual null space; 2)\nA perceptual optimization scheme as a solution to the hyperparametric nature of\nour metamer model that requires tuning of the image-texture tradeoff coefficients\neverywhere in the visual field which are a consequence of internal noise; 3) An\nABX psychophysical evaluation of our metamers where we also find that the rate\nof growth of the receptive fields in our model match V1 for reference metamers\nand V2 between synthesized samples. Our model also renders metamers at roughly\na second, presenting a \u00d71000 speed-up compared to the previous work, which now\nallows for tractable data-driven metamer experiments.", "keywords": ["Metamerism", "foveation", "perception", "style transfer", "psychophysics"], "authorids": ["ICLR.cc/2019/Conference/Paper1238/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce a novel feed-forward framework to generate visual metamers", "pdf": "/pdf/d8e9c0fdef1e913e25b6acfd98208e7e9aafd60a.pdf", "paperhash": "anonymous|towards_metamerism_via_foveated_style_transfer", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Metamerism via Foveated Style Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJzbG20cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1GbfhRqF7", "original": "B1lhu3wUFm", "number": 1239, "cdate": 1538087945109, "ddate": null, "tcdate": 1538087945109, "tmdate": 1538155961974, "tddate": null, "forum": "r1GbfhRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Kernel Change-point Detection with Auxiliary Deep Generative Models", "abstract": "Detecting the emergence of abrupt property changes in time series is a challenging problem. Kernel two-sample test has been studied for this task which makes fewer assumptions on the distributions than traditional parametric approaches. However, selecting kernels is non-trivial in practice. Although kernel selection for the two-sample test has been studied, the insufficient samples in change point detection problem hinder the success of those developed kernel selection algorithms. In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model. With deep kernel parameterization, KL-CPD endows kernel two-sample test with the data-driven kernel to detect different types of change-points in real-world applications. The proposed approach significantly outperformed other state-of-the-art methods in our comparative evaluation of benchmark datasets and simulation studies.", "keywords": ["deep kernel learning", "generative models", "kernel two-sample test", "time series change-point detection"], "authorids": ["ICLR.cc/2019/Conference/Paper1239/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. ", "pdf": "/pdf/97c701f44f56beb1d2fadc0c01236e221adb720d.pdf", "paperhash": "anonymous|kernel_changepoint_detection_with_auxiliary_deep_generative_models", "_bibtex": "@inproceedings{    \nanonymous2019kernel,    \ntitle={Kernel Change-point Detection with Auxiliary Deep Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GbfhRqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyN-M2Rctm", "original": "rkxv5M_cKQ", "number": 1240, "cdate": 1538087945282, "ddate": null, "tcdate": 1538087945282, "tmdate": 1538155961759, "tddate": null, "forum": "HyN-M2Rctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mode Normalization", "abstract": "Normalization methods are a central building block in the deep learning toolbox. They accelerate and stabilize training, while decreasing the dependence on manually tuned learning rate schedules. When learning from multi-modal distributions, the effectiveness of batch normalization (BN), arguably the most prominent normalization method, is reduced. As a remedy, we propose a more flexible approach: by extending the normalization to more than a single mean and variance, we detect modes of data on-the-fly, jointly normalizing samples that share common features. We demonstrate that our method outperforms BN and other widely used normalization techniques in several experiments, including single and multi-task datasets.", "keywords": ["Deep Learning", "Expert Models", "Normalization", "Computer Vision"], "authorids": ["ICLR.cc/2019/Conference/Paper1240/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel normalization method for deep neural networks that is robust to multi-modalities in intermediate feature distributions.", "pdf": "/pdf/c1c188bd5eeb4e05b65cf4d0c74e0b5af3fe098f.pdf", "paperhash": "anonymous|mode_normalization", "_bibtex": "@inproceedings{    \nanonymous2019mode,    \ntitle={Mode Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyN-M2Rctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rk4Wf30qKQ", "original": "BylhVGR9KQ", "number": 1241, "cdate": 1538087945447, "ddate": null, "tcdate": 1538087945447, "tmdate": 1538155961542, "tddate": null, "forum": "rk4Wf30qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Security Analysis of Deep Neural Networks Operating in the Presence of Cache Side-Channel Attacks", "abstract": "Recent work has introduced attacks that extract the architecture information of deep neural networks (DNN), as this knowledge enhances an adversary\u2019s capability to conduct black-box attacks against the model. This paper presents the first in-depth security analysis of DNN fingerprinting attacks that exploit cache side-channels.  First, we define the threat model for these attacks:  our adversary does not need the ability to query the victim model; instead, she runs a co-located process on the host machine victim \u2019s deep learning  (DL) system is running and passively monitors the accesses of the target functions in the shared framework.  Second, we introduce DeepRecon, an attack that reconstructs the architecture of the victim network by using the internal information extracted via Flush+Reload, a cache side-channel technique. Once the attacker observes function invocations that map directly to architecture attributes of the victim network, the attacker can reconstruct the victim\u2019s entire network architecture.  In our evaluation, we demonstrate that an attacker can accurately reconstruct two complex networks (VGG19 and ResNet50) having only observed one forward propagation. Based on the extracted architecture attributes, we also demonstrate that an attacker can build a meta-model that accurately fingerprints the architecture and family of the pre-trained model in a transfer learning setting. From this meta-model,  we evaluate the importance of the observed attributes in the fingerprinting process. Third, we propose and evaluate new framework-level defense techniques that obfuscate our attacker\u2019s observations. Our empirical security analysis represents a step toward understanding the DNNs\u2019 vulnerability to cache side-channel attacks.", "keywords": ["DNN Security Analysis", "Fingerprinting Attacks", "Cache Side-Channel"], "authorids": ["ICLR.cc/2019/Conference/Paper1241/Authors"], "authors": ["Anonymous"], "TL;DR": "We conduct the first in-depth security analysis of DNN fingerprinting attacks that exploit cache side-channels, which represents a step toward understanding the DNN\u2019s vulnerability to side-channel attacks.", "pdf": "/pdf/1956563e1e67368e2362b74febaa42c41682de8a.pdf", "paperhash": "anonymous|security_analysis_of_deep_neural_networks_operating_in_the_presence_of_cache_sidechannel_attacks", "_bibtex": "@inproceedings{    \nanonymous2019security,    \ntitle={Security Analysis of Deep Neural Networks Operating in the Presence of Cache Side-Channel Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rk4Wf30qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkezfhA5Y7", "original": "rkezZeC5YX", "number": 1242, "cdate": 1538087945618, "ddate": null, "tcdate": 1538087945618, "tmdate": 1538155961322, "tddate": null, "forum": "HkezfhA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Rate-Distortion Theory of Adversarial Examples", "abstract": "The generalization ability of deep neural networks (DNNs) is interwined with model complexity, robustness and capacity.\nWe employ information theory to establish an equivalence between a DNN and a noisy communication channel,\nand obtain a notion of capacity that allows us characterize generalization behavior of DNNs for adversarial inputs.", "keywords": ["adversarial examples", "information bottleneck", "robustness"], "authorids": ["ICLR.cc/2019/Conference/Paper1242/Authors"], "authors": ["Anonymous"], "TL;DR": "We suggest that rate-distortion theory precisely characterizes the accuracy versus robustness to adversarial examples trade-off", "pdf": "/pdf/0473ef6e1e66d07d41c3d220889747183f55dc44.pdf", "paperhash": "anonymous|a_ratedistortion_theory_of_adversarial_examples", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Rate-Distortion Theory of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkezfhA5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJlfzhA9Y7", "original": "HJxAC-C5tX", "number": 1243, "cdate": 1538087945790, "ddate": null, "tcdate": 1538087945790, "tmdate": 1538155961113, "tddate": null, "forum": "rJlfzhA9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Distributed Deep Policy Gradient for Competitive Adversarial Environment", "abstract": "This work considers the problem of cooperative learners in partially observable, stochastic environment, receiving feedback in the form of joint reward. The paper presents a flexible multi-agent competitive environment for online training and direct policy performance comparison. This forms a formal problem of a multi-agent Reinforcement Learning (RL) under partial observability, where the goal is to maximize the score performance measured in a direct confrontation. To address the complexity of the problem we propose a distributed deep stochastic policy gradient with individual observations, experience replay, policy transfer, and self-play.", "keywords": ["multi-agent", "partially observable", "reinforcement learning", "deepRL", "self play", "competitive environment"], "authorids": ["ICLR.cc/2019/Conference/Paper1243/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/73466fd3e435fcb744ab600396b1afc1b4653374.pdf", "paperhash": "anonymous|distributed_deep_policy_gradient_for_competitive_adversarial_environment", "_bibtex": "@inproceedings{    \nanonymous2019distributed,    \ntitle={Distributed Deep Policy Gradient for Competitive Adversarial Environment},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlfzhA9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxMG209K7", "original": "rJeyrWA5K7", "number": 1244, "cdate": 1538087945970, "ddate": null, "tcdate": 1538087945970, "tmdate": 1538155960898, "tddate": null, "forum": "HkxMG209K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Alarm System for Segmentation Algorithm Based on Shape Model", "abstract": "It is usually hard for a learning system to predict correctly on the rare events, and there is no exception for segmentation algorithms. Therefore, we hope to build an alarm system to set off alarms when the segmentation result is possibly unsatisfactory. One plausible solution is to project the segmentation results into a low dimensional feature space, and then learn classifiers/regressors in the feature space to predict the qualities of segmentation results. In this paper, we form the feature space using shape feature which is a strong prior information shared among different data, so it is capable to predict the qualities of segmentation results given different segmentation algorithms on different datasets. The shape feature of a segmentation result is captured using the value of loss function when the segmentation result is tested using a Variational Auto-Encoder(VAE). The VAE is trained using only the ground truth masks, therefore the bad segmentation results with bad shapes become the rare events for VAE and will result in large loss value. By utilizing this fact, the VAE is able to detect all kinds of shapes that are out of the distribution of normal shapes in ground truth (GT). Finally, we learn the representation in the one-dimensional feature space to predict the qualities of segmentation results. We evaluate our alarm system on several recent segmentation algorithms for the medical segmentation task. The segmentation algorithms perform differently on different datasets, but our system consistently provides reliable prediction on the qualities of segmentation results.\n", "keywords": ["segmentation evaluation", "shape feature", "variational auto-encoder"], "authorids": ["ICLR.cc/2019/Conference/Paper1244/Authors"], "authors": ["Anonymous"], "TL;DR": "We use VAE to capture the shape feature for automatic segmentation evaluation", "pdf": "/pdf/691df8145f7ab9a2464b11146ecc364f8174a8f8.pdf", "paperhash": "anonymous|an_alarm_system_for_segmentation_algorithm_based_on_shape_model", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Alarm System for Segmentation Algorithm Based on Shape Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxMG209K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxMM2C5K7", "original": "r1guQco9Fm", "number": 1245, "cdate": 1538087946152, "ddate": null, "tcdate": 1538087946152, "tmdate": 1538155960686, "tddate": null, "forum": "rJxMM2C5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Nested Dithered Quantization for Communication Reduction in Distributed Training", "abstract": "In distributed training, the communication cost due to the transmission of gradients\nor the parameters of the deep model is a major bottleneck in scaling up the number\nof processing nodes. To address this issue, we propose dithered quantization for\nthe transmission of the stochastic gradients and show that training with Dithered\nQuantized Stochastic Gradients (DQSG) is similar to the training with unquantized\nSGs perturbed by an independent bounded uniform noise, in contrast to the other\nquantization methods where the perturbation depends on the gradients and hence,\ncomplicating the convergence analysis. We study the convergence of training\nalgorithms using DQSG and the trade off between the number of quantization\nlevels and the training time. Next, we observe that there is a correlation among the\nSGs computed by workers that can be utilized to further reduce the communication\noverhead without any performance loss. Hence, we develop a simple yet effective\nquantization scheme, nested dithered quantized SG (NDQSG), that can reduce the\ncommunication significantly without requiring the workers communicating extra\ninformation to each other. We prove that although NDQSG requires significantly\nless bits, it can achieve the same quantization variance bound as DQSG. Our\nsimulation results confirm the effectiveness of training using DQSG and NDQSG\nin reducing the communication bits or the convergence time compared to the\nexisting methods without sacrificing the accuracy of the trained model.", "keywords": ["machine learning", "distributed training", "dithered quantization", "nested quantization", "distributed compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1245/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper proposes and analyzes two quantization schemes for communicating Stochastic Gradients in distributed learning which would reduce communication costs compare to the state of the art while maintaining the same accuracy.  ", "pdf": "/pdf/c3b6766c0523c7a525928aca2b4f3cb21258a5c1.pdf", "paperhash": "anonymous|nested_dithered_quantization_for_communication_reduction_in_distributed_training", "_bibtex": "@inproceedings{    \nanonymous2019nested,    \ntitle={Nested Dithered Quantization for Communication Reduction in Distributed Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxMM2C5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByWMz305FQ", "original": "BklBHz09FQ", "number": 1246, "cdate": 1538087946320, "ddate": null, "tcdate": 1538087946320, "tmdate": 1538155960474, "tddate": null, "forum": "ByWMz305FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Missing Ingredient in Zero-Shot Neural Machine Translation", "abstract": "Multilingual Neural Machine Translation (NMT) systems are capable of translating between multiple source and target languages within a single system. An important indicator of generalization within these systems is the quality of zero-shot translation - translating between language pairs that the system has never seen during training. However, until now, the zero-shot performance of multilingual models has lagged far behind the quality that can be achieved by using a two step translation process that pivots through an intermediate language (usually English). In this work, we diagnose why multilingual models under-perform in zero shot settings. We propose explicit language invariance losses that guide an NMT encoder towards learning language agnostic representations. Our proposed strategies significantly improve zero-shot translation performance on WMT English-French-German and on the IWSLT 2017 shared task, and for the first time, match the performance of pivoting approaches while maintaining performance on supervised directions.", "keywords": ["Machine Translation", "Multi-lingual processing", "Zero-Shot translation"], "authorids": ["ICLR.cc/2019/Conference/Paper1246/Authors"], "authors": ["Anonymous"], "TL;DR": "Simple similarity constraints on top of multilingual NMT enables high quality translation between unseen language pairs for the first time.", "pdf": "/pdf/225e5c63da4bdd08cc6bf77cdd1c7de0b4d3e32e.pdf", "paperhash": "anonymous|the_missing_ingredient_in_zeroshot_neural_machine_translation", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Missing Ingredient in Zero-Shot Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByWMz305FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkGGfhC5Y7", "original": "B1gm5Ea8YQ", "number": 1247, "cdate": 1538087946492, "ddate": null, "tcdate": 1538087946492, "tmdate": 1538155960267, "tddate": null, "forum": "HkGGfhC5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards a better understanding of Vector Quantized Autoencoders", "abstract": "Deep neural networks with discrete latent variables offer the promise of better symbolic reasoning, and learning abstractions that are more useful to new tasks. There has been a surge in interest in discrete latent variable models, however, despite several recent improvements, the training of discrete latent variable models has remained  challenging and their performance has mostly failed to match their continuous counterparts. Recent work on vector quantized autoencoders (VQ-VAE) has made substantial progress in this direction, with its perplexity almost matching that of a VAE on datasets such as CIFAR-10. In this work, we investigate an alternate training technique for VQ-VAE, inspired by its connection to the Expectation Maximization (EM) algorithm. Training the discrete bottleneck with EM helps us achieve better image generation results on CIFAR-10, and together with knowledge distillation, allows us to develop a non-autoregressive machine translation model whose accuracy almost matches a strong greedy autoregressive baseline Transformer, while being 3.3 times faster at inference.", "keywords": ["machine translation", "vector quantized autoencoders", "non-autoregressive", "NMT"], "authorids": ["ICLR.cc/2019/Conference/Paper1247/Authors"], "authors": ["Anonymous"], "TL;DR": "Understand the VQ-VAE discrete autoencoder systematically using EM and use it to design non-autogressive translation model matching a strong autoregressive baseline.", "pdf": "/pdf/d05101e0bae5fd8760883e2c673f976ddf8a8cbb.pdf", "paperhash": "anonymous|towards_a_better_understanding_of_vector_quantized_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards a better understanding of Vector Quantized Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGGfhC5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgmzhC5F7", "original": "H1ll-BT9Fm", "number": 1248, "cdate": 1538087946656, "ddate": null, "tcdate": 1538087946656, "tmdate": 1538155960060, "tddate": null, "forum": "HkgmzhC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Modern Take on the Bias-Variance Tradeoff in Neural Networks", "abstract": "We revisit the bias-variance tradeoff for neural networks in light of modern empirical findings. The traditional bias-variance tradeoff in machine learning suggests that as model complexity grows, variance increases. Classical bounds in statistical learning theory point to the number of parameters in a model as a measure of model complexity, which means the tradeoff would indicate that variance increases with the size of neural networks. However, we empirically find that variance due to training set sampling is roughly constant (with both width and depth) in practice. Variance caused by the non-convexity of the loss landscape is different. We find that it decreases with width and increases with depth, in our setting. We provide theoretical analysis, in a simplified setting inspired by linear models, that is consistent with our empirical findings for width. We view bias-variance as a useful lens to study generalization through and encourage further theoretical explanation from this perspective.", "keywords": ["bias-variance tradeoff", "deep learning theory", "generalization", "concentration"], "authorids": ["ICLR.cc/2019/Conference/Paper1248/Authors"], "authors": ["Anonymous"], "TL;DR": "We revisit empirically and theoretically the bias-variance tradeoff for neural networks to shed more light on their generalization properties.", "pdf": "/pdf/e3367be861b58154d691cf455634d4b540e65eac.pdf", "paperhash": "anonymous|a_modern_take_on_the_biasvariance_tradeoff_in_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Modern Take on the Bias-Variance Tradeoff in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgmzhC5F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlQfnCqKX", "original": "HJl4QbjtKm", "number": 1249, "cdate": 1538087946831, "ddate": null, "tcdate": 1538087946831, "tmdate": 1538155959844, "tddate": null, "forum": "HJlQfnCqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Predicting the Generalization Gap in Deep Networks with Margin Distributions", "abstract": "As shown in recent research, deep neural networks can perfectly fit randomly labeled data, but with very poor accuracy on held out data. This phenomenon indicates that loss functions such as cross-entropy are not a reliable indicator of generalization. This leads to the crucial question of how generalization gap should be predicted from the training data and network parameters. In this paper, we propose such a measure, and conduct extensive empirical studies on how well it can predict the generalization gap. Our measure is based on the concept of margin distribution, which are the distances of training points to the decision boundary. We find that it is necessary to use margin distributions at multiple layers of a deep network. On the CIFAR-10 and the CIFAR-100 datasets, our proposed measure correlates very strongly with the generalization gap. In addition, we find the following other factors to be of importance: normalizing margin values for scale independence, using characterizations of margin distribution rather than just the margin (closest distance to decision boundary), and working in log space instead of linear space (effectively using a product of margins rather than a sum).\nOur measure can be easily applied to feedforward deep networks with any architecture and may point towards new training loss functions that could enable better generalization.", "keywords": ["Deep learning", "large margin", "generalization bounds", "generalization gap."], "authorids": ["ICLR.cc/2019/Conference/Paper1249/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop a new scheme to predict the generalization gap in deep networks with high accuracy.", "pdf": "/pdf/215470066deac4c7a2984eb537946fae8970bbb0.pdf", "paperhash": "anonymous|predicting_the_generalization_gap_in_deep_networks_with_margin_distributions", "_bibtex": "@inproceedings{    \nanonymous2019predicting,    \ntitle={Predicting the Generalization Gap in Deep Networks with Margin Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlQfnCqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1MXz20cYQ", "original": "HklMDB2qKQ", "number": 1250, "cdate": 1538087947025, "ddate": null, "tcdate": 1538087947025, "tmdate": 1538155959624, "tddate": null, "forum": "B1MXz20cYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Explaining Image Classifiers by Counterfactual Generation", "abstract": "When a black-box classifier processes an input example to render a prediction, which input features are relevant and why? We propose to answer this question by efficiently marginalizing over the universe of plausible alternative values for a subset of features by conditioning a generative model of the input distribution on the remaining features. In contrast with recent approaches that compute alternative feature values ad-hoc---generating counterfactual inputs far from the natural data distribution---our model-agnostic method produces realistic explanations, generating plausible inputs that either preserve or alter the classification confidence. When applied to image classification, our method produces more compact and relevant per-feature saliency assignment, with fewer artifacts compared to previous methods.", "keywords": ["Explainability", "Interpretability", "Generative Models", "Saliency Map", "Machine Learning", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1250/Authors"], "authors": ["Anonymous"], "TL;DR": "We compute saliency by using a strong generative model to efficiently marginalize over plausible alternative inputs, revealing concentrated pixel areas that preserve label information.", "pdf": "/pdf/ac89217127ab08bc4a01b88cf5c135c4203259fc.pdf", "paperhash": "anonymous|explaining_image_classifiers_by_counterfactual_generation", "_bibtex": "@inproceedings{    \nanonymous2019explaining,    \ntitle={Explaining Image Classifiers by Counterfactual Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MXz20cYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJzmzn0ctX", "original": "r1xj-16ctm", "number": 1251, "cdate": 1538087947200, "ddate": null, "tcdate": 1538087947200, "tmdate": 1538155959414, "tddate": null, "forum": "BJzmzn0ctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Scalable Neural Theorem Proving on Knowledge Bases and Natural Language", "abstract": "Reasoning over text and Knowledge Bases (KBs) is a major challenge for ArtificialIntelligence, with applications in machine reading, dialogue, and question answering.  Transducing text to logical forms which can be operated on is a brittle and error-prone process. Operating directly on text by jointly learning representations and transformations thereof by means of neural architectures that lack the ability to learn and exploit general rules can be very data-inefficient and not generalise correctly. These issues are addressed by Neural Theorem Provers (NTPs) (Rockt\u00e4schel & Riedel, 2017), neuro-symbolic systems based on a continuous relaxation of Prolog\u2019s backward chaining algorithm, where symbolic unification between atoms is replaced by a differentiable operator computing the similarity between their embedding representations. In this paper, we first propose Neighbourhood-approximated Neural Theorem Provers (NaNTPs) consisting of two extensions toNTPs, namely a) a method for drastically reducing the previously prohibitive time and space complexity during inference and learning, and b) an attention mechanism for improving the rule learning process, deeming them usable on real-world datasets. Then, we propose a novel approach for jointly reasoning over KB facts and textual mentions, by jointly embedding them in a shared embedding space. The proposed method is able to extract rules and provide explanations\u2014involving both textual patterns and KB relations\u2014from large KBs and text corpora. We show thatNaNTPs perform on par with NTPs at a fraction of a cost, and can achieve competitive link prediction results on challenging large-scale datasets, including WN18, WN18RR, and FB15k-237 (with and without textual mentions) while being able to provide explanations for each prediction and extract interpretable rules.", "keywords": ["Machine Reading", "Natural Language Processing", "Neural Theorem Proving", "Representation Learning", "First Order Logic"], "authorids": ["ICLR.cc/2019/Conference/Paper1251/Authors"], "authors": ["Anonymous"], "TL;DR": "We scale Neural Theorem Provers to large datasets, improve the rule learning process, and extend it to jointly reason over text and Knowledge Bases.", "pdf": "/pdf/8243bbcc53a586820186f9250dd9ade8925cb7e7.pdf", "paperhash": "anonymous|scalable_neural_theorem_proving_on_knowledge_bases_and_natural_language", "_bibtex": "@inproceedings{    \nanonymous2019scalable,    \ntitle={Scalable Neural Theorem Proving on Knowledge Bases and Natural Language},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJzmzn0ctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lXGnRctX", "original": "SyxGNb09YQ", "number": 1252, "cdate": 1538087947369, "ddate": null, "tcdate": 1538087947369, "tmdate": 1538155959204, "tddate": null, "forum": "B1lXGnRctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Classification in the dark using tactile exploration", "abstract": "Combining information from different sensory modalities to execute goal directed actions is a key aspect of human intelligence. Specifically, human agents are very easily able to translate the task communicated in one sensory domain (say vision) into a representation that enables them to complete this task when they can only sense their environment using a separate sensory modality (say touch). In order to build agents with similar capabilities, in this work we consider the problem of a retrieving a target object from a drawer. The agent is provided with an image of a previously unseen object and it explores objects in the drawer using only tactile sensing to retrieve the object that was shown in the image without receiving any visual feedback. Success at this task requires close integration of visual and tactile sensing. We present a method for performing this task in a simulated environment using an anthropomorphic hand. We hope that future research in the direction of combining sensory signals for acting will find the object retrieval from a drawer to be a useful benchmark problem", "keywords": ["tactile sensing", "multimodal representations", "vision", "object identification"], "authorids": ["ICLR.cc/2019/Conference/Paper1252/Authors"], "authors": ["Anonymous"], "TL;DR": "In this work, we study the problem of learning representations to identify novel objects by exploring objects using tactile sensing. Key point here is that the query is provided in image domain.", "pdf": "/pdf/f45a4ba2821dc271070e94959752b3fb440e5af8.pdf", "paperhash": "anonymous|classification_in_the_dark_using_tactile_exploration", "_bibtex": "@inproceedings{    \nanonymous2019classification,    \ntitle={Classification in the dark using tactile exploration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lXGnRctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkl4M3R5K7", "original": "HkgoKh6tt7", "number": 1253, "cdate": 1538087947543, "ddate": null, "tcdate": 1538087947543, "tmdate": 1538155958995, "tddate": null, "forum": "rkl4M3R5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimal Attacks against Multiple Classifiers", "abstract": "We study the problem of designing provably optimal adversarial noise algorithms that induce misclassification in settings where a learner aggregates decisions from multiple classifiers. Given the demonstrated vulnerability of state-of-the-art models to adversarial examples, recent efforts within the field of robust machine learning have focused on the use of ensemble classifiers as a way of boosting the robustness of individual models. In this paper, we design provably optimal attacks against a set of classifiers. We demonstrate how this problem can be framed as finding strategies at equilibrium in a two player, zero sum game between a learner and an adversary and consequently illustrate the need for randomization in adversarial attacks. The main technical challenge we consider is the design of best response oracles that can be implemented in a Multiplicative Weight Updates framework to find equilibrium strategies in the zero-sum game. We develop a series of scalable noise generation algorithms for deep neural networks, and show that it outperforms state-of-the-art attacks on various image classification tasks. Although there are generally no guarantees for deep learning, we show this is a well-principled approach in that it is provably optimal for linear classifiers. The main insight is a geometric characterization of the decision space that reduces the problem of designing best response oracles to minimizing a quadratic function over a set of convex polytopes.", "keywords": ["online learning", "nonconvex optimization", "robust optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1253/Authors"], "authors": ["Anonymous"], "TL;DR": "Paper analyzes the problem of designing adversarial attacks against multiple classifiers, introducing algorithms that are optimal for linear classifiers and which provide state-of-the-art results for deep learning.", "pdf": "/pdf/8b6730a932d8c35e7203ff8c676ba6c763467587.pdf", "paperhash": "anonymous|optimal_attacks_against_multiple_classifiers", "_bibtex": "@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal Attacks against Multiple Classifiers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl4M3R5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1eEG20qKQ", "original": "B1gYhkRcYX", "number": 1254, "cdate": 1538087947712, "ddate": null, "tcdate": 1538087947712, "tmdate": 1538155958781, "tddate": null, "forum": "r1eEG20qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization is a bi-level optimization problem, where the optimal parameters on the training set depend on the current hyperparameters. The best-response function which maps hyperparameters to these optimal parameters allows gradient-based hyperparameter optimization but is difficult to represent and compute when the parameters are high dimensional, as in neural networks. We develop efficient best-response approximations for neural networks by applying insights from the structure of the optimal response in a Jacobian-regularized two-layer linear network to deep, nonlinear networks. The approximation works by scaling and shifting the hidden units by amounts which depend on the current hyperparameters.  We use our approximation for a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response in a neighborhood around the current hyperparameters and optimizing the hyperparameters using the approximate best-response. We show this method outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks.", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1254/Authors"], "authors": ["Anonymous"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/8a385e37d274b9e6d6105e4f42b3ec4f4ff3438f.pdf", "paperhash": "anonymous|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{    \nanonymous2019self-tuning,    \ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eEG20qKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJl4f2A5tQ", "original": "Hkl2ZHZFd7", "number": 1255, "cdate": 1538087947878, "ddate": null, "tcdate": 1538087947878, "tmdate": 1538155958567, "tddate": null, "forum": "BJl4f2A5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Surprising Negative Results for Generative  Adversarial Tree Search ", "abstract": "Although many recent advances in deep reinforcement learning consist of model- free methods, model-based approaches remain an alluring prospect owing to their potential to exploit unsupervised data to learn environment dynamics. Moreover, with new breakthroughs on image-to-image transduction, Pix2Pix GANs are a natural choice for learning to predict the dynamics of environments where ob- servations consist of images (like Atari games). Inspired by AlphaGo, which combines model-based and model-free RL, we propose generative adversarial tree search (GATS), simulating roll-outs with a learned GAN-based dynamics model and reward predictor. We theoretically prove some favorable properties of GATS vis-a-vis the bias-variance trade-off. The approach combines model-based planning via MCTS with model-free learning with DQNs. Empirically, on 5 popular Atari games, despite the dynamics and reward predictors converging quickly to accurate solutions GATS fails to outperform DQNs. We present a hypothesis for why tree search with short roll-outs can fail even given perfect modelling.", "keywords": ["Deep Reinforcement Learning", "Generative Adversarial Nets"], "authorids": ["ICLR.cc/2019/Conference/Paper1255/Authors"], "authors": ["Anonymous"], "TL;DR": "Surprising negative results on Model Based + Model deep RL", "pdf": "/pdf/0ea4761fcbea0d1b66c26f2858fc1ccbf0160b2d.pdf", "paperhash": "anonymous|surprising_negative_results_for_generative_adversarial_tree_search", "_bibtex": "@inproceedings{    \nanonymous2019surprising,    \ntitle={Surprising Negative Results for Generative  Adversarial Tree Search },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl4f2A5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1eVMnA9K7", "original": "BJlGIzC5Fm", "number": 1256, "cdate": 1538087948048, "ddate": null, "tcdate": 1538087948048, "tmdate": 1538155958359, "tddate": null, "forum": "r1eVMnA9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Control Through Non-Parametric Discriminative Rewards", "abstract": "Learning to control an environment without hand-crafted rewards or expert data remains challenging and is at the frontier of reinforcement learning research. We present an unsupervised learning algorithm to train agents to achieve perceptually-specified goals using only a stream of observations and actions. Our agent simultaneously learns a goal-conditioned policy and a goal achievement reward function that measures how similar a state is to the goal state. This dual optimization leads to a co-operative game, giving rise to a learned reward function that reflects similarity in controllable aspects of the environment instead of distance in the space of observations. We demonstrate the efficacy of our agent to learn, in an unsupervised manner, to reach a diverse set of goals on three domains -- Atari, the DeepMind Control Suite and DeepMind Lab.", "keywords": ["deep reinforcement learning", "goals", "UVFA", "mutual information"], "authorids": ["ICLR.cc/2019/Conference/Paper1256/Authors"], "authors": ["Anonymous"], "TL;DR": "Unsupervised reinforcement learning method for learning a policy to robustly achieve perceptually specified goals.", "pdf": "/pdf/83bd865b60cfbd8c742a7495ec84929eb81ce5da.pdf", "paperhash": "anonymous|unsupervised_control_through_nonparametric_discriminative_rewards", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Control Through Non-Parametric Discriminative Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eVMnA9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklVMnR5tQ", "original": "BJgqW-AcYm", "number": 1257, "cdate": 1538087948216, "ddate": null, "tcdate": 1538087948216, "tmdate": 1538155958143, "tddate": null, "forum": "HklVMnR5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Exploring the interpretability of LSTM neural networks over multi-variable data", "abstract": "In learning a predictive model over multivariate time series consisting of target and exogenous variables, the forecasting performance and interpretability of the model are both essential for deployment and uncovering knowledge behind the data. To this end, we propose the interpretable multi-variable LSTM recurrent neural network (IMV-LSTM) capable of providing accurate forecasting as well as both temporal and variable level importance interpretation. In particular, IMVLSTM is equipped with tensorized hidden states and update process, so as tolearn variables-wise hidden states. On top of it, we develop a mixture attention mechanism and associated summarization methods to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of IMV-LSTM in comparison to a variety of baselines. It also exhibits the prospect as an end-to-end framework for both forecasting and knowledge extraction over multi-variate data.\n", "keywords": ["Interpretability", "recurrent neural network", "attention"], "authorids": ["ICLR.cc/2019/Conference/Paper1257/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/e44fe0ff79eda3b1db85b21fbc0e3cda023e01ec.pdf", "paperhash": "anonymous|exploring_the_interpretability_of_lstm_neural_networks_over_multivariable_data", "_bibtex": "@inproceedings{    \nanonymous2019exploring,    \ntitle={Exploring the interpretability of LSTM neural networks over multi-variable data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklVMnR5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyGEM3C9KQ", "original": "rkgF-0HqK7", "number": 1258, "cdate": 1538087948383, "ddate": null, "tcdate": 1538087948383, "tmdate": 1538155957930, "tddate": null, "forum": "HyGEM3C9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control", "abstract": "The Differentiable Neural Computer (DNC) can learn algorithmic and question answering tasks. An analysis of its internal activation patterns reveals three problems: Most importantly, content based look-up results in flat and noisy address distributions, because the lack of key-value separation makes the DNC unable to ignore memory content which is not present in the key and need to be retrieved. Second, DNC's de-allocation of memory results in aliasing, which is a problem for content-based look-up. Thirdly, chaining memory reads with the temporal linkage matrix exponentially degrades the quality of the address distribution. Our  proposed fixes of these problems yield improved performance on arithmetic tasks, and also improve the mean error rate on the bAbI question answering dataset by 43%. ", "keywords": ["rnn", "dnc", "memory augmented neural networks", "mann"], "authorids": ["ICLR.cc/2019/Conference/Paper1258/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/2f98ab4405de875be68055562a20df852c2046ef.pdf", "paperhash": "anonymous|improving_the_differentiable_neural_computer_through_memory_masking_deallocation_and_link_distribution_sharpness_control", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGEM3C9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklSf3CqKm", "original": "rkg8amQqK7", "number": 1259, "cdate": 1538087948550, "ddate": null, "tcdate": 1538087948550, "tmdate": 1538155957710, "tddate": null, "forum": "HklSf3CqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Subgradient Descent Learns Orthogonal Dictionaries", "abstract": "This paper concerns dictionary learning, viz., sparse coding, a fundamental representation learning problem. We show that a subgradient descent algorithm, with random initialization, can recover orthogonal dictionaries on a natural nonsmooth, nonconvex L1 minimization formulation of the problem, under mild statistical assumption on the data. This is in contrast to previous provable methods that require either expensive computation or delicate initialization schemes. Our analysis develops several tools for characterizing landscapes of nonsmooth functions, which might be of independent interest for provable training of deep networks with nonsmooth activations (e.g., ReLU), among other applications. Preliminary experiments corroborate our analysis and show that our algorithm works well empirically in recovering orthogonal dictionaries.", "keywords": ["Dictionary learning", "Sparse coding", "Non-convex optimization", "Theory"], "authorids": ["ICLR.cc/2019/Conference/Paper1259/Authors"], "authors": ["Anonymous"], "TL;DR": "Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.", "pdf": "/pdf/466b410624a7098c52f3fe8841e59f849c9b4007.pdf", "paperhash": "anonymous|subgradient_descent_learns_orthogonal_dictionaries", "_bibtex": "@inproceedings{    \nanonymous2019subgradient,    \ntitle={Subgradient Descent Learns Orthogonal Dictionaries},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklSf3CqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BylBfnRqFm", "original": "S1eGYFpqtm", "number": 1260, "cdate": 1538087948717, "ddate": null, "tcdate": 1538087948717, "tmdate": 1538155957493, "tddate": null, "forum": "BylBfnRqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CAML: Fast Context Adaptation via Meta-Learning", "abstract": "We propose CAML, a meta-learning method for fast adaptation that partitions the model parameters into two parts: context parameters that serve as additional input to the model and are adapted on individual tasks, and shared parameters that are meta-trained and shared across tasks. At test time, the context parameters are updated with one or several gradient steps on a task-specific loss that is backpropagated through the shared part of the network. Compared to approaches that adjust all parameters on a new task (e.g., MAML), our method can be scaled up to larger networks without overfitting on a single task, is easier to implement, and saves memory writes during training and network communication at test time for distributed machine learning systems. We show empirically that this approach outperforms MAML, is less sensitive to the task-specific learning rate, can capture meaningful task embeddings with the context parameters, and outperforms alternative partitionings of the parameter vectors.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1260/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d967f5e4216937e359dc2e2b57dac4456b763511.pdf", "paperhash": "anonymous|caml_fast_context_adaptation_via_metalearning", "_bibtex": "@inproceedings{    \nanonymous2019caml:,    \ntitle={CAML: Fast Context Adaptation via Meta-Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylBfnRqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eBzhRqK7", "original": "ByxjA-0ctm", "number": 1261, "cdate": 1538087948889, "ddate": null, "tcdate": 1538087948889, "tmdate": 1538155957273, "tddate": null, "forum": "S1eBzhRqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "abstract": "Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.", "keywords": ["Evolutionary", "Architecture Search", "NAS"], "authorids": ["ICLR.cc/2019/Conference/Paper1261/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.", "pdf": "/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf", "paperhash": "anonymous|evolutionaryneural_hybrid_agents_for_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019evolutionary-neural,    \ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eBzhRqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SygHGnRqK7", "original": "HylZBn6qKm", "number": 1262, "cdate": 1538087949066, "ddate": null, "tcdate": 1538087949066, "tmdate": 1538155957061, "tddate": null, "forum": "SygHGnRqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Federated Neural Matching", "abstract": "In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. We develop a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through our framework. We then develop an inference approach that allows us to synthesize a more expressive global network without additional supervision or data pooling. We then demonstrate the efficacy of our approach on federated learning problems simulated from two popular image classification datasets.", "keywords": ["Bayesian nonparametrics", "Indian Buffet Process", "Federated Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1262/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a Bayesian nonparametric model for federated learning with neural networks.", "pdf": "/pdf/9ed5608e8fd12e4ad4ae9eb7c9e78a4ff03ab372.pdf", "paperhash": "anonymous|probabilistic_federated_neural_matching", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Federated Neural Matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygHGnRqK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gBz2C9tX", "original": "r1esu-Cqtm", "number": 1263, "cdate": 1538087949238, "ddate": null, "tcdate": 1538087949238, "tmdate": 1538155956847, "tddate": null, "forum": "S1gBz2C9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Importance Resampling for Off-policy Policy Evaluation", "abstract": "Importance sampling is a common approach to off-policy learning in reinforcement learning.  While it is consistent and unbiased, it can result in high variance updates to the parameters for the value function. Weighted importance sampling (WIS) has been explored to reduce variance for off-policy policy evaluation, but only for linear value function approximation. In this work, we explore a resampling strategy to reduce variance, rather than a reweighting strategy. We propose Importance Resampling (IR) for off-policy learning, that resamples experience from the replay buffer and applies a standard on-policy update. The approach avoids using importance sampling ratios directly in the update, instead correcting the distribution over transitions before the update. We characterize the bias and consistency of the our estimator, particularly compared to WIS. We then demonstrate in several toy domains that IR has improved sample efficiency and parameter sensitivity, as compared to several baseline WIS estimators and to IS. We conclude with a demonstration showing IR improves over IS for learning a value function from images in a racing car simulator.", "keywords": ["Reinforcement Learning", "Off-policy policy evaluation", "importance resampling", "importance sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper1263/Authors"], "authors": ["Anonymous"], "TL;DR": "A resampling approach for off-policy policy evaluation in reinforcement learning.", "pdf": "/pdf/a7e41f6cea5c6b25dfb81658254363fb0aa15a44.pdf", "paperhash": "anonymous|importance_resampling_for_offpolicy_policy_evaluation", "_bibtex": "@inproceedings{    \nanonymous2019importance,    \ntitle={Importance Resampling for Off-policy Policy Evaluation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gBz2C9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJMBM2RqKQ", "original": "HJgLez65FQ", "number": 1264, "cdate": 1538087949426, "ddate": null, "tcdate": 1538087949426, "tmdate": 1538155956635, "tddate": null, "forum": "SJMBM2RqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Uncertainty-guided Lifelong Learning in Bayesian Networks", "abstract": "The ability to learn in a setting where tasks arrive in a sequence without access to previous task data is difficult for learning algorithms when restricted in capacity.  In this lifelong learning setting a single model is challenged to learning a new task, while at the same time not forgetting about previous tasks and freeing up capacity for future tasks. We argue that the ability to identify network parameters which are most critical for a learned task plays a critical role to decide which ones to remember. In this work we propose to rely on Bayesian Networks, which inherently model the distribution of a parameter rather than a single value of a parameter.  More specifically, we formulate lifelong learning in the Bayesian-by-Backprop framework, exploiting the parameter uncertainty for two lifelong learning directions. First, weight pruning, where a hard selection is made on which parameters to select per task and, second, weight regularization which can be seen as a softer version to keep important parameters, respectively.  We show the benefit of our approach using diverse object classification datasets in both cases.", "keywords": ["lifelong learning", "continual learning", "sequential learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1264/Authors"], "authors": ["Anonymous"], "TL;DR": "We formulate lifelong learning in the Bayesian-by-Backprop framework, exploiting the parameter uncertainty in two settings: for pruning network parameters and in importance weight based continual learning.", "pdf": "/pdf/8883837e6dee2f537035d71d2a723f05ad4312a4.pdf", "paperhash": "anonymous|uncertaintyguided_lifelong_learning_in_bayesian_networks", "_bibtex": "@inproceedings{    \nanonymous2019uncertainty-guided,    \ntitle={Uncertainty-guided Lifelong Learning in Bayesian Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMBM2RqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkeUG30cFQ", "original": "r1giUzRqY7", "number": 1265, "cdate": 1538087949594, "ddate": null, "tcdate": 1538087949594, "tmdate": 1538155956424, "tddate": null, "forum": "SkeUG30cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Expressive Power of Deep Neural Networks with Circulant Matrices", "abstract": "Recent results from linear algebra stating that any matrix can be decomposed into products of diagonal and circulant matrices has lead to the design of compact deep neural network architectures that perform well in practice. In this paper, we bridge the gap between these good empirical results \nand the theoretical approximation capabilities of Deep diagonal-circulant ReLU networks. More precisely, we first demonstrate  that a Deep diagonal-circulant ReLU networks of\nbounded width and small depth can approximate a deep ReLU network in which the dense matrices are\nof low rank. Based on this result, we provide new bounds on the expressive power and universal approximativeness of this type of networks. We support our experimental results with thorough experiments on a large, real world video classification problem.", "keywords": ["deep learning", "circulant matrices", "universal approximation"], "authorids": ["ICLR.cc/2019/Conference/Paper1265/Authors"], "authors": ["Anonymous"], "TL;DR": "We provid a theoretical study of the properties of Deep circulant-diagonal ReLU Networks and demonstrated that they are bounded width universal approximators.", "pdf": "/pdf/6640b3c1a3ecb4248b3fbb31ce90ec578e2ab4b0.pdf", "paperhash": "anonymous|the_expressive_power_of_deep_neural_networks_with_circulant_matrices", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Expressive Power of Deep Neural Networks with Circulant Matrices},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeUG30cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1gIf305Ym", "original": "HJxX1Xi5KQ", "number": 1266, "cdate": 1538087949761, "ddate": null, "tcdate": 1538087949761, "tmdate": 1538155956205, "tddate": null, "forum": "B1gIf305Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NSGA-Net: A Multi-Objective Genetic Algorithm for Neural Architecture Search", "abstract": "This paper introduces NSGA-Net, an evolutionary approach for neural architecture search (NAS). NSGA-Net is designed with three goals in mind: (1) a NAS procedure for multiple, possibly conflicting, objectives, (2) efficient exploration and exploitation of the space of potential neural network architectures, and (3) output of a diverse set of network architectures spanning a trade-off frontier of the objectives in a single run. NSGA-Net is a population-based search algorithm that explores a space of potential neural network architectures in three steps, namely, a population initialization step that is based on prior-knowledge from hand-crafted architectures, an exploration step comprising crossover and mutation of architectures and finally an exploitation step that applies the entire history of evaluated neural architectures in the form of a Bayesian Network prior. Experimental results suggest that combining the objectives of minimizing both an error metric and computational complexity, as measured by FLOPS, allows NSGA-Net to find competitive neural architectures near the Pareto front of both objectives on two different tasks, object classification and object alignment. NSGA-Net obtains networks that achieve 3.72% (at 4.5 million FLOP) error on CIFAR-10 classification and 8.64% (at 26.6 million FLOP) error on the CMU-Car alignment task.", "keywords": ["neural architecture search", "evolutionary algorithms"], "authorids": ["ICLR.cc/2019/Conference/Paper1266/Authors"], "authors": ["Anonymous"], "TL;DR": "An efficient multi-objective neural architecture search algorithm using NSGA-II", "pdf": "/pdf/f541b25829c22fc27ed58ab01655cd1459e394c3.pdf", "paperhash": "anonymous|nsganet_a_multiobjective_genetic_algorithm_for_neural_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019nsga-net:,    \ntitle={NSGA-Net: A Multi-Objective Genetic Algorithm for Neural Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gIf305Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyfIfnC5Ym", "original": "HygMqg65F7", "number": 1267, "cdate": 1538087949928, "ddate": null, "tcdate": 1538087949928, "tmdate": 1538155955995, "tddate": null, "forum": "SyfIfnC5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving the Generalization of Adversarial Training with Domain Adaptation", "abstract": "By injecting adversarial examples into training data, the adversarial training method is promising for improving the robustness of deep learning models. However, most existing adversarial training approaches are based on a specific type of adversarial attack. It may not provide sufficiently representative samples from the adversarial domain, leading to a weak generalization ability on adversarial examples from other attacks. To scale to large datasets, perturbations on inputs to generate adversarial examples are usually crafted using fast single-step attacks. This work is mainly focused on the adversarial training with the single-step yet efficient FGSM adversary. In this scenario, it is difficult to train a model with great generalization due to the lack of representative adversarial samples, aka the samples are unable to accurately reflect the adversarial domain. To address this problem, we propose a novel Adversarial Training with Domain Adaptation (ATDA) method by regarding the adversarial training with FGSM adversary as a domain adaption task with limited number of target domain samples. The main idea is to learn a representation that is semantically meaningful and domain invariant on the clean domain as well as the adversarial domain. Empirical evaluations demonstrate that ATDA can greatly improve the generalization of adversarial training and achieves state-of-the-art results on standard benchmark datasets.", "keywords": ["adversarial training", "domain adaptation", "adversarial example", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1267/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a novel adversarial training with domain adaptation method that significantly improves the generalization ability on adversarial examples from different attacks.", "pdf": "/pdf/2bf9a01d7f9b1461e4222c501707891eaa0bd1f5.pdf", "paperhash": "anonymous|improving_the_generalization_of_adversarial_training_with_domain_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019improving,    \ntitle={Improving the Generalization of Adversarial Training with Domain Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyfIfnC5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1lIzhC9FX", "original": "S1gBPMAcFm", "number": 1268, "cdate": 1538087950096, "ddate": null, "tcdate": 1538087950096, "tmdate": 1538155955787, "tddate": null, "forum": "H1lIzhC9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to remember: Dynamic Generative Memory for Continual Learning", "abstract": "Continuously trainable models should be able to learn from a stream of data over an undefined period of time. This becomes even more difficult in a strictly incremental context, where data access to previously seen categories is not possible. To that end, we propose making use of a conditional generative adversarial model where the generator is used as a memory module through neural masking to emulate neural plasticity in the human brain. This memory module is further associated with a dynamic capacity expansion mechanism. Taken together, this method facilitates a resource efficient capacity adaption to accommodate new tasks, while retaining previously attained knowledge. The proposed approach outperforms state-of-the-art algorithms on publicly available datasets, overcoming catastrophic forgetting.", "keywords": ["Continual Learning", "Catastrophic Forgetting", "Dynamic Network Expansion"], "authorids": ["ICLR.cc/2019/Conference/Paper1268/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/3ff418cd6b4e2ef142c2202d9db66522cba73ca1.pdf", "paperhash": "anonymous|learning_to_remember_dynamic_generative_memory_for_continual_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to remember: Dynamic Generative Memory for Continual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lIzhC9FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxLG2RcYX", "original": "HJl8UjpqKX", "number": 1269, "cdate": 1538087950272, "ddate": null, "tcdate": 1538087950272, "tmdate": 1538155955580, "tddate": null, "forum": "ryxLG2RcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Abstract Models for Long-Horizon Exploration", "abstract": "Despite recent progress in reinforcement learning (RL), state-of-the-art RL algorithms\ncontinue to struggle with high-dimensional, long-horizon, sparse-reward\ntasks. Even with a perfect model, model-based RL can be intractable because the state\nspace is often high-dimensional (e.g. over 10^100 states). We address this by automatically\nconstructing an abstract Markov Decision Process (MDP) with an exponentially\nsmaller number of states (e.g. 10^5), where the actions are skills learned\nby a worker policy. We learn a near-optimal policy on the resulting abstract MDP,\nwhich maps to a near-optimal policy on the original MDP. Our approach provably\nmakes monotonic progress and is guaranteed to learn a near-optimal policy.\nWe empirically evaluate our approach on three of the hardest games from the\nArcade Learning Environment: Montezuma\u2019s Revenge, Pitfall!, and Private Eye,\nand outperform the previous state-of-the-art by over a factor of 2 in\neach game. In Pitfall!, our approach is the first to achieve superhuman performance\nwithout demonstrations", "keywords": ["Reinforcement Learning", "Hierarchical Reinforcement Learning", "Model-based Reinforcement Learning", "Exploration"], "authorids": ["ICLR.cc/2019/Conference/Paper1269/Authors"], "authors": ["Anonymous"], "TL;DR": "We automatically construct and explore a small abstract Markov Decision Process, enabling us to achieve state-of-the-art results on Montezuma's Revenge, Pitfall!, and Private Eye by a significant margin.", "pdf": "/pdf/d6de0bafc1fae1e054439e0c8a3c733cd477cb2a.pdf", "paperhash": "anonymous|learning_abstract_models_for_longhorizon_exploration", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Abstract Models for Long-Horizon Exploration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxLG2RcYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lIMn05F7", "original": "rkxbK0a9YX", "number": 1270, "cdate": 1538087950450, "ddate": null, "tcdate": 1538087950450, "tmdate": 1538155955368, "tddate": null, "forum": "S1lIMn05F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Direct Approach to Robust Deep Learning Using Adversarial Networks", "abstract": "Deep neural networks have been shown to perform well in many classical machine learning problems, especially in image classification tasks. However, researchers have found that neural networks can be easily fooled, and they are surprisingly sensitive to small perturbations imperceptible to humans.  Carefully crafted input images (adversarial examples) can force a well-trained neural network to provide arbitrary outputs.  Including adversarial examples during training is a popular defense mechanism against adversarial attacks. In this paper we propose a new defensive mechanism under the generative adversarial network~(GAN) framework. We model the adversarial noise using a generative network, trained jointly with a classification discriminative network as a minimax game. We show empirically that our adversarial network approach works well against black box attacks, with performance on par with state-of-art methods such as ensemble adversarial training and adversarial training with projected gradient descent.\n", "keywords": ["deep learning", "adversarial learning", "generative adversarial networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1270/Authors"], "authors": ["Anonymous"], "TL;DR": "Jointly train an adversarial noise generating network with a classification network to provide better robustness to adversarial attacks.", "pdf": "/pdf/85e28fff82c7b31e41cea4011ea85d544d14f18f.pdf", "paperhash": "anonymous|a_direct_approach_to_robust_deep_learning_using_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Direct Approach to Robust Deep Learning Using Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lIMn05F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgvf3RcFQ", "original": "HklvwfC5YQ", "number": 1271, "cdate": 1538087950617, "ddate": null, "tcdate": 1538087950617, "tmdate": 1538155955160, "tddate": null, "forum": "rJgvf3RcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Inductive Biases in Deep Reinforcement Learning", "abstract": "Many deep reinforcement learning algorithms contain inductive biases that sculpt the agent's objective and its interface to the environment. These inductive biases can take many forms, including domain knowledge and pretuned hyper-parameters. In general, there is a trade-off between generality and performance when we use such biases. Stronger biases can lead to faster learning, but weaker biases can potentially lead to more general algorithms that work on a wider class of problems.\nThis trade-off is relevant because these inductive biases are not free; substantial effort may be required to obtain relevant domain knowledge or to tune hyper-parameters effectively. In this paper, we re-examine several domain-specific components that modify the agent's objective and environmental interface.  We investigated whether the performance deteriorates when all these fixed components are replaced with adaptive solutions from the literature.  In our experiments, performance sometimes decreased with the adaptive components, as one might expect when comparing to components crafted for the domain, but sometimes the adaptive components performed better. We then investigated the main benefit of having fewer domain-specific components, by comparing the learning performance of the two systems on a different set of continuous control problems, without additional tuning of either system.  As hypothesized, the system with adaptive components performed better on many of the tasks.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1271/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cb4e289ebf704d6b7d066a967dc219cc0a67a7f9.pdf", "paperhash": "anonymous|on_inductive_biases_in_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Inductive Biases in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgvf3RcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxPz2C9Ym", "original": "Bye15F-cYm", "number": 1272, "cdate": 1538087950789, "ddate": null, "tcdate": 1538087950789, "tmdate": 1538155954946, "tddate": null, "forum": "ByxPz2C9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "AIM: Adversarial Inference by Matching Priors and Conditionals", "abstract": "Effective inference for a generative adversarial model remains an important and challenging problem. We propose a novel framework, Adversarial Inference by Matching priors and conditionals (AIM), which explicitly matches prior and conditional distributions in both data and code spaces, and puts a direct constraint on the dependency structure of the generative model. We derive an equivalent form of the prior and conditional matching objective that can be optimized efficiently without any parametric assumption on the data. We validate the effectiveness of AIM on the MNIST, CIFAR-10, and CelebA datasets by conducting quantitative and qualitative evaluations. Results show that AIM significantly improves both reconstruction and generation compared with other adversarial inference models.", "keywords": ["generative adversarial network", "generative model", "inference"], "authorids": ["ICLR.cc/2019/Conference/Paper1272/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f423eb88596d4f1fa941f008cdef630f960c70c9.pdf", "paperhash": "anonymous|aim_adversarial_inference_by_matching_priors_and_conditionals", "_bibtex": "@inproceedings{    \nanonymous2019aim:,    \ntitle={AIM: Adversarial Inference by Matching Priors and Conditionals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxPz2C9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkevMnRqYQ", "original": "ByxW5sTcKX", "number": 1273, "cdate": 1538087950959, "ddate": null, "tcdate": 1538087950959, "tmdate": 1538155954731, "tddate": null, "forum": "rkevMnRqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Implicit Information in an Initial State", "abstract": "Reinforcement learning (RL) agents optimize only the features specified in a reward function and are indifferent to anything left out inadvertently. This means that we must not only tell a household robot what to do, but also prevent it from knocking over a vase or stepping on a toy train. It is easy to forget these preferences, since we are so used to having them satisfied. Our key insight is that when a robot is deployed in an environment that humans act in, the state of the environment is already optimized for what humans want. We can therefore use this implicit information from the state to fill in the blanks. We develop an algorithm based on Maximum Causal Entropy IRL and use it to evaluate the idea in a suite of proof-of-concept environments designed to show its properties. We find that information from the initial state can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized.", "keywords": ["Preference learning", "Inverse reinforcement learning", "Inverse optimal stochastic control", "Maximum entropy reinforcement learning", "Apprenticeship learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1273/Authors"], "authors": ["Anonymous"], "TL;DR": "When a robot is deployed in an environment that humans have been acting in, the state of the environment is already optimized for what humans want, and we can use this to infer human preferences.", "pdf": "/pdf/b89300a7ba6b8a18cbe576482aa2d7d533450c0b.pdf", "paperhash": "anonymous|the_implicit_information_in_an_initial_state", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Implicit Information in an Initial State},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkevMnRqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rylDfnCqF7", "original": "HyxuP0h9F7", "number": 1274, "cdate": 1538087951133, "ddate": null, "tcdate": 1538087951133, "tmdate": 1538155954507, "tddate": null, "forum": "rylDfnCqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Lagging Inference Networks and Posterior Collapse in Variational Autoencoders", "abstract": "The variational autoencoder (VAE) is an efficient method to learn probabilistic latent variable models by the use of an inference network, which predicts a distribution over latent variables given the input. However, VAEs are known to suffer from ``posterior collapse'' when combined with flexible neural autoregressive generators such as LSTMs or PixelCNNs, where the generator tends to ignore the latent variables and the variational posterior collapses to the prior. In this paper, we investigate this problem from the perspective of training dynamics. We find that the approximated posterior distribution lags far behind the model's true posterior in the initial stages of training, which pressures the generator to ignore the latent encoding. To address this issue, we propose an extremely simple training procedure for VAE models that mitigates the lagging issue: aggressively optimizing the inference network with more updates before reverting back to basic VAE training. Despite introducing neither new components nor significant complexity over basic VAEs, our approach is able to circumvent the collapse problem that has plagued a large amount of previous work using VAE-based models.\nEmpirically, our approach outperforms strong autoregressive baselines on text and image benchmarks in terms of density estimation, land achieves results competitive to more complicated previous methods. Our method also trains 5x faster on average than the most comparable state-of-the-art method, the semi-amortized VAE.", "keywords": ["variational autoencoders", "posterior collapse", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper1274/Authors"], "authors": ["Anonymous"], "TL;DR": "To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates", "pdf": "/pdf/276fd60afc6d12da882024786a293dfb659cbaab.pdf", "paperhash": "anonymous|lagging_inference_networks_and_posterior_collapse_in_variational_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019lagging,    \ntitle={Lagging Inference Networks and Posterior Collapse in Variational Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylDfnCqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyewf3AqYX", "original": "ryx6Ob0cFX", "number": 1275, "cdate": 1538087951307, "ddate": null, "tcdate": 1538087951307, "tmdate": 1538155954296, "tddate": null, "forum": "Hyewf3AqYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks", "abstract": "Depending on how much information an adversary can access to, adversarial attacks can be classified as white-box attack and black-box attack. In both cases, optimization-based attack algorithms can achieve relatively low distortions and high attack success rates. However, they usually suffer from poor time and query complexities, thereby limiting their practical usefulness. In this work, we focus on the problem of developing efficient and effective optimization-based adversarial attack algorithms. In particular, we propose a novel adversarial attack framework for both white-box and black-box settings based on the non-convex Frank-Wolfe algorithm. We show in theory that the proposed attack algorithms are efficient with an O(1/\\sqrt{T}) convergence rate, which, to our knowledge, is the first convergence rate analysis for the zeroth-order non-convex Frank-Wolfe type algorithm. The empirical results on attacking Inception V3 model with the ImageNet dataset also verify the efficiency and effectiveness of the proposed algorithms. They attain a 100% attack success rate in both white-box and  black-box attacks, and are more time and query efficient than the state-of-the-art baseline algorithms.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1275/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8551f7f30e2acf4760fa2de2b1cd2fd737a4b4fd.pdf", "paperhash": "anonymous|a_frankwolfe_framework_for_efficient_and_effective_adversarial_attacks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyewf3AqYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SylPMnR9Ym", "original": "Byl9P2wpu7", "number": 1276, "cdate": 1538087951481, "ddate": null, "tcdate": 1538087951481, "tmdate": 1538155954085, "tddate": null, "forum": "SylPMnR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning what you can do before doing anything", "abstract": "Intelligent agents are able to learn and understand the action spaces of other agents by simply observing them act. Such representations could help them to quickly learn to predict effects of their own actions on the environment and plan complex interaction sequences. Current deep learning methods can capture the structured representations needed for such predictive capabilities, but only when given abundant, action-labeled data. We propose an unsupervised method to learn representations of an agent\u2019s action space purely from visual observations. Our method uses stochastic future prediction to learn a latent variable that captures (i) the dynamic properties of scenes while being minimally sensitive to static scene content and (ii) the compositional structure of actions, reflecting the fact that changes they induce can be composed to produce a cumulative effect on the environment. We show the applicability of our method to synthetic settings and its potential to capture action spaces in complex, realistic visual settings. Our learned representations perform comparably to existing supervised methods on tasks such as action-conditioned video prediction and visual servoing, while requiring orders of magnitude fewer action-labeled videos. ", "keywords": ["unsupervised learning", "vision", "motion", "action space", "video prediction", "variational models"], "authorids": ["ICLR.cc/2019/Conference/Paper1276/Authors"], "authors": ["Anonymous"], "TL;DR": "We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.", "pdf": "/pdf/c4d4f703ae75c64c84c33b8f4a6d5c73d4208190.pdf", "paperhash": "anonymous|learning_what_you_can_do_before_doing_anything", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning what you can do before doing anything},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SylPMnR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeOMhA5K7", "original": "BkeWVd3qK7", "number": 1277, "cdate": 1538087951648, "ddate": null, "tcdate": 1538087951648, "tmdate": 1538155953870, "tddate": null, "forum": "HJeOMhA5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Human-Guided Column Networks: Augmenting Deep Learning with Advice", "abstract": "While extremely successful in several applications, especially with low-level representations; sparse, noisy samples and structured domains (with multiple objects and interactions) are some of the open challenges in most deep models. Column Networks, a deep architecture, can succinctly capture such domain structure and interactions, but may still be prone to sub-optimal learning from sparse and noisy samples. Inspired by the success of human-advice guided learning in AI, especially in data-scarce domains, we propose Knowledge-augmented Column Networks that leverage human advice/knowledge for better learning with noisy/sparse samples. Our experiments demonstrate how our approach leads to either superior overall performance or faster convergence.", "keywords": ["Knowledge-guided learning", "Human advice", "Column Networks", "Knowledge-based relational deep model", "Collective classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1277/Authors"], "authors": ["Anonymous"], "TL;DR": "Guiding relation-aware deep models towards better learning with human knowledge.", "pdf": "/pdf/53505ad692482326a1037a294abfd45a8ef112ba.pdf", "paperhash": "anonymous|humanguided_column_networks_augmenting_deep_learning_with_advice", "_bibtex": "@inproceedings{    \nanonymous2019human-guided,    \ntitle={Human-Guided Column Networks: Augmenting Deep Learning with Advice},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeOMhA5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJldzhA5tQ", "original": "HkxxGZ39Km", "number": 1278, "cdate": 1538087951817, "ddate": null, "tcdate": 1538087951817, "tmdate": 1538155953666, "tddate": null, "forum": "HJldzhA5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning powerful policies and better generative models by interaction", "abstract": "Model-based reinforcement learning approaches have the promise of being sample efficient. Much of the progress in learning dynamics models in RL has been made by learning models via supervised learning. There is enough evidence that humans build a model of the environment, not only by observing the environment but also by interacting with the environment. Interaction with the environment allows humans to carry out  \\textit{experiments}: taking actions that help uncover true casual relationships which in turn can be used for building better dynamics models. Analogously, we would expect such interaction to be helpful for a learning agent while it learns to model the dynamics of the environment. In this paper, we build upon this intuition, by using an auxiliary cost function to ensure consistency between what the agent observes (by actually performing actions in the real world) and what it hallucinates (by imagining to have taken actions in the environment). Our empirical analysis shows that the proposed approach helps to train powerful policies as well as better dynamics models. ", "keywords": ["model-based reinforcement learning", "deep learning", "generative agents", "policy gradient", "imitation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1278/Authors"], "authors": ["Anonymous"], "TL;DR": "In this paper, we formulate a way to ensure consistency between the predictions of dynamics model and the real observations from the environment. Thus allowing us to learn powerful policies, as well as better dynamics models.", "pdf": "/pdf/ee279634592f8129e2529b57f2244636b38853eb.pdf", "paperhash": "anonymous|learning_powerful_policies_and_better_generative_models_by_interaction", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning powerful policies and better generative models by interaction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJldzhA5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJg_fnRqF7", "original": "H1llo5DFFX", "number": 1279, "cdate": 1538087951984, "ddate": null, "tcdate": 1538087951984, "tmdate": 1538155953442, "tddate": null, "forum": "BJg_fnRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep clustering based on a mixture of autoencoders", "abstract": "In this paper we propose a Deep Autoencoder Mixture Clustering (DAMIC) algorithm. It is based on a mixture of deep autoencoders where each cluster is represented by an autoencoder. A clustering network transforms the data into another space and then selects one of the clusters. Next, the autoencoder associated with this cluster is used to reconstruct the data-point. The clustering algorithm jointly learns the nonlinear data representation and the set of autoencoders. The optimal clustering is found by minimizing the reconstruction loss of the mixture of autoencoder network. Unlike other deep clustering algorithms, no regularization term is needed to avoid data collapsing to a single point. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.", "keywords": ["deep clustering", "mixture of experts", "mixture of autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper1279/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a deep clustering method where instead of a centroid each cluster is represented by an autoencoder", "pdf": "/pdf/a71fe2eb4a08b69562465509f78c87f8a844cf53.pdf", "paperhash": "anonymous|deep_clustering_based_on_a_mixture_of_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep clustering based on a mixture of autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJg_fnRqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkeuz20cYm", "original": "BklK1fqcY7", "number": 1280, "cdate": 1538087952156, "ddate": null, "tcdate": 1538087952156, "tmdate": 1538155953237, "tddate": null, "forum": "Bkeuz20cYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Double Neural Counterfactual Regret Minimization", "abstract": "Counterfactual regret minimization (CRF) is a fundamental and effective technique for solving imperfect information games. However, the original CRF algorithm only works for discrete state and action spaces, and the resulting strategy is maintained as a tabular representation. Such tabular representation limits the method from being directly applied to large games and continuing to improve from a poor strategy profile. In this paper, we propose a double neural representation for the Imperfect Information Games, where one neural network represents the cumulative regret, and the other represents the average strategy. Furthermore, we adopt the counterfactual regret minimization algorithm to optimize this double neural representation. To make neural learning efficient, we also developed several novel techniques including a robust sampling method, mini-batch  Monte Carlo counterfactual regret minimization (MCCFR) and Monte Carlo counterfactual regret minimization plus (MCCFR+) which may be of independent interests. Experimentally, we demonstrate that the proposed double neural algorithm converges significantly better than the reinforcement learning counterpart. ", "keywords": ["Counterfactual Regret Minimization", "Imperfect Information game"], "authorids": ["ICLR.cc/2019/Conference/Paper1280/Authors"], "authors": ["Anonymous"], "TL;DR": "We proposed a double neural CFR which can match the performance of tabular based CFR and opens up the possibility for a purely neural approach to directly solve large imperfect information game.", "pdf": "/pdf/47070abd615fb10886a0e0330a9f15a1bf676d05.pdf", "paperhash": "anonymous|double_neural_counterfactual_regret_minimization", "_bibtex": "@inproceedings{    \nanonymous2019double,    \ntitle={Double Neural Counterfactual Regret Minimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkeuz20cYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkedznAqKQ", "original": "B1xKkFKcFQ", "number": 1281, "cdate": 1538087952326, "ddate": null, "tcdate": 1538087952326, "tmdate": 1538155953035, "tddate": null, "forum": "BkedznAqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LanczosNet: Multi-Scale Deep Graph Convolutional Networks", "abstract": "We propose Lanczos network (LanczosNet) which uses the Lanczos algorithm to construct low rank approximations of the graph Laplacian for graph convolution.\nRelying on the tridiagonal decomposition of the Lanczos algorithm, we not only efficiently exploit multi-scale information via fast approximated computation of matrix power but also design learnable spectral filters.\nBeing fully differentiable, LanczosNet facilitates both graph kernel learning as well as learning node embeddings. \nWe show the connection between our LanczosNet and graph based manifold learning, especially diffusion maps.\nWe benchmark our model against $8$ recent deep graph networks on citation datasets and QM8 quantum chemistry dataset. \nExperimental results show that our model achieves the state-of-the-art performance in most tasks.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1281/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8eed39aad14cffc65648f0167b66763c33f43241.pdf", "paperhash": "anonymous|lanczosnet_multiscale_deep_graph_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019lanczosnet:,    \ntitle={LanczosNet: Multi-Scale Deep Graph Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkedznAqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkGuG2R5tm", "original": "HJgNfW6qtm", "number": 1282, "cdate": 1538087952502, "ddate": null, "tcdate": 1538087952502, "tmdate": 1538155952827, "tddate": null, "forum": "SkGuG2R5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Spreading vectors for similarity search", "abstract": "Discretizing floating-point vectors is a fundamental step of modern indexing methods. State-of-the-art techniques learn parameters of the quantizers on training data for optimal performance, thus adapting quantizers to the data. In this work, we propose to reverse this paradigm and adapt the data to the quantizer: we train a neural net whose last layers form a fixed parameter-free quantizer, such as pre-defined points of a sphere. As a proxy objective, we design and train a neural network that favors uniformity in the spherical latent space, while preserving the neighborhood structure after the mapping.  For this purpose, we propose a new regularizer derived from the Kozachenko-Leonenko differential entropy estimator and combine it with a locality-aware triplet loss. \nExperiments show that our end-to-end approach outperforms most learned quantization methods, and is competitive with the state of the art on widely adopted benchmarks. Further more, we show that training without the quantization step results in almost no difference in accuracy, but yields a generic catalyser that can be applied with any subsequent quantization technique.\n", "keywords": ["dimensionality reduction", "similarity search", "indexing", "differential entropy"], "authorids": ["ICLR.cc/2019/Conference/Paper1282/Authors"], "authors": ["Anonymous"], "TL;DR": "We learn a neural network that uniformizes the input distribution, which leads to competitive indexing performance in high-dimensional space", "pdf": "/pdf/338ff2b1aa988edef5dea485f0806d94ccd2ceed.pdf", "paperhash": "anonymous|spreading_vectors_for_similarity_search", "_bibtex": "@inproceedings{    \nanonymous2019spreading,    \ntitle={Spreading vectors for similarity search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGuG2R5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgKzh0cY7", "original": "Hyxm3vaqKQ", "number": 1283, "cdate": 1538087952672, "ddate": null, "tcdate": 1538087952672, "tmdate": 1538155952619, "tddate": null, "forum": "SkgKzh0cY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Video-to-Video Translation", "abstract": "Unsupervised image-to-image translation is a recently proposed task of translating an image to a different style or domain given only unpaired image examples at training time. In this paper, we formulate a new task of unsupervised video-to-video translation, which poses its own unique challenges. Translating video implies learning not only the appearance of objects and scenes but also realistic motion and transitions between consecutive frames. We investigate the performance of per-frame video-to-video translation using existing image-to-image translation networks, and propose a spatio-temporal 3D translator as an alternative solution to this problem. We evaluate our 3D method on multiple synthetic datasets, such as moving colorized digits, as well as the realistic segmentation-to-video GTA dataset and a new CT-to-MRI volumetric images translation dataset. Our results show that frame-wise translation produces realistic results on a single frame level but underperforms significantly on the scale of the whole video compared to our three-dimensional translation approach, which is better able to learn the complex structure of video and motion and continuity of object appearance. ", "keywords": ["Generative Adversarial Networks", "Computer Vision", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1283/Authors"], "authors": ["Anonymous"], "TL;DR": "Proposed new task, datasets and baselines; 3D Conv CycleGAN preserves object properties across frames; batch structure in frame-level methods matters.", "pdf": "/pdf/09123844b56e4f98240b819d1ba3c83b8cd7a6f2.pdf", "paperhash": "anonymous|unsupervised_videotovideo_translation", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Video-to-Video Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgKzh0cY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyeKf30cFQ", "original": "ryej0CJ5Km", "number": 1284, "cdate": 1538087952836, "ddate": null, "tcdate": 1538087952836, "tmdate": 1538155952408, "tddate": null, "forum": "SyeKf30cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A theoretical framework for deep locally connected ReLU network", "abstract": "Understanding theoretical properties of deep and locally connected nonlinear network, such as deep convolutional neural network (DCNN), is still a hard problem despite its empirical success. In this paper, we propose a novel theoretical framework for such networks with ReLU nonlinearity. The framework explicitly formulates data distribution, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm. The framework is built upon teacher-student setting, by expanding the student forward/backward propagation onto the teacher's computational graph. The resulting model does not impose unrealistic assumptions (e.g., Gaussian inputs, independence of activation, etc). Our framework could help facilitate theoretical analysis of many practical issues, e.g. overfitting, generalization, disentangled representations in deep networks. ", "keywords": ["theoretical analysis", "deep network", "optimization", "disentangled representation"], "authorids": ["ICLR.cc/2019/Conference/Paper1284/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper presents a theoretical framework that models data distribution explicitly for deep and locally connected ReLU network", "pdf": "/pdf/c2704888888ccc31bc82bcca70404e2798af4de3.pdf", "paperhash": "anonymous|a_theoretical_framework_for_deep_locally_connected_relu_network", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A theoretical framework for deep locally connected ReLU network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyeKf30cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByetGn0cYX", "original": "BkxPW-T9F7", "number": 1285, "cdate": 1538087953011, "ddate": null, "tcdate": 1538087953011, "tmdate": 1538155952198, "tddate": null, "forum": "ByetGn0cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Planning with Sequential Monte Carlo", "abstract": "Planning is a fundamental ability of intelligent agents, which allows them to reason about their future\nbehavior and efficiently learn new tasks. Despite its importance, planning remains an open problem\nin complex environments. Current challenges include model compounding errors in roll-outs and\nexponential search space over trajectories. In this work, we propose a novel formulation of planning,\nwhich views it as a probabilistic inference problem over future optimal trajectories.  This enabled\nus to use sampling methods, and thus, tackle planning in continuous and high-dimensional spaces\nusing a fixed computational budget. We designed a new algorithm, Sequential Monte Carlo Planning\n(SMCP), by leveraging modern methods in Sequential Monte Carlo (SMC), Bayesian smoothing,\nand control as inference. Following, we draw parallels between our algorithm and popular planning\nmethods such as Monte Carlo Tree Search (MCTS) (Kearns et al., 2002) and Random Shooting\nmethods (Rubinstein & Kroese, 2004). Furthermore, we present experimental results competitive to\nstate-of-the-art methods on standard continuous control tasks. To conclude, we provide direction for\nfuture research in hopes of encouraging new lines of work in this domain.", "keywords": ["control as inference", "probabilistic planning", "sequential monte carlo", "model based reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1285/Authors"], "authors": ["Anonymous"], "TL;DR": "Leveraging control as inference and Sequential Monte Carlo methods, we proposed a probabilistic planning algorithm.", "pdf": "/pdf/6579f9cca92eb994d6cbe250af1f45134f086d44.pdf", "paperhash": "anonymous|probabilistic_planning_with_sequential_monte_carlo", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Planning with Sequential Monte Carlo},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByetGn0cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlYzhR9tm", "original": "rklwCKT9FX", "number": 1286, "cdate": 1538087953184, "ddate": null, "tcdate": 1538087953184, "tmdate": 1538155951989, "tddate": null, "forum": "HJlYzhR9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Language Modeling with Graph Temporal Convolutional Networks", "abstract": "Recently, there have been some attempts to use non-recurrent neural models for language modeling. \nHowever, a noticeable performance gap still remains. \nWe propose a non-recurrent neural language model, dubbed graph temporal convolutional network (GTCN), that relies on graph neural network blocks and convolution operations. While the standard recurrent neural network language models encode sentences sequentially without modeling higher-level structural information, our model regards sentences as graphs and processes input words within a message propagation framework, aiming to learn better syntactic information by inferring skip-word connections. Specifically, the graph network blocks operate in parallel and learn the underlying graph structures in sentences without any additional annotation pertaining to structure knowledge. Experiments demonstrate that the model without recurrence can achieve comparable perplexity results in language modeling tasks and successfully learn syntactic information.", "keywords": ["Graph Neural Network", "Language Modeling", "Convolution"], "authorids": ["ICLR.cc/2019/Conference/Paper1286/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/dce702241e936d676a30c8986b5621fca6b240ab.pdf", "paperhash": "anonymous|language_modeling_with_graph_temporal_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019language,    \ntitle={Language Modeling with Graph Temporal Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlYzhR9tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByftGnR9KX", "original": "Skl3B3octQ", "number": 1287, "cdate": 1538087953361, "ddate": null, "tcdate": 1538087953361, "tmdate": 1538155951778, "tddate": null, "forum": "ByftGnR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "FlowQA: Grasping Flow in History for Conversational Machine Comprehension", "abstract": "Conversational machine comprehension requires the understanding of the conversation history, such as previous question/answer pairs,  the document context, and the current question.  To enable existing machine comprehension models to encode the history comprehensively, we introduce a general mechanism, Flow, which incorporates effectively and efficiently the intermediate representations generated during the process of answering previous questions, through an alternating parallel processing structure. Our final model, FlowQA, shows superior performances on multiple datasets and domains, including two recently proposed conversational challenge datasets (QuAC and CoQA) and a sequential instruction understanding task (all three domains in SCONE), outperforming the state-of-the-art models.", "keywords": ["Machine Comprehension", "Conversational Agent", "Natural Language Processing", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1287/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose the Flow mechanism and an end-to-end architecture, FlowQA, that achieves SotA on two conversational QA datasets and a sequential instruction understanding task.", "pdf": "/pdf/20b667e841dcb432089b9d1b70a6ec02f37329fa.pdf", "paperhash": "anonymous|flowqa_grasping_flow_in_history_for_conversational_machine_comprehension", "_bibtex": "@inproceedings{    \nanonymous2019flowqa:,    \ntitle={FlowQA: Grasping Flow in History for Conversational Machine Comprehension},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByftGnR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJx9f305t7", "original": "H1g8vyA5Ym", "number": 1288, "cdate": 1538087953529, "ddate": null, "tcdate": 1538087953529, "tmdate": 1538155951568, "tddate": null, "forum": "BJx9f305t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "W2GAN: RECOVERING AN OPTIMAL TRANSPORTMAP WITH A GAN", "abstract": "Understanding and improving Generative Adversarial Networks (GAN) using notions\nfrom Optimal Transportation (OT) theory has been a successful area of study,\noriginally established by the introduction of the Wasserstein GAN (WGAN). An\nincreasing number of GANs incorporate OT for improving their discriminators,\nbut that is so far the sole way for the two domains to cross-fertilize. We consolidate\nthe bridge between GANs and OT with one model: W2GAN, where the\ndiscriminator approximates the second Wasserstein distance. This model exhibits a\ntwofold connection: the discriminator implicitly computes an optimal map and the\ngenerator follows an optimal transport map during training. Perhaps surprisingly,\nwe also provide empirical evidence that other GANs also approximately following\nthe Optimal Transport.", "keywords": ["Optimal Transportation", "Deep Learning", "Generative Adversarial Networks", "Wasserstein Distance"], "authorids": ["ICLR.cc/2019/Conference/Paper1288/Authors"], "authors": ["Anonymous"], "TL;DR": "\"A GAN-style model to recover a solution of the Monge Problem\"", "pdf": "/pdf/29f1de658f3a4e193a281de93616d1ca6c469fff.pdf", "paperhash": "anonymous|w2gan_recovering_an_optimal_transportmap_with_a_gan", "_bibtex": "@inproceedings{    \nanonymous2019w2gan:,    \ntitle={W2GAN: RECOVERING AN OPTIMAL TRANSPORTMAP WITH A GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJx9f305t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxqMhC5YQ", "original": "ryeTLW05FX", "number": 1289, "cdate": 1538087953696, "ddate": null, "tcdate": 1538087953696, "tmdate": 1538155951359, "tddate": null, "forum": "HJxqMhC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "End-to-End Multi-Lingual Multi-Speaker Speech Recognition", "abstract": "The expressive power of end-to-end automatic speech recognition (ASR) systems enables direct estimation of the character or word label sequence from  a sequence of acoustic features. Direct optimization of the whole system is advantageous because it not only eliminates the internal linkage necessary for hybrid systems,  but also extends the scope of potential application use cases by training the model for multiple objectives. Several multi-lingual ASR systems were recently proposed based on a monolithic neural network architecture without language-dependent modules, showing that modeling of multiple languages is well within the capabilities of an end-to-end framework. There has also been growing interest in multi-speaker speech recognition, which enables generation of multiple label sequences from single-channel mixed speech. In particular, a multi-speaker end-to-end ASR system that can directly model one-to-many mappings without additional auxiliary clues was recently proposed. In this paper, we propose an all-in-one end-to-end multi-lingual multi-speaker ASR system that integrates the capabilities of these two systems.  The proposed model is evaluated using mixtures of two speakers generated by using 10 languages, including mixed-language utterances. ", "keywords": ["end-to-end ASR", "multi-lingual ASR", "multi-speaker ASR", "code-switching", "encoder-decoder", "connectionist temporal classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1289/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5a2417c87058d260939b1619f5b703feeaf2e6b3.pdf", "paperhash": "anonymous|endtoend_multilingual_multispeaker_speech_recognition", "_bibtex": "@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-End Multi-Lingual Multi-Speaker Speech Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxqMhC5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkg5fh0ctQ", "original": "Bye0wyhqKX", "number": 1290, "cdate": 1538087953870, "ddate": null, "tcdate": 1538087953870, "tmdate": 1538155951152, "tddate": null, "forum": "rkg5fh0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Transferring SLU Models in Novel Domains", "abstract": "Spoken language understanding (SLU) is a critical component in building dialogue systems. When building models for novel natural language domains, a major challenge is the lack of data in in the new domains, no matter whether the data is annotated or not. Recognizing and annotating \"intent\" and \"slot\" of natural languages is a time-consuming process. Therefore, spoken language understanding in low resource domains remains a crucial problem to address. In this paper, we address this problem by proposing a transfer-learning method, whereby an SLU model is transferred to a novel but data-poor domain via a deep neural network framework. We  also introduce meta-learning in our work to bridge the semantic relations between seen and unseen data, allowing new intents to be recognized and new slots to be filled with much lower new training effort. We show the performance improvement via analytical and experimental results for spoken language understanding in low resource domains. We show that our method can also handle novel intent recognition and slot-filling tasks. Our methodology provides a feasible solution for alleviating data shortages in spoken language understanding.", "keywords": ["transfer learning", "semantic representation", "spoken language understanding"], "authorids": ["ICLR.cc/2019/Conference/Paper1290/Authors"], "authors": ["Anonymous"], "TL;DR": "v1", "pdf": "/pdf/62ed174f38d18302d8df65ec8c2694602dccda4f.pdf", "paperhash": "anonymous|transferring_slu_models_in_novel_domains", "_bibtex": "@inproceedings{    \nanonymous2019transferring,    \ntitle={Transferring SLU Models in Novel Domains},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkg5fh0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lcM3AcKm", "original": "BkxHz6ncKm", "number": 1291, "cdate": 1538087954045, "ddate": null, "tcdate": 1538087954045, "tmdate": 1538155950942, "tddate": null, "forum": "r1lcM3AcKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RNNs with Private and Shared Representations for Semi-Supervised Sequence Learning", "abstract": "Training recurrent neural networks (RNNs) on long sequences using backpropagation through time (BPTT) remains a fundamental challenge. \nIt has been shown that adding a local unsupervised loss term into the optimization objective makes the training of RNNs on long sequences more effective. \nWhile the importance of an unsupervised task can in principle be controlled by a coefficient in the objective function, the gradients with respect to the unsupervised loss term still influence all the hidden state dimensions, which might cause important information about the supervised task to be degraded or erased. \nCompared to existing semi-supervised sequence learning methods, this paper focuses upon a traditionally overlooked mechanism -- an architecture with explicitly designed private and shared hidden units designed to mitigate the detrimental influence of the auxiliary unsupervised loss over the main supervised task.\nWe achieve this by dividing RNN hidden space into a private space for the supervised task and a shared space for both the supervised and unsupervised tasks. We present extensive experiments with the proposed framework on several long sequence modeling benchmark datasets. Results indicate that the proposed framework can yield performance gains in RNN models where long term dependencies are notoriously challenging to deal with. ", "keywords": ["recurrent neural network", "semi-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1291/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper focuses upon a traditionally overlooked mechanism -- an architecture with explicitly designed private and shared hidden units designed to mitigate the detrimental influence of the auxiliary unsupervised loss over the main supervised task.", "pdf": "/pdf/b845dfbee6c7106841ddce3748ea671dc2ce68a3.pdf", "paperhash": "anonymous|rnns_with_private_and_shared_representations_for_semisupervised_sequence_learning", "_bibtex": "@inproceedings{    \nanonymous2019rnns,    \ntitle={RNNs with Private and Shared Representations for Semi-Supervised Sequence Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lcM3AcKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1g5Gh05KQ", "original": "BJeuxc6cKX", "number": 1292, "cdate": 1538087954218, "ddate": null, "tcdate": 1538087954218, "tmdate": 1538155950730, "tddate": null, "forum": "r1g5Gh05KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks", "abstract": "In this paper we present a novel optimization algorithm called Advanced Neuroevolution. The aim for this algorithm is to train deep neural networks, and eventually act as an alternative to Stochastic Gradient Descent (SGD) and its variants as needed.We evaluated our algorithm on the MNIST dataset, as well as on several global optimization problems such as the Ackley function. We find the algorithm performing relatively well for both cases, overtaking other global optimization algorithms such as Particle Swarm Optimization (PSO) and Evolution Strategies (ES).\n", "keywords": ["Evolutionary Algorithm", "Optimization", "MNIST"], "authorids": ["ICLR.cc/2019/Conference/Paper1292/Authors"], "authors": ["Anonymous"], "TL;DR": "A new algorithm to train deep neural networks. Tested on optimization functions and MNIST.", "pdf": "/pdf/2ae00ab0d742f5c97e9625ad257b7fcac027ad0b.pdf", "paperhash": "anonymous|advanced_neuroevolution_a_gradientfree_algorithm_to_train_deep_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019advanced,    \ntitle={Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g5Gh05KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lqMn05Ym", "original": "BygZzp35YX", "number": 1293, "cdate": 1538087954394, "ddate": null, "tcdate": 1538087954394, "tmdate": 1538155950512, "tddate": null, "forum": "S1lqMn05Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Information asymmetry in KL-regularized RL", "abstract": "Many real world tasks exhibit rich structure that is repeated across different parts of the state space or in time. In this work we study the possibility of leveraging such repeated structure to speed up and regularize learning. We start from the KL regularized expected reward objective which introduces an additional component, a default policy. Instead of relying on a fixed default policy, we learn it from data. But crucially, we restrict the amount of information the default policy receives, forcing it to learn reusable behaviors that help the policy learn faster. We formalize this strategy and discuss connections to information bottleneck approaches and to the variational EM algorithm. We present empirical results in both discrete and continuous action domains and demonstrate that, for certain tasks, learning a default policy alongside the policy can significantly speed up and improve learning.\nPlease watch the video demonstrating learned experts and default policies on several continuous control tasks ( https://youtu.be/U2qA3llzus8 ).", "keywords": ["Deep Reinforcement Learning", "Continuous Control", "RL as Inference"], "authorids": ["ICLR.cc/2019/Conference/Paper1293/Authors"], "authors": ["Anonymous"], "TL;DR": "Limiting state information for the default policy can improvement performance, in a KL-regularized RL framework where both agent and default policy are optimized together", "pdf": "/pdf/85df266a4edb147aa87e619ef37844404d225536.pdf", "paperhash": "anonymous|information_asymmetry_in_klregularized_rl", "_bibtex": "@inproceedings{    \nanonymous2019information,    \ntitle={Information asymmetry in KL-regularized RL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lqMn05Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlif3C5FQ", "original": "Syg1k6J5KX", "number": 1294, "cdate": 1538087954564, "ddate": null, "tcdate": 1538087954564, "tmdate": 1538155950305, "tddate": null, "forum": "BJlif3C5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering", "abstract": "Open-domain question answering remains a challenging task as it requires models that are capable of understanding questions and answers, collecting useful information, and reasoning over evidence. Previous work typically formulates this task as a reading comprehension or entailment problem given evidence retrieved from search engines. However, existing techniques struggle to retrieve indirectly related evidence when no directly related evidence is provided, especially for complex questions where it is hard to parse precisely what the question asks. In this paper we propose a retriever-reader model that learns to attend on essential terms during the question answering process. We build (1) an essential term selector which first identifies the most important words in a question, then reformulates the query and searches for related evidence; and (2) an enhanced reader that distinguishes between essential terms and distracting words to predict the answer. We evaluate our model on multiple open-domain QA datasets where it outperforms the existing state-of-the-art, notably leading to an improvement of 8.1% on the AI2 Reasoning Challenge (ARC) dataset.", "keywords": ["Open-domain question answering"], "authorids": ["ICLR.cc/2019/Conference/Paper1294/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/dee21fa5763055629b0e8bfa7b9123e9eeac0a37.pdf", "paperhash": "anonymous|learning_to_attend_on_essential_terms_an_enhanced_retrieverreader_model_for_opendomain_question_answering", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlif3C5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgiM20cYX", "original": "r1lCFGCqKX", "number": 1295, "cdate": 1538087954725, "ddate": null, "tcdate": 1538087954725, "tmdate": 1538155950094, "tddate": null, "forum": "BkgiM20cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Self-Supervised Method for Mapping Human Instructions to Robot Policies", "abstract": "In this paper, we propose a modular approach which separates the instruction-to-action mapping procedure into two separate stages. The two stages are bridged via an intermediate representation called a goal, which stands for the result after a robot performs a specific task. \nThe first stage maps an input instruction to a goal, while the second stage maps the goal to an appropriate policy selected from a set of robot policies.  The policy is selected with an aim to guide the robot to reach the goal as close as possible.  We implement the above two stages as a framework consisting of two distinct modules: an instruction-goal mapping module and a goal-policy mapping module.  Given a human instruction in the evaluation phase, the instruction-goal mapping module first translates the instruction to a robot-interpretable goal.  Once a goal is derived by the instruction-goal mapping module, the goal-policy mapping module then follows up to search through the goal-policy pairs to look for policy to be mapped by the instruction.  Our experimental results show that the proposed method is able to learn an effective instruction-to-action mapping procedure in an environment with a given instruction set more efficiently than the baselines.   In addition to the impressive data-efficiency, the results also show that our method can be adapted to a new instruction set and a new robot action space much faster than the baselines.  The evidence suggests that our modular approach does lead to better adaptability and efficiency.  ", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1295/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7c55071f6be1ffb6af48db8d2bfe7b6a77ef5595.pdf", "paperhash": "anonymous|a_selfsupervised_method_for_mapping_human_instructions_to_robot_policies", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Self-Supervised Method for Mapping Human Instructions to Robot Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgiM20cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJliMh09F7", "original": "B1xcGa1qY7", "number": 1296, "cdate": 1538087954886, "ddate": null, "tcdate": 1538087954886, "tmdate": 1538155949886, "tddate": null, "forum": "rJliMh09F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diversity-Sensitive Conditional Generative Adversarial Networks", "abstract": "We propose a simple yet highly effective method that addresses the mode-collapse problem in the Conditional Generative  Adversarial  Network (cGAN). Although conditional distributions are multi-modal (i.e., having many modes) in practice, most cGAN approaches tend to learn an overly simplified distribution where an input is always mapped to a single output regardless of variations in latent code. To address such issue, we propose to explicitly regularize the generator to produce diverse outputs depending on latent codes. The proposed regularization is simple, general, and can be easily integrated into most conditional GAN objectives. Additionally, explicit regularization on generator allows our method to control a balance between visual quality and diversity. We demonstrate the effectiveness of our method on three conditional generation tasks: image-to-image translation, image inpainting, and future video prediction. We show that simple addition of our regularization to existing models leads to surprisingly diverse generations, substantially outperforming the previous approaches for multi-modal conditional generation specifically designed in each individual task.", "keywords": ["Conditional Generative Adversarial Network", "mode-collapse", "multi-modal generation"], "authorids": ["ICLR.cc/2019/Conference/Paper1296/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a simple and general approach that avoids a mode collapse problem in various conditional GANs.", "pdf": "/pdf/77db08ff55c7097e49db8f2a66831980911aa357.pdf", "paperhash": "anonymous|diversitysensitive_conditional_generative_adversarial_networks", "_bibtex": "@inproceedings{    \nanonymous2019diversity-sensitive,    \ntitle={Diversity-Sensitive Conditional Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJliMh09F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gsz30cKX", "original": "HJxQcfC9tX", "number": 1297, "cdate": 1538087955054, "ddate": null, "tcdate": 1538087955054, "tmdate": 1538155949677, "tddate": null, "forum": "H1gsz30cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Unreasonable Effectiveness of (Zero) Initialization in Deep Residual Learning", "abstract": "Normalization layers are a staple in state-of-the-art deep neural network architectures. They are widely believed to stabilize training, enable higher learning rate, accelerate convergence and improve generalization, though the reason for their effectiveness is still an active research topic. In this work, we challenge the commonly-held beliefs by showing that none of the perceived benefits is unique to normalization. Specifically, we propose ZeroInit, an initialization motivated by solving the exploding and vanishing gradient problem at the beginning of training by initializing as a zero function. We find training residual networks with ZeroInit to be as stable as training with normalization - even for networks with 10,000 layers. Furthermore, with proper regularization, ZeroInit without normalization matches or exceeds the performance of state-of-the-art residual networks in image classification and machine translation.", "keywords": ["deep learning", "residual networks", "initialization"], "authorids": ["ICLR.cc/2019/Conference/Paper1297/Authors"], "authors": ["Anonymous"], "TL;DR": "All you need to train deep residual networks is a good initialization; normalization layers are not necessary.", "pdf": "/pdf/faaa7e9038f851aa079427a5f3c85a002b2aa0b8.pdf", "paperhash": "anonymous|the_unreasonable_effectiveness_of_zero_initialization_in_deep_residual_learning", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Unreasonable Effectiveness of (Zero) Initialization in Deep Residual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gsz30cKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkesGnCcFX", "original": "HkxAheGEYX", "number": 1298, "cdate": 1538087955226, "ddate": null, "tcdate": 1538087955226, "tmdate": 1538155949469, "tddate": null, "forum": "BkesGnCcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards", "abstract": "Multi-goal reinforcement learning (MGRL) addresses tasks where the desired goal state can change for every trial. State-of-the-art algorithms model these problems such that the reward formulation depends on the goals, to associate them with high reward. This dependence introduces additional goal reward resampling steps in algorithms like Hindsight Experience Replay (HER) that reuse trials in which the agent fails to reach the goal by recomputing rewards as if reached states were psuedo-desired goals. We propose a reformulation of goal-conditioned value functions for MGRL that yields a similar algorithm, while removing the dependence of reward functions on the goal. Our formulation thus obviates the requirement of reward-recomputation that is needed by HER and its extensions. We also extend a closely related algorithm, Floyd-Warshall Reinforcement Learning, from tabular domains to deep neural networks for use as a baseline. Our results are competetive with HER while substantially improving sampling efficiency in terms of reward computation. \n", "keywords": ["Floyd-Warshall", "Reinforcement learning", "goal conditioned value functions", "multi-goal"], "authorids": ["ICLR.cc/2019/Conference/Paper1298/Authors"], "authors": ["Anonymous"], "TL;DR": "Do Goal-Conditioned Value Functions need Goal-Rewards to Learn?", "pdf": "/pdf/a5d20758e48df1a2e3cc19a35fbbb2366d9cc085.pdf", "paperhash": "anonymous|learning_goalconditioned_value_functions_with_onestep_path_rewards_rather_than_goalrewards", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkesGnCcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygsfnR9Ym", "original": "rJxDGe59K7", "number": 1299, "cdate": 1538087955390, "ddate": null, "tcdate": 1538087955390, "tmdate": 1538155949255, "tddate": null, "forum": "HygsfnR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Recall Traces: Backtracking Models for Efficient Reinforcement Learning", "abstract": "In many environments only a tiny subset of all states yield high reward.  In these cases, few of the interactions with the environment provide a relevant learning signal. Hence, we may want to preferentially train on those high-reward states and the probable trajectories leading to them. \nTo this end, we advocate for the use of a \\textit{backtracking model} that predicts the preceding states that terminate at a given high-reward state.  We can train a model which, starting from a high value state (or one that is estimated to have high value), predicts and samples which (state, action)-tuples may have led to that high value state. These traces of (state, action) pairs, which we refer to as Recall Traces, sampled from this backtracking model starting from a high value state, are informative as they terminate in good states, and hence we can use these traces to improve a policy. We provide a variational interpretation for this idea and a practical algorithm in which the backtracking model samples from an approximate posterior distribution over trajectories which lead to large rewards. Our method improves the sample efficiency of both on- and off-policy RL algorithms across several environments and tasks.  ", "keywords": ["Model free RL", "Variational Inference"], "authorids": ["ICLR.cc/2019/Conference/Paper1299/Authors"], "authors": ["Anonymous"], "TL;DR": "A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.", "pdf": "/pdf/f91f9160721e63013ee94602aa6393338bede99d.pdf", "paperhash": "anonymous|recall_traces_backtracking_models_for_efficient_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019recall,    \ntitle={Recall Traces: Backtracking Models for Efficient Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygsfnR9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyehMhC9Y7", "original": "S1ewNGRcYQ", "number": 1300, "cdate": 1538087955556, "ddate": null, "tcdate": 1538087955556, "tmdate": 1538155949047, "tddate": null, "forum": "SyehMhC9Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Imitative Models: Perception-Driven Forecasting for Flexible Planning and Control", "abstract": "Imitation learning provides an appealing framework for autonomous control: in many tasks, demonstrations can be readily obtained from human experts, and using demonstration data removes the need for costly and potentially dangerous on-policy trials in the real world. On the other hand, model-based reinforcement learning offers considerably more flexibility: a model learned from data can be reused at test-time to achieve a wide variety of goals. In this paper, we aim to combine these benefits to learn imitative models: predictive models that can be used to plan behaviors at test-time that achieve user specified goals, while remaining close to the distribution of behaviors seen in the demonstration data. We find that this method substantially improves on the performance of both direct imitation and model-based RL in a simulated driving task, and can be learned efficiently and safely using only demonstration data without on-policy data collection.", "keywords": ["imitation learning", "forecasting", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper1300/Authors"], "authors": ["Anonymous"], "TL;DR": "Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control", "pdf": "/pdf/e7f06a9d6c29d2a4170ecc522e99891059f5388b.pdf", "paperhash": "anonymous|imitative_models_perceptiondriven_forecasting_for_flexible_planning_and_control", "_bibtex": "@inproceedings{    \nanonymous2019imitative,    \ntitle={Imitative Models: Perception-Driven Forecasting for Flexible Planning and Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyehMhC9Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HklnzhR9YQ", "original": "r1lX-a5cYX", "number": 1301, "cdate": 1538087955715, "ddate": null, "tcdate": 1538087955715, "tmdate": 1538155948836, "tddate": null, "forum": "HklnzhR9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks", "abstract": "We develop new approximation and statistical learning theories of convolutional neural networks (CNNs) via the ResNet-type structure where the channel size, width, and filter size are fixed. It is shown that a ResNet-type CNN is a universal approximator and its expression ability is no worse than fully connected neural networks (FNNs) with a \\textit{block-sparse} structure even if the size of each layer in the CNN is fixed. Our result is general in the sense that we can automatically translate any approximation rate achieved by block-sparse FNNs into that by CNNs. Thanks to the general theory, it is shown that learning on CNNs satisfies optimality in approximation and estimation of several important function classes.\n\nAs applications, we consider two types of function classes to be estimated: the Barron class and the H\\\"older class. We prove the regularized empirical risk minimization (ERM) estimator can achieve the same rate as FNNs even the channel size, filter size, and width of CNNs are constant with respect to the sample size. This is minimax optimal (up to logarithmic factors) for the H\\\"older class. Our proof is based on sophisticated evaluations of the covering number of CNNs and the non-trivial parameter rescaling technique to control the Lipschitz constant of CNNs to be constructed.", "keywords": ["CNN", "ResNet", "learning theory", "approximation theory", "non-parametric estimation", "block-sparse"], "authorids": ["ICLR.cc/2019/Conference/Paper1301/Authors"], "authors": ["Anonymous"], "TL;DR": "It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.", "pdf": "/pdf/5d1049a39e663fc5bab274ddf45840b2b757b2c9.pdf", "paperhash": "anonymous|approximation_and_nonparametric_estimation_of_resnettype_convolutional_neural_networks_via_blocksparse_fullyconnected_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019approximation,    \ntitle={Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklnzhR9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skl3M20qYQ", "original": "rye_cGAcY7", "number": 1302, "cdate": 1538087955935, "ddate": null, "tcdate": 1538087955935, "tmdate": 1538155948622, "tddate": null, "forum": "Skl3M20qYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Non-Synergistic Variational Autoencoders", "abstract": "Learning disentangling representations of the independent factors of variations that explain the data in an unsupervised setting is still a major challenge. In the following paper we address the task of disentanglement and introduce a new state-of-the-art approach called Non-synergistic variational Autoencoder (Non-Syn VAE). Our model draws inspiration from population coding, where the notion of synergy arises when we describe the encoded information by neurons in the form of responses from the stimuli. If those responses convey more information together than separate as independent sources of encoding information, they are acting synergetically. By penalizing the synergistic mutual information within the latents we encourage information independence and by doing that disentangle the latent factors. Notably, our approach could be added to the VAE framework easily, where the new ELBO function is still a lower bound on the log likelihood. In addition, we qualitatively compare our model with Factor VAE and show that this one implicitly minimises the synergy of the latents.", "keywords": ["vae", "unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1302/Authors"], "authors": ["Anonymous"], "TL;DR": "Minimising the synergistic mutual information within the latents and the data for the task of disentanglement using the VAE framework.", "pdf": "/pdf/7833c73abe14c35964bbb956520e8c6c895bcb80.pdf", "paperhash": "anonymous|nonsynergistic_variational_autoencoders", "_bibtex": "@inproceedings{    \nanonymous2019non-synergistic,    \ntitle={Non-Synergistic Variational Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skl3M20qYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygnfn0qF7", "original": "SygEdbAqY7", "number": 1303, "cdate": 1538087956100, "ddate": null, "tcdate": 1538087956100, "tmdate": 1538155948410, "tddate": null, "forum": "rygnfn0qF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Language Model Pre-training for Hierarchical Document Representations", "abstract": "Hierarchical neural architectures can efficiently capture long-distance dependencies and have been used for many document-level tasks such as summarization, document segmentation, and fine-grained sentiment analysis. However, effective usage of such a large context can difficult to learn, especially in the case where there is limited labeled data available.\nBuilding on the recent success of language model pretraining methods for learning flat representations of text, we propose algorithms for pre-training hierarchical document representations from unlabeled data. Unlike prior work, which has focused on pre-training contextual token representations or context-independent sentence/paragraph representations, our hierarchical document representations include fixed-length sentence/paragraph representations which integrate contextual information from the entire documents. Experiments on document segmentation, document-level question answering, and extractive document summarization demonstrate the effectiveness of the proposed pre-training algorithms.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1303/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/faa5383f7b5d890e51ce4ee6fe7f34b51ed18887.pdf", "paperhash": "anonymous|language_model_pretraining_for_hierarchical_document_representations", "_bibtex": "@inproceedings{    \nanonymous2019language,    \ntitle={Language Model Pre-training for Hierarchical Document Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygnfn0qF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1lnzn0ctQ", "original": "B1xa-XacFQ", "number": 1304, "cdate": 1538087956274, "ddate": null, "tcdate": 1538087956274, "tmdate": 1538155948200, "tddate": null, "forum": "B1lnzn0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA", "abstract": "Deep neural networks based on unfolding an iterative algorithm, for example, LISTA (learned iterative shrinkage thresholding algorithm), have been an empirical success for sparse signal recovery. The weights of these neural networks are currently determined by data-driven \u201cblack-box\u201d training. In this work, we propose Analytic LISTA (ALISTA), where the weight matrix in LISTA is computed as the solution to a data-free optimization problem, leaving only the stepsize and threshold parameters to data-driven learning. This signi\ufb01cantly simpli\ufb01es the training. Speci\ufb01cally, the data-free optimization problem is based on coherence minimization. We show our ALISTA retains the optimal linear convergence proved in (Chen et al., 2018) and has a performance comparable to LISTA. Furthermore, we extend ALISTA to convolutional linear operators, again determined in a data-free manner. We also propose a feed-forward framework that combines the data-free optimization and ALISTA networks from end to end, one that can be jointly trained to gain robustness to small perturbations in the encoding model.", "keywords": ["sparse recovery", "neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1304/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/aeeda1abcbe10553a9dfe965bcb3f7fa6891436d.pdf", "paperhash": "anonymous|alista_analytic_weights_are_as_good_as_learned_weights_in_lista", "_bibtex": "@inproceedings{    \nanonymous2019alista:,    \ntitle={ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lnzn0ctQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJMnG2C9YX", "original": "Syes4fOqF7", "number": 1305, "cdate": 1538087956443, "ddate": null, "tcdate": 1538087956443, "tmdate": 1538155947993, "tddate": null, "forum": "SJMnG2C9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Complementary-label learning for arbitrary losses and models", "abstract": "In contrast to the standard classification paradigm where the true (or possibly noisy) class is given to each training pattern, complementary-label learning only uses training patterns each equipped with a complementary label. This only specifies one of the classes that the pattern does not belong to. The seminal paper on complementary-label learning proposed an unbiased estimator of the classification risk that can be computed only from complementarily labeled data. How- ever, it required a restrictive condition on the loss functions, making it impossible to use popular losses such as the softmax cross-entropy loss. Recently, another formulation with the softmax cross-entropy loss was proposed with consistency guarantee. However, this formulation does not explicitly involve a risk estimator. Thus model/hyper-parameter selection is not possible by cross-validation\u2014 we may need additional ordinarily labeled data for validation purposes, which is not available in the current setup. In this paper, we give a novel general framework of complementary-label learning, and derive an unbiased risk estimator for arbitrary losses and models. We further improve the risk estimator by non-negative correction and demonstrate its superiority through experiments.", "keywords": ["complementary labels", "weak supervision"], "authorids": ["ICLR.cc/2019/Conference/Paper1305/Authors"], "authors": ["Anonymous"], "TL;DR": "From now on, you can train ResNet and DenseNet, even if no class label given for training is correct!", "pdf": "/pdf/e98a6e24cbb3e2d9545a12aa83f4115c1bc1f800.pdf", "paperhash": "anonymous|complementarylabel_learning_for_arbitrary_losses_and_models", "_bibtex": "@inproceedings{    \nanonymous2019complementary-label,    \ntitle={Complementary-label learning for arbitrary losses and models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMnG2C9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byxpfh0cFm", "original": "r1gFusacKQ", "number": 1306, "cdate": 1538087956613, "ddate": null, "tcdate": 1538087956613, "tmdate": 1538155947783, "tddate": null, "forum": "Byxpfh0cFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Augmentation via Data Subsampling", "abstract": "Data augmentation is commonly used to encode invariances in learning methods. However, this process is often performed in an inefficient manner, as artificial examples are created by applying a number of transformations to all points in the training set. The resulting explosion of the dataset size can be an issue in terms of storage and training costs, as well as in selecting and tuning the optimal set of transformations to apply. In this work, we demonstrate that it is possible to significantly reduce the number of data points included in data augmentation while realizing the same accuracy and invariance benefits of augmenting the entire dataset. We propose a novel set of subsampling policies, based on model influence and loss, that can achieve a 90% reduction in augmentation set size while maintaining the accuracy gains of standard data augmentation.", "keywords": ["data augmentation", "invariance", "subsampling", "influence"], "authorids": ["ICLR.cc/2019/Conference/Paper1306/Authors"], "authors": ["Anonymous"], "TL;DR": "Selectively augmenting difficult to classify points results in efficient training.", "pdf": "/pdf/ac8b94c652d10b2e0b242084d51b5f67b594057d.pdf", "paperhash": "anonymous|efficient_augmentation_via_data_subsampling", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Augmentation via Data Subsampling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byxpfh0cFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJl6M2C5Y7", "original": "BJeEYCa5KQ", "number": 1307, "cdate": 1538087956774, "ddate": null, "tcdate": 1538087956774, "tmdate": 1538155947569, "tddate": null, "forum": "rJl6M2C5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Online Hyperparameter Adaptation via Amortized Proximal Optimization", "abstract": "Effective performance of neural networks depends criticially on effective tuning of optimization hyperparameters, especially learning rates (and schedules thereof). We present Amortized Proximal Optimization, which takes the perspective that each optimization step should approximately minimize a proximal objective (similar to the ones used to motivate natural gradient and trust region policy optimization). Optimization hyperparameters are adapted to best minimize the proximal objective after one weight update. We show that an idealized version of APO (where an oracle minimizes the proximal objective exactly) achieves second-order convergence rates for neural networks. APO incurs minimal computational overhead. We experiment with using APO to adapt a variety of optimization hyperparameters online during training, including (possibly layer-specific) learning rates, damping coefficients, and gradient variance exponents. For a variety of network architectures and optimization algorithms (including SGD, RMSprop, and K-FAC), we show that with minimal tuning, APO performs competitively with carefully tuned optimizers.", "keywords": ["hyperparameters", "optimization", "learning rate adaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper1307/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce amortized proximal optimization (APO), a method to adapt a variety of optimization hyperparameters online during training, including learning rates, damping coefficients, and gradient variance exponents.", "pdf": "/pdf/54389c41f62c3d2de7733b9c7097351bca85ea9c.pdf", "paperhash": "anonymous|online_hyperparameter_adaptation_via_amortized_proximal_optimization", "_bibtex": "@inproceedings{    \nanonymous2019online,    \ntitle={Online Hyperparameter Adaptation via Amortized Proximal Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl6M2C5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJG6G2RqtX", "original": "SJeBFnFcK7", "number": 1308, "cdate": 1538087956938, "ddate": null, "tcdate": 1538087956938, "tmdate": 1538155947353, "tddate": null, "forum": "SJG6G2RqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Value Propagation Networks", "abstract": "We present Value Propagation (VProp), a set of parameter-efficient differentiable planning modules built on Value Iteration which can successfully be trained using reinforcement learning to solve unseen tasks, has the capability to generalize to larger map sizes, and can learn to navigate in dynamic environments. We show that the modules enable learning to plan when the environment also includes stochastic elements, providing a cost-efficient learning system to build low-level size-invariant planners for a variety of interactive navigation problems. We evaluate on static and dynamic configurations of MazeBase grid-worlds, with randomly generated environments of several different sizes, and on a StarCraft navigation scenario, with more complex dynamics, and pixels as input.", "keywords": ["Reinforcement Learning", "Value Iteration", "Navigation", "Convolutional Neural Networks", "Learning to plan"], "authorids": ["ICLR.cc/2019/Conference/Paper1308/Authors"], "authors": ["Anonymous"], "TL;DR": "We present planners based on convnets that are sample-efficient and that generalize to larger instances of navigation and pathfinding problems.", "pdf": "/pdf/40394ed5977d4585c5d85198e47dc93de9443168.pdf", "paperhash": "anonymous|value_propagation_networks", "_bibtex": "@inproceedings{    \nanonymous2019value,    \ntitle={Value Propagation Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJG6G2RqtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJz6MnC5YQ", "original": "HylebAT5Ym", "number": 1309, "cdate": 1538087957108, "ddate": null, "tcdate": 1538087957108, "tmdate": 1538155947138, "tddate": null, "forum": "SJz6MnC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DEEP GRAPH TRANSLATION", "abstract": "The tremendous success of deep generative models on generating continuous data\nlike image and audio has been achieved; however, few deep graph generative models\nhave been proposed to generate discrete data such as graphs. The recently proposed\napproaches are typically unconditioned generative models which have no\ncontrol over modes of the graphs being generated. Differently, in this paper, we\nare interested in a new problem named Deep Graph Translation: given an input\ngraph, the goal is to infer a target graph by learning their underlying translation\nmapping. Graph translation could be highly desirable in many applications such\nas disaster management and rare event forecasting, where the rare and abnormal\ngraph patterns (e.g., traffic congestions and terrorism events) will be inferred prior\nto their occurrence even without historical data on the abnormal patterns for this\nspecific graph (e.g., a road network or human contact network). To this end, we\npropose a novel Graph-Translation-Generative Adversarial Networks (GT-GAN)\nwhich translates one mode of the input graphs to its target mode. GT-GAN consists\nof a graph translator where we propose new graph convolution and deconvolution\nlayers to learn the global and local translation mapping. A new conditional\ngraph discriminator has also been proposed to classify target graphs by conditioning\non input graphs. Extensive experiments on multiple synthetic and real-world\ndatasets demonstrate the effectiveness and scalability of the proposed GT-GAN.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1309/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/f086f09adc7973bd5cbdba350b6ee6ed5ad281b4.pdf", "paperhash": "anonymous|deep_graph_translation", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={DEEP GRAPH TRANSLATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJz6MnC5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1g6zn09tm", "original": "H1xk8RpcYm", "number": 1310, "cdate": 1538087957286, "ddate": null, "tcdate": 1538087957286, "tmdate": 1538155946721, "tddate": null, "forum": "S1g6zn09tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Latent Transformations for View Synthesis with Conditional Convolutional Networks", "abstract": "We propose a fully-convolutional conditional generative model, the latent transformation neural network (LTNN), capable of view synthesis using a light-weight neural network suited for real-time applications. In contrast to existing conditional\ngenerative models which incorporate conditioning information via concatenation, we introduce a dedicated network component, the conditional transformation unit (CTU), designed to learn the latent space transformations corresponding to specified target views. In addition, a consistency loss term is defined to guide the network toward learning the desired latent space mappings, a task-divided decoder is constructed to refine the quality of generated views, and an adaptive discriminator is introduced to improve the adversarial training process. The generality of the proposed methodology is demonstrated on a collection of three diverse tasks: multi-view reconstruction on real hand depth images, view synthesis of real and synthetic faces, and the rotation of rigid objects. The proposed model is shown to exceed state-of-the-art results in each category while simultaneously achieving a reduction in the computational demand required for inference by 30% on average.", "keywords": ["conditional generative model", "deep learning", "fully-convolutional network", "image attribute modification", "multi-view reconstruction", "view sythesis"], "authorids": ["ICLR.cc/2019/Conference/Paper1310/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce an effective, general framework for incorporating conditioning information into inference-based generative models.", "pdf": "/pdf/14e16fecd8cd1c66370d30c6c0c6a2d5e531d7fa.pdf", "paperhash": "anonymous|latent_transformations_for_view_synthesis_with_conditional_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019latent,    \ntitle={Latent Transformations for View Synthesis with Conditional Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1g6zn09tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJlpM3RqKQ", "original": "Byg0eunKFQ", "number": 1311, "cdate": 1538087957456, "ddate": null, "tcdate": 1538087957456, "tmdate": 1538155946512, "tddate": null, "forum": "SJlpM3RqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Expanding the Reach of Federated Learning by Reducing Client Resource Requirements", "abstract": "Communication on heterogeneous edge networks is a fundamental bottleneck in Federated Learning (FL), restricting both model capacity and user participation. To address this issue, we introduce two novel strategies to reduce communication costs: (1) the use of lossy compression on the global model sent server-to-client; and (2) Federated Dropout, which allows users to efficiently train locally on smaller subsets of the global model and also provides a reduction in both client-to-server communication and local computation. We empirically show that these strategies, combined with existing compression approaches for client-to-server communication, collectively provide up to a 9.6x reduction in server-to-client communication, a 1.5x reduction in local computation, and a 24x reduction in upload communication, all without degrading the quality of the final model. We thus comprehensively reduce FL's impact on client device resources, allowing higher capacity models to be trained, and a more diverse set of users to be reached.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1311/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/df01b90d345d69095417a8e88486a112eacbb7de.pdf", "paperhash": "anonymous|expanding_the_reach_of_federated_learning_by_reducing_client_resource_requirements", "_bibtex": "@inproceedings{    \nanonymous2019expanding,    \ntitle={Expanding the Reach of Federated Learning by Reducing Client Resource Requirements},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlpM3RqKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgAfh09tm", "original": "ByxD1WActX", "number": 1312, "cdate": 1538087957627, "ddate": null, "tcdate": 1538087957627, "tmdate": 1538155946287, "tddate": null, "forum": "BJgAfh09tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin", "abstract": "Latent space based GAN methods and attention based encoder-decoder architectures have achieved impressive results in text generation and Unsupervised NMT respectively. Leveraging the two domains, we propose an adversarial latent space based architecture capable of generating parallel sentences in two languages concurrently and translating bidirectionally. The bilingual generation goal is achieved by sampling from the latent space that is adversarially constrained to be shared between both languages. First an NMT model is trained, with back-translation and an adversarial setup, to enforce a latent state between the two languages. The encoder and decoder are shared for the two translation directions. Next, a GAN is trained to generate \u2018synthetic\u2019 code mimicking the languages\u2019 shared latent space. This code is then fed into the decoder to generate text in either language. We perform our experiments on Europarl and Multi30k datasets, on the English-French language pair, and document our performance using both Supervised and Unsupervised NMT.", "keywords": ["Text Generation", "Machine Translation", "Deep Learning", "GAN"], "authorids": ["ICLR.cc/2019/Conference/Paper1312/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a novel method for Bilingual Text Generation producing parallel concurrent sentences in two languages.", "pdf": "/pdf/0b8cbbd7c568ec67b6b6135d588e1f1a0154c853.pdf", "paperhash": "anonymous|bilingualgan_neural_text_generation_and_neural_machine_translation_as_two_sides_of_the_same_coin", "_bibtex": "@inproceedings{    \nanonymous2019bilingual-gan:,    \ntitle={Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgAfh09tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkeAf2CqY7", "original": "SJlxGPLctX", "number": 1313, "cdate": 1538087957792, "ddate": null, "tcdate": 1538087957792, "tmdate": 1538155946075, "tddate": null, "forum": "BkeAf2CqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficient Federated Learning via Variational Dropout", "abstract": "As an emerging field, federated learning has recently attracted considerable attention.\nCompared to distributed learning in the datacenter setting, federated learning\nhas more strict constraints on computate efficiency of the learned model and communication\ncost during the training process. In this work, we propose an efficient\nfederated learning framework based on variational dropout. Our approach is able\nto jointly learn a sparse model while reducing the amount of gradients exchanged\nduring the iterative training process. We demonstrate the superior performance\nof our approach on achieving significant model compression and communication\nreduction ratios with no accuracy loss.", "keywords": ["federated learning", "communication efficient", "variational dropout", "sparse model"], "authorids": ["ICLR.cc/2019/Conference/Paper1313/Authors"], "authors": ["Anonymous"], "TL;DR": "a joint model and gradient sparsification method for federated learning", "pdf": "/pdf/c41dd33dfd4a894f2150995ab3092a9a031cd16f.pdf", "paperhash": "anonymous|efficient_federated_learning_via_variational_dropout", "_bibtex": "@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Federated Learning via Variational Dropout},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeAf2CqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1gRM2A5YX", "original": "Hkl7z7Gdt7", "number": 1314, "cdate": 1538087957958, "ddate": null, "tcdate": 1538087957958, "tmdate": 1538155945866, "tddate": null, "forum": "H1gRM2A5YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Analysis of Memory Organization for Dynamic Neural Networks", "abstract": "An increasing number of neural memory networks have been developed, leading to the need for a systematic approach to analyze and compare their underlying memory structures. Thus, in this paper, we first create a framework for memory organization and then compare four popular dynamic models: vanilla recurrent neural network, long short term memory, neural stack and neural RAM. This analysis helps to open the dynamic neural network' black box from the memory usage prospective. Accordingly, a taxonomy for these networks and their variants is proposed and proved using a unifying architecture. With the taxonomy, both network architectures and learning tasks are classified into four classes. And a one-to-one mapping is built between them to help practitioners select the appropriate architecture. To exemplify each task type, four synthetic tasks with different memory requirements are developed. Moreover, we use two natural language processing applications to apply the methodology in a realistic setting. ", "keywords": ["memory analysis", "recurrent neural network", "LSTM", "neural Turing machine", "neural stack", "differentiable neural computers"], "authorids": ["ICLR.cc/2019/Conference/Paper1314/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d786de70476d3e6b1734fd951e6afd3d195cb2da.pdf", "paperhash": "anonymous|analysis_of_memory_organization_for_dynamic_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019analysis,    \ntitle={Analysis of Memory Organization for Dynamic Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gRM2A5YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyxAfnA5tm", "original": "rJ0ngAqF7", "number": 1315, "cdate": 1538087958132, "ddate": null, "tcdate": 1538087958132, "tmdate": 1538155945654, "tddate": null, "forum": "HyxAfnA5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL", "abstract": "Humans and animals can learn complex predictive models that allow them to accurately and reliably reason about real-world phenomena, and they can adapt such models extremely quickly in the face of unexpected changes. Deep neural network models allow us to represent very complex functions, but lack this capacity for rapid online adaptation. The goal in this paper is to develop a method for continual online learning from an incoming stream of data, using deep neural network models. We formulate an online learning procedure that uses stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Furthermore, we observe that meta-learning can be used to meta-train a model such that this direct online adaptation with SGD is effective, which is otherwise not the case for large function approximators. We apply our method to model-based reinforcement learning, where adapting the predictive model is critical for control; we demonstrate that our online learning via meta-learning algorithm outperforms alternative prior methods, and enables effective continuous adaptation in non-stationary task distributions such as varying terrains, motor failures, and unexpected disturbances.", "keywords": ["meta-learning", "model-based", "reinforcement learning", "online learning", "adaptation"], "authorids": ["ICLR.cc/2019/Conference/Paper1315/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b76c692a12aaf0efd05ec67fd50a60a5d64c98cb.pdf", "paperhash": "anonymous|deep_online_learning_via_metalearning_continual_adaptation_for_modelbased_rl", "_bibtex": "@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxAfnA5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJe0Gn0cY7", "original": "Hye6yRp5t7", "number": 1316, "cdate": 1538087958299, "ddate": null, "tcdate": 1538087958299, "tmdate": 1538155945429, "tddate": null, "forum": "BJe0Gn0cY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fixing Posterior Collapse with delta-VAEs", "abstract": "Due to the phenomenon of \u201cposterior collapse\u201d, current latent variable generativemodels pose a challenging design choice which trades-off optimizing the ELBObut handicapping the decoders\u2019 capacity and expressivity, or changing the loss tosomething that is not directly minimizing the description length. In this paper wepropose an alternative that utilizes the best, most powerful generative models asdecoders, whilst optimizing the proper variational lower bound all while ensuringthat  the  latent  variables  preserve  and  encode  useful  information. delta-VAEs  pro-posed here achieve this by constraining the variational family for the posterior tohave a minimum distance to the prior, which resembles the classic representationlearning approach of slow feature analysis. We demonstrate the efficacy of our ap-proach at modeling images:  learning representations, improving sample quality,and improving state of the art log-likelihood on CIFAR-10 and ImageNet32\u00d732.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1316/Authors"], "authors": ["Anonymous"], "TL;DR": " Avoid posterior collapse by lower bounding the rate.", "pdf": "/pdf/d6121649ba7ee554e5b281306b577614625cc9c0.pdf", "paperhash": "anonymous|fixing_posterior_collapse_with_deltavaes", "_bibtex": "@inproceedings{    \nanonymous2019fixing,    \ntitle={Fixing Posterior Collapse with delta-VAEs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe0Gn0cY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syx0Mh05YQ", "original": "S1e47365Y7", "number": 1317, "cdate": 1538087958462, "ddate": null, "tcdate": 1538087958462, "tmdate": 1538155945218, "tddate": null, "forum": "Syx0Mh05YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Grid-like Units with Vector Representation of Self-Position and Matrix Representation of Self-Motion", "abstract": "This paper proposes a simple model for learning grid-like units for spatial awareness and navigation. In this model, the self-position of the agent is represented by a vector, and the self-motion of the agent is represented by a block-diagonal matrix. Each component of the vector is a unit (or a cell). The model consists of the following two sub-models. (1) Motion sub-model. The movement from the current position to the next position is modeled by matrix-vector multiplication, i.e., multiplying the matrix representation of the motion to the current vector representation of the position in order to  obtain the vector representation of the next position. (2) Localization sub-model. The adjacency between any two positions is a monotone decreasing function of their Euclidean distance, and the adjacency is modeled by the inner product between the vector representations of the two positions. Both sub-models can be implemented by neural networks. The motion sub-model is a recurrent network with dynamic weight matrix, and the localization sub-model is a feedforward network. The model can be learned by minimizing a loss function that combines the loss functions of the two sub-models. The learned units exhibit grid-like patterns (as well as stripe patterns) in both 2D and 3D environments. The learned model can be used for path integral and path planning. Moreover, the learned representation is capable of error correction.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1317/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b18016473ef02a374ee59cbc72b4bbe38d312da7.pdf", "paperhash": "anonymous|learning_gridlike_units_with_vector_representation_of_selfposition_and_matrix_representation_of_selfmotion", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Grid-like Units with Vector Representation of Self-Position and Matrix Representation of Self-Motion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syx0Mh05YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byey7n05FQ", "original": "ByetyWp5Ym", "number": 1318, "cdate": 1538087958644, "ddate": null, "tcdate": 1538087958644, "tmdate": 1538155945009, "tddate": null, "forum": "Byey7n05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control", "abstract": "We propose a plan online and learn offline framework for the setting where an agent with an internal model needs to continually act and learn in the world. Our work builds on the synergistic relationship between local trajectory optimization, global value function learning, and exploration. We study how trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate value function learning. Conversely, we also study how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, we also demonstrate how trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. Combining these components enable solutions to complex complex control tasks like humanoid locomotion and dexterous in-hand manipulation in the equivalent of a few minutes of experience in the real world.", "keywords": ["deep reinforcement learning", "exploration", "model-based"], "authorids": ["ICLR.cc/2019/Conference/Paper1318/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a framework that incorporates planning for efficient exploration and learning in complex environments.", "pdf": "/pdf/6a8c01511a837155fda637d9184d19481d64f987.pdf", "paperhash": "anonymous|plan_online_learn_offline_efficient_learning_and_exploration_via_modelbased_control", "_bibtex": "@inproceedings{    \nanonymous2019plan,    \ntitle={Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byey7n05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkx1m2C5YQ", "original": "rklhjGAqKm", "number": 1319, "cdate": 1538087958815, "ddate": null, "tcdate": 1538087958815, "tmdate": 1538155944803, "tddate": null, "forum": "rkx1m2C5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces", "abstract": "State estimation together with state prediction is a crucial task for many applications. Typically, sensory observations give only partial and noisy information about the state of the environment. A well-known tool for performing state estimation under these conditions is the Kalman filter (Kalman et al., 1960). However, the Kalman filter is limited to problems with known, linear models and good estimates about the system noise. Recent deep learning approaches integrate a non-linear encoder into the KF equations that maps the high-dimensional observation to the typically low-dimensional state of the system (Haarnoja et al., 2016). However, these approaches are still limited to systems with known dynamics that\nare either linear or it requires approximations such as an extended Kalman filter. In contrast, our approach does not use a pre-defined state representation but learns a high-dimensional factorized representation that is used for inference us-\ning locally linear models. While our locally linear modelling and factorization assumptions are in general not true for the original low-dimensional state space of the system, the network finds a high-dimensional latent space where these as-\nsumptions hold to perform efficient inference. This state representation is learned jointly with the transition and noise models by backpropagation. The resulting network architecture, which we call Recurrent Kalman Network (RKN), can be\nused for any time-series data, similar to a LSTM (Hochreiter and Schmidhuber, 1997) but uses an explicit representation of uncertainty. As shown by our experiments, the RKN obtains much more accurate uncertainty estimates than an LSTM\nor Gated Recurrent Units (GRUs) (Cho et al., 2014) while also showing a slightly improved prediction performance.", "keywords": ["state estimation", "recurrent neural networks", "Kalman Filter", "deep learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1319/Authors"], "authors": ["Anonymous"], "TL;DR": "Kalman Filter based recurrent model for efficient state estimation,  principled uncertainty handling and end to end learning of dynamic models in high dimensional spaces.", "pdf": "/pdf/9a57fcd21b712dc647087480b95175ac84709ebd.pdf", "paperhash": "anonymous|recurrent_kalman_networks_factorized_inference_in_highdimensional_deep_feature_spaces", "_bibtex": "@inproceedings{    \nanonymous2019recurrent,    \ntitle={Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkx1m2C5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkzyX3CcFQ", "original": "rygR1UpcY7", "number": 1320, "cdate": 1538087958989, "ddate": null, "tcdate": 1538087958989, "tmdate": 1538155944591, "tddate": null, "forum": "HkzyX3CcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Contextual Recurrent Convolutional Model for Robust Visual Learning", "abstract": "Feedforward convolutional neural network has achieved a great success in many computer vision tasks. While it validly imitates the hierarchical structure of biological visual system, it still lacks one essential architectural feature: contextual recurrent connections with feedback, which widely exists in biological visual system. In this work, we designed a Contextual Recurrent Convolutional Network with this feature embedded in a standard CNN structure. We found that such feedback connections could enable lower layers to ``rethink\" about their representations given the top-down contextual information. We carefully studied the components of this network, and showed its robustness and superiority over feedforward baselines in such tasks as noise image classification, partially occluded object recognition and fine-grained image classification. We believed this work could be an important step to help bridge the gap between computer vision models and real biological visual system.", "keywords": ["contextual modulation", "recurrent convolutional network", "robust visual learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1320/Authors"], "authors": ["Anonymous"], "TL;DR": "we proposed a novel contextual recurrent convolutional network with robust property of visual learning ", "pdf": "/pdf/1bd07381b3435c7e8acfe726f13928318cde013b.pdf", "paperhash": "anonymous|contextual_recurrent_convolutional_model_for_robust_visual_learning", "_bibtex": "@inproceedings{    \nanonymous2019contextual,    \ntitle={Contextual Recurrent Convolutional Model for Robust Visual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzyX3CcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyG1QnRqF7", "original": "ByxPS-CqFm", "number": 1321, "cdate": 1538087959166, "ddate": null, "tcdate": 1538087959166, "tmdate": 1538155944374, "tddate": null, "forum": "SyG1QnRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Towards Resisting Large Data Variations via Introspective Learning", "abstract": "Learning deep networks which can resist large variations between training andtesting data is essential to build accurate and robust image classifiers.  Towardsthis end, a typical strategy is to apply data augmentation to enlarge the trainingset.   However,  standard  data  augmentation  is  essentially  a  brute-force  strategywhich is inefficient,  as it performs all the pre-defined transformations  to everytraining sample. In this paper, we propose a principled approach to train networkswith  significantly  improved  resistance  to  large  variations  between  training  andtesting data.  This is achieved by embedding a learnable transformation moduleinto the introspective networks (Jin et al., 2017; Lazarow et al., 2017; Lee et al.,2018), which is a convolutional neural network (CNN) classifier empowered withgenerative capabilities.  Our approach alternatively synthesizes pseudo-negativesamples with learned transformations and enhances the classifier by retraining itwith synthesized samples.  Experimental results verify that our approach signif-icantly improves the ability of deep networks to resist large variations betweentraining and testing data and achieves classification accuracy improvements onseveral benchmark datasets, including MNIST, affNIST, SVHN and CIFAR-10.", "keywords": ["Introspective learning", "Large variations resistance", "Image classification", "Generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper1321/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose a principled approach that endows classifiers with the ability to resist larger variations between training and testing data in an intelligent and efficient manner.", "pdf": "/pdf/d4eb9f4a639aa5465cf1f78ce7f013fb572766ba.pdf", "paperhash": "anonymous|towards_resisting_large_data_variations_via_introspective_learning", "_bibtex": "@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Resisting Large Data Variations via Introspective Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyG1QnRqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hk41X2AqtQ", "original": "B1lUKFp5YQ", "number": 1322, "cdate": 1538087959336, "ddate": null, "tcdate": 1538087959336, "tmdate": 1538155944165, "tddate": null, "forum": "Hk41X2AqtQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchically-Structured Variational Autoencoders for Long Text Generation", "abstract": "Variational autoencoders (VAEs) have received much attention recently as an end-to-end architecture for text generation. Existing methods primarily focus on synthesizing relatively short sentences (with less than twenty words). In this paper, we propose a novel framework, hierarchically-structured variational autoencoder (hier-VAE), for generating long and coherent units of text. To enhance the model\u2019s plan-ahead ability, intermediate sentence representations are introduced into the generative networks to guide the word-level predictions. To alleviate the typical optimization challenges associated with textual VAEs, we further employ a hierarchy of stochastic layers between the encoder and decoder networks. Extensive experiments are conducted to evaluate the proposed method, where hier-VAE is shown to make effective use of the latent codes and achieve lower perplexity relative to language models. Moreover, the generated samples from hier-VAE also exhibit superior quality according to both automatic and human evaluations. ", "keywords": ["Natural Language Processing", "Text Generation", "Variational Autoencoders"], "authorids": ["ICLR.cc/2019/Conference/Paper1322/Authors"], "authors": ["Anonymous"], "TL;DR": "Propose a hierarchically-structured variational autoencoder for generating long and coherent units of text", "pdf": "/pdf/5d6572096e206d68a63549e58e53a7122d3388bd.pdf", "paperhash": "anonymous|hierarchicallystructured_variational_autoencoders_for_long_text_generation", "_bibtex": "@inproceedings{    \nanonymous2019hierarchically-structured,    \ntitle={Hierarchically-Structured Variational Autoencoders for Long Text Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hk41X2AqtQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJ4km2R5t7", "original": "SJl9k0TrYQ", "number": 1323, "cdate": 1538087959516, "ddate": null, "tcdate": 1538087959516, "tmdate": 1538155943958, "tddate": null, "forum": "rJ4km2R5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding", "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusive to a single task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all tasks performs better than training a separate model per task. However, the low absolute performance of our best model indicates the need for improved general NLU systems.", "keywords": ["natural language understanding", "multi-task learning", "evaluation"], "authorids": ["ICLR.cc/2019/Conference/Paper1323/Authors"], "authors": ["Anonymous"], "TL;DR": "We present a multi-task benchmark and analysis platform for evaluating generalization in natural language understanding systems.", "pdf": "/pdf/2336608494f9c402b2b168d485ac0ce569f1cfd8.pdf", "paperhash": "anonymous|glue_a_multitask_benchmark_and_analysis_platform_for_natural_language_understanding", "_bibtex": "@inproceedings{    \nanonymous2019glue:,    \ntitle={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJ4km2R5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gl7hC5Km", "original": "r1gi0vp9Km", "number": 1324, "cdate": 1538087959691, "ddate": null, "tcdate": 1538087959691, "tmdate": 1538155943743, "tddate": null, "forum": "r1gl7hC5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adapting Auxiliary Losses Using Gradient Similarity", "abstract": "One approach to deal with the statistical inefficiency of neural networks is to rely on auxiliary losses that help building useful representations. However is not  always trivial to know if an auxiliary task will be helpful for the main task and when it could start  hurting.  We explore using gradient cosine similarity as an adaptive  weight for the  auxiliary loss, and demonstrate the usefulness of the proposed algorithm in a few domains,  including multi-task supervised learning using subsets of ImageNet, and reinforcement learning using Atari games.  Additionally, we show that our approach is guaranteed to converge to critical points of the main task. This is not guaranteed otherwise, and in principle adding a mis-matched auxiliary loss can lead to divergence on the main task.\n", "keywords": ["auxiliary losses", "transfer learning", "task similarity", "deep learning", "deep reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1324/Authors"], "authors": ["Anonymous"], "TL;DR": "Auxiliary tasks need to match the main task to improve learning; we propose to use cosine distance between gradients of an unknown auxiliary task to protect from negative interference with learning the main task.", "pdf": "/pdf/814bb3277e2e356cafa11b9ab372a2e2e91b97e4.pdf", "paperhash": "anonymous|adapting_auxiliary_losses_using_gradient_similarity", "_bibtex": "@inproceedings{    \nanonymous2019adapting,    \ntitle={Adapting Auxiliary Losses Using Gradient Similarity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gl7hC5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1lgm3C5t7", "original": "HJxBnMR5Y7", "number": 1325, "cdate": 1538087959857, "ddate": null, "tcdate": 1538087959857, "tmdate": 1538155943531, "tddate": null, "forum": "r1lgm3C5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal discriminative quantum neural networks", "abstract": "Quantum mechanics fundamentally forbids deterministic discrimination of quantum states and 9b8d to discriminate among various pure and mixed quantum states exhibiting a trade-off between minimizing erroneous and inconclusive outcomes with comparable performance to theoretically optimal POVMs. We train the circuit on different classes of quantum data and evaluate the generalization error on unseen mixed quantum states. This generalization power hence distinguishes our work from standard circuit optimization and provides an example of quantum machine learning for a task that has inherently no classical analog.", "keywords": ["quantum machine learning", "quantum data classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1325/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c49955d35d428925168604330d0ad2bc4f713261.pdf", "paperhash": "anonymous|universal_discriminative_quantum_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal discriminative quantum neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lgm3C5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlxm30cKm", "original": "SJelTc6cFm", "number": 1326, "cdate": 1538087960022, "ddate": null, "tcdate": 1538087960022, "tmdate": 1538155943319, "tddate": null, "forum": "BJlxm30cKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Empirical Study of Example Forgetting during Deep Neural Network Learning", "abstract": "Inspired by the phenomenon of catastrophic forgetting, we investigate the learning dynamics of neural networks as they train on single classification tasks. Our goal is to understand whether a related phenomenon occurs when data does not undergo a clear distributional shift. We define a ``forgetting event'' to have occurred when an individual training example transitions from being classified correctly to incorrectly over the course of learning. Across several benchmark data sets, we find that: (i) certain examples are forgotten with high frequency, and some not at all; (ii) a data set's (un)forgettable examples generalize across neural architectures; and (iii) based on forgetting dynamics, a significant fraction of examples can be omitted from the training data set while still maintaining state-of-the-art generalization performance.", "keywords": ["catastrophic forgetting", "sample weighting", "deep generalization"], "authorids": ["ICLR.cc/2019/Conference/Paper1326/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.", "pdf": "/pdf/30f382ab018756169c8432a8750ccb219a8ad985.pdf", "paperhash": "anonymous|an_empirical_study_of_example_forgetting_during_deep_neural_network_learning", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Empirical Study of Example Forgetting during Deep Neural Network Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlxm30cKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJeem3C9F7", "original": "Byg4dbo5YQ", "number": 1327, "cdate": 1538087960186, "ddate": null, "tcdate": 1538087960186, "tmdate": 1538155943108, "tddate": null, "forum": "BJeem3C9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pix2Scene: Learning Implicit 3D Representations from Images", "abstract": "Modelling 3D scenes from 2D images is a long-standing problem in computer vision with implications in, e.g., simulation and robotics. We propose pix2scene, a deep generative-based approach that implicitly models the geometric properties of a scene from images. Our method learns the depth and orientation of scene points visible in images. Our model can then predict the structure of a scene from various, previously unseen view points. It relies on a bi-directional adversarial learning mechanism to generate scene representations from a latent code, inferring the 3D representation of the underlying scene geometry. We showcase a novel differentiable renderer to train the 3D model in an end-to-end fashion, using only images. We demonstrate the generative ability of our model qualitatively on both a custom dataset and on ShapeNet. Finally, we evaluate the effectiveness of the learned 3D scene representation in supporting a 3D spatial reasoning.", "keywords": ["Representation learning", "generative model", "adversarial learning", "implicit 3D generation", "scene generation"], "authorids": ["ICLR.cc/2019/Conference/Paper1327/Authors"], "authors": ["Anonymous"], "TL;DR": "pix2scene: a deep generative based approach for implicitly modelling the geometrical properties of a 3D scene from images", "pdf": "/pdf/d11ba55bcc452a1d2744a304d538f2cdcda8cfa5.pdf", "paperhash": "anonymous|pix2scene_learning_implicit_3d_representations_from_images", "_bibtex": "@inproceedings{    \nanonymous2019pix2scene:,    \ntitle={Pix2Scene: Learning Implicit 3D Representations from Images},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeem3C9F7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1zlmnA5K7", "original": "Bkeo84aqFm", "number": 1328, "cdate": 1538087960355, "ddate": null, "tcdate": 1538087960355, "tmdate": 1538155942902, "tddate": null, "forum": "S1zlmnA5K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Batch-Constrained Reinforcement Learning", "abstract": "This work examines batch reinforcement learning--the task of maximally exploiting a given batch of off-policy data, without further data collection. Due to errors introduced by extrapolation, we find that standard off-policy deep reinforcement learning algorithms such as DQN and DDPG are only capable of learning with data correlated to their current policy, making them ineffective for most off-policy applications. We introduce a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space to force the agent towards behaving on-policy with respect to a subset of the given data. We extend this notion to deep reinforcement learning, and to the best of our knowledge, present the first continuous control deep reinforcement learning algorithm which can learn effectively from uncorrelated off-policy data.", "keywords": ["reinforcement learning", "off-policy", "imitation", "batch reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1328/Authors"], "authors": ["Anonymous"], "TL;DR": "We describe conditions where off-policy deep reinforcements algorithms fail and present a solution.", "pdf": "/pdf/52cffbb6a6921179986a920bb0edaa6e8e0b96e5.pdf", "paperhash": "anonymous|batchconstrained_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019batch-constrained,    \ntitle={Batch-Constrained Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1zlmnA5K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1g-X3RqKm", "original": "ryln1AP5Ym", "number": 1329, "cdate": 1538087960527, "ddate": null, "tcdate": 1538087960527, "tmdate": 1538155942695, "tddate": null, "forum": "B1g-X3RqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Proposed Hierarchy of Deep Learning Tasks", "abstract": "As the pace of deep learning innovation accelerates, it becomes increasingly important to organize the space of problems by relative difficultly.  Looking to other fields for inspiration, we see analogies to the Chomsky Hierarchy in computational linguistics and time and space complexity in theoretical computer science.\n\nAs a complement to prior theoretical work on the data and computational requirements of learning, this paper presents an empirical approach. We introduce a methodology for measuring validation error scaling with data and model size and test tasks in natural language, vision, and speech domains. We find that power-law validation error scaling exists across a breadth of factors and that model size scales sublinearly with data size, suggesting that simple learning theoretic models offer insights into the scaling behavior of realistic deep learning settings, and providing a new perspective on how to organize the space of  problems. \n\nWe measure the power-law exponent---the \"steepness\" of the learning curve---and propose using this metric to sort problems by degree of difficulty.  There is no data like more data, but some tasks are more effective at taking advantage of more data.  Those that are more effective are easier on the proposed scale. \n\nUsing this approach, we can observe that studied tasks in speech and vision domains scale faster than those in the natural language domain, offering insight into the observation that progress in these areas has proceeded more rapidly than in natural language.", "keywords": ["Deep learning", "scaling with data", "computational complexity", "learning curves", "speech recognition", "image recognition", "machine translation", "language modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper1329/Authors"], "authors": ["Anonymous"], "TL;DR": "We use 50 GPU years of compute time to study how deep learning scales with more data, and propose a new way to organize the space of problems by difficulty.", "pdf": "/pdf/cf2d05da49f06b82d0f3d7def5639e560da0e8ab.pdf", "paperhash": "anonymous|a_proposed_hierarchy_of_deep_learning_tasks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Proposed Hierarchy of Deep Learning Tasks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1g-X3RqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlWXhC5Km", "original": "SyxTCZAct7", "number": 1330, "cdate": 1538087960710, "ddate": null, "tcdate": 1538087960710, "tmdate": 1538155942475, "tddate": null, "forum": "HJlWXhC5Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Control Visual Abstractions for Structured Exploration in Deep Reinforcement Learning", "abstract": "Exploration in environments with sparse rewards, even in simple environments, is a key challenge. How do we design agents with generic inductive biases so that they can temporally explore instead of just location exploration schemes? We propose an unsupervised reinforcement learning agent which simultaneously learns a discrete pixel abstractions model that preserves spatial geometry of the environment, derives geometric intrinsic reward functions from such abstractions to induce a basis set of behaviors (options) trained with off-policy learning, and finally learns to compose and explore in this options space to optimize for extrinsically defined tasks. We propose an agent that learns a structured exploration algorithm end-to-end using discrete visual abstractions model from raw pixels. We show that our approach can scale to a variety of domains with competitive performance, including navigation in 3D environments and Atari games with sparse rewards.", "keywords": ["exploration", "deep reinforcement learning", "intrinsic motivation", "unsupervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1330/Authors"], "authors": ["Anonymous"], "TL;DR": "structured exploration in deep reinforcement learning via unsupervised visual abstraction discovery and control", "pdf": "/pdf/07e0069d18d307acce4f5a36913dc8c0970c916c.pdf", "paperhash": "anonymous|learning_to_control_visual_abstractions_for_structured_exploration_in_deep_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Control Visual Abstractions for Structured Exploration in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlWXhC5Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1fWmnR5tm", "original": "SJed-otcFm", "number": 1331, "cdate": 1538087960881, "ddate": null, "tcdate": 1538087960881, "tmdate": 1538155942262, "tddate": null, "forum": "r1fWmnR5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Search Efficient DenseNet with Layer-wise Pruning", "abstract": "Deep neural networks have achieved outstanding performance in many real-world applications with the expense of huge computational resources. The DenseNet, one of the recently proposed neural network architecture, has achieved the state-of-the-art performance in many visual tasks. However, it has great redundancy due to the dense connections of the internal structure, which leads to high computational costs in training such dense networks. To address this issue,  we design a reinforcement learning framework to search for efficient DenseNet architectures with layer-wise pruning (LWP) for different tasks, while retaining the original advantages of DenseNet, such as feature reuse, short paths, etc. In this framework, an agent evaluates the importance of each connection between any two block layers, and prunes the redundant connections. In addition, a novel reward-shaping trick is introduced to make DenseNet reach a better trade-off between accuracy and float point operations (FLOPs). Our experiments show that DenseNet with LWP is more compact and efficient than existing alternatives.  ", "keywords": ["reinforcement learning", "DenseNet", "neural network compression"], "authorids": ["ICLR.cc/2019/Conference/Paper1331/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/6e55047547d4f5968ef74ad2955621e858d6222a.pdf", "paperhash": "anonymous|learning_to_search_efficient_densenet_with_layerwise_pruning", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Search Efficient DenseNet with Layer-wise Pruning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1fWmnR5tm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1MW72AcK7", "original": "B1gGTliYYm", "number": 1332, "cdate": 1538087961051, "ddate": null, "tcdate": 1538087961051, "tmdate": 1538155942055, "tddate": null, "forum": "H1MW72AcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimal Control Via Neural Networks: A Convex Approach", "abstract": "Control of complex systems involves both system identification and controller design. Deep neural networks have proven to be successful in many identification tasks, however, from model-based control perspective, these networks are difficult to work with because they are typically nonlinear and nonconvex. Therefore many systems are still identified and controlled based on simple linear models despite their poor representation capability.\n\nIn this paper we bridge the gap between model accuracy and control tractability faced by neural networks, by explicitly constructing networks that are convex with respect to their inputs. We show that these input convex networks can be trained to obtain accurate models of complex physical systems. In particular, we design input convex recurrent neural networks to capture temporal behavior of dynamical systems. Then optimal controllers can be achieved via solving a convex model predictive control problem. Experiment results demonstrate the good potential of the proposed input convex neural network based approach in a variety of control applications. In particular we show that in the MuJoCo locomotion tasks, we could achieve over 10% higher performance using 5 times less time compared with state-of-the-art model-based reinforcement learning method; and in the building HVAC control example, our method achieved up to 20% energy reduction compared with classic linear models.\n", "keywords": ["optimal control", "input convex neural network", "convex optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1332/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/8f480ab940d384c795d6dbf71718a8d2382b6b32.pdf", "paperhash": "anonymous|optimal_control_via_neural_networks_a_convex_approach", "_bibtex": "@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal Control Via Neural Networks: A Convex Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1MW72AcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJ4Z72Rctm", "original": "Hklsyep9t7", "number": 1333, "cdate": 1538087961217, "ddate": null, "tcdate": 1538087961217, "tmdate": 1538155941846, "tddate": null, "forum": "SJ4Z72Rctm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Composing Entropic Policies using Divergence Correction", "abstract": "Deep reinforcement learning (RL) algorithms have made great strides in recent years. An important remaining challenge is the ability to quickly transfer existing skills to novel tasks, and to combine existing skills with newly acquired ones. In domains where tasks are solved by composing skills this capacity holds the promise of dramatically reducing the data requirements of deep RL algorithms, and hence of greatly increasing their applicability. Recent work has studied ways of composing behaviors represented in the form of action-value functions. We analyze these methods to highlight their strengths and weaknesses, and point out situations where each of them is susceptible to poor performance. To perform this analysis we extend generalized policy improvement to the max-entropy framework and introduce a method for the practical implementation of successor features in continuous action spaces. Then we propose a novel approach which achieves an approximately optimal result. This method works by explicitly learning the (discounted, future) divergence between policies. We study this approach in the  tabular case and propose a scalable variant that is applicable in multi-dimensional continuous action spaces.\nWe compare our novel approach with existing ones on a range of non-trivial continuous control problems with compositional structure, and demonstrate near-optimal performance despite requiring less information than competing approaches.", "keywords": ["maximum entropy RL", "policy composition", "deep rl"], "authorids": ["ICLR.cc/2019/Conference/Paper1333/Authors"], "authors": ["Anonymous"], "TL;DR": "Two new methods for combining entropic policies: maximum entropy generalized policy improvement, and divergence correction.", "pdf": "/pdf/a9b657797522440b9e0ca93d7d1fd9103ff119cd.pdf", "paperhash": "anonymous|composing_entropic_policies_using_divergence_correction", "_bibtex": "@inproceedings{    \nanonymous2019composing,    \ntitle={Composing Entropic Policies using Divergence Correction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJ4Z72Rctm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxZX20qFQ", "original": "HJlqU5j5Ym", "number": 1334, "cdate": 1538087961393, "ddate": null, "tcdate": 1538087961393, "tmdate": 1538155941637, "tddate": null, "forum": "ByxZX20qFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Adaptive Input Representations for Neural Language Modeling", "abstract": "We introduce adaptive input representations for neural language modeling which extend the adaptive softmax of Grave et al. (2017) to input representations of variable capacity. There are several choices on how to factorize the input and output layers, and whether to model words, characters or sub-word units. We perform a systematic comparison of popular choices for a self-attentional architecture. Our experiments show that models equipped with adaptive embeddings are more than twice as fast to train than the popular character input CNN while having a lower number of parameters. We achieve a new state of the art on the WikiText-103 benchmark of 20.51 perplexity, improving the next best known result by 8.7 perplexity.  On the Billion-Word benchmark, we achieve a state of the art of 24.14 perplexity.", "keywords": ["Neural language modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper1334/Authors"], "authors": ["Anonymous"], "TL;DR": "Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.", "pdf": "/pdf/a94f22b8d82d18f26dce21beeac38bb4f7ab175b.pdf", "paperhash": "anonymous|adaptive_input_representations_for_neural_language_modeling", "_bibtex": "@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Input Representations for Neural Language Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxZX20qFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkezXnA9YX", "original": "rJlWru6qKm", "number": 1335, "cdate": 1538087961565, "ddate": null, "tcdate": 1538087961565, "tmdate": 1538155941429, "tddate": null, "forum": "HkezXnA9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Systematic Generalization: What Is Required and Can It Be Learned?", "abstract": "Numerous models for grounded language understanding have been recently proposed, including (i) generic modules that can be used easily adapted to any given task with little adaptation and (ii) intuitively appealing modular models that require background knowledge to be instantiated. We compare generic and modular models in how much they lend themselves to a particular form of systematic generalization. Using a synthetic VQA test, we evaluate which models are capable of reasoning about all possible object pairs after training on only a small subset of them. Our findings show that the generalization of modular models is much more systematic and that it is highly sensitive to the module layout, i.e. to how exactly the modules are connected. We furthermore investigate if modular models that generalize well could be made more end-to-end by learning their layout and parametrization. We show how end-to-end methods  from prior work often learn a wrong layout and a spurious parametrization that do not facilitate systematic generalization.\n", "keywords": ["systematic generalization", "language understanding", "visual questions answering", "neural module networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1335/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that modular structured models are the best in terms of systematic generalization and that their end-to-end versions don't generalize as well.", "pdf": "/pdf/46033bce3d5357765425d81e21f216ee68bf6cc6.pdf", "paperhash": "anonymous|systematic_generalization_what_is_required_and_can_it_be_learned", "_bibtex": "@inproceedings{    \nanonymous2019systematic,    \ntitle={Systematic Generalization: What Is Required and Can It Be Learned?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkezXnA9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxfm2CqKm", "original": "ByxtLbC9F7", "number": 1336, "cdate": 1538087961739, "ddate": null, "tcdate": 1538087961739, "tmdate": 1538155941220, "tddate": null, "forum": "HJxfm2CqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Discovering General-Purpose Active Learning Strategies", "abstract": "We propose a general-purpose approach to discovering active learning (AL) strategies from data. These strategies are transferable from one domain to another and can be used in conjunction with many machine learning models. To this end, we formalize the annotation process as a Markov decision process, design universal state and action spaces and introduce a new reward function that precisely reflects the AL objective of minimizing the annotation cost We seek to find an optimal (non-myopic) AL strategy using reinforcement learning. We evaluate the learned strategies on multiple unrelated domains and show that they consistently outperform state-of-the-art baselines.", "keywords": ["active learning", "meta learning", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1336/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/04b1cd8910a3ae131e3819cacefdbbd0be8a36f5.pdf", "paperhash": "anonymous|discovering_generalpurpose_active_learning_strategies", "_bibtex": "@inproceedings{    \nanonymous2019discovering,    \ntitle={Discovering General-Purpose Active Learning Strategies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxfm2CqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxMX2R9YQ", "original": "HyxNVyAct7", "number": 1337, "cdate": 1538087961915, "ddate": null, "tcdate": 1538087961915, "tmdate": 1538155941012, "tddate": null, "forum": "ryxMX2R9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "CGNF: Conditional Graph Neural Fields", "abstract": "Graph convolutional networks have achieved tremendous success in the tasks of graph node classification. These models could learn a better node representation through encoding the graph structure and node features. However, the correlation between the node labels are not considered. In this paper, we propose a novel architecture for graph node classification, named conditional graph neural fields (CGNF). By integrating the conditional random fields (CRF) in the graph convolutional networks, we explicitly model a joint probability of the entire set of node labels, thus taking advantage of neighborhood label information in the node label prediction task. \nOur model could have both the representation capacity of graph neural networks and the prediction power of CRFs. Experiments on several graph datasets demonstrate effectiveness of CGNF.", "keywords": ["graph neural networks", "energy models", "conditional random fields", "label correlation"], "authorids": ["ICLR.cc/2019/Conference/Paper1337/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/7d6089ce80f44da1391e4148600714bb5e1ca739.pdf", "paperhash": "anonymous|cgnf_conditional_graph_neural_fields", "_bibtex": "@inproceedings{    \nanonymous2019cgnf:,    \ntitle={CGNF: Conditional Graph Neural Fields},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxMX2R9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkgGmh09FQ", "original": "BkgDNZC5YQ", "number": 1338, "cdate": 1538087962078, "ddate": null, "tcdate": 1538087962078, "tmdate": 1538155940796, "tddate": null, "forum": "BkgGmh09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a vision task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and hoe televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today. And this in-turn prevents SR from being deployed to devices that require them. In this paper, we perform one of the only systematic studies of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures and efficiency trade-offs; for example, highly compact SR models suitable for DSPs and FPGAs -- along with SR models suitable for smartphones that are 3x smaller than those of comparable quality found in the literature. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["ICLR.cc/2019/Conference/Paper1338/Authors"], "authors": ["Anonymous"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/0757b2bd9ce64d5086437bf6ed1f896e7e89e580.pdf", "paperhash": "anonymous|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgGmh09FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryfz73C9KQ", "original": "SyxBGV9cKX", "number": 1339, "cdate": 1538087962248, "ddate": null, "tcdate": 1538087962248, "tmdate": 1538155940589, "tddate": null, "forum": "ryfz73C9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Neural Predictive Belief Representations", "abstract": "Unsupervised representation learning has succeeded with excellent results in many applications. It is an especially powerful tool  to learn a good representation of environments with partial or noisy observations. In partially observable domains it is important for the representation to encode a belief state---a sufficient statistic of the observations seen so far. In this paper, we investigate whether it is possible to learn such a belief representation using modern neural architectures. Specifically, we focus on one-step frame prediction and two variants of contrastive predictive coding (CPC)  as the objective functions to learn the representations. To evaluate these learned representations, we test how well they can predict various pieces of information about the underlying state of the environment, e.g., position of the agent in a 3D maze. We show that all three methods are able to learn belief representations of the environment---they encode not only the state information, but also its uncertainty, a crucial aspect of belief states. We also find that for CPC multi-step predictions and action-conditioning are critical for accurate belief representations in visually complex environments. The ability of neural representations to capture the belief information has the potential to spur new advances for learning and planning in partially observable domains, where leveraging uncertainty is essential for optimal decision making.", "keywords": ["belief states", "representation learning", "contrastive predictive coding", "reinforcement learning", "predictive state representations", "deep reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1339/Authors"], "authors": ["Anonymous"], "TL;DR": "We investigate the quality of belief state representations of partially observable dynamic environments learned with modern neural architectures.", "pdf": "/pdf/2d1b7f6ace37536396c202d694eebf126f4d250c.pdf", "paperhash": "anonymous|neural_predictive_belief_representations", "_bibtex": "@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Predictive Belief Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryfz73C9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1ffQnRcKX", "original": "rJlr9aj5Y7", "number": 1340, "cdate": 1538087962408, "ddate": null, "tcdate": 1538087962408, "tmdate": 1538155940375, "tddate": null, "forum": "B1ffQnRcKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Automatically Composing Representation Transformations as a Means for Generalization", "abstract": "How can we build a learner that can capture the essence of what makes a hard problem more complex than a simple one, break the hard problem along characteristic lines into smaller problems it knows how to solve, and sequentially solve the smaller problems until the larger one is solved?  To work towards this goal, we focus on learning to generalize in a particular family of problems that exhibit compositional and recursive structure: their solutions can be found by composing in sequence a set of reusable partial solutions.  Our key idea is to recast the problem of generalization as a problem of learning algorithmic procedures: we can formulate a solution to this family as a sequential decision-making process over transformations between representations.  Our formulation enables the learner to learn the structure and parameters of its own computation graph with sparse supervision, make analogies between problems by transforming one problem representation to another, and exploit modularity and reuse to scale to problems of varying complexity. Experiments on solving a variety of multilingual arithmetic problems demonstrate that our method discovers the hierarchical decomposition of a problem into its subproblems, generalizes out of distribution to unseen problem classes, and extrapolates to harder versions of the same problem, yielding a 10-fold reduction in sample complexity compared to a monolithic recurrent neural network. We further show that our method can compose learned spatial transformations to recover canonical MNIST digits from transformed ones.", "keywords": ["compositionality", "deep learning", "metareasoning"], "authorids": ["ICLR.cc/2019/Conference/Paper1340/Authors"], "authors": ["Anonymous"], "TL;DR": "We explore the problem of compositional generalization and propose a means for endowing neural network architectures with the ability to compose themselves to solve these problems.", "pdf": "/pdf/2c71181ecbe21a70a4347e735adba87a870b6aeb.pdf", "paperhash": "anonymous|automatically_composing_representation_transformations_as_a_means_for_generalization", "_bibtex": "@inproceedings{    \nanonymous2019automatically,    \ntitle={Automatically Composing Representation Transformations as a Means for Generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1ffQnRcKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1xQQhAqKX", "original": "rJgJYSk5FQ", "number": 1341, "cdate": 1538087962574, "ddate": null, "tcdate": 1538087962574, "tmdate": 1538155940161, "tddate": null, "forum": "r1xQQhAqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Modeling Uncertainty with Hedged Instance Embeddings", "abstract": "Instance embeddings are an efficient and versatile image representation that facilitates applications like recognition, verification, retrieval, and clustering. Many metric learning methods represent the input as a single point in the embedding space. Often the distance between points is used as a proxy for match confidence. However, this can fail to represent uncertainty which can arise when the input is ambiguous, e.g., due to occlusion or blurriness. This work addresses this issue and explicitly models the uncertainty by \u201chedging\u201d the location of each input in the embedding space. We introduce the hedged instance embedding (HIB) in which embeddings are modeled as random variables and the model is trained under the variational information bottleneck principle (Alemi et al., 2016; Achille & Soatto, 2018). Empirical results on our new N-digit MNIST dataset show that our method leads to the desired behavior of \u201chedging its bets\u201d across the embedding space upon encountering ambiguous inputs. This results in improved performance for image matching and classification tasks, more structure in the learned embedding space, and an ability to compute a per-exemplar uncertainty measure which is correlated with downstream performance.", "keywords": ["uncertainty", "instance embedding"], "authorids": ["ICLR.cc/2019/Conference/Paper1341/Authors"], "authors": ["Anonymous"], "TL;DR": "The paper proposes using probability distributions instead of points for instance embeddings tasks such as recognition and verification.", "pdf": "/pdf/27e900bd78f6c132042637891cf50735adc070fa.pdf", "paperhash": "anonymous|modeling_uncertainty_with_hedged_instance_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019modeling,    \ntitle={Modeling Uncertainty with Hedged Instance Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xQQhAqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJemQ209FQ", "original": "S1gzuKpctX", "number": 1342, "cdate": 1538087962748, "ddate": null, "tcdate": 1538087962748, "tmdate": 1538155939951, "tddate": null, "forum": "BJemQ209FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Navigate the Web", "abstract": "Learning in environments with large state and action spaces as well as sparse\nrewards can hinder the ability of a Reinforcement Learning (RL) agent to learn\nthrough trial-and-error. For instance, the problem of following natural language\ninstructions on theWeb (such as booking a flight ticket) leads to RL settings where\ninput vocabulary and number of actionable elements on a page can grow very\nlarge. Even though recent approaches improve the success rate on relatively simpler\nenvironments with the help of human demonstrations to guide the exploration,\nthey still fail in environments where the set of possible instructions can reach millions.\nWe approach the aforementioned problems from a different perspective and\npropose a meta-trainer that can generate unbounded amount of experience for an\nagent to learn from. Instead of learning from a complicated instruction with a\nlarge vocabulary, we decompose it into multiple sub-instructions and schedule a\ncurriculum in which an agent is tasked with gradually increasing subset of these\nrelatively easier sub-instructions. We train DQN, deep reinforcement learning\nagent, with Q-value function approximated with a novel QWeb neural network\narchitecture on these smaller, synthetic instructions. We evaluate the ability of\nour agent to generalize to new instructions on World of Bits benchmark, on forms\nwith 100 elements, supporting 14 million possible instructions. The QWeb agent\noutperforms the baseline without using any human demonstration achieving 100%\nsuccess rate on several difficult environments.", "keywords": ["navigating web pages", "reinforcement learning", "q learning", "curriculum learning", "meta training"], "authorids": ["ICLR.cc/2019/Conference/Paper1342/Authors"], "authors": ["Anonymous"], "TL;DR": "We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.", "pdf": "/pdf/d0d1fe0dbaeda1a374824148055434ede528f322.pdf", "paperhash": "anonymous|learning_to_navigate_the_web", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Navigate the Web},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJemQ209FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJG7m2AcF7", "original": "BJxZ1T69Fm", "number": 1343, "cdate": 1538087962921, "ddate": null, "tcdate": 1538087962921, "tmdate": 1538155939740, "tddate": null, "forum": "HJG7m2AcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Is Wasserstein all you need?", "abstract": "We propose a unified framework for building unsupervised representations of entities and their compositions, by viewing each entity as a histogram over its contexts. This enables us to take advantage of optimal transport and construct representations that effectively harness the geometry of the underlying space containing the contexts. Our method captures uncertainty via modelling the entities as distributions and simultaneously provides interpretability with the optimal transport map, hence giving a novel perspective for building rich and powerful feature representations. As a guiding example, we formulate unsupervised representations for text, and demonstrate it on tasks such as sentence similarity and word entailment detection. Empirical results show strong advantages gained through the proposed framework. This approach can be used for any unsupervised or supervised problem (on text or other modalities) with a co-occurrence structure, such as any sequence data. The key tools at the core of this framework are Wasserstein distances and Wasserstein barycenters, hence raising the question from our title.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1343/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/c0a4f3e71ac67f1aef0a9bb602115bc9f233eb6d.pdf", "paperhash": "anonymous|is_wasserstein_all_you_need", "_bibtex": "@inproceedings{    \nanonymous2019is,    \ntitle={Is Wasserstein all you need?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJG7m2AcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJxmXhRcK7", "original": "rJxdAB3qYm", "number": 1344, "cdate": 1538087963080, "ddate": null, "tcdate": 1538087963080, "tmdate": 1538155939532, "tddate": null, "forum": "BJxmXhRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TENSOR RING NETS ADAPTED DEEP MULTI-TASK LEARNING", "abstract": "Recent deep multi-task learning (MTL) has been shown to be quite successful in alleviating data scarcity of some task by utilizing domain-specific knowledge from related tasks. In this work, we propose a novel knowledge sharing mechanism for linking task-specific models, namely tensor ring multi-task learning (TRMTL). TRMTL models each task with one separate DNN and encodes DNN\u2019s parameters with a sequence of latent tensor cores. Meanwhile, the parameter sharing scheme is carried out among the subsets of latent tensor cores of multiple tasks in a distributed manner. Our model has a highly compact representation and is efficient in transferring the task-invariant knowledge, while being super flexible in learning the task-specific features. TRMTL is a general framework that readily subsumes other tensor factorization based deep MTL methods. TRMTL also allows each individual task to have its own distinct input and output feature dimensionality of each layer. Experiments on a variety of datasets demonstrate our model is capable of significantly improving each single task\u2019s performance, particularly favourable in scenarios where some of the tasks have insufficient data.", "keywords": ["deep learning", "deep multi-task learning", "tensor factorization", "tensor ring nets"], "authorids": ["ICLR.cc/2019/Conference/Paper1344/Authors"], "authors": ["Anonymous"], "TL;DR": "a deep multi-task learning model adapting tensor ring representation", "pdf": "/pdf/b4f2d0c44a47f74f9c414bfbb8fa2dd1ca507537.pdf", "paperhash": "anonymous|tensor_ring_nets_adapted_deep_multitask_learning", "_bibtex": "@inproceedings{    \nanonymous2019tensor,    \ntitle={TENSOR RING NETS ADAPTED DEEP MULTI-TASK LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxmXhRcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByxmXnA9FQ", "original": "Bkgt9qZ9K7", "number": 1345, "cdate": 1538087963250, "ddate": null, "tcdate": 1538087963250, "tmdate": 1538155939321, "tddate": null, "forum": "ByxmXnA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A variational Dirichlet framework for out-of-distribution detection", "abstract": "With the recently rapid development in deep learning, deep neural networks have been widely adopted in many real-life applications. However, deep neural networks are known to have very little control over its uncertainty for test examples, which can potentially cause very harmful and annoying consequences in practical scenarios. In this paper, we are particularly interested in designing a higher-order uncertainty metric for deep neural networks and investigate its performance on the out-of-distribution detection task proposed by~\\cite{hendrycks2016baseline}. Our method is based on a variational inference framework where we interpret the output distribution $p(x)$ as a stochastic variable $z$ lying on a simplex of multi-dimensional space and represent the higher-order uncertainty via the entropy of the latent distribution $p(z)$. Under the variational Bayesian framework with a given dataset $D$, we propose to adopt Dirichlet distribution as the approximate posterior $F_{\\theta}(z|x)$ to approach the true posterior distribution $p(z|D)$ by maximizing the evidence lower bound of marginal likelihood. By identifying the over-concentration issue in the Dirichlet framework, we further design a log-scaling smoothing function to avert such issue and greatly increase the robustness of the entropy-based uncertainty measure. Through comprehensive experiments on various datasets and architectures, our proposed variational Dirichlet framework is observed to yield state-of-the-art results for out-of-distribution detection.", "keywords": ["out-of-distribution detection", "variational inference", "Dirichlet distribution", "deep learning", "uncertainty measure"], "authorids": ["ICLR.cc/2019/Conference/Paper1345/Authors"], "authors": ["Anonymous"], "TL;DR": "A new framework based variational inference for out-of-distribution detection", "pdf": "/pdf/13850e29724b6b6b354956865505d1ee41c4f57d.pdf", "paperhash": "anonymous|a_variational_dirichlet_framework_for_outofdistribution_detection", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A variational Dirichlet framework for out-of-distribution detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxmXnA9FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rye7XnRqFm", "original": "BJexWx05FX", "number": 1346, "cdate": 1538087963425, "ddate": null, "tcdate": 1538087963425, "tmdate": 1538155939104, "tddate": null, "forum": "rye7XnRqFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning", "abstract": "Goal-oriented learning has become a core concept in the reinforcement learning (RL) framework, extending the reward signal as a sole way to define tasks. Generalized value functions (GVFs) utilize an array of independent value functions, each trained for a specific goal, while universal value function approximators (UVFAs) enable generalization between goals by providing them in input. As parameterizing value functions with goals increases the learning complexity, efficiently reusing past experience to update estimates towards several goals at once becomes desirable, but requires independent updates per goal for both GVFs and UVFAs.\nConsidering that a significant number of RL environments can support spatial coordinates as goals - such as on-screen location of the character in ATARI or SNES games, we propose a novel goal-oriented agent called Q-map that utilizes an autoencoder-like neural network to predict the minimum number of steps towards each coordinate in a single forward pass. This architecture is similar to Horde with parameter sharing and allows the agent to discover correlations between visual patterns and navigation. For example learning how to use a ladder in a game could be transferred to other ladders later.\nWe show how this network can be efficiently trained with a 3D variant of Q-learning to update the estimates towards all goals at once. While the Q-map agent could be used for a wide range of applications, we propose a novel exploration mechanism in place of epsilon-greedy that relies on goal selection at a predicted target distance followed by several steps taken towards it, thus allowing the agent to take much longer and coherent exploratory steps in the environment.\nWe demonstrate the accuracy and generalization qualities of the Q-map agent on a grid-world environment and then demonstrate how the proposed exploration mechanism allows the agent to explore much further than random walks on the notoriously difficult Montezuma's Revenge game and finally show how the combination of Q-map with a task-learner DQN agent improves the performance on the Super Mario All-Stars game.", "keywords": ["reinforcement learning", "goal-oriented", "convolutions", "off-policy"], "authorids": ["ICLR.cc/2019/Conference/Paper1346/Authors"], "authors": ["Anonymous"], "TL;DR": "Q-map is a reinforcement learning agent that uses a convolutional autoencoder-like architecture to efficiently learn to navigate its environment.", "pdf": "/pdf/7f32bf362b19e61379f115fe3f03ccb3c75bc8ab.pdf", "paperhash": "anonymous|qmap_a_convolutional_approach_for_goaloriented_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019q-map:,    \ntitle={Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rye7XnRqFm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgEQnRqYQ", "original": "BJgQjZiqtX", "number": 1347, "cdate": 1538087963607, "ddate": null, "tcdate": 1538087963607, "tmdate": 1538155938895, "tddate": null, "forum": "HkgEQnRqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space", "abstract": "We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.", "keywords": ["knowledge graph embedding", "knowledge graph completion", "adversarial sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper1347/Authors"], "authors": ["Anonymous"], "TL;DR": "A new state-of-the-art approach for knowledge graph embedding.", "pdf": "/pdf/7ac19a9a6e63fd627ec30ac08dc89d6aa62b3b76.pdf", "paperhash": "anonymous|rotate_knowledge_graph_embedding_by_relational_rotation_in_complex_space", "_bibtex": "@inproceedings{    \nanonymous2019rotate:,    \ntitle={RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgEQnRqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1eEmn05tQ", "original": "SkxfTq65FX", "number": 1348, "cdate": 1538087963780, "ddate": null, "tcdate": 1538087963780, "tmdate": 1538155938687, "tddate": null, "forum": "S1eEmn05tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Uncertainty in Multitask Transfer Learning", "abstract": "Using variational Bayes neural networks, we develop an algorithm capable of accumulating knowledge into a prior from multiple different tasks. This results in a rich prior capable of few-shot learning on new tasks. The posterior can go beyond the mean field approximation and yields good uncertainty on the performed experiments. Analysis on toy tasks show that it can learn from significantly different tasks while finding similarities among them. Experiments on Mini-Imagenet reach state of the art with 74.5% accuracy on 5 shot learning. Finally, we provide two new benchmarks, each showing a failure mode of existing meta learning algorithms such as MAML and prototypical Networks.", "keywords": ["Multi Task", "Transfer Learning", "Hierarchical Bayes", "Variational Bayes", "Meta Learning", "Few Shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1348/Authors"], "authors": ["Anonymous"], "TL;DR": "A scalable method for learning an expressive prior over neural networks across multiple tasks.", "pdf": "/pdf/17b5166ce21f3d47f1889b2f256be1290f92d5cf.pdf", "paperhash": "anonymous|uncertainty_in_multitask_transfer_learning", "_bibtex": "@inproceedings{    \nanonymous2019uncertainty,    \ntitle={Uncertainty in Multitask Transfer Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eEmn05tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJGVX3CqYm", "original": "SJleNcaqYX", "number": 1349, "cdate": 1538087963950, "ddate": null, "tcdate": 1538087963950, "tmdate": 1538155938480, "tddate": null, "forum": "BJGVX3CqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search", "abstract": "Recent work in network quantization has substantially reduced the time and space complexity of neural network inference, enabling their deployment on embedded and mobile devices with limited computational and memory resources. However, existing quantization methods often represent all weights and activations with the same precision (bit-width). In this paper, we explore a new dimension of the design space: quantizing different layers with different bit-widths. We formulate this problem as a neural architecture search problem and propose a novel differentiable neural architecture search (DNAS) framework to efficiently explore its exponential search space with gradient-based optimization. Experiments show we surpass the state-of-the-art compression of ResNet on CIFAR-10 and ImageNet. Our quantized models with 21.1x smaller model size or 103.9x lower computational cost can still outperform baseline quantized or even full precision models.", "keywords": ["Neural Net Quantization", "Neural Architecture Search"], "authorids": ["ICLR.cc/2019/Conference/Paper1349/Authors"], "authors": ["Anonymous"], "TL;DR": "A novel differentiable neural architecture search framework for mixed quantization of ConvNets.", "pdf": "/pdf/c28f925c389b2212e02c426c60439e409aef7401.pdf", "paperhash": "anonymous|mixed_precision_quantization_of_convnets_via_differentiable_neural_architecture_search", "_bibtex": "@inproceedings{    \nanonymous2019mixed,    \ntitle={Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJGVX3CqYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkzNXhC9KQ", "original": "S1g2BGAFY7", "number": 1350, "cdate": 1538087964121, "ddate": null, "tcdate": 1538087964121, "tmdate": 1538155938277, "tddate": null, "forum": "HkzNXhC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "NASAP Coding:  Neural-Network-Based Adaptive Sample-Space & Adaptive Probability Lossy Coding", "abstract": "We propose Adaptive Sample-space & Adaptive Probability (ASAP) coding, an efficient neural-network based method for lossy data compression.\nOur ASAP coding distinguishes itself from the conventional method based on adaptive arithmetic coding in that it models the probability distribution for the quantization process in such a way that one can conduct back-propagation for the quantization width that determines the support of the distribution. \nOur ASAP also trains the model with a novel, hyper-parameter free multiplicative loss for the rate-distortion tradeoff.  \nWith our ASAP encoder, we are able to compress the image files in the Kodak dataset to as low as one fifth the size of the JPEG-compressed image without compromising their visual quality, and achieved the state-of-the-art result in terms of MS-SSIM based rate-distortion tradeoff. ", "keywords": ["Data compression", "Image compression", "Deep Learning", "Convolutional neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1350/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/cb16e04502c94b04767dc362479fb71acb54b6f6.pdf", "paperhash": "anonymous|nasap_coding_neuralnetworkbased_adaptive_samplespace_adaptive_probability_lossy_coding", "_bibtex": "@inproceedings{    \nanonymous2019nasap,    \ntitle={NASAP Coding:  Neural-Network-Based Adaptive Sample-Space & Adaptive Probability Lossy Coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzNXhC9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkNN7nR5Ym", "original": "HyxujC65tQ", "number": 1351, "cdate": 1538087964286, "ddate": null, "tcdate": 1538087964286, "tmdate": 1538155938067, "tddate": null, "forum": "HkNN7nR5Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Associate Normalization", "abstract": "Normalization is a key technique for training deep neural networks. It improves the stability of the training process and thus makes the networks easier to train. However, in typical normalization methods, the rescaling parameters that control the mean and variance of the output do not associate with any input information during the forward phase. Therefore, inputs of different types are treated as from the exact same distribution, which may limit the feature expressiveness of normalization module. We present Associate Normalization (AssocNorm) to overcome the above limitation. AssocNorm extracts the key information from input features and connects them with rescaling parameters by an auto-encoder-like neural network in the normalization module. Furthermore, AssocNorm normalizes the features of each example individually, so the accuracy is relatively stable for different batch sizes. The experimental results show that AssocNorm achieves better performance than Batch Normalization on several benchmark datasets under various hyper-parameter settings.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1351/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/dafadd0d99988dd952ac6d854e9bf8a3c2e6ba4e.pdf", "paperhash": "anonymous|associate_normalization", "_bibtex": "@inproceedings{    \nanonymous2019associate,    \ntitle={Associate Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkNN7nR5Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1V4QhAqYQ", "original": "SyeJpwEqtQ", "number": 1352, "cdate": 1538087964448, "ddate": null, "tcdate": 1538087964448, "tmdate": 1538155937855, "tddate": null, "forum": "H1V4QhAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Augment your batch: better training with larger batches", "abstract": "Recently, there is regained interest in large batch training of neural networks, both of theory and practice. New insights and methods allowed certain models to be trained using large batches with no adverse impact on performance. Most works focused on accelerating wall clock training time by modifying the learning rate schedule, without introducing accuracy degradation. \nWe propose to use large batch training to boost accuracy and accelerate convergence by combining it with data augmentation. Our method, \"batch augmentation\", suggests using multiple instances of each sample at the same large batch. We show empirically that this simple yet effective method improves convergence and final generalization accuracy. We further suggest possible reasons for its success.", "keywords": ["Large Batch Training", "Augmentation", "Deep Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1352/Authors"], "authors": ["Anonymous"], "TL;DR": "Improve accuracy by large batches composed of multiple instances of each sample at the same batch", "pdf": "/pdf/5b132b0574207bd1950cf7ebb9e7371ec673de4e.pdf", "paperhash": "anonymous|augment_your_batch_better_training_with_larger_batches", "_bibtex": "@inproceedings{    \nanonymous2019augment,    \ntitle={Augment your batch: better training with larger batches},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1V4QhAqYQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HyeS73ActX", "original": "SJl6f8p9t7", "number": 1353, "cdate": 1538087964608, "ddate": null, "tcdate": 1538087964608, "tmdate": 1538155937648, "tddate": null, "forum": "HyeS73ActX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Multi-Objective Value Iteration with Parameterized Threshold-Based Safety Constraints", "abstract": "We consider an environment with multiple reward functions. One of them represents goal achievement and the others represent instantaneous safety conditions. We consider a scenario where the safety rewards should always be above some thresholds. The thresholds are parameters with values that differ between users.\n%The thresholds are not known at the time the policy is being designed.\nWe efficiently compute a family of policies that cover all threshold-based constraints and maximize the goal achievement reward. We introduce a new parameterized threshold-based scalarization method of the reward vector that encodes our objective. We present novel data structures to store the value functions of the Bellman equation that allow their efficient computation using the value iteration algorithm. We present results for both discrete and continuous state spaces. ", "keywords": ["reinforcement learning", "Markov decision processes", "safety constraints", "multi-objective optimization", "geometric analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper1353/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/caf28a8d07a76b1da53dc1c5e5de2a800e5c035c.pdf", "paperhash": "anonymous|multiobjective_value_iteration_with_parameterized_thresholdbased_safety_constraints", "_bibtex": "@inproceedings{    \nanonymous2019multi-objective,    \ntitle={Multi-Objective Value Iteration with Parameterized Threshold-Based Safety Constraints},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeS73ActX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byxr73R5FQ", "original": "Hye8Ba2qF7", "number": 1354, "cdate": 1538087964771, "ddate": null, "tcdate": 1538087964771, "tmdate": 1538155937441, "tddate": null, "forum": "Byxr73R5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Successor Options : An Option Discovery Algorithm for Reinforcement Learning", "abstract": "Hierarchical Reinforcement Learning is a popular method to exploit temporal abstractions in order to tackle the curse of dimensionality. The options framework is one such hierarchical framework that models the notion of skills or options. However, learning a collection of task-agnostic transferable skills is a challenging task. Option discovery typically entails using heuristics, the majority of which revolve around discovering bottleneck states. In this work, we adopt a method complementary to the idea of discovering bottlenecks. Instead, we attempt to discover ``landmark\" sub-goals which are prototypical states of well connected regions. These sub-goals are points from which densely connected set of states are easily accessible. We propose a new model called Successor options that leverages Successor Representations to achieve the same. We also design a novel pseudo-reward for learning the intra-option policies. Additionally, we describe an Incremental Successor options model that iteratively builds options and explores in environments where exploration through primitive actions is inadequate to form the Successor Representations. Finally, we demonstrate the efficacy of our approach on a collection of grid worlds and on complex high dimensional environments like Deepmind-Lab.\n", "keywords": ["Hierarchical Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1354/Authors"], "authors": ["Anonymous"], "TL;DR": "An option discovery method for Reinforcement Learning using the Successor Representation", "pdf": "/pdf/21e0dbd50ac3ac600480379c855eb645cf47d8ef.pdf", "paperhash": "anonymous|successor_options_an_option_discovery_algorithm_for_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019successor,    \ntitle={Successor Options : An Option Discovery Algorithm for Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byxr73R5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryzHXnR5Y7", "original": "BkxAFx05Y7", "number": 1355, "cdate": 1538087964947, "ddate": null, "tcdate": 1538087964947, "tmdate": 1538155937235, "tddate": null, "forum": "ryzHXnR5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SELECT VIA PROXY: EFFICIENT DATA SELECTION FOR TRAINING DEEP NETWORKS", "abstract": "At internet scale, applications collect a tremendous amount of data by logging user events, analyzing text, and collecting images. This data powers a variety of machine learning models for tasks such as image classification, language modeling, content recommendation, and advertising. However, training large models over all available data can be computationally expensive, creating a bottleneck in the development of new machine learning models. In this work, we develop a novel approach to efficiently select a subset of training data to achieve faster training with no loss in model predictive performance. In our approach, we first train a small proxy model quickly, which we then use to estimate the utility of individual training data points, and then select the most informative ones for training the large target model. Extensive experiments show that our approach leads to a 1.6x and 1.8x speed-up on CIFAR10 and SVHN by selecting 60% and 50% subsets of the data, while maintaining the predictive performance of the model trained on the entire dataset. Further, our method is robust to design choices.", "keywords": ["data selection", "deep learning", "uncertainty sampling"], "authorids": ["ICLR.cc/2019/Conference/Paper1355/Authors"], "authors": ["Anonymous"], "TL;DR": "we develop an efficient method for selecting training data to quickly and efficiently learn large machine learning models.", "pdf": "/pdf/d38914765bdec3c9a9662f8144bca10a2df73212.pdf", "paperhash": "anonymous|select_via_proxy_efficient_data_selection_for_training_deep_networks", "_bibtex": "@inproceedings{    \nanonymous2019select,    \ntitle={SELECT VIA PROXY: EFFICIENT DATA SELECTION FOR TRAINING DEEP NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryzHXnR5Y7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkzSQhCcK7", "original": "r1gQfcp9Fm", "number": 1356, "cdate": 1538087965114, "ddate": null, "tcdate": 1538087965114, "tmdate": 1538155937024, "tddate": null, "forum": "HkzSQhCcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "STCN: Stochastic Temporal Convolutional Networks", "abstract": "Convolutional architectures have recently been shown to be competitive on many sequence modelling tasks when compared to the de-facto standard for sequence modeling of recurrent neural networks (RNNs), while providing significant computational advantages due to inherent parallelism.  However, there currently remains a performance gap to more expressive stochastic RNN variants, especially those with several layers of dependent random variables.  In this work, we propose stochastic temporal convolutional networks (STCNs) a novel architecture that combines the computational advantages of temporal convolutional networks (TCN) with the representational power and robustness of stochastic latent spaces.  In particular, we propose a hierarchy of latent variables, tightly integrated with blocks of dilated convolutions, that captures temporal dependencies at different time-scales. We show that the proposed architecture achieves state of the art log-likelihoods across several tasks.  Finally, we show that the model is capable of predicting high-quality synthetic samples over a long-range temporal horizon in a variety of tasks including modeling of handwritten individual digits and text.    ", "keywords": ["latent variables", "variational inference", "temporal convolutional networks", "sequence modeling", "auto-regressive modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper1356/Authors"], "authors": ["Anonymous"], "TL;DR": "We combine the computational advantages of temporal convolutional architectures with the expressiveness of stochastic latent variables.", "pdf": "/pdf/65976db707fd967c8e2ead6e69e5c3e4bdff7885.pdf", "paperhash": "anonymous|stcn_stochastic_temporal_convolutional_networks", "_bibtex": "@inproceedings{    \nanonymous2019stcn:,    \ntitle={STCN: Stochastic Temporal Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzSQhCcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HygS7n0cFQ", "original": "BJgsSv6qFm", "number": 1357, "cdate": 1538087965285, "ddate": null, "tcdate": 1538087965285, "tmdate": 1538155936815, "tddate": null, "forum": "HygS7n0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning", "abstract": "Humans learn to play video games significantly faster than the state-of-the-art reinforcement learning (RL) algorithms. People seem to build simple models that are easy to learn to support planning and strategic exploration. Inspired by this, we investigate two issues in leveraging model-based RL for sample efficiency. First we investigate how to perform strategic exploration when exact planning is not feasible and empirically show that optimistic Monte Carlo Tree Search outperforms posterior sampling methods. Second we show how to learn simple deterministic models to support fast learning using object representation. We illustrate the benefit of these ideas by introducing a novel algorithm, Strategic Object Oriented Reinforcement Learning (SOORL), that outperforms state-of-the-art algorithms in the game of Pitfall! in less than 50 episodes.", "keywords": ["Reinforcement Learning", "Strategic Exploration", "Model Based Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1357/Authors"], "authors": ["Anonymous"], "TL;DR": "We studied exploration with imperfect planning and used object representation to learn simple models and introduced a new sample efficient RL algorithm that achieves state of the art results on Pitfall!", "pdf": "/pdf/55f6170d303ecb98c0eb5a6bded7145f616e4227.pdf", "paperhash": "anonymous|fast_exploration_with_simplified_models_and_approximately_optimistic_planning_in_model_based_reinforcement_learning", "_bibtex": "@inproceedings{    \nanonymous2019fast,    \ntitle={Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygS7n0cFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJlSQnR5t7", "original": "HJekaeTqKQ", "number": 1358, "cdate": 1538087965454, "ddate": null, "tcdate": 1538087965454, "tmdate": 1538155936607, "tddate": null, "forum": "BJlSQnR5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deepstr\u00f6m Networks", "abstract": "Recent work has focused on combining kernel methods and deep learning. With this in mind, we introduce Deepstr\u00f6m networks -- a new architecture of neural networks which we use to replace top dense layers of standard convolutional architectures with an approximation of a kernel function by relying on the Nystr\u00f6m approximation. \nOur approach is easy highly flexible. It is compatible with any kernel function and it allows exploiting multiple kernels. \nWe show that Deepstr\u00f6m networks reach state-of-the-art performance on standard datasets like SVHN and CIFAR100. One benefit of the method lies in its limited number of learnable parameters which make it particularly suited for small training set sizes, e.g. from 5 to 20 samples per class. Finally we illustrate two ways of using multiple kernels, including a multiple Deepstr\u00f6m  setting, that exploits a kernel on each feature map output by the convolutional part of the model.    ", "keywords": ["kernels", "Nystr\u00f6m approximation", "deep convnets"], "authorids": ["ICLR.cc/2019/Conference/Paper1358/Authors"], "authors": ["Anonymous"], "TL;DR": "A new neural architecture where top dense layers of standard convolutional architectures are replaced with an approximation of a kernel function by relying on the Nystr\u00f6m approximation.", "pdf": "/pdf/58aa26133d794a545700320dfeed0cfbda47e6ea.pdf", "paperhash": "anonymous|deepstr\u00f6m_networks", "_bibtex": "@inproceedings{    \nanonymous2019deepstr\u00f6m,    \ntitle={Deepstr\u00f6m Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlSQnR5t7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByeLmn0qtX", "original": "HkeW1mCcF7", "number": 1359, "cdate": 1538087965619, "ddate": null, "tcdate": 1538087965619, "tmdate": 1538155936399, "tddate": null, "forum": "ByeLmn0qtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Domain Adaptation", "abstract": "This paper proposes variational domain adaptation, a uni\ufb01ed, scalable, simple\nframework for learning multiple distributions through variational inference. Un-\nlike the existing methods on domain transfer through deep generative models, such\nas CycleGAN (Zhu et al., 2017a) and StarGAN (Choi et al., 2017), the variational\ndomain adaptation has three advantages. Firstly, the samples from the target are\nnot required. Instead, the framework requries one known source as a prior p(x)\nand binary discriminators, p(D i |x), discriminating the target domain D i from oth-\ners. Consequently, the framework regards a target as a posterior that can be ex-\nplicitly formulated through the Bayesian inference, p(x|D i ) \u221d p(D i |x)p(x), as\nexhibited by a further proposed model of multi-domain variational autoencoder\n(MD-VAE). Secondly, the framework is scablable to large-scale domains. MD-\nVAE sophisticatedly puts together all the domains as well as the samples drawn\nfrom the prior into normal distributions in the same latent space as embeddings.\nThe model enables us to expand the method to uncountable in\ufb01nite domains such\nas continuous domains as well as interpolation. Thirdly, with MD-VAE, no need\nto search hyperparameter anymore. Although several domain transfer based on\nadversarial learning need sophisticated automatic/manual hyperparameter search,\nMD-VAE fast converges with less tuning because it has only one trainable matrix\nin addition to VAE. In the experiment part, we experimentally demonstrate the\nbene\ufb01t with multi-domain image generation task on CelebA and facial image data\nthat are obtained based on evaluation by 60 users, the model generates an ideal\nimage that can be evaluated to be good by multiple users. Additionally, our exper-\nimental result exhibits that our model outperforms several state-of-the-art models.", "keywords": ["domain adaptation", "variational inference", "multi-domain"], "authorids": ["ICLR.cc/2019/Conference/Paper1359/Authors"], "authors": ["Anonymous"], "TL;DR": "This paper proposes variational domain adaptation, a uni\ufb01ed, scalable, simple framework for learning multiple distributions through variational inference", "pdf": "/pdf/2eb5ef07fa824dfff298134f8a268592f0a5a4a6.pdf", "paperhash": "anonymous|variational_domain_adaptation", "_bibtex": "@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Domain Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeLmn0qtX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Bkl87h09FX", "original": "r1gsiO4BF7", "number": 1360, "cdate": 1538087965790, "ddate": null, "tcdate": 1538087965790, "tmdate": 1538155936187, "tddate": null, "forum": "Bkl87h09FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Looking for ELMo's friends: Sentence-Level Pretraining Beyond Language Modeling", "abstract": "Work on the problem of contextualized word representation\u2014the development of reusable neural network components for sentence understanding\u2014has recently seen a  surge of progress centered on the unsupervised pretraining task of language modeling with methods like ELMo (Peters et al., 2018). This paper contributes the first large-scale systematic study comparing different pretraining tasks in this context, both as complements to language modeling and as potential alternatives. The primary results of the study support the use of language modeling as a pretraining task and set a new state of the art among comparable models using multitask learning with language models. However, a closer look at these results reveals worryingly strong baselines and strikingly varied results across target tasks, suggesting that the widely-used paradigm of pretraining and freezing sentence encoders may not be an ideal platform for further work.\n", "keywords": ["natural language processing", "transfer learning", "multitask learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1360/Authors"], "authors": ["Anonymous"], "TL;DR": "We compare many tasks and task combinations for pretraining sentence-level BiLSTMs for NLP tasks. Language modeling is the best single pretraining task, but simple baselines also do well.", "pdf": "/pdf/6fc8c16b4ec6a15f9f86d559fcb492cbb8712449.pdf", "paperhash": "anonymous|looking_for_elmos_friends_sentencelevel_pretraining_beyond_language_modeling", "_bibtex": "@inproceedings{    \nanonymous2019looking,    \ntitle={Looking for ELMo's friends: Sentence-Level Pretraining Beyond Language Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkl87h09FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkxLXnAcFQ", "original": "H1lN44aqt7", "number": 1361, "cdate": 1538087965960, "ddate": null, "tcdate": 1538087965960, "tmdate": 1538155935978, "tddate": null, "forum": "HkxLXnAcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Closer Look at Few-shot Classification", "abstract": "Few-shot classi\ufb01cation aims to learn a classi\ufb01er to recognize unseen classes during training with limited labeled examples. While signi\ufb01cant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison dif\ufb01cult. In this paper, we present 1) a consistent comparative analysis of several representative few-shot classi\ufb01cation algorithms, with results showing that deeper backbones signi\ufb01cantly reduce the gap across methods including the baseline, 2) a slightly modi\ufb01ed baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the mini-ImageNet and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classi\ufb01cation algorithms. Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones. In a realistic, cross-domain evaluation setting, we show that a baseline method with a standard \ufb01ne-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms.", "keywords": ["few shot classification", "meta-learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1361/Authors"], "authors": ["Anonymous"], "TL;DR": " A detailed empirical study in few-shot classification that revealing challenges in standard evaluation setting and showing a new direction.", "pdf": "/pdf/5a2a6a27a00dc2a8640a6da572404cb2e6efedf0.pdf", "paperhash": "anonymous|a_closer_look_at_fewshot_classification", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Closer Look at Few-shot Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxLXnAcFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJxUX2C9Ym", "original": "rylEgRTcFQ", "number": 1362, "cdate": 1538087966126, "ddate": null, "tcdate": 1538087966126, "tmdate": 1538155935768, "tddate": null, "forum": "HJxUX2C9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Iterative Binary Decisions", "abstract": "The complexity of functions a neural network approximates make it hard to explain what the classification decision is based on. In this work, we present a framework that exposes more information about this decision-making process. Instead of producing a classification in a single step, our model iteratively makes binary sub-decisions which, when combined as a whole, ultimately produces the same classification result while revealing a decision tree as thought process. While there is generally a trade-off between interpretability and accuracy, the insights our model generates come at a negligible loss in accuracy. The decision tree resulting from the sequence of binary decisions of our model reveal a hierarchical clustering of the data and can be used as learned attributes in zero-shot learning.", "keywords": ["explainable AI", "interpretability", "deep learning", "decision tree", "zero-shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1362/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/a66e6bbdcf336d21c6d37985525568e0e3a48402.pdf", "paperhash": "anonymous|iterative_binary_decisions", "_bibtex": "@inproceedings{    \nanonymous2019iterative,    \ntitle={Iterative Binary Decisions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxUX2C9Ym},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1GIQhCcYm", "original": "ryerFq35F7", "number": 1363, "cdate": 1538087966304, "ddate": null, "tcdate": 1538087966304, "tmdate": 1538155935557, "tddate": null, "forum": "B1GIQhCcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised  one-to-many image translation", "abstract": "We perform completely unsupervised one-sided image to image translation between a source domain $X$ and a target domain $Y$ such that we preserve relevant underlying shared semantics (e.g., class, size, shape, etc). \nIn particular, we are interested in a more difficult case than those typically addressed in the literature, where the source and target are ``far\" enough that reconstruction-style or pixel-wise approaches fail.\nWe argue that transferring (i.e., \\emph{translating}) said relevant information should involve both discarding source domain-specific information while incorporate target domain-specific information, the latter of which we model with a noisy prior distribution. \nIn order to avoid the degenerate case where the generated samples are only explained by the prior distribution, we propose to minimize an estimate of the mutual information between the generated sample and the sample from the prior distribution. We discover that the architectural choices are an important factor to consider in order to preserve the shared semantic between $X$ and $Y$. \nWe show state of the art results on the MNIST to SVHN task for unsupervised image to image translation.", "keywords": ["Image-to-image", "Translation", "Unsupervised", "Generation", "Adversarial", "Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1363/Authors"], "authors": ["Anonymous"], "TL;DR": "We train an image to image translation network that take as input the source image and a sample from a prior distribution to generate a sample from the target distribution", "pdf": "/pdf/91fe2252aae23d28681a05d8039bf213989a7fd1.pdf", "paperhash": "anonymous|unsupervised_onetomany_image_translation", "_bibtex": "@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised  one-to-many image translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GIQhCcYm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1GLm2R9Km", "original": "S1giBny9YX", "number": 1364, "cdate": 1538087966470, "ddate": null, "tcdate": 1538087966470, "tmdate": 1538155935349, "tddate": null, "forum": "H1GLm2R9Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning More Interpretable, Backpropagation-Free Deep Architectures with Kernels", "abstract": "One can substitute each neuron in any neural network with a kernel machine and obtain a counterpart powered by kernel machines. The new network inherits the expressive power and architecture of the original but works in a more intuitive way since each node enjoys the simple interpretation as a hyperplane (in a reproducing kernel Hilbert space). Further, using the kernel multilayer perceptron as an example, we prove that in classification, an optimal representation that minimizes the risk of the network can be characterized for each hidden layer. This result removes the need of backpropagation in learning the model and can be generalized to any feedforward kernel network. Moreover, unlike backpropagation, which turns models into black boxes, the optimal hidden representation enjoys an intuitive geometric interpretation, making the dynamics of learning in a deep kernel network simple to understand. Empirical results are provided to validate our theory.", "keywords": ["supervised learning", "backpropagation-free deep architecture", "kernel method", "model interpretability"], "authorids": ["ICLR.cc/2019/Conference/Paper1364/Authors"], "authors": ["Anonymous"], "TL;DR": "We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. ", "pdf": "/pdf/542a263967cbdcfd2e268a922aeffb6ebe7f7d66.pdf", "paperhash": "anonymous|learning_more_interpretable_backpropagationfree_deep_architectures_with_kernels", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning More Interpretable, Backpropagation-Free Deep Architectures with Kernels},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1GLm2R9Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJgP7hR5YQ", "original": "ryeBGLT5FX", "number": 1365, "cdate": 1538087966632, "ddate": null, "tcdate": 1538087966632, "tmdate": 1538155935143, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1365/Authors"], "authors": ["Anonymous"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/bfcefc69929a83938abc3b753b4eea0b68b47466.pdf", "paperhash": "anonymous|composition_and_decomposition_of_gans", "_bibtex": "@inproceedings{    \nanonymous2019composition,    \ntitle={COMPOSITION AND DECOMPOSITION OF GANS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgP7hR5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BkewX2C9tX", "original": "SylcW6T5FX", "number": 1366, "cdate": 1538087966805, "ddate": null, "tcdate": 1538087966805, "tmdate": 1538155934934, "tddate": null, "forum": "BkewX2C9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Analyzing Federated Learning through an Adversarial Lens", "abstract": "Federated learning distributes model training among a multitude of agents, who, guided by privacy concerns, perform training using their local data but share only the parameter updates, for iterative aggregation at the server. In this work,  we operate within the confines of the federated learning paradigm, and explore the threat of targeted backdoor attacks on the global model, via model poisoning(as opposed to data poisoning) initiated by a single malicious agent with no collusion. Specifically, we consider a highly constrained adversary that (i) has partial observability into the model parameter space due to lack of knowledge of other agents\u2019 updates;  (ii) operates in an environment where training data are i.i.d. between the agents (hence spurious updates will easily standout among benign ones); and(iii) has its single malicious update (mostly) cancelled by multiple benign updates.For this highly constrained adversary, we propose a sequence of model poisoning strategies that starting with malicious update boosting,  incrementally introduce various forms of regularization, followed by parameter estimation to improve on both attack success and stealth.  For each strategy, we analyze its impact on the model parameter space, design possible detection approaches and incorporate the insights for gaining stealth. Finally, we use a suite of interpretability techniques to generate visual explanations of the decision boundary and internal feature representations of a benign and malicious model and show that the explanations are nearly visually indistinguishable. Our evaluation results indicate that even a highly constrained adversary can generate successful model poisoning attacks while simultaneously maintaining stealth, thus highlighting the vulnerability of the federated learning setting and the need for effective defense strategies.", "keywords": ["federated learning", "model poisoning"], "authorids": ["ICLR.cc/2019/Conference/Paper1366/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5db8d199242000d2a0c2f6af54a8a436ebb27bb0.pdf", "paperhash": "anonymous|analyzing_federated_learning_through_an_adversarial_lens", "_bibtex": "@inproceedings{    \nanonymous2019analyzing,    \ntitle={Analyzing Federated Learning through an Adversarial Lens},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkewX2C9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sylw7nCqFQ", "original": "Syx_JFvoOm", "number": 1367, "cdate": 1538087966981, "ddate": null, "tcdate": 1538087966981, "tmdate": 1538155934724, "tddate": null, "forum": "Sylw7nCqFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "IMAGE DEFORMATION META-NETWORK FOR ONE-SHOT LEARNING", "abstract": "Humans can robustly learn novel visual concepts even when images undergo various deformations and loose certain information. Incorporating this ability to synthesize deformed instances of new concepts might help visual recognition systems perform better one-shot learning, i.e., learning concepts from one or few examples. Our key insight is that, while the deformed images might not be visually realistic, they still maintain critical semantic information and contribute significantly in formulating classifier decision boundaries. Inspired by the recent progress on meta-learning, we combine a meta-learner with an image deformation network that produces additional training examples, and optimize both models in an endto- end manner. The deformation network learns to synthesize images by fusing a pair of images\u2014a probe image that keeps the visual content and a gallery image that diversifies the deformations. We demonstrate results on the widely used oneshot learning benchmarks (miniImageNet and ImageNet 1K challenge datasets), which significantly outperform the previous state-of-the-art approaches.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1367/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/ed2810a0ec8c3f74e4f1404d164ca5c6bdfb07c6.pdf", "paperhash": "anonymous|image_deformation_metanetwork_for_oneshot_learning", "_bibtex": "@inproceedings{    \nanonymous2019image,    \ntitle={IMAGE DEFORMATION META-NETWORK FOR ONE-SHOT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sylw7nCqFQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyMDXnCcF7", "original": "B1euLbAqF7", "number": 1368, "cdate": 1538087967148, "ddate": null, "tcdate": 1538087967148, "tmdate": 1538155934519, "tddate": null, "forum": "SyMDXnCcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Mean Field Theory of Batch Normalization", "abstract": "We develop a mean field theory for batch normalization in fully-connected feedforward neural networks. In so doing, we provide a precise characterization of signal propagation and gradient backpropagation in wide batch-normalized networks at initialization. We find that gradient signals grow exponentially in depth and that these exploding gradients cannot be eliminated by tuning the initial weight variances or by adjusting the nonlinear activation function. Indeed, batch normalization itself is the cause of gradient explosion. As a result, vanilla batch-normalized networks without skip connections are not trainable at large depths for common initialization schemes, a prediction that we verify with a variety of empirical simulations. While gradient explosion cannot be eliminated, it can be reduced by tuning the network close to the linear regime, which improves the trainability of deep batch-normalized networks without residual connections. Finally, we investigate the learning dynamics of batch-normalized networks and observe that after a single step of optimization the networks achieve a relatively stable equilibrium in which gradients have dramatically smaller dynamic range.", "keywords": ["theory", "batch normalization", "mean field theory", "trainability"], "authorids": ["ICLR.cc/2019/Conference/Paper1368/Authors"], "authors": ["Anonymous"], "TL;DR": "Batch normalization causes exploding gradients in vanilla feedforward networks.", "pdf": "/pdf/6e50613b991606e617800256ca9f5e3935db63f3.pdf", "paperhash": "anonymous|a_mean_field_theory_of_batch_normalization", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Mean Field Theory of Batch Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyMDXnCcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkMD73A5FX", "original": "BJl1mFacKX", "number": 1369, "cdate": 1538087967316, "ddate": null, "tcdate": 1538087967316, "tmdate": 1538155934312, "tddate": null, "forum": "rkMD73A5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Can I trust you more? Model-Agnostic Hierarchical Explanations", "abstract": "Interactions such as double negation in sentences and scene interactions in images are common forms of complex dependencies captured by state-of-the-art machine learning models. We propose Mah\u00e9, a novel approach to provide Model-Agnostic Hierarchical Explanations of how powerful machine learning models, such as deep neural networks, capture these dependencies, either context-dependent or context-free.  Specifically, Mah\u00e9 provides context-dependent explanations by a novel local interpretation algorithm that effectively captures any-order interactions, and obtains context-free explanations through generalizing context-dependent interactions to explain global behaviors. Experimental results show that Mah\u00e9 obtains improved local interaction interpretations over state-of-the-art methods and successfully provides explanations of interactions that are context-free.", "keywords": ["interpretability", "interactions", "context-dependent", "context-free"], "authorids": ["ICLR.cc/2019/Conference/Paper1369/Authors"], "authors": ["Anonymous"], "TL;DR": "A new framework for context-dependent and context-free explanations of predictions", "pdf": "/pdf/7111a5cb3269fc51ca7ba3714765358c14ea4006.pdf", "paperhash": "anonymous|can_i_trust_you_more_modelagnostic_hierarchical_explanations", "_bibtex": "@inproceedings{    \nanonymous2019can,    \ntitle={Can I trust you more? Model-Agnostic Hierarchical Explanations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMD73A5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1lvm305YQ", "original": "S1x6TbRcFX", "number": 1370, "cdate": 1538087967507, "ddate": null, "tcdate": 1538087967507, "tmdate": 1538155934105, "tddate": null, "forum": "S1lvm305YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer", "abstract": "In this work, we address the problem of musical timbre transfer, where the goal is to manipulate the timbre of a sound sample from one instrument to match another instrument while preserving other musical content, such as pitch, rhythm, and loudness. In principle, one could apply image-based style transfer techniques to a time-frequency representation of an audio signal, but this depends on having a representation that allows independent manipulation of timbre as well as high-quality waveform generation. We introduce TimbreTron, an audio processing pipeline which combines three powerful ideas from different domains: Constant Q Transform (CQT) spectrogram for audio representation, a variant of CycleGAN for timbre transfer and WaveNet-Synthesizer for high quality audio generation. We verified that CQT TimbreTron in principle and in practice is more suitable than its STFT counterpart, even though STFT is more commonly used for audio representation. Based on human perceptual evaluations, we confirmed that timbre was transferred recognizably while the musical content was preserved by TimbreTron.", "keywords": ["Generative models", "Timbre Transfer", "Wavenet", "CycleGAN"], "authorids": ["ICLR.cc/2019/Conference/Paper1370/Authors"], "authors": ["Anonymous"], "TL;DR": "We present the TimbreTron, a pipeline for perfoming high-quality timbre transfer on musicalwaveforms using CQT-domain style transfer.", "pdf": "/pdf/96506a9dc1eb087864205da3fe2c5e098aab19cc.pdf", "paperhash": "anonymous|timbretron_a_wavenetcyclegancqtaudio_pipeline_for_musical_timbre_transfer", "_bibtex": "@inproceedings{    \nanonymous2019timbretron:,    \ntitle={TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lvm305YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1gd7nCcF7", "original": "S1e5Z7T5F7", "number": 1372, "cdate": 1538087967846, "ddate": null, "tcdate": 1538087967846, "tmdate": 1538155933901, "tddate": null, "forum": "S1gd7nCcF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Self-Supervised Generalisation with Meta Auxiliary Learning", "abstract": "Auxiliary learning has been shown to improve the generalisation performance of a principal task. But typically, this requires manually-defined auxiliary tasks based on domain knowledge. In this paper, we consider that it may be possible to automatically learn these auxiliary tasks to best suit the principal task, towards optimum auxiliary tasks without any human knowledge. We propose a novel method, Meta Auxiliary Learning (MAXL), which we design for the task of image classification, where the auxiliary task is hierarchical sub-class image classification. The role of the meta learner is to determine sub-class target labels to train a multi-task evaluator, such that these labels improve the generalisation performance on the principal task. Experiments on three different CIFAR datasets show that MAXL outperforms baseline auxiliary learning methods, and is competitive even with a method which uses human-defined sub-class hierarchies. MAXL is self-supervised and general, and therefore offers a promising new direction towards automated generalisation.", "keywords": ["meta learning", "auxiliary learning", "multi-task learning", "self-supervised learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1372/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose Meta AuXiliary Learning (MAXL), a learning framework which can automatically generate auxiliary tasks to improve generalisation of the principal task in a self-supervised manner. ", "pdf": "/pdf/a1ec729447ebde35fed52f6adbe392725c0fa310.pdf", "paperhash": "anonymous|selfsupervised_generalisation_with_meta_auxiliary_learning", "_bibtex": "@inproceedings{    \nanonymous2019self-supervised,    \ntitle={Self-Supervised Generalisation with Meta Auxiliary Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gd7nCcF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SJf_XhCqKm", "original": "SJgZ-z0qt7", "number": 1373, "cdate": 1538087968021, "ddate": null, "tcdate": 1538087968021, "tmdate": 1538155933700, "tddate": null, "forum": "SJf_XhCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Open Loop Hyperparameter Optimization and Determinantal Point Processes", "abstract": "Driven by the need for parallelizable hyperparameter optimization methods, this paper studies open loop search methods: sequences that are predetermined and can be generated before a single configuration is evaluated. Examples include grid search, uniform random search, low discrepancy sequences, and other sampling distributions.\nIn particular, we propose the use of k-determinantal point processes in  hyperparameter optimization via random search. Compared to conventional uniform random search where hyperparameter settings are sampled independently, a k-DPP promotes diversity.  We describe an approach that transforms hyperparameter search spaces for efficient use with a k-DPP. In addition, we introduce a novel Metropolis-Hastings algorithm which can sample from k-DPPs defined over any space from which uniform samples can be drawn, including spaces with a mixture of discrete and continuous dimensions or tree structure. Our experiments show significant benefits  in realistic scenarios with a limited budget for training supervised learners, whether in serial or parallel.", "keywords": ["hyperparameter optimization", "black box optimization"], "authorids": ["ICLR.cc/2019/Conference/Paper1373/Authors"], "authors": ["Anonymous"], "TL;DR": "We address fully parallel hyperparameter optimization with Determinantal Point Processes. ", "pdf": "/pdf/3531cd38c529efc4f988285026fa60bc6ffe9575.pdf", "paperhash": "anonymous|open_loop_hyperparameter_optimization_and_determinantal_point_processes", "_bibtex": "@inproceedings{    \nanonymous2019open,    \ntitle={Open Loop Hyperparameter Optimization and Determinantal Point Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJf_XhCqKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJfOXnActQ", "original": "SJgrzW05FX", "number": 1374, "cdate": 1538087968189, "ddate": null, "tcdate": 1538087968189, "tmdate": 1538155933487, "tddate": null, "forum": "BJfOXnActQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Learn with Conditional Class Dependencies", "abstract": "Neural networks can learn to extract statistical properties from data, but they seldom make use of structured information from the label space to help representation learning. Although some label structure can implicitly be obtained when training on huge amounts of data, in a few-shot learning context where little data is available, making explicit use of the label structure can inform the model to reshape the representation space to reflect a global sense of class dependencies.  We propose a meta-learning framework, Conditional class-Aware Meta-Learning (CAML), that conditionally transforms feature representations based on a metric space that is trained to capture inter-class dependencies. This enables a conditional modulation of the feature representations of the base-learner to impose regularities informed by the label space. Experiments show that the conditional transformation in CAML leads to more disentangled representations and achieves competitive results on the miniImageNet benchmark.", "keywords": ["meta-learning", "learning to learn", "few-shot learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1374/Authors"], "authors": ["Anonymous"], "TL;DR": "CAML is an instance of MAML with conditional class dependencies.", "pdf": "/pdf/adf2c8167eb2cc07c43f236b3914f88210758c6d.pdf", "paperhash": "anonymous|learning_to_learn_with_conditional_class_dependencies", "_bibtex": "@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Learn with Conditional Class Dependencies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfOXnActQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkVOXhAqY7", "original": "HJerTRnqtX", "number": 1375, "cdate": 1538087968365, "ddate": null, "tcdate": 1538087968365, "tmdate": 1538155933286, "tddate": null, "forum": "rkVOXhAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Conditional Entropy Bottleneck", "abstract": "We present a new family of objective functions, which we term the Conditional Entropy Bottleneck (CEB). We demonstrate the application of CEB to classification tasks. In our experiments, CEB gives: well-calibrated predictions; essentially perfect detection of challenging out-of-distribution examples and powerful whitebox adversarial examples; and natural robustness to the same. Finally, we report that CEB fails to learn a dataset with fixed random labels, providing a possible resolution to the problem of generalization observed in Zhang et al. (2016).", "keywords": ["representation learning", "information theory", "uncertainty", "out-of-distribution detection", "adversarial example robustness", "generalization", "objective function"], "authorids": ["ICLR.cc/2019/Conference/Paper1375/Authors"], "authors": ["Anonymous"], "TL;DR": "The Conditional Entropy Bottleneck is an information-theoretic objective function for learning optimal representations.", "pdf": "/pdf/3303528454f54a58ebb10d2cc4e1fbee51bf41a9.pdf", "paperhash": "anonymous|the_conditional_entropy_bottleneck", "_bibtex": "@inproceedings{    \nanonymous2019the,    \ntitle={The Conditional Entropy Bottleneck},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkVOXhAqY7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1ltQ3R9KQ", "original": "B1eP38n9Y7", "number": 1376, "cdate": 1538087968533, "ddate": null, "tcdate": 1538087968533, "tmdate": 1538155933075, "tddate": null, "forum": "H1ltQ3R9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Causal Reasoning from Meta-learning", "abstract": "Discovering and exploiting the causal structure in data is a crucial challenge for intelligent agents. Though powerful formalisms for causal reasoning have been developed, applying them in real-world domains is often difficult because the frameworks make idealized assumptions. Here we explore whether modern deep reinforcement learning can be used to train agents to perform causal reasoning, without incorporating explicit principles of causal reasoning. We adopt a meta-learning approach, where the agent learns a policy for conducting experiments via causal interventions, in order to support a subsequent task which rewards making accurate causal inferences. We also found the agent could make sophisticated counterfactual predictions, as well as learn to draw causal inferences from passive observational data, when such inferences were possible. Our results suggest that applied causal reasoning in complex settings may benefit from powerful learning-based approaches. More generally, this work may offer new strategies for structured exploration in reinforcement learning, by providing agents with the ability to perform and interpret experiments.", "keywords": ["meta-learning", "causal reasoning", "deep reinforcement learning", "artificial intelligence"], "authorids": ["ICLR.cc/2019/Conference/Paper1376/Authors"], "authors": ["Anonymous"], "TL;DR": "meta-learn a learning algorithm capable of causal reasoning", "pdf": "/pdf/e5ec5eb9f534d19da6a41b820d116296e25986c0.pdf", "paperhash": "anonymous|causal_reasoning_from_metalearning", "_bibtex": "@inproceedings{    \nanonymous2019causal,    \ntitle={Causal Reasoning from Meta-learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ltQ3R9KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJlt7209Km", "original": "HkxQDfAqtQ", "number": 1377, "cdate": 1538087968704, "ddate": null, "tcdate": 1538087968704, "tmdate": 1538155932868, "tddate": null, "forum": "HJlt7209Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Theoretical and Empirical Study of Adversarial Examples", "abstract": "Many techniques are developed to defend against adversarial examples at scale. So far, the most successful defenses generate adversarial examples during each training step and add them to the training data. Yet, this brings significant computational overhead.  In this paper, we investigate defenses against adversarial attacks. First, we propose feature smoothing, a simple data augmentation method with little computational overhead. Essentially, feature smoothing trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point.  The intuition behind feature smoothing is to generate virtual data points as close as adversarial examples, and to avoid the computational burden of generating data during training. Our experiments on MNIST and CIFAR10 datasets explore different combinations of known regularization and data augmentation methods and show that feature smoothing with logit squeezing performs best for both adversarial and clean accuracy. Second, we propose an unified framework to understand the connections and differences among different efficient methods by analyzing the biases and variances of decision boundary. We show that under some symmetrical assumptions, label smoothing, logit squeezing, weight decay, mix up and feature smoothing all produce an unbiased estimation of the decision boundary with smaller estimated variance. All of those methods except weight decay are also stable when the assumptions no longer hold.", "keywords": ["Adversarial examples", "Feature smoothing", "Data augmentation", "Decision boundary"], "authorids": ["ICLR.cc/2019/Conference/Paper1377/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/76464c5355c85e5069dc29348781f264867a321e.pdf", "paperhash": "anonymous|theoretical_and_empirical_study_of_adversarial_examples", "_bibtex": "@inproceedings{    \nanonymous2019theoretical,    \ntitle={Theoretical and Empirical Study of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlt7209Km},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkgYmhR9KX", "original": "rkeG6Xi9FQ", "number": 1378, "cdate": 1538087968875, "ddate": null, "tcdate": 1538087968875, "tmdate": 1538155932656, "tddate": null, "forum": "HkgYmhR9KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "AD-VAT: An Asymmetric Dueling mechanism for learning Visual Active Tracking", "abstract": "Visual active tracking (VAT) aims at following a target object by autonomously controlling the motion system of a tracker given visual observations. In this paper, we propose a novel method which adopts an asymmetric dueling mechanism for learning visual active tracking, namely AD-VAT. In AD-VAT, the target and the tracker are mutual opponents, i.e, the tracker manages to lockup the target, and the target tries to escape from the tracker. In the implementation, both the tracker and the target are approximated by deep networks, and their policies that map environment observations to control actions can be learned via reinforcement learning in an end-to-end manner. The tracker and the target are asymmetric in observations, network structures and reward functions. Different from the tracker, the target is modeled with a tracker-aware network, i.e, besides its own observation, the tracker's observations and actions are also fed as input to the network. In addition, it learns to predict the tracker's reward as an auxiliary task.  We argue that such an asymmetric adversarial mechanism is able to learn a stronger target,  which vice versa induces a more robust tracker. The experimental results, in both 2D and 3D environments, demonstrate that the proposed method leads to a faster convergence in training the tracker and more robust tracking behaviors in different testing scenarios.", "keywords": ["Active tracking", "reinforcement learning", "adversarial learning", "multi agent"], "authorids": ["ICLR.cc/2019/Conference/Paper1378/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose AD-VAT, where the tracker and the target object, viewed as two learnable agents, are opponents and can mutually enhance during training.", "pdf": "/pdf/8fec03cfa2542493a50e891efa398ffbb21569c9.pdf", "paperhash": "anonymous|advat_an_asymmetric_dueling_mechanism_for_learning_visual_active_tracking", "_bibtex": "@inproceedings{    \nanonymous2019ad-vat:,    \ntitle={AD-VAT: An Asymmetric Dueling mechanism for learning Visual Active Tracking},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgYmhR9KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rygFmh0cKm", "original": "H1lqdpT9KX", "number": 1379, "cdate": 1538087969052, "ddate": null, "tcdate": 1538087969052, "tmdate": 1538155932439, "tddate": null, "forum": "rygFmh0cKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Difficulties of Probability Distillation", "abstract": "Probability distillation has recently been of interest to deep learning practitioners as it presents a practical solution for sampling from autoregressive models for deployment in real-time applications. We identify a pathological optimization issue with the commonly adopted stochastic minimization of the (reverse) KL divergence, owing to sparse gradient signal from the teacher model due to curse of dimensionality. We also explore alternative principles for distillation, and show that one can achieve qualitatively better results than with KL minimization. \n", "keywords": ["Probability distillation", "Autoregressive models", "normalizing flows", "wavenet", "pixelcnn"], "authorids": ["ICLR.cc/2019/Conference/Paper1379/Authors"], "authors": ["Anonymous"], "TL;DR": "We point out an optimization issue of distillation with KL divergence, and explore different alternatives", "pdf": "/pdf/332c8efc16bd5dd346473190cbd34ce6dedfe5a4.pdf", "paperhash": "anonymous|on_difficulties_of_probability_distillation", "_bibtex": "@inproceedings{    \nanonymous2019on,    \ntitle={On Difficulties of Probability Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygFmh0cKm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryxY73AcK7", "original": "BJxFw76qF7", "number": 1380, "cdate": 1538087969222, "ddate": null, "tcdate": 1538087969222, "tmdate": 1538155932226, "tddate": null, "forum": "ryxY73AcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal Lipschitz Functions", "abstract": "Training neural networks with a Lipschitz constraint provides improved generalization, robustness, and interpretability. However, existing techniques either fail to guarantee a Lipschitz constraint or are unable to universally approximate Lipschitz functions. Often, a small Lipschitz constant is enforced by considering constraints on the network weights, but little attention is payed to the choice of activation function. We identify Jacobian norm of network layers as a scarce resource in representing Lipschitz functions and show that common activation functions are unable to effectively utilize this. We show that with common activation functions networks are unable to learn even the simplest Lipschitz functions, such as the absolute value function. With this insight, we introduce a novel activation function, the GroupSort activation, which partitions the hidden layer and sorts the units within each partition. Empirically, we identify pathologies of common activation functions and confirm that these theoretical observations are relevant in practice. ", "keywords": ["deep learning", "lipschitz neural networks", "generalization", "universal approximation", "adversarial examples", "generative models", "optimal transport"], "authorids": ["ICLR.cc/2019/Conference/Paper1380/Authors"], "authors": ["Anonymous"], "TL;DR": "We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.", "pdf": "/pdf/a6742db599d34a12d7f1129fd9fee909d1354ced.pdf", "paperhash": "anonymous|universal_lipschitz_functions", "_bibtex": "@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Lipschitz Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxY73AcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJxF73R9tX", "original": "Bkx26o69Km", "number": 1381, "cdate": 1538087969392, "ddate": null, "tcdate": 1538087969392, "tmdate": 1538155932017, "tddate": null, "forum": "rJxF73R9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Knows When it Doesn\u2019t Know: Deep Abstaining Classifiers", "abstract": "We introduce the deep abstaining classifier -- a deep neural network trained with a novel loss function that provides an abstention option during training. This allows  the DNN to abstain on confusing or difficult-to-learn examples while improving performance on the non-abstained samples. We show that such deep abstaining classifiers can: (i) learn representations for structured noise -- where noisy training labels or confusing examples are correlated with underlying features -- and then learn to abstain based on such features; (ii) enable robust learning in the presence of arbitrary or unstructured noise by identifying noisy samples; and (iii) be used as an effective out-of-category detector that learns to reliably abstain when presented with samples from  unknown classes. We provide analytical results on loss function behavior that enable automatic tuning of accuracy and coverage. We demonstrate the utility of the deep abstaining classifier using multiple image benchmarks.", "keywords": ["deep learning", "robust learning", "abstention", "representation learning", "abstaining classifier", "open-set detection"], "authorids": ["ICLR.cc/2019/Conference/Paper1381/Authors"], "authors": ["Anonymous"], "TL;DR": "A deep abstaining neural network trained with a novel loss function that learns representations for when to abstain enabling robust learning in the presence of different types of noise.", "pdf": "/pdf/dd755be26d271f0052f6ca432f9167ecab295802.pdf", "paperhash": "anonymous|knows_when_it_doesnt_know_deep_abstaining_classifiers", "_bibtex": "@inproceedings{    \nanonymous2019knows,    \ntitle={Knows When it Doesn\u2019t Know: Deep Abstaining Classifiers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxF73R9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "S1ecm2C9K7", "original": "SJxe0x0qFX", "number": 1382, "cdate": 1538087969558, "ddate": null, "tcdate": 1538087969558, "tmdate": 1538155931809, "tddate": null, "forum": "S1ecm2C9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Feature-Wise Bias Amplification", "abstract": "We study the phenomenon of bias amplification in classifiers, wherein a machine learning model learns to predict classes with a greater disparity than the underlying ground truth. We demonstrate that bias amplification can arise via inductive bias in gradient descent methods resulting in overestimation of importance of moderately-predictive ``weak'' features if insufficient training data is available. This overestimation gives rise to feature-wise bias amplification -- a previously unreported form of bias that can be traced back to the features of a trained model. Through analysis and experiments, we show that the while some bias cannot be mitigated without sacrificing accuracy, feature-wise bias amplification can be mitigated through targeted feature selection. We present two new feature selection algorithms for mitigating bias amplification in linear models, and show how they can be adapted to convolutional neural networks efficiently. Our experiments on synthetic and real data demonstrate that these algorithms consistently lead to reduced bias without harming accuracy, in some cases eliminating predictive bias altogether while providing modest gains in accuracy.", "keywords": ["bias", "bias amplification", "classification"], "authorids": ["ICLR.cc/2019/Conference/Paper1382/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/6002968e345eb4774f3a8a861d1bfa414ea027e1.pdf", "paperhash": "anonymous|featurewise_bias_amplification", "_bibtex": "@inproceedings{    \nanonymous2019feature-wise,    \ntitle={Feature-Wise Bias Amplification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1ecm2C9K7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "H1e572A5tQ", "original": "S1g3_03qFm", "number": 1383, "cdate": 1538087969720, "ddate": null, "tcdate": 1538087969720, "tmdate": 1538155931597, "tddate": null, "forum": "H1e572A5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TarMAC: Targeted Multi-Agent Communication", "abstract": "We explore the collaborative multi-agent setting where a team of deep reinforcement learning agents attempt to solve a shared task in partially observable environments. In this scenario, learning an effective communication protocol is key. We propose a communication protocol that allows for targeted communication, where agents learn \\emph{what} messages to send and \\emph{who} to send them to. Additionally, we introduce a multi-stage communication approach where the agents co-ordinate via several rounds of communication before taking an action in the environment. We evaluate our approach on several cooperative multi-agent tasks, of varying difficulties with varying number of agents, in a variety of environments ranging from 2D grid layouts of shapes and simulated traffic junctions to complex 3D indoor environments. We demonstrate the benefits of targeted as well as multi-stage communication. Moreover, we show that the targeted communication strategies learned by the agents are quite interpretable and intuitive.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1383/Authors"], "authors": ["Anonymous"], "TL;DR": "Targeted communication in multi-agent cooperative reinforcement learning", "pdf": "/pdf/3423bb3b9be8759b098b8e3b7d6a9f506eb042e3.pdf", "paperhash": "anonymous|tarmac_targeted_multiagent_communication", "_bibtex": "@inproceedings{    \nanonymous2019tarmac:,    \ntitle={TarMAC: Targeted Multi-Agent Communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1e572A5tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Byg5QhR5FQ", "original": "H1xeFkAqFX", "number": 1384, "cdate": 1538087969893, "ddate": null, "tcdate": 1538087969893, "tmdate": 1538155931385, "tddate": null, "forum": "Byg5QhR5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Top-Down Neural Model For Formulae", "abstract": "We present a simple neural model that given a formula and a property tries to answer the question whether the formula has the given property, for example whether a propositional formula is always true. A structure of formula is captured by a feedforward neural network build recursively for the given formula in a top-down manner. The results of this network are then processed by two recurrent neural networks. One of the interesting aspects of our model is that how propositional atoms are treated. They do not occur explicitly in our model, they only influence how the final model looks like, but for example their names are completely irrelevant.\n", "keywords": ["logic", "formula", "recursive neural networks", "recurrent neural networks"], "authorids": ["ICLR.cc/2019/Conference/Paper1384/Authors"], "authors": ["Anonymous"], "TL;DR": "A top-down approach how to recursively represent propositional formulae by neural networks is presented.", "pdf": "/pdf/d76822cfe465a30a52abaf380494ad62ec2344f7.pdf", "paperhash": "anonymous|topdown_neural_model_for_formulae", "_bibtex": "@inproceedings{    \nanonymous2019top-down,    \ntitle={Top-Down Neural Model For Formulae},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byg5QhR5FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Syf9Q209YQ", "original": "rJe70FnqY7", "number": 1385, "cdate": 1538087970125, "ddate": null, "tcdate": 1538087970125, "tmdate": 1538155931174, "tddate": null, "forum": "Syf9Q209YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Manifold regularization with GANs for semi-supervised learning", "abstract": "Generative Adversarial Networks are powerful generative models that can model the manifold of natural images. We leverage this property to perform manifold regularization by approximating a variant of the Laplacian norm using a Monte Carlo approximation that is easily computed with the GAN. When incorporated into the semi-supervised feature-matching GAN we achieve state-of-the-art results for GAN-based semi-supervised learning on CIFAR-10 and SVHN benchmarks, with a method that is significantly easier to implement than competing methods. We find that manifold regularization improves the quality of generated images, and is affected by the quality of the GAN used to approximate the regularizer.", "keywords": ["semi-supervised learning", "generative adversarial networks", "manifold regularization"], "authorids": ["ICLR.cc/2019/Conference/Paper1385/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4422407e3fd49b67dda7a2364138fb84499a1086.pdf", "paperhash": "anonymous|manifold_regularization_with_gans_for_semisupervised_learning", "_bibtex": "@inproceedings{    \nanonymous2019manifold,    \ntitle={Manifold regularization with GANs for semi-supervised learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syf9Q209YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ByGq7hRqKX", "original": "Skx4sVgdKX", "number": 1386, "cdate": 1538087970294, "ddate": null, "tcdate": 1538087970294, "tmdate": 1538155930964, "tddate": null, "forum": "ByGq7hRqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Cross-Task Knowledge Transfer for Visually-Grounded Navigation", "abstract": "Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for two different tasks: learning to follow navigational instructions and embodied question answering. In this paper, we aim to learn a multitask model capable of jointly learning both tasks, and transferring knowledge of words and their grounding in visual objects across tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual objects in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for zero-shot transfer to instructions containing new words by leveraging object detectors.", "keywords": [], "authorids": ["ICLR.cc/2019/Conference/Paper1386/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/5b3117cfa2e5e7780a0a15953dae10b9b027815a.pdf", "paperhash": "anonymous|crosstask_knowledge_transfer_for_visuallygrounded_navigation", "_bibtex": "@inproceedings{    \nanonymous2019cross-task,    \ntitle={Cross-Task Knowledge Transfer for Visually-Grounded Navigation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByGq7hRqKX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rJ4qXnCqFX", "original": "HklagkpcKm", "number": 1387, "cdate": 1538087970460, "ddate": null, "tcdate": 1538087970460, "tmdate": 1538155930746, "tddate": null, "forum": "rJ4qXnCqFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Knowledge Graph Embeddings", "abstract": "We develop a probabilistic extension of state-of-the-art embedding models for link prediction in relational knowledge graphs. Knowledge graphs are collections of relational facts, where each fact states that a certain relation holds between two entities, such as people, places, or objects. We argue that knowledge graphs should be treated within a Bayesian framework because even large knowledge graphs typically contain only few facts per entity, leading effectively to a small data problem where parameter uncertainty matters. We introduce a probabilistic reinterpretation of the DistMult (Yang et al., 2015) and ComplEx (Trouillon et al., 2016) models and employ variational inference to estimate a lower bound on the marginal likelihood of the data. We find that the main benefit of the Bayesian approach is that it allows for efficient, gradient based optimization over hyperparameters, which would lead to divergences in a non-Bayesian treatment. Models with such learned hyperparameters improve over the state-of-the-art by a significant margin, as we demonstrate on several benchmarks.", "keywords": ["knowledge graph", "variational inference", "probabilistic models", "representation learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1387/Authors"], "authors": ["Anonymous"], "TL;DR": "Scalable hyperparameter learning for knowledge graph embedding models using variational EM", "pdf": "/pdf/6177f277dc7b7f59c89807d4238042483f696387.pdf", "paperhash": "anonymous|probabilistic_knowledge_graph_embeddings", "_bibtex": "@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Knowledge Graph Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJ4qXnCqFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SkgiX2Aqtm", "original": "SklRPf05tm", "number": 1388, "cdate": 1538087970694, "ddate": null, "tcdate": 1538087970694, "tmdate": 1538155930536, "tddate": null, "forum": "SkgiX2Aqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PIE: Pseudo-Invertible Encoder", "abstract": "We consider the problem of information compression from high dimensional data. Where many studies consider the problem of compression by non-invertible trans- formations, we emphasize the importance of invertible compression. We introduce new class of likelihood-based auto encoders with pseudo bijective architecture, which we call Pseudo Invertible Encoders. We provide the theoretical explanation of their principles. We evaluate Gaussian Pseudo Invertible Encoder on MNIST, where our model outperform WAE and VAE in sharpness of the generated images.", "keywords": ["Invertible Mappings", "Bijectives", "Dimensionality reduction", "Autoencoder"], "authorids": ["ICLR.cc/2019/Conference/Paper1388/Authors"], "authors": ["Anonymous"], "TL;DR": "New Class of Autoencoders with pseudo invertible architecture", "pdf": "/pdf/4a50784150a5a5917d0281159ab0819601cab6ba.pdf", "paperhash": "anonymous|pie_pseudoinvertible_encoder", "_bibtex": "@inproceedings{    \nanonymous2019pie:,    \ntitle={PIE: Pseudo-Invertible Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgiX2Aqtm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyls7h05FQ", "original": "ryx6bfCcFQ", "number": 1389, "cdate": 1538087970863, "ddate": null, "tcdate": 1538087970863, "tmdate": 1538155930317, "tddate": null, "forum": "Hyls7h05FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A Differentiable Self-disambiguated Sense Embedding Model via Scaled Gumbel Softmax", "abstract": "We present a differentiable multi-prototype word representation model that disentangles senses of polysemous words and produces meaningful sense-specific embeddings without external resources. It jointly learns how to disambiguate senses given local context and how to represent senses using hard attention. Unlike previous multi-prototype models, our model approximates discrete sense selection in a differentiable manner via a modified Gumbel softmax. We also propose a novel human evaluation task that quantitatively measures (1) how meaningful the learned sense groups are to humans and (2) how well the model is able to disambiguate senses given a context sentence. Our model outperforms competing approaches on both human evaluations and multiple word similarity tasks.", "keywords": ["unsupervised representation learning", "sense embedding", "word sense disambiguation", "human evaluation"], "authorids": ["ICLR.cc/2019/Conference/Paper1389/Authors"], "authors": ["Anonymous"], "TL;DR": "Disambiguate and embed word senses with a differentiable hard-attention model using Scaled Gumbel Softmax", "pdf": "/pdf/4c1e637c66cb5275d8f08b9b8c4baae6c4e2dd47.pdf", "paperhash": "anonymous|a_differentiable_selfdisambiguated_sense_embedding_model_via_scaled_gumbel_softmax", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A Differentiable Self-disambiguated Sense Embedding Model via Scaled Gumbel Softmax},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyls7h05FQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJej72AqF7", "original": "HJempMC5YQ", "number": 1390, "cdate": 1538087971038, "ddate": null, "tcdate": 1538087971038, "tmdate": 1538155930110, "tddate": null, "forum": "BJej72AqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A MAX-AFFINE SPLINE PERSPECTIVE OF RECURRENT NEURAL NETWORKS", "abstract": "We develop a framework for understanding and improving recurrent neural net-works (RNNs) using max-affine spline operators (MASO). We prove that RNNsusing piecewise affine and convex nonlinearities can be written as a simple piece-wise affine spline operator. The resulting representation provides several new per-spectives for analyzing RNNs, three of which we study in this paper.  First, weshow that an RNN internally partitions the input space during training using vec-tor quantization and that it builds up the partition through time. Second, we showthat the affine parameter of an RNN corresponds to an input-specific template,from which we can interpret an RNN as performing a simple template matching(matched filtering) given the input. Third, by closely examining the MASO RNN formula, we prove that injecting Gaussian noise in the initial hidden state in RNNs corresponds to an explicit L2regularization on the affine parameters, which links to exploding gradient issues and improves generalization.  Extensive experimentson several datasets of various modalities demonstrates and validates each of theabove analyses.  In particular, using initial hidden states elevates simple RNNs tostate-of-the-art performance on these datasets", "keywords": ["RNN", "max-affine spline operators"], "authorids": ["ICLR.cc/2019/Conference/Paper1390/Authors"], "authors": ["Anonymous"], "TL;DR": "We provide new insights and interpretations of RNNs from a max-affine spline operators perspective", "pdf": "/pdf/e7bf3e61149dc93d3bfd2e8782e1c45ccb929173.pdf", "paperhash": "anonymous|a_maxaffine_spline_perspective_of_recurrent_neural_networks", "_bibtex": "@inproceedings{    \nanonymous2019a,    \ntitle={A MAX-AFFINE SPLINE PERSPECTIVE OF RECURRENT NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJej72AqF7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Sklsm20ctX", "original": "S1l_Fc65KQ", "number": 1391, "cdate": 1538087971209, "ddate": null, "tcdate": 1538087971209, "tmdate": 1538155929889, "tddate": null, "forum": "Sklsm20ctX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Competitive experience replay", "abstract": "Deep learning has achieved remarkable successes in solving challenging reinforcement learning (RL) problems. However, it still often suffers from the need to engineer a reward function that not only reflects the task but is also carefully shaped. This limits the applicability of RL in the real world. It is therefore of great practical importance to develop algorithms which can learn from unshaped, sparse reward signals, e.g. a binary signal indicating successful task completion.\nWe propose a novel method called competitive experience replay, which efficiently supplements a sparse reward by placing learning in the context of an exploration competition between a pair of agents.\nOur method complements the recently proposed hindsight experience replay (HER) by inducing an automatic exploratory curriculum.\nWe evaluate our approach on the tasks of reaching various goal locations in an ant maze and manipulating objects with a robotic arm.\nEach task provides only binary rewards indicating whether or not the goal is completed.\nOur method asymmetrically augments these sparse rewards for a pair of agents each learning the same task, creating a competitive game designed to drive exploration.\nExtensive experiments demonstrate that this method leads to faster converge and improved task performance.", "keywords": ["reinforcement learning", "sparse reward", "goal-based learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1391/Authors"], "authors": ["Anonymous"], "TL;DR": "a novel method to learn with sparse reward using adversarial reward re-labeling", "pdf": "/pdf/84417b2347251f7b4846e8c45b6a9560c72af7fa.pdf", "paperhash": "anonymous|competitive_experience_replay", "_bibtex": "@inproceedings{    \nanonymous2019competitive,    \ntitle={Competitive experience replay},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sklsm20ctX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "SyGjQ30qFX", "original": "r1gNFzCctm", "number": 1392, "cdate": 1538087971387, "ddate": null, "tcdate": 1538087971387, "tmdate": 1538155929678, "tddate": null, "forum": "SyGjQ30qFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "TopicGAN: Unsupervised Text Generation from Explainable Latent Topics", "abstract": "Learning discrete representations of data and then generating data from the discovered representations have been increasingly studied, because the obtained discrete representations can benefit unsupervised learning. However, the performance of learning discrete representations of textual data with deep generative models has not been widely explored.  In this work, we propose TopicGAN, a two-step generative model on text generation, which is able to discover discrete latent topics of texts and generate natural language from the discovered latent topics in an unsupervised fashion. Promising results are shown on unsupervised text classification and text generation for both subjective and objective evaluation.", "keywords": ["unsupervised learning", "topic model", "text generation"], "authorids": ["ICLR.cc/2019/Conference/Paper1392/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/50ee350f1abb2bd745d9b475326d525e408744fc.pdf", "paperhash": "anonymous|topicgan_unsupervised_text_generation_from_explainable_latent_topics", "_bibtex": "@inproceedings{    \nanonymous2019topicgan:,    \ntitle={TopicGAN: Unsupervised Text Generation from Explainable Latent Topics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyGjQ30qFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1xhQhRcK7", "original": "BJgBPch9KX", "number": 1393, "cdate": 1538087971556, "ddate": null, "tcdate": 1538087971556, "tmdate": 1538155929468, "tddate": null, "forum": "B1xhQhRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures", "abstract": "This paper addresses the problem of evaluating learning systems in safety critical domains such as autonomous driving, where failures can have catastrophic consequences. To this end, we focus on two problems: searching for scenarios when learned agents fail and the related problem of assessing their probability of failure. The standard method for agent evaluation in reinforcement learning, Vanilla Monte Carlo, can severely underestimate agent failure probabilities, leading to the deployment of unsafe agents. In our experiments, we observe this even after allocating equal compute to training and evaluation. To address this shortcoming, we draw upon the rare event probability estimation literature and propose an adversarial evaluation approach. Our approach focuses evaluation on difficult scenarios that are selected adversarially, while still providing unbiased estimates of failure probabilities. To do this, we propose a continuation approach to learning a failure probability predictor. This leverages data from related agents to overcome issues of data sparsity and allows the adversary to reuse data gathered for training the agent. We demonstrate the efficacy of adversarial evaluation on two complex reinforcement learning domains (humanoid control and simulated driving). Experimental results show that our methods can find catastrophic failures and estimate failures rates of agents multiple orders of magnitude faster (hours instead of days) than standard evaluation schemes.", "keywords": ["agent evaluation", "adversarial examples", "robustness", "safety", "reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1393/Authors"], "authors": ["Anonymous"], "TL;DR": "We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.", "pdf": "/pdf/5f7943a45689cc4ba4427af30ab0b0cf3a8963b5.pdf", "paperhash": "anonymous|rigorous_agent_evaluation_an_adversarial_approach_to_uncover_catastrophic_failures", "_bibtex": "@inproceedings{    \nanonymous2019rigorous,    \ntitle={Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xhQhRcK7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1gnQ20qYX", "original": "Syxnl_Y9t7", "number": 1394, "cdate": 1538087971732, "ddate": null, "tcdate": 1538087971732, "tmdate": 1538155929265, "tddate": null, "forum": "r1gnQ20qYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Pearl: Prototype lEArning via Rule Lists", "abstract": "Deep neural networks have demonstrated promising classification performance on many healthcare applications. However, the interpretability of those models are often lacking. On the other hand, classical interpretable models such as rule lists or decision trees do not lead to the same level of accuracy as deep neural networks. Despite their interpretable structures, the resulting rules are often too complex to be interpretable (due to the potentially large depth of rule lists). In this work, we present PEARL, short for Prototype lEArning via Rule Lists, which iteratively use rule lists to guide a neural network to learn representative data prototypes. The resulting prototype neural network provides  accurate prediction, and the prediction can be easily explained by  prototype and its guiding rule lists. Thanks to the prediction power of neural networks, the rule lists defining prototypes are more concise and hence provide better interpretability. On two real-world electronic healthcare records (EHR) datasets, PEARL consistently outperforms all baselines,  achieving performance improvement over conventional rule learning by up to 28% and over prototype learning by up to 3%. Experimental results also show the resulting interpretation of PEARL is simpler than the standard rule learning.", "keywords": ["rule list learning", "prototype learning", "interpretability", "healthcare"], "authorids": ["ICLR.cc/2019/Conference/Paper1394/Authors"], "authors": ["Anonymous"], "TL;DR": "a method combining rule list learning and prototype learning ", "pdf": "/pdf/e308f5746e0a3835396f9177cae53e7ef37a9222.pdf", "paperhash": "anonymous|pearl_prototype_learning_via_rule_lists", "_bibtex": "@inproceedings{    \nanonymous2019pearl:,    \ntitle={Pearl: Prototype lEArning via Rule Lists},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gnQ20qYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Skz3Q2CcFX", "original": "r1elGLhqKm", "number": 1395, "cdate": 1538087971922, "ddate": null, "tcdate": 1538087971922, "tmdate": 1538155929061, "tddate": null, "forum": "Skz3Q2CcFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae", "abstract": "Embeddings are a fundamental component of many modern machine learning and natural language processing models.\nUnderstanding them and visualizing them is essential for gathering insights about the information they capture and the behavior of the models.\nState of the art in analyzing embeddings consists in projecting them in two-dimensional planes without any interpretable semantics associated to the axes of the projection, which makes detailed analyses and comparison among multiple sets of embeddings challenging.\nIn this work, we propose to use explicit axes defined as algebraic formulae over embeddings to project them into a lower dimensional, but semantically meaningful subspace, as a simple yet effective analysis and visualization methodology.\nThis methodology assigns an interpretable semantics to the measures of variability and the axes of visualizations, allowing for both comparisons among different sets of embeddings and fine-grained inspection of the embedding spaces.\nWe demonstrate the power of the proposed methodology through a series of case studies that make use of visualizations constructed around the underlying methodology and through a user study. The results show how the methodology is effective at providing more profound insights than classical projection methods and how it is widely applicable to many other use cases.", "keywords": ["visualization", "embeddings", "representations", "t-sne", "natural", "language", "processing", "machine", "learning", "algebra"], "authorids": ["ICLR.cc/2019/Conference/Paper1395/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for task-oriented analysis tasks and it outperforms t-SNE in our user study.", "pdf": "/pdf/177801d5438d9c9ce4dee7c8b2a13a0a06b495ff.pdf", "paperhash": "anonymous|visualizing_and_understanding_the_semantics_of_embedding_spaces_via_algebraic_formulae", "_bibtex": "@inproceedings{    \nanonymous2019visualizing,    \ntitle={Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skz3Q2CcFX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxn7nR5KX", "original": "S1liVh3cF7", "number": 1396, "cdate": 1538087972118, "ddate": null, "tcdate": 1538087972118, "tmdate": 1538155928854, "tddate": null, "forum": "rkxn7nR5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Incremental Few-Shot Learning with Attention Attractor Networks", "abstract": "Machine learning classifiers are often trained to recognize a set of pre-defined classes. However,\nin many real applications, it is often desirable to have the flexibility of learning additional\nconcepts, without re-training on the full training set. This paper addresses this problem,\nincremental few-shot learning, where a regular classification network has already been trained to\nrecognize a set of base classes; and several extra novel classes are being considered, each with\nonly a few labeled examples. After learning the novel classes, the model is then evaluated on the\noverall performance of both base and novel classes. To this end, we propose a meta-learning model,\nthe Attention Attractor Network, which regularizes the learning of novel classes. In each episode,\nwe train a set of new weights to recognize novel classes until they converge, and we show that the\ntechnique of recurrent back-propagation can back-propagate through the optimization process and\nfacilitate the learning of the attractor network regularizer. We demonstrate that the learned\nattractor network can recognize novel classes while remembering old classes without the need to\nreview the original training set, outperforming baselines that do not rely on an iterative\noptimization process.", "keywords": ["meta-learning", "few-shot learning", "incremental learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1396/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/4d77c27d3e71c414017a176619d977eeebcd51bd.pdf", "paperhash": "anonymous|incremental_fewshot_learning_with_attention_attractor_networks", "_bibtex": "@inproceedings{    \nanonymous2019incremental,    \ntitle={Incremental Few-Shot Learning with Attention Attractor Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxn7nR5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJgnmhA5KQ", "original": "H1gD8-n5Km", "number": 1397, "cdate": 1538087972306, "ddate": null, "tcdate": 1538087972306, "tmdate": 1538155928640, "tddate": null, "forum": "BJgnmhA5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diverse Machine Translation with a Single Multinomial Latent Variable", "abstract": "There are many ways to translate a sentence into another language. Explicit modeling of such uncertainty may enable better model fitting to the data and it may enable users to express a preference for how to translate a piece of content. Latent variable models are a natural way to represent uncertainty. Prior work investigated the use of multivariate continuous and discrete latent variables, but their interpretation and use for generating a diverse set of hypotheses have been elusive. In this work, we drastically simplify the model, using just a single multinomial latent variable. The resulting mixture of experts model can be trained efficiently via hard-EM and can generate a diverse set of hypothesis by parallel greedy decoding. We perform extensive experiments on three WMT benchmark datasets that have multiple human references, and we show that our model provides a better trade-off between quality and diversity of generations compared to all baseline methods.\\footnote{Code to reproduce this work is available at: anonymized URL.}", "keywords": ["machine translation", "latent variable models", "diverse decoding"], "authorids": ["ICLR.cc/2019/Conference/Paper1397/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/b78538bbb15c4fa456a7f6d269ae6e1302c4e52d.pdf", "paperhash": "anonymous|diverse_machine_translation_with_a_single_multinomial_latent_variable", "_bibtex": "@inproceedings{    \nanonymous2019diverse,    \ntitle={Diverse Machine Translation with a Single Multinomial Latent Variable},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgnmhA5KQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "rkxhX209FX", "original": "S1xpkDi5Fm", "number": 1398, "cdate": 1538087972473, "ddate": null, "tcdate": 1538087972473, "tmdate": 1538155928430, "tddate": null, "forum": "rkxhX209FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "An Active Learning Framework for Efficient Robust Policy Search", "abstract": "Robust Policy Search is the problem of learning policies that do not degrade in performance when subject to unseen environment model parameters. It is particularly relevant for transferring policies learned in a simulation environment to the real world. Several existing approaches involve sampling large batches of trajectories which reflect the differences in various possible environments, and then selecting some subset of these to learn robust policies, such as the ones that  result in the worst performance. We propose an active learning based framework, EffAcTS, to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset. We apply this framework to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of our approach on standard continuous control tasks. We also present a Multi-Task Learning perspective to the problem of Robust Policy Search, and draw connections from our proposed framework to existing work on Multi-Task Learning.", "keywords": ["Deep Reinforcement Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1398/Authors"], "authors": ["Anonymous"], "TL;DR": "An Active Learning framework that leads to efficient robust RL and opens up possibilities in Multi-Task RL", "pdf": "/pdf/5da20b0a1253f56b2728289c6fe9bc0c8b054ff4.pdf", "paperhash": "anonymous|an_active_learning_framework_for_efficient_robust_policy_search", "_bibtex": "@inproceedings{    \nanonymous2019an,    \ntitle={An Active Learning Framework for Efficient Robust Policy Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxhX209FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJepX2A9tX", "original": "r1l1Cup5KQ", "number": 1399, "cdate": 1538087972638, "ddate": null, "tcdate": 1538087972638, "tmdate": 1538155928221, "tddate": null, "forum": "BJepX2A9tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Rotation Equivariant Networks via Conic Convolution and the DFT", "abstract": "Performance of neural networks can be significantly improved by encoding known invariance for particular tasks. Many image classification tasks, such as those related to cellular imaging, exhibit invariance to rotation. In particular, to aid convolutional neural networks in learning rotation invariance, we consider a simple, efficient conic convolutional scheme that encodes rotational equivariance, along with a method for integrating the magnitude response of the 2D-discrete-Fourier transform (2D-DFT) to encode global rotational invariance. We call our new method the Conic Convolution and DFT Network (CFNet). We evaluated the efficacy of CFNet as compared to a standard CNN and group-equivariant CNN (G-CNN) for several different image classification tasks and demonstrated improved performance, including classification accuracy, computational efficiency, and its robustness to hyperparameter selection. Taken together, we believe CFNet represents a new scheme that has the potential to improve many imaging analysis applications.", "keywords": ["deep learning", "rotation equivariance", "bioimaging analysis"], "authorids": ["ICLR.cc/2019/Conference/Paper1399/Authors"], "authors": ["Anonymous"], "TL;DR": "We propose conic convolution and the 2D-DFT to encode rotation equivariance into an neural network.", "pdf": "/pdf/2323f8059dbe38b3443ce8e04f93334e31dbf086.pdf", "paperhash": "anonymous|rotation_equivariant_networks_via_conic_convolution_and_the_dft", "_bibtex": "@inproceedings{    \nanonymous2019rotation,    \ntitle={Rotation Equivariant Networks via Conic Convolution and the DFT},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJepX2A9tX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1g6XnCcKQ", "original": "HklclZ3qFX", "number": 1400, "cdate": 1538087972806, "ddate": null, "tcdate": 1538087972806, "tmdate": 1538155928012, "tddate": null, "forum": "B1g6XnCcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Object-Contrastive Networks: Unsupervised Object Representations", "abstract": "Discovering objects and their attributes is of great importance for autonomous agents to effectively operate in human environments. This task is particularly challenging due to the ubiquitousness of objects and all their nuances in perceptual and semantic detail. In this paper we present an unsupervised approach for learning disentangled representations of objects entirely from unlabeled monocular videos. These continuous representations are not biased by or limited by a discrete set of labels determined by human labelers. The proposed representation is trained with a metric learning loss, where objects with homogeneous features are pushed together, while those with heterogeneous features are pulled apart. We show these unsupervised embeddings allow to discover object attributes and can enable robots to self-supervise in previously unseen environments. We quantitatively evaluate performance on a large-scale synthetic dataset with 12k object models, as well as on a real dataset collected by a robot and show that our unsupervised object understanding generalizes to previously unseen objects. Specifically, we demonstrate the effectiveness of our approach on robotic manipulation tasks, such as pointing at and grasping of objects. An interesting and perhaps surprising finding in this approach is that given a limited set of objects, object correspondences will naturally emerge when using metric learning without requiring explicit positive pairs.", "keywords": ["self-supervised robotics", "object understanding", "object representations", "metric learning", "unsupervised vision"], "authorids": ["ICLR.cc/2019/Conference/Paper1400/Authors"], "authors": ["Anonymous"], "TL;DR": "An unsupervised approach for learning disentangled representations of objects entirely from unlabeled monocular videos.", "pdf": "/pdf/de707f8d8cde22b31f14616b7200cb0b62d80870.pdf", "paperhash": "anonymous|objectcontrastive_networks_unsupervised_object_representations", "_bibtex": "@inproceedings{    \nanonymous2019object-contrastive,    \ntitle={Object-Contrastive Networks: Unsupervised Object Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1g6XnCcKQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJz6QhR9YQ", "original": "BJe9Eipctm", "number": 1401, "cdate": 1538087972974, "ddate": null, "tcdate": 1538087972974, "tmdate": 1538155927799, "tddate": null, "forum": "HJz6QhR9YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games ", "abstract": "Deep Reinforcement Learning algorithms lead to agents that can solve difficult decision making problems in complex environments. However, many difficult multi-agent competitive games, especially real-time strategy games are still considered beyond the capability of current deep reinforcement learning algorithms, although there has been a recent effort to change this \\citep{openai_2017_dota, vinyals_2017_starcraft}. Moreover, when the opponents in a competitive game are suboptimal, the current \\textit{Nash Equilibrium} seeking, self-play algorithms are often unable to generalize their strategies to opponents that play strategies vastly different from their own. This suggests that a learning algorithm that is beyond conventional self-play is necessary. We develop Hierarchical Agent with Self-play (HASP), a learning approach for obtaining hierarchically structured policies that can achieve higher performance than conventional self-play on competitive games through the use of a diverse pool of sub-policies we get from Counter Self-Play (CSP). We demonstrate that the ensemble policy generated by HASP can achieve better performance while facing unseen opponents that use sub-optimal policies. On a motivating iterated Rock-Paper-Scissor game and a partially observable real-time strategic game (http://generals.io/), we are led to the conclusion that HASP can perform better than conventional self-play as well as achieve 77% win rate against FloBot, an open-source agent which has ranked at position number 2 on the online leaderboards.", "keywords": ["deep reinforcement learning", "self-play", "real-time strategic game", "multi-agent"], "authorids": ["ICLR.cc/2019/Conference/Paper1401/Authors"], "authors": ["Anonymous"], "TL;DR": "We develop Hierarchical Agent with Self-play (HASP), a learning approach for obtaining hierarchically structured policies that can achieve high performance than conventional self-play on competitive real-time strategic games.", "pdf": "/pdf/fe7c68a56facc76cf105f3d936721c20a65d4c6c.pdf", "paperhash": "anonymous|hierarchical_deep_reinforcement_learning_agent_with_counter_selfplay_on_competitive_games", "_bibtex": "@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJz6QhR9YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryza73R9tQ", "original": "rJl4eu4qtQ", "number": 1402, "cdate": 1538087973152, "ddate": null, "tcdate": 1538087973152, "tmdate": 1538155927579, "tddate": null, "forum": "ryza73R9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Machine Translation With Weakly Paired Bilingual Documents", "abstract": "Neural machine translation, which achieves near human-level performance in some languages, strongly relies on the availability of large amounts of parallel sentences, which hinders its applicability to low-resource language pairs. Recent works explore the possibility of unsupervised machine translation with monolingual data only, leading to much lower accuracy compared with the supervised one. Observing that weakly paired bilingual documents are much easier to collect than bilingual sentences, e.g., from Wikipedia, news websites or books, in this paper, we investigate the training of translation models with weakly paired bilingual documents. Our approach contains two components/steps. First, we provide a simple approach to mine implicitly bilingual sentence pairs from document pairs which can then be used as supervised signals for training. Second, we leverage the topic consistency of two weakly paired documents and learn the sentence-to-sentence translation by constraining the word distribution-level alignments.  We evaluate our proposed method on weakly paired documents from Wikipedia on four tasks, the widely used WMT16 German$\\leftrightarrow$English and WMT13 Spanish$\\leftrightarrow$English tasks, and obtain $24.1$/$30.3$ and $28.0$/$27.6$ BLEU points separately, outperforming\nstate-of-the-art unsupervised results by more than 5 BLEU points and reducing the gap between unsupervised translation and supervised translation up to 50\\%. ", "keywords": ["Natural Language Processing", "Machine Translation", "Unsupervised Learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1402/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/9789c159392408e931564db1fd90c5a0b949cc69.pdf", "paperhash": "anonymous|machine_translation_with_weakly_paired_bilingual_documents", "_bibtex": "@inproceedings{    \nanonymous2019machine,    \ntitle={Machine Translation With Weakly Paired Bilingual Documents},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryza73R9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJE6X305Fm", "original": "rklZ0zA9t7", "number": 1403, "cdate": 1538087973322, "ddate": null, "tcdate": 1538087973322, "tmdate": 1538155927371, "tddate": null, "forum": "HJE6X305Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Don't let your Discriminator  be fooled", "abstract": "Generative Adversarial Networks are one of the leading tools in generative modeling, image editing and content creation. \nHowever, they are hard to train as they require a delicate balancing act between two deep networks fighting a never ending duel. Some of the most promising adversarial models today minimize a Wasserstein objective. It is smoother and more stable to optimize. In this paper, we show that the Wasserstein distance is just one out of a large family of objective functions that yield these properties. By making the discriminator of a GAN robust to adversarial attacks we can turn any GAN objective into a smooth and stable loss. We experimentally show that any GAN objective, including Wasserstein GANs, benefit from adversarial robustness both quantitatively and qualitatively. The training additionally becomes more robust to suboptimal choices of hyperparameters, model architectures, or objective functions.", "keywords": ["GAN", "generative models", "computer vision"], "authorids": ["ICLR.cc/2019/Conference/Paper1403/Authors"], "authors": ["Anonymous"], "TL;DR": "A discriminator that is not easily fooled by adversarial example makes GAN training more robust and leads to a smoother objective.", "pdf": "/pdf/b6df3191a85b631afb160dbc752dd11f366df8ff.pdf", "paperhash": "anonymous|dont_let_your_discriminator_be_fooled", "_bibtex": "@inproceedings{    \nanonymous2019don't,    \ntitle={Don't let your Discriminator  be fooled},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJE6X305Fm},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HylTXn0qYX", "original": "ryexB5jqtQ", "number": 1404, "cdate": 1538087973493, "ddate": null, "tcdate": 1538087973493, "tmdate": 1538155927166, "tddate": null, "forum": "HylTXn0qYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Efficiently testing local optimality and escaping saddles for ReLU networks", "abstract": "We provide a theoretical algorithm for checking local optimality and escaping saddles at nondifferentiable points of empirical risks of two-layer ReLU networks. Our algorithm receives any parameter value and returns: local minimum, second-order stationary point, or a strict descent direction. The presence of M data points on the nondifferentiability of the ReLU divides the parameter space into at most 2^M regions, which makes analysis difficult. By exploiting polyhedral geometry, we reduce the total computation down to one convex quadratic program (QP) for each hidden node, O(M) (in)equality tests, and one (or a few) nonconvex QP. For the last QP, we show that our specific problem can be solved efficiently, in spite of nonconvexity. In the benign case, we solve one equality constrained QP, and we prove that projected gradient descent solves it exponentially fast. In the bad case, we have to solve a few more inequality constrained QPs, but we prove that the time complexity is exponential only in the number of inequality constraints. Our experiments show that either benign case or bad case with very few inequality constraints occurs, implying that our algorithm is efficient in most cases.", "keywords": ["local optimality", "second-order stationary point", "escaping saddle points", "nondifferentiability", "ReLU", "empirical risk"], "authorids": ["ICLR.cc/2019/Conference/Paper1404/Authors"], "authors": ["Anonymous"], "TL;DR": "A theoretical algorithm for testing local optimality and extracting descent directions at nondifferentiable points of empirical risks of one-hidden-layer ReLU networks.", "pdf": "/pdf/0b7968bb259c6d5e5869b3f6ee87e1073d564510.pdf", "paperhash": "anonymous|efficiently_testing_local_optimality_and_escaping_saddles_for_relu_networks", "_bibtex": "@inproceedings{    \nanonymous2019efficiently,    \ntitle={Efficiently testing local optimality and escaping saddles for ReLU networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylTXn0qYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "B1e0X3C9tQ", "original": "BJevFIj9tX", "number": 1405, "cdate": 1538087973665, "ddate": null, "tcdate": 1538087973665, "tmdate": 1538155926951, "tddate": null, "forum": "B1e0X3C9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Diagnosing and Enhancing VAE Models", "abstract": "Although variational autoencoders (VAEs) represent a widely influential deep generative model, many aspects of the underlying energy function remain poorly understood.  In particular, it is commonly believed that Gaussian encoder/decoder assumptions reduce the effectiveness of VAEs in generating realistic samples.  In this regard, we rigorously analyze the VAE objective, differentiating situations where this belief is and is not actually true.  We then leverage the corresponding insights to develop a simple VAE enhancement that requires no additional hyperparameters or sensitive tuning.  Quantitatively, this proposal produces crisp samples and stable FID scores that are actually competitive with state-of-the-art GAN models, all while retaining desirable attributes of the original VAE architecture.", "keywords": ["variational autoencoder", "generative models"], "authorids": ["ICLR.cc/2019/Conference/Paper1405/Authors"], "authors": ["Anonymous"], "TL;DR": "We closely analyze the VAE objective function and draw novel conclusions that lead to simple enhancements.", "pdf": "/pdf/6dbb34132fd2f583559db43956a6be87ceb3905f.pdf", "paperhash": "anonymous|diagnosing_and_enhancing_vae_models", "_bibtex": "@inproceedings{    \nanonymous2019diagnosing,    \ntitle={Diagnosing and Enhancing VAE Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e0X3C9tQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HJeRm3Aqt7", "original": "rklVKWA5FQ", "number": 1406, "cdate": 1538087973834, "ddate": null, "tcdate": 1538087973834, "tmdate": 1538155926736, "tddate": null, "forum": "HJeRm3Aqt7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "GenEval: A Benchmark Suite for Evaluating Generative Models", "abstract": "Generative models are important for several practical applications, from low level image processing tasks, to model-based planning in robotics. More generally,\nthe study of generative models is motivated by the long-standing endeavor to model uncertainty and to discover structure by leveraging unlabeled data.\nUnfortunately, the lack of an ultimate task of interest has hindered progress in the field, as there is no established way to\ncompare models and, often times, evaluation is based on mere visual inspection of samples drawn from such models.\n\nIn this work, we aim at addressing this problem by introducing a new benchmark evaluation suite, dubbed \\textit{GenEval}.\nGenEval hosts a large array of distributions capturing many important\nproperties of real datasets, yet in a controlled setting, such as lower intrinsic dimensionality, multi-modality, compositionality,\nindependence and causal structure. Any model can be easily plugged for evaluation, provided it can generate samples.\n\nOur extensive evaluation suggests that different models have different strenghts, and that GenEval is a great tool to gain insights about how models and metrics work.\nWe offer GenEval to the community~\\footnote{Available at: \\it{coming soon}.} and believe that this benchmark will facilitate comparison and development of\nnew generative models.", "keywords": ["generative models", "GAN", "VAE", "Real NVP"], "authorids": ["ICLR.cc/2019/Conference/Paper1406/Authors"], "authors": ["Anonymous"], "TL;DR": "We introduce battery of synthetic distributions and metrics for measuring the success of generative models  ", "pdf": "/pdf/61d5b0233e6a2eb97d766483d516f278a7201e54.pdf", "paperhash": "anonymous|geneval_a_benchmark_suite_for_evaluating_generative_models", "_bibtex": "@inproceedings{    \nanonymous2019geneval:,    \ntitle={GenEval: A Benchmark Suite for Evaluating Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeRm3Aqt7},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "ryM07h0cYX", "original": "rkl2qtPFY7", "number": 1407, "cdate": 1538087973999, "ddate": null, "tcdate": 1538087973999, "tmdate": 1538155926520, "tddate": null, "forum": "ryM07h0cYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Reinforced Pipeline Optimization: Behaving Optimally with Non-Differentiabilities", "abstract": "Many machine learning systems are implemented as pipelines. A pipeline is essentially a chain/network of information processing units. As information flows in and out and gradients vice versa, ideally, a pipeline can be trained end-to-end via backpropagation provided with the right supervision and loss function. However, this is usually impossible in practice, because either the loss function itself may be non-differentiable, or there may exist some non-differentiable units. One popular way to superficially resolve this issue is to separate a pipeline into a set of differentiable sub-pipelines and train them with isolated loss functions. Yet, from a decision-theoretical point of view, this is equivalent to making myopic decisions using ad hoc heuristics along the pipeline while ignoring the real utility, which prevents the pipeline from behaving optimally. In this paper, we show that by converting a pipeline into a stochastic counterpart, it can then be trained end-to-end in the presence of non-differentiable parts. Thus, the resulting pipeline is optimal under certain conditions with respect to any criterion attached to it. In experiments, we apply the proposed approach - reinforced pipeline optimization - to Faster R-CNN, a state-of-the-art object detection pipeline, and obtain empirically near-optimal object detectors consistent with its base design in terms of mean average precision.", "keywords": ["Pipeline Optimization", "Reinforcement Learning", "Stochastic Computation Graph", "Faster R-CNN"], "authorids": ["ICLR.cc/2019/Conference/Paper1407/Authors"], "authors": ["Anonymous"], "TL;DR": "By converting an originally non-differentiable pipeline into a stochastic counterpart, we can then train the converted pipeline completely end-to-end while optimizing any criterion attached to it.", "pdf": "/pdf/c2e107946e5bf2053891096c2be8c71a19d822ee.pdf", "paperhash": "anonymous|reinforced_pipeline_optimization_behaving_optimally_with_nondifferentiabilities", "_bibtex": "@inproceedings{    \nanonymous2019reinforced,    \ntitle={Reinforced Pipeline Optimization: Behaving Optimally with Non-Differentiabilities},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryM07h0cYX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "HkzRQhR9YX", "original": "Skx58XActm", "number": 1408, "cdate": 1538087974177, "ddate": null, "tcdate": 1538087974177, "tmdate": 1538155926312, "tddate": null, "forum": "HkzRQhR9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Tree-Structured Recurrent Switching Linear Dynamical Systems for Multi-Scale Modeling", "abstract": "Many real-world systems studied are governed by complex, nonlinear\n  dynamics.  By modeling these dynamics, we can gain insight into how\n  these systems work, make predictions about how they will behave, and\n  develop strategies for controlling them. While there are many\n  methods for modeling nonlinear dynamical systems, existing\n  techniques face a trade off between offering interpretable\n  descriptions and making accurate predictions.  Here, we develop a\n  class of models that aims to achieve both simultaneously, smoothly\n  interpolating between simple descriptions and more complex, yet also\n  more accurate models.  Our probabilistic model achieves this\n  multi-scale property through of a hierarchy of locally\n  linear dynamics that jointly approximate global nonlinear dynamics.\n  We call it the tree-structured recurrent switching linear dynamical system.\n  To fit this model, we present a fully-Bayesian sampling procedure using\n  P\\'{o}lya-Gamma data augmentation to allow for fast and\n  conjugate Gibbs sampling.  Through a variety of synthetic and real examples,\n  we show how these models outperform existing methods in both interpretability\n  and predictive capability.", "keywords": ["machine learning", "bayesian statistics", "dynamical systems"], "authorids": ["ICLR.cc/2019/Conference/Paper1408/Authors"], "authors": ["Anonymous"], "pdf": "/pdf/d01f10944207fadd987b682a3ac2d1355c276689.pdf", "paperhash": "anonymous|treestructured_recurrent_switching_linear_dynamical_systems_for_multiscale_modeling", "_bibtex": "@inproceedings{    \nanonymous2019tree-structured,    \ntitle={Tree-Structured Recurrent Switching Linear Dynamical Systems for Multi-Scale Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzRQhR9YX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "r1V0m3C5YQ", "original": "HygiBnh5Km", "number": 1409, "cdate": 1538087974359, "ddate": null, "tcdate": 1538087974359, "tmdate": 1538155926084, "tddate": null, "forum": "r1V0m3C5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Coupled Recurrent Models for Polyphonic Music Composition", "abstract": "This work describes a novel recurrent model for music composition, which accounts for the rich statistical structure of polyphonic music. There are many ways to factor the probability distribution over musical scores; we consider the merits of various approaches and propose a new factorization that decomposes a score into a collection of concurrent, coupled time series: \"parts.\" The model we propose borrows ideas from both convolutional neural models and recurrent neural models; we argue that these ideas are natural for capturing music's pitch invariances, temporal structure, and polyphony.\n\nWe train generative models for homophonic and polyphonic composition on the KernScores dataset (Sapp, 2005), a collection of 2,300 musical scores comprised of around 2.8 million notes spanning time from the Renaissance to the early 20th century. While evaluation of generative models is know to be hard (Theis et al., 2016), we present careful quantitative results using a unit-adjusted cross entropy metric that is independent of how we factor the distribution over scores. We also present qualitative results using a blind discrimination test.\n", "keywords": ["music composition", "music generation", "polyphonic music modeling"], "authorids": ["ICLR.cc/2019/Conference/Paper1409/Authors"], "authors": ["Anonymous"], "TL;DR": "New recurrent generative models for composition of rhythmically complex, polyphonic music.", "pdf": "/pdf/54f3bc17d5303dd1080688e76e1fa2b584a48bad.pdf", "paperhash": "anonymous|coupled_recurrent_models_for_polyphonic_music_composition", "_bibtex": "@inproceedings{    \nanonymous2019coupled,    \ntitle={Coupled Recurrent Models for Polyphonic Music Composition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1V0m3C5YQ},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "BJe1E2R5KX", "original": "SJxgvWb9KQ", "number": 1410, "cdate": 1538087974523, "ddate": null, "tcdate": 1538087974523, "tmdate": 1538155925852, "tddate": null, "forum": "BJe1E2R5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees", "abstract": "Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL. However, the theoretical understanding of such methods has been rather limited. This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees. We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward. The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model. The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires no explicit uncertainty quantification. Instantiating our framework with simplification gives a  variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO). Experiments demonstrate that SLBO achieves the state-of-the-art performance when only 1M or fewer samples are permitted on a range of continuous control benchmark tasks.", "keywords": ["model-based reinforcement learning", "sample efficiency", "deep reinforcement learning"], "authorids": ["ICLR.cc/2019/Conference/Paper1410/Authors"], "authors": ["Anonymous"], "TL;DR": "We design model-based reinforcement learning algorithms with theoretical guarantees and achieve state-of-the-art results on Mujuco benchmark tasks when one million or fewer samples are permitted.", "pdf": "/pdf/57fce953857713037cb49b9ddcc2ae83ff3eba36.pdf", "paperhash": "anonymous|algorithmic_framework_for_modelbased_deep_reinforcement_learning_with_theoretical_guarantees", "_bibtex": "@inproceedings{    \nanonymous2019algorithmic,    \ntitle={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe1E2R5KX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}, {"id": "Hyg_X2C5FX", "original": "rkgTbxR9Ym", "number": 1371, "cdate": 1538087967675, "ddate": null, "tcdate": 1538087967675, "tmdate": 1538155925635, "tddate": null, "forum": "Hyg_X2C5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Visualizing and Understanding Generative Adversarial Networks", "abstract": "Generative Adversarial Networks (GANs) have recently achieved impressive results for many real-world applications.  As an active research topic, many GAN variants have emerged with immprovements in sample quality and training stability. However, visualization and understanding of GANs is largely missing. How does a GAN represent our visual world internally?  What causes the artifacts in GAN results?  How do architectural choices affect GAN learning?  Answering such questions could enable us to develop new insights and better models.\n\nIn this work, we present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. We first identify a group of interpretable units that are closely related to \\concepts with a segmentation-based network dissection method. Then, we quantify the causal effect of interpretable units by measuring the ability of interventions to control objects in the output. Finally, we examine the contextual relationship between these units and their surrounding by inserting the discovered \\concepts into new images. We show several practical applications enabled by our framework, from comparing internal representations across different layers, models, and datasets, to improving GANs by locating and  removing ``artifacts'' units, to interactively manipulating objects in the scene.  We will open source our interactive online tools to help  researchers and practitioners better understand their models.", "paperhash": "anonymous|visualizing_and_understanding_generative_adversarial_networks", "TL;DR": "GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.", "authorids": ["ICLR.cc/2019/Conference/Paper1371/Authors"], "authors": ["Anonymous"], "keywords": ["GANs", "representation", "interpretability", "causality"], "pdf": "/pdf/698fe867781c14123dddb0bc455a38cbcd6b67ac.pdf", "_bibtex": "@inproceedings{    \nanonymous2019visualizing,    \ntitle={Visualizing and Understanding Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyg_X2C5FX},    \nnote={under review}    \n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"tags": []}}]}
